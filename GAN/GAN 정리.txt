1.gan시작하기
	gan은 생성적모델과 판별모델로 이루어진 모델
	gan의 이론적으로 도달점은 내시균형에 도달하는것
	
	생성자는 입력으로 랜덤숫자벡터(가우시안잡음같은)를 받아서,
	출력으로 최대한 진짜같은 가짜샘플을 만들고,
	목표는 훈련데이터셋의 샘플과 구분이 불가능한 샘플을 생성하는것
	
	판별자는 훈련데이터셋과 생성자가 만든가짜샘플을 받아서,
	출력으로 입력샘플이 진짜일 확률을 뱉고
	목표는 생성자가 만든 가짜샘플과 훈련데이터셋의 진짜샘플을 구별하는것
	1.gan훈련
		훈련시엔 먼저 
		판별자를 훈련하고
			훈련데이터셋에서 랜덤하게 샘플을 선택하고
			새로운 잡음벡터를 얻어서 생성자로 가짜샘플을 생성한후에
			판별자로 둘을 분류하고
			분류오차를 계산하고 전체오차를 판별자에만 역전파해서 업데이트하고 판별자의 분류오차를 최소화함
		생성자를 훈련함
			생성자로 랜덤하게 잡음벡터에서 가짜샘플을 생성
			판별자로 분류
			분류오차를 계산하고(전부 가짜니까 많이속인만큼) 생성자에만 역전파해서 판별자의 오차를 제일 크게할수있게 만듬
		
	2.균형에 도달하기
		훈련반복은 이론상 내시균형에 도달할때 중지임
		내시균형은
			생성자가 훈련데이터와 구별이 안가는데이터를 생성해서
			판별자가 찍기할수밖에 없을때
		근데 실제 실무에선 내시균형에 도달하기가 불가능함(실제로 수렴을 하더라도 지역최소값일 확률이 높고,gan은 복잡성이 매우크기때문)
		그래도 대충수렴한값(지역최소값)써도 괜찮은결과물이 나옴
		그러니까 아직은 저정도로 만족해도댐
	
	
	3.gan사용처
		gan으로 이미지변경(남자를 여자로,말을 얼룩말로)하고싶으면 cyclegan쓰면됨 
		
		
		
			
2.오토인코더와 생성학습		
1.생성모델링
	오토인코더가 동작할땐 입력값과 출력값이 같은거처럼 보이지만 완전히 같지 않은 결과값을 얻지 않도록하는 잠재층이 있음
2.오토인코더의 동작방식
	오토인코더는 인코더와 디코더 두 부분으로 나눠져있음
	인코더로 데이터를 압축하고,압축된 데이터를 디코더가 해석하는식으로 데이터의 양을 줄임
	여기서 나는 손실을 재구성 손실이라고 부름
	
	반복되는 개념은 사전에 동의한 추상적인 표현으로 단순화하는게 양이 더적으니까 그런식으로 압축해서,효율적인 패턴을 찾아 정보를 압축함
	결과적으로 더 적은 차원만 전송하면되니 대역폭이 줄어듬
	
	이론적으로,이해하는데 너무 손해보지않으면서(재구성손실이 그렇게 크지않으면서)양을 최대한 줄인 정보 병목지점을 통해 최대한 많은 정보를 전달하는게 목표임
	
3.오토인코더와 gan의 비교
	오토인코더와 gan의 차이는,오토인코더는 하나의 손실함수로 모델 전체를 훈련한다는것이고,gan은 생성자와 판별자에 각각 다른 손실함수를 사용한다는것
	오토인코더는 명시적인 최적화함수(원본과의 차이)가 있지만,gan은 명시적 지표가 없음(둘이싸우는거기때문에)
	
4.오토인코더의 구성
	오토인코더는 
		입력-인코더-크기가 줄어든 잠재공간(압축된데이터)-디코더-출력
	으로 구성됨
	일반적으로 디코더는 인코더를 거꾸로 뒤집은 네트워크로 구성함
	
	오토인코더의 훈련은
		이미지x를 오토인코더에 입력
		재구성된 이미지x`를 얻음
		x와 x`의 재구성손실을 측정
	으로 이루어짐
	이렇게해서 재구성손실을 최소화하는 파라미터로 경사하강법을써서 업데이트해서 찾음
	
5.오토인코더 활용
	오토인코더는 간단하지만 얻을수있는게 많음
	먼저, 공짜로(데이터라벨링없이)압축된 표현을 얻음
	압축된 표현으로 데이터와 타깃클래스의 유사도를 빠르게 확인할수있는 이상치탐지가 있고,검색에도 적용할수있음
	
	또 다른 예로는 노이즈제거와 흑백이미지 채색을 할수있음
	
	그리고 일부 gan들은 오토인코더를 구조의 일부로 활용해 훈련을 안정화함
	
	그리고 제일 큰 장점은,레이블된 데이터가 필요없다는것임
	자기훈련이라서(자기자신이 레이블)
	
	그리고 오토인코더를 사용해 새로운 이미지를 생성할수 있음 (디코더에 잡음넣어서 이미지를 생성함)
			
6.비지도학습
	비지도학습은 레이블이 안된 데이터를 사용해 학습하는 방식
	예를들어 군집같은게있음
	
	비지도학습은 특정목적으로 레이블링할 필요 없이 어떤 데이터든 사용할수있음
	반면 지도학습은 레이블이 없으면,훈련이 불가능함
	
	오토인코더는 네트워크 2개로 이루어져있음,인코더와 디코더
	두 네트워크 모두 활성화함수와 중간층을 가짐,이는 네트워크마다 2개의 가중치행렬이 있다는 뜻
	
	인코더에선 하나는 입력과 중간층 사이에있고 하나는 중간층과 잠재표현층 사이에 있음
	디코더에선 하나는 잠재표현층과 중간층 사이에,하나는 중간층과 출력층 사이에 있음 
	
	만약 가중치 행렬이 하나면,이건 주성분분석과(pca,제일 길게나오는 차원을 파악해서 그방향으로 프레스로찍는거)
	
	1.오토인코더로 데이터생성
		오토인코더로 데이터생성을 할떈,인코더 부분을 떼어내고,
		잠재공간과 디코더만 써서 잠재공간에 잡음을 넣어서 샘플을 쉽게 뽑을수있음(클래스는 반복이나 그리드탐색으로 찾으면됨)
		
	2.변이형 오토인코더
		변이형 오토인코더는 잠재공간을 단순한 수의 집합이 아닌 학습된 평균과 표준편차를 지닌 분포로 표현함
		변이형 오토인코더는 베이즈이론에 기반한 머신러닝기법임,즉 분포를 학습해야 한다는 뜻
		그래서 제약이 추가됨
		
		다른말로 빈도기반 오토인코더는 잠재공간을 수의 배열로 학습하지만,변이형 오토인코더는 분포를 정의하는데 맞는 파라미터를 찾음
		
		그 다음 잠재분포에서 샘플링해서 숫자를 얻고(즉 랜덤하게찍어서) 그 숫자를 디코더에 주입함 
			
			
7.코드
	기본적으로 입력-인코더-크기가 줄어든 잠재공간(압축된데이터)-디코더-출력임
	인코더는
		input 784
		dense( 256)
		dense(2)평균 dense(2)로그분산  -출력
		lambda(샘플링함수)(평균,로그분산)
		
		model(인풋,[평균,로그분산,람다])
	이런식으로 평균 로그분산 람다를 전부 내보내면 변이형 오토인코더임
	출력은 숫자 하나가 나옴
	
	평균과 로그분산은 다음 람다식으로도 보내고,출력에도 연결되어있음
	저기서 평균과 로그분산은,람다식에서 그걸 사용하는식으로 오차를 만들어서,평균과 로그분산으로 학습시킴(제약)
	
	샘플링함수는 keras.backend.random_normal()에 평균과 표준편차를 넣고
	return 평균+exp(로그분산/2)*keras.backend.random_normal(mean=0.,stddev=1.0)
	넣어서 샘플링함
	즉 샘플링함수가 제약으로 작동함
	
	
	디코더는
		input 2 
		dense(256) 잠재공간을 중간층의 차원으로 변환
		dense (784 acti sigmoid) 원본차원변환과 출력
		
		model(인풋,784dense)
	로 만든뒤
	둘을 합쳐서 모델을 만들면되는데,람다식을 출력값으로 연결하면됨
	그리고 손실를 정의하고 옵티마이저를 설정하고(adam 무지성으로때려박자) 훈련하면됨
	
	즉 변이형 오토인코더는 샘플링을 하고,결과가 잡음처럼 보이기떄문에,잡음을 박아서 생성모델로 쓰기좋음
	
			
8.근데 왜 GAN?
	오토인코더가 생성이 되긴하지만,평균에 가까운 값을 뽑기때문에,
	쌍봉분포처럼 산이 두개이상이면 값을 이상한데를뽑아서 품질이 좋지 않게 나옴(한계가 있음)
	
			
		




		
3.첫번째 gan 구현
1.gan기초
	gan은 생성자와 판별자로 구성되는데,둘은 각기 다른 비용함수를 가짐
	둘다 판별자의 손실을 사용해 역전파로 자기의 네트워크를 훈련하는데
	판별자는 진짜와 가짜샘플에 대한 손실을 최소화하고
	생성자는 자신이 생성한 가짜샘플에 대해 판별자의 손실이 최대화 되도록함(가짜샘플을 전부 레이블1(정답)로 주고 가장 높히기위해 노력함)
	
	순서는 먼저 판별자부터 훈련을 한 다음,생성자를 훈련함
	각각 순서마다 판별자만 훈련하고,생성자는 잠그고
	생성자만 훈련하고 판별자는 잠그는식으로 외부파라미터는 잠금
	
	생성자는 처음엔 무작위잡음이었다가,점점 훈련 데이터셋의 데이터분포를 흉내내는샘플을 생성하게됨
	결국 이미지든 뭐든 컴퓨터입장에선 채널이 여러개인 행렬일뿐이니까(다차원행렬) 거기서 패턴을 찾아낼수 있음
	거꾸로말해서 패턴이 없는 이미지는 그냥 잡음일뿐임
	
	생성자모델은 객체인식모델(어떤객체가 있는지,또 어디에있는지)의 역과정이라고 생각할수도 있음
	패턴을 인식하는게 아니라 패턴을 합성하는걸 학습함
	
	1.비용함수
		gan의 비용함수는 두 네트워크 모두 두 네트워크의 파라미터에 모두 의존함
		생성자도 판별자의 판별결과와 자신의 생성에 모두 의존하고
		판별자도 생성자가 생성한 결과와 자신의 판별결과에 모두 의존함
		
		그래서 변수를 줄여야하니 상대방의 파라미터의 튜닝을 막는것
		
		그래서 gan이 자주 모드붕괴같은게 일어나는것(불안정함)
		
	2.훈련과정
		기본적인 신경망들은 최적화문제임(공간내에서 비용이 감소되는 곳으로 움직이는식) 그래서 지역최소점이나 전영최소점에 도달하기가 나름 쉬움
		근데 gan은 전체모델의 절반만(자기자신만) 튜닝할수 있기 때문에 게임이론에 더 가까움
		그리고 gan의 목표점인 내시균형은,모든 선택지의 기댓값이 동일해서 찍을수밖에 없을때 일어나는데,이런건 불가능함(매우어려움)
		그래서 그냥 적당히 수렴시켜서 결과물 뽑아보고 괜찮으면 쓰는거
	
2.생성자와 판별자
	생성자는 랜덤한 잡음벡터를 받고 가짜샘플을 생성하고,판별자는 실제샘플과 가짜샘플을받아서 진짜인지아닌지 리턴함
	생성자는 다른건 관심없고 자기가 만든게 진짜라고 인식되기만 하면(거짓양성만 커지면)되는거고
	판별자는 진짜양성과 진짜음성을 최대화하려고 노력함
			
3.gan 훈련알고리즘
	gan의 훈련은 미니배치단위로 함
	1.판별자훈련
		랜덤한 진짜 미니배치를 받고
		랜덤 잡음벡터의 미니배치를 받아서 그걸로 가짜 미니배치를 생성함
		둘다 각각 분류손실을 계산하고,전체오차를 역전파해서 분류손실을 최소화하게 판별자만 업데이트함(트레인을 2번함 진짜한번 가짜한번)
	2.생성자훈련
		랜덤 잡음벡터의 미니배치를 받아서 그걸로 가짜 미니배치를 생성함
		가짜 미니배치의 레이블을 전부 1로한뒤에(진짜로 레이블을잡은뒤에) 오차를 역전파해서 판별자의 오차가 커지도록 생성자만 업데이트함
	이렇게 각자 자기꺼만 건드리는이유는 자기가 제어할수있는 파라미터만 바꾸기위해서
	
	
4.mnist생성gan(튜토리얼)
	1.생성자구현
		간단히만들꺼니까 생성자는 하나의 은닉층을 가짐
		잡음을 받아서 28x28x1의 이미지를 생성
		은닉층은 leakyRelu(기울기가 0이안되는 relu)를 사용하고 
		출력층엔 tanh를 써서 출력범위를 -1~1로 조정함
		시그모이드보다 tanh가 좀 더 또렷한 이미지가 나오는 경향이 있음
		
		모델생성코드
			model=sequential
				dense(128,input_dim=인풋크기)
				LeakyReLU(alpha=0.01) 위에 넣어도됨 dense층에
				dense(28*28*1,acti='tanh')
				Reshape(이미지차원크기)
				
		
	2.판별자 구현
		판별자는 28x28x1의 이미지를 받아 진짜인지를 나타내는 확률을 출력함,일반적인 분류모델이라고 봐도됨
		
		모델생성코드
			model=sequential
				Flatten(input_shape=이미지차원크기) 이미지를 일렬로 펼침
				dense(128)
				LeakyReLU(alpha=0.01)
				dense(1,acti='sigmoid')
		꼭 생성자랑 비슷하게 만들필요없는데 제일 간단한 모델구조라서 겹치는거임
		생성모델과 분류모델역할만 하면됨
		
	3.모델생성(로스등등)
		먼저 이미지니까 로스는 바이너리 크로스엔트로피쓰면되고,옵티마이저는 무지성아담 쓰면됨
		생성자와 판별자를 생성하고
		판별자는 컴파일함
		새 모델을 만들어서 생성자와 판별자를 연결시키고(이 모델로 생성자를 훈련함) 이모델은 판별자의 훈련가능성을 false시켜둠
		그리고 똑같이 로스옵티마이저 설정함
		
	4.훈련
		훈련시 순서
			먼저 이미지전처리를 하고
			배치크기만큼 미리 레이블을 만들어둔뒤에(real fake 둘다)
			진짜배치에서 랜덤이미지를 배치크기만큼 가져오고
			잡음벡터에서 배치를 뽑은다음에 가짜배치를 생성하고 (predict)      //데이터전처리끝
			
			진짜이미지로 판별자를 훈련(train_on_batch)
			가짜이미지로 판별자를 훈련(train_on_batch)
			그뒤 그래프그리거나 뭐 다른용도로 쓰기위해 진짜와 가짜이미지의 손실을 합쳐서 반나눠서 저장   //판별자훈련끝
			
			잡음백터에서 배치만큼 뽑은뒤에
			잡음벡터에 진짜레이블로 판별자를 훈련(판별자는 잠겨있으니까 생성자만 훈련됨)
			
			그리고 필요하면 손실과 정확도 저장하고
			샘플 이미지 출력하고싶으면 출력
		
		샘플이미지출력시엔84페이지 코드 따라쓰자 인터넷에도 똑같은거널린듯
		
		
		
	5.모델실행
		모델을 실행할때 반복횟수와 배치크기를 선택하고 모델을 훈련해야댐
		여기서 반복횟수와 배치크기를 결정할수있는 수식같은게 없어서 과정을 보면서 시행착오를 해야함
		
		그렇치만 배치는 메모리에 들어갈수있을만큼 작아야하고,반복을 많이하면 오래걸리니까 대충 알아서 맞춰보자
		손실 모니터링하면서 손실이 평탄해지는 부근에서 반복을 멈추면됨(이거도 과대적합나니까 조기종료하는식으로 하면됨)
	
	
	
	
	
4.dcgan(합성곱gan)	
	
	
	
	
	
	
	
			
			
			
			
			
			