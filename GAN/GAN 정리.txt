1.gan시작하기
	gan은 생성적모델과 판별모델로 이루어진 모델
	gan의 이론적으로 도달점은 내시균형에 도달하는것
	
	생성자는 입력으로 랜덤숫자벡터(가우시안잡음같은)를 받아서,
	출력으로 최대한 진짜같은 가짜샘플을 만들고,
	목표는 훈련데이터셋의 샘플과 구분이 불가능한 샘플을 생성하는것
	
	판별자는 훈련데이터셋과 생성자가 만든가짜샘플을 받아서,
	출력으로 입력샘플이 진짜일 확률을 뱉고
	목표는 생성자가 만든 가짜샘플과 훈련데이터셋의 진짜샘플을 구별하는것
	1.gan훈련
		훈련시엔 먼저 
		판별자를 훈련하고
			훈련데이터셋에서 랜덤하게 샘플을 선택하고
			새로운 잡음벡터를 얻어서 생성자로 가짜샘플을 생성한후에
			판별자로 둘을 분류하고
			분류오차를 계산하고 전체오차를 판별자에만 역전파해서 업데이트하고 판별자의 분류오차를 최소화함
		생성자를 훈련함
			생성자로 랜덤하게 잡음벡터에서 가짜샘플을 생성
			판별자로 분류
			분류오차를 계산하고(전부 가짜니까 많이속인만큼) 생성자에만 역전파해서 판별자의 오차를 제일 크게할수있게 만듬
		
	2.균형에 도달하기
		훈련반복은 이론상 내시균형에 도달할때 중지임
		내시균형은
			생성자가 훈련데이터와 구별이 안가는데이터를 생성해서
			판별자가 찍기할수밖에 없을때
		근데 실제 실무에선 내시균형에 도달하기가 불가능함(실제로 수렴을 하더라도 지역최소값일 확률이 높고,gan은 복잡성이 매우크기때문)
		그래도 대충수렴한값(지역최소값)써도 괜찮은결과물이 나옴
		그러니까 아직은 저정도로 만족해도댐
	
	
	3.gan사용처
		gan으로 이미지변경(남자를 여자로,말을 얼룩말로)하고싶으면 cyclegan쓰면됨 
		
		
		
			
2.오토인코더와 생성학습		
1.생성모델링
	오토인코더가 동작할땐 입력값과 출력값이 같은거처럼 보이지만 완전히 같지 않은 결과값을 얻지 않도록하는 잠재층이 있음
2.오토인코더의 동작방식
	오토인코더는 인코더와 디코더 두 부분으로 나눠져있음
	인코더로 데이터를 압축하고,압축된 데이터를 디코더가 해석하는식으로 데이터의 양을 줄임
	여기서 나는 손실을 재구성 손실이라고 부름
	
	반복되는 개념은 사전에 동의한 추상적인 표현으로 단순화하는게 양이 더적으니까 그런식으로 압축해서,효율적인 패턴을 찾아 정보를 압축함
	결과적으로 더 적은 차원만 전송하면되니 대역폭이 줄어듬
	
	이론적으로,이해하는데 너무 손해보지않으면서(재구성손실이 그렇게 크지않으면서)양을 최대한 줄인 정보 병목지점을 통해 최대한 많은 정보를 전달하는게 목표임
	
3.오토인코더와 gan의 비교
	오토인코더와 gan의 차이는,오토인코더는 하나의 손실함수로 모델 전체를 훈련한다는것이고,gan은 생성자와 판별자에 각각 다른 손실함수를 사용한다는것
	오토인코더는 명시적인 최적화함수(원본과의 차이)가 있지만,gan은 명시적 지표가 없음(둘이싸우는거기때문에)
	
4.오토인코더의 구성
	오토인코더는 
		입력-인코더-크기가 줄어든 잠재공간(압축된데이터)-디코더-출력
	으로 구성됨
	일반적으로 디코더는 인코더를 거꾸로 뒤집은 네트워크로 구성함
	
	오토인코더의 훈련은
		이미지x를 오토인코더에 입력
		재구성된 이미지x`를 얻음
		x와 x`의 재구성손실을 측정
	으로 이루어짐
	이렇게해서 재구성손실을 최소화하는 파라미터로 경사하강법을써서 업데이트해서 찾음
	
5.오토인코더 활용
	오토인코더는 간단하지만 얻을수있는게 많음
	먼저, 공짜로(데이터라벨링없이)압축된 표현을 얻음
	압축된 표현으로 데이터와 타깃클래스의 유사도를 빠르게 확인할수있는 이상치탐지가 있고,검색에도 적용할수있음
	
	또 다른 예로는 노이즈제거와 흑백이미지 채색을 할수있음
	
	그리고 일부 gan들은 오토인코더를 구조의 일부로 활용해 훈련을 안정화함
	
	그리고 제일 큰 장점은,레이블된 데이터가 필요없다는것임
	자기훈련이라서(자기자신이 레이블)
	
	그리고 오토인코더를 사용해 새로운 이미지를 생성할수 있음 (디코더에 잡음넣어서 이미지를 생성함)
			
6.비지도학습
	비지도학습은 레이블이 안된 데이터를 사용해 학습하는 방식
	예를들어 군집같은게있음
	
	비지도학습은 특정목적으로 레이블링할 필요 없이 어떤 데이터든 사용할수있음
	반면 지도학습은 레이블이 없으면,훈련이 불가능함
	
	오토인코더는 네트워크 2개로 이루어져있음,인코더와 디코더
	두 네트워크 모두 활성화함수와 중간층을 가짐,이는 네트워크마다 2개의 가중치행렬이 있다는 뜻
	
	인코더에선 하나는 입력과 중간층 사이에있고 하나는 중간층과 잠재표현층 사이에 있음
	디코더에선 하나는 잠재표현층과 중간층 사이에,하나는 중간층과 출력층 사이에 있음 
	
	만약 가중치 행렬이 하나면,이건 주성분분석과(pca,제일 길게나오는 차원을 파악해서 그방향으로 프레스로찍는거)
	
	1.오토인코더로 데이터생성
		오토인코더로 데이터생성을 할떈,인코더 부분을 떼어내고,
		잠재공간과 디코더만 써서 잠재공간에 잡음을 넣어서 샘플을 쉽게 뽑을수있음(클래스는 반복이나 그리드탐색으로 찾으면됨)
		
	2.변이형 오토인코더
		변이형 오토인코더는 잠재공간을 단순한 수의 집합이 아닌 학습된 평균과 표준편차를 지닌 분포로 표현함
		변이형 오토인코더는 베이즈이론에 기반한 머신러닝기법임,즉 분포를 학습해야 한다는 뜻
		그래서 제약이 추가됨
		
		다른말로 빈도기반 오토인코더는 잠재공간을 수의 배열로 학습하지만,변이형 오토인코더는 분포를 정의하는데 맞는 파라미터를 찾음
		
		그 다음 잠재분포에서 샘플링해서 숫자를 얻고(즉 랜덤하게찍어서) 그 숫자를 디코더에 주입함 
			
			
7.코드
	기본적으로 입력-인코더-크기가 줄어든 잠재공간(압축된데이터)-디코더-출력임
	인코더는
		input 784
		dense( 256)
		dense(2)평균 dense(2)로그분산  -출력
		lambda(샘플링함수)(평균,로그분산)
		
		model(인풋,[평균,로그분산,람다])
	이런식으로 평균 로그분산 람다를 전부 내보내면 변이형 오토인코더임
	출력은 숫자 하나가 나옴
	
	평균과 로그분산은 다음 람다식으로도 보내고,출력에도 연결되어있음
	저기서 평균과 로그분산은,람다식에서 그걸 사용하는식으로 오차를 만들어서,평균과 로그분산으로 학습시킴(제약)
	
	샘플링함수는 keras.backend.random_normal()에 평균과 표준편차를 넣고
	return 평균+exp(로그분산/2)*keras.backend.random_normal(mean=0.,stddev=1.0)
	넣어서 샘플링함
	즉 샘플링함수가 제약으로 작동함
	
	
	디코더는
		input 2 
		dense(256) 잠재공간을 중간층의 차원으로 변환
		dense (784 acti sigmoid) 원본차원변환과 출력
		
		model(인풋,784dense)
	로 만든뒤
	둘을 합쳐서 모델을 만들면되는데,람다식을 출력값으로 연결하면됨
	그리고 손실를 정의하고 옵티마이저를 설정하고(adam 무지성으로때려박자) 훈련하면됨
	
	즉 변이형 오토인코더는 샘플링을 하고,결과가 잡음처럼 보이기떄문에,잡음을 박아서 생성모델로 쓰기좋음
	
			
8.근데 왜 GAN?
	오토인코더가 생성이 되긴하지만,평균에 가까운 값을 뽑기때문에,
	쌍봉분포처럼 산이 두개이상이면 값을 이상한데를뽑아서 품질이 좋지 않게 나옴(한계가 있음)
	
			
		




		
3.첫번째 gan 구현		
			
			
			
			
			
			
			
			