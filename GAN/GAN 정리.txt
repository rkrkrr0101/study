1.gan시작하기
	gan은 생성적모델과 판별모델로 이루어진 모델
	gan의 이론적으로 도달점은 내시균형에 도달하는것
	
	생성자는 입력으로 랜덤숫자벡터(가우시안잡음같은)를 받아서,
	출력으로 최대한 진짜같은 가짜샘플을 만들고,
	목표는 훈련데이터셋의 샘플과 구분이 불가능한 샘플을 생성하는것
	
	판별자는 훈련데이터셋과 생성자가 만든가짜샘플을 받아서,
	출력으로 입력샘플이 진짜일 확률을 뱉고
	목표는 생성자가 만든 가짜샘플과 훈련데이터셋의 진짜샘플을 구별하는것
	1.gan훈련
		훈련시엔 먼저 
		판별자를 훈련하고
			훈련데이터셋에서 랜덤하게 샘플을 선택하고
			새로운 잡음벡터를 얻어서 생성자로 가짜샘플을 생성한후에
			판별자로 둘을 분류하고
			분류오차를 계산하고 전체오차를 판별자에만 역전파해서 업데이트하고 판별자의 분류오차를 최소화함
		생성자를 훈련함
			생성자로 랜덤하게 잡음벡터에서 가짜샘플을 생성
			판별자로 분류
			분류오차를 계산하고(전부 가짜니까 많이속인만큼) 생성자에만 역전파해서 판별자의 오차를 제일 크게할수있게 만듬
		
	2.균형에 도달하기
		훈련반복은 이론상 내시균형에 도달할때 중지임
		내시균형은
			생성자가 훈련데이터와 구별이 안가는데이터를 생성해서
			판별자가 찍기할수밖에 없을때
		근데 실제 실무에선 내시균형에 도달하기가 불가능함(실제로 수렴을 하더라도 지역최소값일 확률이 높고,gan은 복잡성이 매우크기때문)
		그래도 대충수렴한값(지역최소값)써도 괜찮은결과물이 나옴
		그러니까 아직은 저정도로 만족해도댐
	
	
	3.gan사용처
		gan으로 이미지변경(남자를 여자로,말을 얼룩말로)하고싶으면 cyclegan쓰면됨 
		
		
		
			
2.오토인코더와 생성학습		
1.생성모델링
	오토인코더가 동작할땐 입력값과 출력값이 같은거처럼 보이지만 완전히 같지 않은 결과값을 얻지 않도록하는 잠재층이 있음
2.오토인코더의 동작방식
	오토인코더는 인코더와 디코더 두 부분으로 나눠져있음
	인코더로 데이터를 압축하고,압축된 데이터를 디코더가 해석하는식으로 데이터의 양을 줄임
	여기서 나는 손실을 재구성 손실이라고 부름
	
	반복되는 개념은 사전에 동의한 추상적인 표현으로 단순화하는게 양이 더적으니까 그런식으로 압축해서,효율적인 패턴을 찾아 정보를 압축함
	결과적으로 더 적은 차원만 전송하면되니 대역폭이 줄어듬
	
	이론적으로,이해하는데 너무 손해보지않으면서(재구성손실이 그렇게 크지않으면서)양을 최대한 줄인 정보 병목지점을 통해 최대한 많은 정보를 전달하는게 목표임
	
3.오토인코더와 gan의 비교
	오토인코더와 gan의 차이는,오토인코더는 하나의 손실함수로 모델 전체를 훈련한다는것이고,gan은 생성자와 판별자에 각각 다른 손실함수를 사용한다는것
	오토인코더는 명시적인 최적화함수(원본과의 차이)가 있지만,gan은 명시적 지표가 없음(둘이싸우는거기때문에)
	
4.오토인코더의 구성
	오토인코더는 
		입력-인코더-크기가 줄어든 잠재공간(압축된데이터)-디코더-출력
	으로 구성됨
	일반적으로 디코더는 인코더를 거꾸로 뒤집은 네트워크로 구성함
	
	오토인코더의 훈련은
		이미지x를 오토인코더에 입력
		재구성된 이미지x`를 얻음
		x와 x`의 재구성손실을 측정
	으로 이루어짐
	이렇게해서 재구성손실을 최소화하는 파라미터로 경사하강법을써서 업데이트해서 찾음
	
5.오토인코더 활용
	오토인코더는 간단하지만 얻을수있는게 많음
	먼저, 공짜로(데이터라벨링없이)압축된 표현을 얻음
	압축된 표현으로 데이터와 타깃클래스의 유사도를 빠르게 확인할수있는 이상치탐지가 있고,검색에도 적용할수있음
	
	또 다른 예로는 노이즈제거와 흑백이미지 채색을 할수있음
	
	그리고 일부 gan들은 오토인코더를 구조의 일부로 활용해 훈련을 안정화함
	
	그리고 제일 큰 장점은,레이블된 데이터가 필요없다는것임
	자기훈련이라서(자기자신이 레이블)
	
	그리고 오토인코더를 사용해 새로운 이미지를 생성할수 있음 (디코더에 잡음넣어서 이미지를 생성함)
			
6.비지도학습
	비지도학습은 레이블이 안된 데이터를 사용해 학습하는 방식
	예를들어 군집같은게있음
	
	비지도학습은 특정목적으로 레이블링할 필요 없이 어떤 데이터든 사용할수있음
	반면 지도학습은 레이블이 없으면,훈련이 불가능함
	
	오토인코더는 네트워크 2개로 이루어져있음,인코더와 디코더
	두 네트워크 모두 활성화함수와 중간층을 가짐,이는 네트워크마다 2개의 가중치행렬이 있다는 뜻
	
	인코더에선 하나는 입력과 중간층 사이에있고 하나는 중간층과 잠재표현층 사이에 있음
	디코더에선 하나는 잠재표현층과 중간층 사이에,하나는 중간층과 출력층 사이에 있음 
	
	만약 가중치 행렬이 하나면,이건 주성분분석과(pca,제일 길게나오는 차원을 파악해서 그방향으로 프레스로찍는거)
	
	1.오토인코더로 데이터생성
		오토인코더로 데이터생성을 할떈,인코더 부분을 떼어내고,
		잠재공간과 디코더만 써서 잠재공간에 잡음을 넣어서 샘플을 쉽게 뽑을수있음(클래스는 반복이나 그리드탐색으로 찾으면됨)
		
	2.변이형 오토인코더
		변이형 오토인코더는 잠재공간을 단순한 수의 집합이 아닌 학습된 평균과 표준편차를 지닌 분포로 표현함
		변이형 오토인코더는 베이즈이론에 기반한 머신러닝기법임,즉 분포를 학습해야 한다는 뜻
		그래서 제약이 추가됨
		
		다른말로 빈도기반 오토인코더는 잠재공간을 수의 배열로 학습하지만,변이형 오토인코더는 분포를 정의하는데 맞는 파라미터를 찾음
		
		그 다음 잠재분포에서 샘플링해서 숫자를 얻고(즉 랜덤하게찍어서) 그 숫자를 디코더에 주입함 
			
			
7.코드
	기본적으로 입력-인코더-크기가 줄어든 잠재공간(압축된데이터)-디코더-출력임
	인코더는
		input 784
		dense( 256)
		dense(2)평균 dense(2)로그분산  -출력
		lambda(샘플링함수)(평균,로그분산)
		
		model(인풋,[평균,로그분산,람다])
	이런식으로 평균 로그분산 람다를 전부 내보내면 변이형 오토인코더임
	출력은 숫자 하나가 나옴
	
	평균과 로그분산은 다음 람다식으로도 보내고,출력에도 연결되어있음
	저기서 평균과 로그분산은,람다식에서 그걸 사용하는식으로 오차를 만들어서,평균과 로그분산으로 학습시킴(제약)
	
	샘플링함수는 keras.backend.random_normal()에 평균과 표준편차를 넣고
	return 평균+exp(로그분산/2)*keras.backend.random_normal(mean=0.,stddev=1.0)
	넣어서 샘플링함
	즉 샘플링함수가 제약으로 작동함
	
	
	디코더는
		input 2 
		dense(256) 잠재공간을 중간층의 차원으로 변환
		dense (784 acti sigmoid) 원본차원변환과 출력
		
		model(인풋,784dense)
	로 만든뒤
	둘을 합쳐서 모델을 만들면되는데,람다식을 출력값으로 연결하면됨
	그리고 손실를 정의하고 옵티마이저를 설정하고(adam 무지성으로때려박자) 훈련하면됨
	
	즉 변이형 오토인코더는 샘플링을 하고,결과가 잡음처럼 보이기떄문에,잡음을 박아서 생성모델로 쓰기좋음
	
			
8.근데 왜 GAN?
	오토인코더가 생성이 되긴하지만,평균에 가까운 값을 뽑기때문에,
	쌍봉분포처럼 산이 두개이상이면 값을 이상한데를뽑아서 품질이 좋지 않게 나옴(한계가 있음)
	
			
		




		
3.첫번째 gan 구현
1.gan기초
	gan은 생성자와 판별자로 구성되는데,둘은 각기 다른 비용함수를 가짐
	둘다 판별자의 손실을 사용해 역전파로 자기의 네트워크를 훈련하는데
	판별자는 진짜와 가짜샘플에 대한 손실을 최소화하고
	생성자는 자신이 생성한 가짜샘플에 대해 판별자의 손실이 최대화 되도록함(가짜샘플을 전부 레이블1(정답)로 주고 가장 높히기위해 노력함)
	
	순서는 먼저 판별자부터 훈련을 한 다음,생성자를 훈련함
	각각 순서마다 판별자만 훈련하고,생성자는 잠그고
	생성자만 훈련하고 판별자는 잠그는식으로 외부파라미터는 잠금
	
	생성자는 처음엔 무작위잡음이었다가,점점 훈련 데이터셋의 데이터분포를 흉내내는샘플을 생성하게됨
	결국 이미지든 뭐든 컴퓨터입장에선 채널이 여러개인 행렬일뿐이니까(다차원행렬) 거기서 패턴을 찾아낼수 있음
	거꾸로말해서 패턴이 없는 이미지는 그냥 잡음일뿐임
	
	생성자모델은 객체인식모델(어떤객체가 있는지,또 어디에있는지)의 역과정이라고 생각할수도 있음
	패턴을 인식하는게 아니라 패턴을 합성하는걸 학습함
	
	1.비용함수
		gan의 비용함수는 두 네트워크 모두 두 네트워크의 파라미터에 모두 의존함
		생성자도 판별자의 판별결과와 자신의 생성에 모두 의존하고
		판별자도 생성자가 생성한 결과와 자신의 판별결과에 모두 의존함
		
		그래서 변수를 줄여야하니 상대방의 파라미터의 튜닝을 막는것
		
		그래서 gan이 자주 모드붕괴같은게 일어나는것(불안정함)
		
	2.훈련과정
		기본적인 신경망들은 최적화문제임(공간내에서 비용이 감소되는 곳으로 움직이는식) 그래서 지역최소점이나 전영최소점에 도달하기가 나름 쉬움
		근데 gan은 전체모델의 절반만(자기자신만) 튜닝할수 있기 때문에 게임이론에 더 가까움
		그리고 gan의 목표점인 내시균형은,모든 선택지의 기댓값이 동일해서 찍을수밖에 없을때 일어나는데,이런건 불가능함(매우어려움)
		그래서 그냥 적당히 수렴시켜서 결과물 뽑아보고 괜찮으면 쓰는거
	
2.생성자와 판별자
	생성자는 랜덤한 잡음벡터를 받고 가짜샘플을 생성하고,판별자는 실제샘플과 가짜샘플을받아서 진짜인지아닌지 리턴함
	생성자는 다른건 관심없고 자기가 만든게 진짜라고 인식되기만 하면(거짓양성만 커지면)되는거고
	판별자는 진짜양성과 진짜음성을 최대화하려고 노력함
			
3.gan 훈련알고리즘
	gan의 훈련은 미니배치단위로 함
	1.판별자훈련
		랜덤한 진짜 미니배치를 받고
		랜덤 잡음벡터의 미니배치를 받아서 그걸로 가짜 미니배치를 생성함
		둘다 각각 분류손실을 계산하고,전체오차를 역전파해서 분류손실을 최소화하게 판별자만 업데이트함(트레인을 2번함 진짜한번 가짜한번)
	2.생성자훈련
		랜덤 잡음벡터의 미니배치를 받아서 그걸로 가짜 미니배치를 생성함
		가짜 미니배치의 레이블을 전부 1로한뒤에(진짜로 레이블을잡은뒤에) 오차를 역전파해서 판별자의 오차가 커지도록 생성자만 업데이트함
	이렇게 각자 자기꺼만 건드리는이유는 자기가 제어할수있는 파라미터만 바꾸기위해서
	
	
4.mnist생성gan(튜토리얼)
	1.생성자구현
		간단히만들꺼니까 생성자는 하나의 은닉층을 가짐
		잡음을 받아서 28x28x1의 이미지를 생성
		은닉층은 leakyRelu(기울기가 0이안되는 relu)를 사용하고 
		출력층엔 tanh를 써서 출력범위를 -1~1로 조정함
		시그모이드보다 tanh가 좀 더 또렷한 이미지가 나오는 경향이 있음
		
		모델생성코드
			model=sequential
				dense(128,input_dim=인풋크기)
				LeakyReLU(alpha=0.01) 위에 넣어도됨 dense층에
				dense(28*28*1,acti='tanh')
				Reshape(이미지차원크기)
				
		
	2.판별자 구현
		판별자는 28x28x1의 이미지를 받아 진짜인지를 나타내는 확률을 출력함,일반적인 분류모델이라고 봐도됨
		
		모델생성코드
			model=sequential
				Flatten(input_shape=이미지차원크기) 이미지를 일렬로 펼침
				dense(128)
				LeakyReLU(alpha=0.01)
				dense(1,acti='sigmoid')
		꼭 생성자랑 비슷하게 만들필요없는데 제일 간단한 모델구조라서 겹치는거임
		생성모델과 분류모델역할만 하면됨
		
	3.모델생성(로스등등)
		먼저 이미지니까 로스는 바이너리 크로스엔트로피쓰면되고,옵티마이저는 무지성아담 쓰면됨
		생성자와 판별자를 생성하고
		판별자는 컴파일함
		새 모델을 만들어서 생성자와 판별자를 연결시키고(이 모델로 생성자를 훈련함) 이모델은 판별자의 훈련가능성을 false시켜둠
		그리고 똑같이 로스옵티마이저 설정함
		
	4.훈련
		훈련시 순서
			먼저 이미지전처리를 하고
			배치크기만큼 미리 레이블을 만들어둔뒤에(real fake 둘다)
			진짜배치에서 랜덤이미지를 배치크기만큼 가져오고
			잡음벡터에서 배치를 뽑은다음에 가짜배치를 생성하고 (predict)      //데이터전처리끝
			
			진짜이미지로 판별자를 훈련(train_on_batch)
			가짜이미지로 판별자를 훈련(train_on_batch)
			그뒤 그래프그리거나 뭐 다른용도로 쓰기위해 진짜와 가짜이미지의 손실을 합쳐서 반나눠서 저장   //판별자훈련끝
			
			잡음백터에서 배치만큼 뽑은뒤에
			잡음벡터에 진짜레이블로 판별자를 훈련(판별자는 잠겨있으니까 생성자만 훈련됨)
			
			그리고 필요하면 손실과 정확도 저장하고
			샘플 이미지 출력하고싶으면 출력
		
		샘플이미지출력시엔84페이지 코드 따라쓰자 인터넷에도 똑같은거널린듯
		
		
		
	5.모델실행
		모델을 실행할때 반복횟수와 배치크기를 선택하고 모델을 훈련해야댐
		여기서 반복횟수와 배치크기를 결정할수있는 수식같은게 없어서 과정을 보면서 시행착오를 해야함
		
		그렇치만 배치는 메모리에 들어갈수있을만큼 작아야하고,반복을 많이하면 오래걸리니까 대충 알아서 맞춰보자
		손실 모니터링하면서 손실이 평탄해지는 부근에서 반복을 멈추면됨(이거도 과대적합나니까 조기종료하는식으로 하면됨)
	
	
	
	
	
4.dcgan(합성곱gan)	
	dcgan은 합성곱gan임
1.합성곱신경망
	1.필터
		합성곱신경망은 알고있겠지만 하나 이상의 필터가 입력층을 슬라이딩하면서 합성곱을 수행함
		각 필터는 작은 너비x높이를 가지지만 모든깊이에 같이 적용됨(필터는 모든채널을 같이먹음,즉 rgb3채널이면 3채널 동시에 적용됨)
		
		입력위를 슬라이딩 할때마다 각 필터는 하나의 활성화값을 출력함 ,이건 입력과 필터의 점곱으로 계산함
		이래서 2차원맵이 만들어지고,이런 필터가 모여서 3차원출력층이 됨
		그래서 출력의 깊이(채널)는 사용한 필터의 수임
		
	2.파라미터 공유
		합성곱에서 특정 필터의 파라미터는  모든 입력값에 공유됨(같은 필터내에서)
		그래서 각 필터마다 파라미터를 달리해서 특정 목적에 특화된(선만 뽑는다던지 모서리찾는다던지) 필터가 생성되게됨
		그래서 파라미터의 갯수가 크게 줄어들고,이미지의 위치에 상관없이 일정하게 뽑을수있음
	
2.배치정규화
	배치정규화는 뭐 알고있겠지만 막 입력층에서만 정규화해서 들어오는게 충분하지않으니까 
	중간중간에 정규화를 해주는층임(각 파라미터마다 바뀌는 스케일이 다를수있으니까)
	그래서 대충 무지성으로 때려박는듯 좀 큰모델에서는
	
	계산식은 알필요없고 케라스 batchnormalization쓰면됨

3.mnist생성dcgan
	이거도 그냥 gan이랑 별차이없긴함 생성자쪽 모델만 좀다르고(층이다르니까) 판별자는 일반 합성곱분류모델
	
	1.생성자층
		합성곱으로 생성모델을 만드려면 잡음으로 업스케일링하는 느낌으로 층을 만들면됨
		여기서 메인은 전치합성곱층(conv2DTranspose)
		일반적인 합성곱층은 채널을 늘리고 너비높이를 줄이는데,전치합성곱은 반대로 동작함,깊이를 줄이고 너비와 높이를 증가시킴
		(패딩이 same일경우) 전치층의 입력값* 스트라이드의 배수만큼 (2이면 2배 3이면 3배) 출력값의너비높이가 커짐(채널은 정한크기대로나오고)
		(패딩이 valid일경우) (입력값-1)*스트라이드의배수+필터수만큼 나옴(채널은 정한크기대로나오고)
		
		생성자모델생성
			모델=시퀸셜
				dense(7*7*256,input_dim=잡음배치크기)
				reshape(7,7,256)
				conv2DTranspose(128,커널사이즈 3 스트라이드 2 패딩='same')//7*7*256이 14*14*128로 댐
				batchnormalization
				leakyRelu
				conv2DTranspose(64,커널사이즈 3 스트라이드 1 패딩='same')//14 14 64
				batchnormalization
				leakyRelu
				conv2DTranspose(1,커널사이즈 3 스트라이드 2 패딩='same')//28 28 1
				Activation('tanh')

	2.판별자층
		그냥 일반 합성곱분류모델임
		
		판별자모델생성
			모델=시퀸셜
				conv2D(32,커널사이즈 3 스트라이드 2 input_shape=이미지크기(28 28 1) 패딩 same)//14 14 32으로 바뀜
				leakyRelu
				conv2D(64,커널사이즈 3 스트라이드 2 패딩 same) //7 7 64로 바뀜
				leakyRelu
				conv2D(128,커널사이즈 3 스트라이드 2 패딩 same)//3 3 128로 바뀜
				leakyRelu
				Flatten//이미지 평탄화해서 한줄로바꿔줌
				dense(1,acti sigmoid)
				
	3.모델생성과 실행
		그냥 gan과 완전히똑같음
		결국 모델생성하고 분류하는거라서 코드그대로써도됨
		
		
	4.결론
		그냥gan보단 합성곱이 결과물이 월등히 좋게나옴
		




		
5.gan훈련의 어려움과 노하우		

1.평가
	1.평가방법
		gan의 평가방법중,이론적으로 가장 좋은방법은,
		대상이 그릴수 있는 모든이미지중 gan이 그린게 포함되어있는지 확인하는것이지만 당연히불가능
		
		그다음으론 이미지를 평가하고 찾을걸 정의한 다음 사람이 확인하는것,
		당연히 이것도 1에포크마다 사람이 레이블매겨야하니 비현실적임
		
		그래서 그다음으로 나온게 최대가능도(최대우도법)같은걸로 하는건데 이거도 샘플이 너무 많이필요하고,
		과도하게 일반화하는(몸이 여러개인 기린) 문제가 있음(과잉일반화문제)
		
		그래서 샘플을 평가할수있어야하는데,단순하게 최대가능도를 사용할수는 없음
		
		그래서 사용하는게 인셉션점수와 프레셰 인셉션 거리임
		
	2.인셉션점수(IS)
		좋은 확률적 평가 방법이 가져야할것은
			1.생성된 샘플은 실제 사물과 같고 구분이 가능해야함(클래스)
			2.생성된 샘플을 원본 데이터셋에 있는 모든 클래스를 포함해야함(모드붕괴나면안됨)
			
		인셉션 점수는 
			진짜 분포와 생성된 분포사이의 kl발산(두 분포의 부피를 계산하고 겹친 부분의 부피를 계산해서 뻄,완전히겹치면 0)을 계산하고
			거기에 지수함수를 적용하면 끝
		
		이렇게 해서 적용시켜보면,사람이랑 비슷하게 생각하고,구분이 불가능하면(클래스) 낮은점수를 줌(1번 만족)
		
	3.프레셰 인셉션 거리(FID)
		이건 2번을 만족시키기위해 나온 방법임
		얘는 잡음에 강하고 클래스 내부의 샘플 누락을 감지할수 있어서 인셉션점수를 향상시킴
		
		기본적으로 그냥인셉션점수는 클래스하나로 쭉밀어도 되버려서 모드붕괴나기가 쉬움
		그래서 나온게 FID
		
		얘는 그냥 픽셀공간에서 이미지 사이 거리를(임베딩이라고 생각해도됨)계산함
		인셉션모델에 이미지를 통과시켜,진짜와 생성된 두 분포의 임베딩된 평균,분산,공분산의 거리를 평가함
		
		이미지뿐 아니라 분류기가 잘 훈련되어 있다면 이 분류기의 예측을 사용해서 샘플의 현실적으로 보이는지 측정할수 있음


2.훈련의 어려움
	gan은 여러 문제가 생길수 있음
		모드붕괴
			모드붕괴는 일부 클래스가 샘플에 잘 나타나지 않는것(mnist에서 8이 없다든가)
			네트워크가 수렴해도 모드붕괴가 일어날수있음,FID로 어느정도 해결가능
		느린수렴
			수렴이 오래걸려서 모델훈련에 일주일씩 걸리는것 
		과잉 일반화
			이상한 모드가 발생하는것(몸이 여러개인 기린,동그라미가 3개인 mnist)
		
		모드붕괴와 과잉일반화는 다시 훈련을 하는거로 해결되는 경우도 있지만,이거자체가 알고리즘이 불안정하다는 소리임
		그래서 앞으로 나올게 해결하는데 도움을 줌
		
		1.신경망 깊이 늘리기
			네트워크를 안정되게 학습하는 가장 쉬운방법은 복잡도를 낮추는것임
			
			간단한 생성자와 판별자를 사용하면 금방 안정상태에 도달할수 있음
			여기서 훈련을 하면서 복잡도를 추가할수있음(네트워크의 크기를 계속 늘림 좋은 성능을 얻을때까지)
			
			예를 들어 4x4로 시작해서 두배씩 늘리면서 1024x1024가 될떄까지 이 과정을 반복함

		2.게임 설정 변경
			gan에서 두 상대가 경쟁하는것은 게임과 비슷함,
			그래서 두 네트워크들은 목표와 달성하려는것을 알아야하고 승리할 가능성이 높은지를 알아야함
			즉 규칙과 거리지표가 필요함(손실을 커스텀함)
			근데 모든 gan에 같은 지표를 사용한다고 다 잘 적용되지않음
			
			1.최소-최대 gan
				이건 판별자가 실제 샘플을 가짜로 착각할 가능성을 최소화하거나,가짜를 진짜로 착각하는걸 최소화하고,
				생성자는 판별자의 음수가 손실이 된다는걸 설명하는 것임
				실제로 사용하진 않지만 이해는하고있어야함
				
			2.비포화 gan(nsgan)
				최소최대같은건 생성자의 느림수렴같은걸 종종 일으킴
				그래서 나온게 비포화gan
				얘는 두 손실함수가 직접 경쟁하는게 아니라 두 손실함수를 독립적으로 만듬(방향성은 같음)
				판별자는 최소최대와 동일하지만
				생성자는 훈련 초기에 기울기가 큼(식이 있긴한데 이해안해도될거같음)
				즉 많은 그레이디언트를 받아서 초기훈련속도를 올림
				
				얘는 왜 내시균형에 도달하는지는 잘 모르겠음
				
				nsgan은 이런 특징을 가짐
					js발산과 점근적으로 일치하지않음
					이론적으로 정의하기 더 힘든 평형상태를 가짐
					
				그냥 하다보니 나온 모델인가봄
				
				얘의 훈련 종료시기를 결정하는건 샘플을 보고 괜찮다싶으면 사람이 수동으로 멈춰야됨
				뭐 fid나 is같은거로 종료시기를 찾을수는 있다는데 일반적이진 않나봄
				
				실제로 둘이 싸우는거라서 로스만 가지고 평가는 힘들고 직접봐야되는듯
				그래도 WGAN보다 훨씬 빠른가봄
			3.WGAN
				이건 nsgan보다 느린대신 좀 더 명확함
					해석이 용이하고 종료기준이 명확함
					경험적으로 wgan이 더 나은 결과를 만드는 경향이 있음
					손실의 이론적 뒷받침이 명확함,즉 계산할수가 있음
					
				얘는 샘플의 비주얼품질과 명확히 관련되어있는 EM거리(확률분포중 거리차이에 대한 기댓값을 가장 작게추정한값)를 손실함수로 사용함
				
				여기엔 판별자가(비평자라고도 부름) em거리를 추정하고 함수의 모델파라미터를 바꾸어가면서 진짜분포와 생성된분포 사이의 최대차이를 찾고 그걸 츶정함
				판별자는 이동해야할 확률질량의 양을 최대화하는(em거리를 늘리는)함수를 찾아서 생성자를 최대로 어렵게함
				생성자는 em거리를 최소화해야함
				
				얘의 장점은 
					1.판별자손실과 체감품질 사이의 상관관계를 보여준다고 검증이 되어있어서,그냥 em거리를 재서 언제멈출지를 정할수있음
					2.wgan을 훈련해서 수렴시킬수있음
					
				얘는 em거리의 근사버전을 사용해 평가하는데,실제 데이터분포를 모르면 em거리를 정확히 재기 어렵기때문
				
				그냥 em거리가 js나 kl보다 더 낫다고만 알고있어도될듯
				
				일반적으로 wgan쓰면되나봄
				
				
3.게임설정정리
	손실함수랑 표 있음 133페이지에 필요하면 참고
	그냥 wgan이나 wgan-gp(그레이디언트패널티)를 제일 많이씀
			
				

4.훈련 노하우
	기본적으로 wgan으로 시작하고,adam을 사용함
	1.입력 정규화
		입력은 이미지를 -1~1사이로 정규화하는게 좋고,생성자의 출력도 tanh로 제한두는게좋음
	2.배치 정규화
		배치정규화는 판별자에선 막 써도 되는데 생성자에선 결과가 나빠지는경우도 있어서 좀 주의해서 써야함 좀나빠진다싶으면 뺴보고
	3.그레이디언트 패널티
		그레이디언트 노름이 너무 크면 뭔가 문제가 생김 
		근데 단순하게 클리핑(상하단 잘라내기)하면 그거때문에 그레이디언트 소멸이나 폭주가 나올수있음,그래서 입력에대한 출력의 기울기 노름을 제한할수있음
		즉,입력이 조금바뀌었으면 가중치를 너무 많이 바꾸면 안됨
		
		보통 프레임워크에서 간단하게 제한할수있음
	4.더 많은 판별자 훈련
		이건 확실하진않으니까 주의를 해야함
		하는법은
			생성자가 뭘 만들기전에 판별자를 먼저 훈련함
			훈련반복마다 판별자를 더 많이 업데이트함,생성자 한번 업데이트에 판별자 5번업데이트함
	5.희소한 그레이디언트 피하기
		맥스풀링이나 relu같은애들은 값이 너무 많이 사라져버리니까 쓰면안됨
		쓸거면 평균풀링을 쓰는게 그나마 정보를 어느정도 남길수있음(얘도 사라지긴하지만)
		그리고 relu는 음수값이 전부 다 날아가버리기때문에 쓰면안되고 
		leakyRelu같은거에 만약 값이 음수면 0.1*x 양수면 leakyRelu하는식으로 해결할수있음 
		
	6.소프트레이블과 잡음 레이블
		레이블에 잡음을 넣거나 완화시킴(원사이드 레이블 스무딩,이진레이블에 0과 0.9를 쓰는등)
		보통은 잡음넣거나 클리핑하는게 좋다고함(확신없음 여긴)
	
	
6.progan
	기본적으로 모델을 만들때 바닥부터 만드는경우는 별로없고,어디서 모델 받아와서 쓰는경우가 많음
	progan의 중요 포인트는
		고해상도 층으로 점진적 증가와 단계적 도입
		미니배치 표준편차
		균등학습률
		픽셀별 특성 정규화
	가 있음
	
1.잠재공간 보간
	출력을 위한 초깃값을 만드는 저해상도 공간을 잠재공간이라 부름
	progan도 초기훈련된 잠재공간은 의미있는 속성을 가짐
	예를들어 이미지에 안경을 씌우는 벡터를 찾을수있으면,같은벡터로 다른이미지에도 안경을 씌울수있음
	그리고 랜덤한 벡터 두개를 선택하고 둘 사이를 점진적으로 이동하면서 조금씩 두번째 벡터로 변하는 이미지를 얻을수있는데
	이걸 보간이라고함

2.gan의 발전
	1.고해상도 층으로 점진적 증대와 단계적 도입
		이건 처음부터 고해상도 층을 사용하면 복잡도가 매우 커지니까,
		4x4같은 작은크기부터 미리 훈련해서 미리 러프하게 복잡도를 쳐낸다음 해상도를 늘리는방식으로 함
		즉 4x4에서 몇에포크를 보내고,8x8에서 좀 있다가 이런식으로 점진적으로 크게만듬
		딥러닝할때 어디서 모델받아와서 뒤에 dense붙여서 하는거랑 비슷한느낌이긴한듯 trainable true로 두는건 다르지만
		
		그래도 해상도가 늘어날때엔 훈련에 큰 영향을 끼치긴하니까(일시적으로 로스가 급증하니까)
		점진적으로 그냥 업스케일링한거랑 업스케일링한걸 다음단계로 넘긴거랑 적당히 합쳐서 좀 적응하게 만든다음에 그냥 업스케일링한걸 보낸걸 제거함
		이걸 반복해서 원하는 해상도로 올림
		
		업스케일링 코드랑 합치는거 코드는 145쪽에있음
		업스케일링은 레이어선택해서 사이즈잰다음에(가로세로) tf.image.resize_nearest_neighbor(레이어,사이즈)로 업스케일링하고 리턴
		층을 합치는건 레이어를 받아서 업스케일링하고 서로 같은크기인지 확인한후에 서로 알파를 곱해서 더해서 리턴함
		
	2.미니배치 표준편차
		이건 모드붕괴를 막기위한거
		미니배치의 생성자가 만들거나,실제데이터에서 온 미니배치에 있는 모든픽셀의 표준편차를 판별자에게 제공해서,
		만약 표준편차가 낮으면 이걸 가짜라고 인식함(실제샘플은 분산이 클 확률이 높기떄문,비슷한사진이 별로안들어가니까)
		만드는건 147쪽에있음
		
		대충 설명하면 미니배치를 받아서 크기를 바꾼뒤(+1차원해서 차원하나많은 행렬로 만들어서 사용 4D)
		이걸 모든 미니배치에 대해 표준편차를 계산하고(4d-3d)
		모든 채널에 대해 표준편차를 평균내고(3d-2d) 하나의 2d표준편차행렬을 뽑은뒤(각 픽셀이나 하나의특성맵에 대응되는 )
		그 표준편차행렬에 대해 표준편차를 평균내서(2d-스칼라값) 하나의 스칼라값을 리턴함
		코드상에선
		즉 4d에서 axis1로 평균을내서(4d-2d) 그거로 분산을내고  그거로 표편을 낸후에 전체를 평균해서 1차원을뽑고 그걸 스칼라값으로 만들어서
		그룹과 픽셀에 맞게 변환하고 keras.backend.concatenate로 특성맵을 추가하는함수를 리턴함
		
	3.균등학습률
		이건 그냥 하다보니 이렇게하면 잘되어서 나온 방법임 이론은 이해잘못해도됨
		이건 대충 모든 가중치를 어떤 범위이내로 정규화함
		w`=w/c인데 상수c는 가중치행렬의 크기에따라 결정되니까 층마다 다름
		만약 어떤파라미터가 최적점에 도달하기위해 크게바뀌어야하면 c가 그렇게만들수있음
		이건 adam과 다른건,adam은 기울기에 대해 정규화를 하는데 
		균등학습률은 모든 파라미터가 같은 다이나믹 레인지(한특성이 미니배치에서 얼마나 다양한지)를 갖게해서 같은 학습속도를 낼수있게함(전부 똑같이움직이게함)

	4.생성자의 픽셀별 특성 정규화
		특성을 정규화해야하는 이유는,특성값이 값자기 커지는게 발산의 초기신호이기 때문
		일반적으로 신경망은 어떤 형태든 정규화를 사용하는데,배치정규화를 쓰려면 개별샘플을 평균할수있도록 미니배치크기가 커야함
		근데 배치정규화는 높은해상도를 위해선 너무 많은 메모리가 필요함
		그래서 픽셀별 특성 정규화가 나온거
		
		픽셀 정규화는 다음층의 입력으로 들어가기전에 각 층의 활성화 크기를 사용함
		이건 모든 픽셀에 대해,모든특성맵에서 그 픽셀 위치의값을 모은뒤 그걸 각 픽셀마다 정규화한뒤 인풋에 그걸로 나눠서 브로드캐스팅을 한후 다음층으로 넘김
		즉 모든특성맵을 합치고 정규화하고 넘김
		이건 생성자에만 적용하면됨,두 네트워크가 경쟁할때만 활성화크기가 폭주로 이어지기때문

3.주요 혁신 요약
	progan 논문쓴애들은 swd(em거리를 최소화하기위한 실제데이터와 생성샘플의 조각)를 썻는데 fid(실제와 생성샘플간의 임베딩거리의 차이)가 더 좋은거래
	
	그리고 중요한점은,미니배치가 잘 동작하지않음,픽셀이 커지면 gpu메모리에 많이못넣어서 미니배치를 줄여야하는데,그러면 성능이 낮아짐


4.텐서플로허브를 사용한 실습
	텐서플로허브에서 모델 가져다쓰는게 요즘은 일반적임
	허브모듈 임포트하고 url로 호출하고 잡음차원만들고 그거 넣으면 생성하는데 그거 reshape하면됨





7.SGAN
1.SGAN소개
	SGAN은 준지도학습으로 분류기를 훈련시키는 gan임
	보통 gan들이 생성자에 관심이 많지만,얘는 분류기에 관심이 더 많음
	
	SGAN은 판별자가 다중 분류를 수행하는 gan임
	즉 진짜 가짜 두개의 클래스만 구분하는게 아니라 n+1(클래스전체와 가짜)를 구분하도록 학습함
	mnist기준 11개의 레이블이 있음
	여기서 확률은 0~9까지가 1.0으로 하나 있고,진짜인지 가짜인지가 하나 더 있음
	
	1.구조
		SGAN 생성자의 목적과 구현은 그냥gan이랑 같음
		근데 판별자는 다중클래스분류를 해야하기때문에 출력도 다르고,입력도 둘(진짜,가짜)이 아니라 셋(진짜+레이블,진짜+레이블x+가짜)을 받음
		
		여기서 판별자의 목표는 입력이 진짜일경우 해당클래스로 분류하고,아니면 가짜로 분류함
		
	2.훈련과정
		일반적인 gan이 d(x)와 d(x`)의 손실을 계산하고 총손실을 역전파해서 판별자를 훈련하고,생성자는 d(x`)의 손실을 최대로하게 역전파했다면,
		SGAN은 d(x)와 d(x`)에 더해 d((x,y))의 손실도 계산해야함,즉 이중목표임(가짜진짜,진짜분류)
		즉 지도손실과 비지도손실 두종류의 손실임
		
	3.훈련목표
		앞서말했다시피 얘는 분류기를 목표로 함
		적은량의 레이블을 사용해 완전한 지도학습분류기에 가까운 정확도를 내는 준지도학습분류기로 만드는것
		생성자는 그냥 훈련도와주는거뿐
	
2.SGAN구현
	얘는 구현할떄,레이블데이터는 소프트맥스로 판별하고,레이블없는거랑 가짜는 시그모이드로 가짜진짜판별만 함
	
	1.전처리
		앞에넣을거넣고 데이터는 라벨만 좀떼두고 나머지는 깡데이터만 사용
	2.생성자
		생성자는 일반gan과 완전히동일(conv2DTranspose로 크기늘리면서 채널줄이는거)
	3.판별자
		판별자의 메인부분은 일반gan과 같음 드롭아웃정도가 추가된정도
		근데 그 메인부분을 지도학습과 비지도학습으로 나눠서 적용시킴
		층추가함수를 지도 비지도 둘다 만들고
		
		지도학습은 받은모델에 소프트맥스층 추가해서 리턴하고
		비지도학습은 진짜클래스의 확률분포를 지수함수연산(0.4 이러니까 다 작아짐)해서 다 더한뒤(한개의 추정이 높으면 진짜,전부 비슷하면 가짜) 
		진짜대 가짜의 이진확률로 변환해서 리턴함
		
	4.모델구성
		모델은 먼저 기반모델을 생성하고(이건 지도,비지도 둘다 공유되어서 훈련받음)
		지도학습모델을 만들고 컴파일하고
		비지도모델을 만들고 컴파일하고
		비지도판별자동결처리(컴파일시점에서 확정이 되기떄문에,미리 비지도를 컴파일해뒀으면 만들어둔거엔 영향이안감)후
		생성자를 만들고 생성자꺼는 비지도판별자를사용하고 컴파일
	5.훈련
		먼저 지도학습판별자를 훈련시키고
			레이블된샘플의 미니배치를얻고
			미니배치에 대해 다중클래스분류손실을 역전파해서 모델을 업데이트하고 손실최소화
		비지도판별자를 훈련시키고
			레이블없는 진짜샘플의 랜덤 미니배치를 얻어서
			미니배치에 대해 이진분류손실을 역전파해서 모델을업데이트하고 손실최소화
			랜덤잡음의 미니배치를 얻어 가짜샘플의 미니배치를 생성하고
			가짜미니배치에 대해 이진분류손실을 역전파해서 모델을 업데이트하고 손실최소화
		생성자를 훈련
			랜던잡음의 미니배치를 얻어 가짜샘플의 미니배치를 생성하고
			가짜미니배치에 대해 이진분류손실을 역전파해서 모델을 업데이트하고 손실을 최대화시킴
			
		
		훈련코드는 다를게없음
		
			레이블된 진짜샘플훈련
			레이블안된 진짜샘플훈련
			가짜이미지만들고
			가짜샘플훈련
			가짜이미지 다시 만들고
			생성자훈련
			
			
		판별자의 지도학습 손실값이 평탄해질떄까지 반복수를 늘리는데,평탄해지면 금방멈춰야함 과대적합나니까
		
3.지도학습분류기와 비교
	확실히 전부 레이블된거보다는 성능이떨어지지만(비지도레이블이 전부 레이블된거),그냥 레이블만 가지고 한거보단 성능이 훨씬좋음
	
		
		
		
	
8.CGAN
	cgan은 생성자와 판별자 모두 레이블을 사용하는 gan임
	생성자가 특정 레이블을 생성하게 만들수있음(기존gan은 그 클래스가 나올떄까지 계속돌려야했음)
1.cgan소개
	cgan은 판별자가 진짜샘플-레이블과 가짜샘플-레이블을 구분하고,진짜샘플과 레이블이 맞는지도 구분할수있음
	여기서 진짜샘플의 레이블확인은 직접훈련하진않고,진짜샘플-레이블 훈련을 한 부산물임
	
	1.생성자
		생성자는 잡음벡터와 레이블을 받아서 x`|y로 합성함
		얘도 목적은 레이블이 주어졌을때 진짜샘플에 가능한 한 가깝게 보이는것
	2.판별자
		판별자는 진짜샘플과 진짜레이블을 받고,가짜샘플과 샘플을 합성할때 사용한레이블을 받음
		진짜샘플에선 진짜데이터를 구별하고,그에 맞는 쌍을 판별하는걸 배우고
		가짜샘플에선 가짜데이터-레이블쌍을 판별하는걸 배움
		즉 진짜샘플과 가짜를 구분하도록 학습함
		
	3.요약
		즉 생성자는 잡음과 레이블을 받아서 
		레이블에 맞도록 생성된 가짜샘플을 리턴하고,
		레이블에 맞는 진짜같은 샘플생성이 목표
		
		판별자는 진짜샘플-레이블과 가짜샘플-레이블을 받아서 
		입력샘플이 진짜면서 짝이 맞는지를 나타내는 확률을 리턴하고,
		가짜샘플레이블과 진짜샘플레이블을 구별하는게 목표
		
		즉 판별자가 잘못된 쌍을 거부하기위해 진짜샘플-가짜레이블쌍,가짜샘플-가짜레이블쌍으로 훈련하지않음
		가짜샘플에 대한 레이블도 생성자와 판별자에 둘다 동일하게 들어감

2.cgan구현
	1.생성자
		cgan생성자는 다른데는똑같은데,
		입력부분에서 레이블을 임베딩시켜서 잡음벡터와 합침(곱연산)
		그러면 레이블에 따른 고정적인 패턴이 잡음벡터에 각인되게됨
		
			기본모델을 똑같이쓰고 미리만들어둔후
			레이블을 받아서 
			임베딩으로 변환하고(Embedding층 첫파라미터는 레이블의갯수(0~9면 10개)두번쨰파라미터는 차원의크기)
			임베딩텐서를 Flatten해서 
			잡음과 원소별곱셈(Multiply)
			그위에 모델을 올림
			
		임베딩은 원하는 레이블이나 단어나 그런걸 특정 벡터로 표현할수있음(자기가 원하는 크기의 밀집벡터로)
			
	2.판별자
		얘도 다른데는 비슷하고 입력이미지에 레이블로 채널을 추가해서(도장찍기) 
		레이블에 따른 패턴이 이미지에 각인되게 만드는데
		
		얘는 레이블을 임베딩층으로 이미지크기만큼의 밀집벡터로 변환하고
		그걸 이미지차원크기로 바꾼다음에 그걸 이미지에 채널 하나 추가하는식으로 추가함(흑백일경우 28*28*2 rgb면 28*28*4가됨)
		
		그리고 판별자네트워크를 좀 더 크게해야함 특히 처음부분이 채널이 하나 추가됐으니까 채널수를 늘려줘야됨(32->64)
		
		
	3.모델생성
		모델은 똑같이 만들면됨 레이블추가된거말고 바뀐거없음
		
	4.훈련
		훈련은
			판별자훈련
				진짜샘플과 레이블의 랜덤 미니배치를 받고
				진짜샘플을 계산하고 손실을 역전파
				잡음벡터와 레이블로 가짜미니배치를 생성
				가짜샘플을 계산하고 손실을 최소화
			생성자훈련
				잡음벡터와 레이블로 가짜미니배치를 생성하고
				가짜샘플을 계산하고 판별자의 손실을 최대화하게 생성자를 업데이트
				
		즉
			가짜이미지생성(판별자)
			진짜훈련
			가짜훈련
			
			가짜이미지 재생성(생성자)
			생성자훈련
				
		순으로 똑같이하면됨
	
	

9.cycleGAN
1.사이클gan 소개
	사이클gan은 사과를 오렌지로 바꾸는식으로,이미지를받아서 특정물체나 스타일을 바꿔줌
	얘는 이미지를 입력받아서 이미지를 출력하는데,
	얘는 생성자랑 판별자가 2개임,정확히는 cgan이 2개 오토인코더처럼 붙어있다고 생각하면됨
	그래서 판별자마다 데이터셋이 필요함(사과,오렌지면 사과데이터셋 오렌지데이터셋)
	
2.사이클일관성 손실
	그래서 여기서 첫 손실이 나오는데,a사진을 b로 바꾼다음 b를 a로 바꾸면 원래사진과 재구성된 사진은 이론상 같아야하는데,
	여기서 같지않은만큼이 첫번째 손실인 사이클일관성 손실임(L1노름임,이미지의 각 픽셀과 재구성이미지의 픽셀의 절대값차이)
	
	역번역이라고 생각하면됨 한글을 영어로 바꾸고 그걸 다시 한글로 바꿨을때 같냐는 소리
	
	그러려면 한글을 영어로 바꾸는 생성자랑,영어를 한글로 바꾸는 생성자 두개가 필요함
	
	여기선 훈련을 정방향 역방향(A-B-A,B-A-B) 두개로 하는데 그래야 A판별자 B판별자 둘다 진짜랑 가짜 둘다 볼수있음
	
3.적대손실	
	그리고 또 생성자마다 자기의 판별자를 가지고있는데,거기서 나오는 손실이 적대손실임
	A-B-A순이니 적대손실이 2번일어남(2번바뀌니까)
	즉 사과에서 진짜처럼 보이는 오렌지로 바꿔야하고 변환된 오렌지를 진짜처럼 보이는 사과로 바꿔야함
	
	특히 첫번째판별자가 중요한데,첫번째를 이상하게해버리면 두번쨰꺼까지 같이 영향받음
	
4.동일성 손실
	동일성 손실은 gan이 사진의 전반적인 색 구성(색온도)를 유지하게 하는 규제항임
	꼭 들어가야하는건 아닌데 어지간하면 넣음
	사진의 색조가 원본 이미지의 색조와 일치하게 만드는 규제
	
	이미지에 여러 필터를 적용하고 나서도 원본으로 복원할수 있게 한다고생각하면됨
	
	그래서 이걸위해서 B-A생성자에 A에 이미 있는 이미지를 넣어서 올바른 도메인의 이미지를 이해하게 만듬
	
5.손실정리
	즉 적대손실은 두개의 판별자에 의한 손실로,이미지가 선명하고 진짜 이미지와 구별하기 힘들게 만들고
	사이클 일관성 손실은 정방향 역방향으로 있는데 A-B-A일때 두번변화시킨 이미지가 같게 만믈고 B-A-B일때 두번 변화시킨 이미지가 같게 만듬
	
	즉 둘을 합쳐서 총 4개의 손실임
	
6.구조
	1.전체구조
		사이클GAN은 CGAN을 2개 오토인코더처럼 만들어둔것,첫 GAN을 거친 이미지를 잠재공간이라고 생각하면됨
		
		구조는 A-B-A일때는 AB생성자의 판별자가 진짜이미지를 보고,BA판별자가 변환된 이미지를 봄
		반대일땐 그대로 반대
		
		즉
			진짜이미지가
			AB판별자에게 주입되어 진짜인지 아닌지 판단하고
			생성자에게 주입되어 B로 변환되고
			BA판별자가 진짜인지 아닌지 판단하고
			생성자에게 주입되어 A로 변환해서 
			사이클완성
			
		정리하면
			AB생성자는 A의 진짜사진이나 B에서 A로 변환한 사진을 받아서 B에있는 진짜사진처럼 보이는 이미지를 만듬
			BA생성자는 B의 진짜사진이나 A에서 B로 변환한 사진을 받아서 A에있는 진짜사진처럼 보이는 이미지를 만듬
			A판별자는 A의 진짜사진이나 B에서 A로 변환한 사진을 받아서 이 사진이 진짜일 확률을 뱉음
			B판별자는 B의 진짜사진이나 A에서 B로 변환한 사진을 받아서 이 사진이 진짜일 확률을 뱉음
	
	2.생성자 구조
		생성자는 오토인코더처럼 생긴 구조를 가짐(U-NET)
		128을 입력으로 받으면 64 32 16 8 16 32 64 128로 뱉는식의 오토인코더구조임
		
		그리고 128~8의 인코더는 일반적인 합성곱층을 사용하는데
		인코더의 합성곱층과 디코더의 합성곱층은 같은크기끼리 스킵연결이 있고,
		디코더의 채널 절반은 이 스킵연결에서 옴(디코더는 인코더의 채널의 2배임 인코더채널과 자기가만든채널)
		디코더는 업샘플링층과 마지막합성곱층으로 이미지를 원본이미지와 동일한 크기로 만듬
		
		이 오토인코더들은 다운샘플링하는동안 분류와 넓은 영역을 이해하는데 초점을 맞추고,
		고해상도의 스킵연결로 정확한 분할에 도움이 되는 세부사항을 유지하는것(정확한 위치파악,다운샘플링하면 해상도가줄어서 대충 그위치쯤에 있다식이 되어버리니까 )
		
		즉 이런 오토인코더2개가 모인게 사이클GAN임
		
	3.판별자구조
		판별자는 채널이 하나인 일련의 값임(합성곱구조)이건 나중에 평균내서 확률을 구할수있는 작은 판별자집합이라고 생각할수있음
		이런식의 구조를 한 이유는 합성곱으로만 설계하면 수정얼마안하고 해상도를 올릴수있기때문
		실제구현자체는 기본판별자랑 비슷함
		
7.CYCLE GAN구현
	1.전처리
		사이클gan클래스
			임포트하고
			데이터 전처리하고(이거도 따로 분리되있는데 나중에 필요하면보자 dataloader클래스)
			판별자의 크기 계산하고
			생성자와 판별자 첫 필터갯수 지정하고
			사이클일관성손실 가중치랑 동일성손실 가중치 지정하고
			옵티마이저 설정(adam)
			
	2.신경망 큰틀		
		신경망 구성(INIT)
			A판별자생성
			B판별자생성
			AB판별자컴파일
			
			AB생성자생성
			BA생성자생성
			
			A입력이미지받고
			B입력이미지받고
			
			FAKEB생성(AB생성자로)
			FAKEA생성(BA생성자로)
			B를 A로 되돌리기(BA생성자에 FAKEB넣어서)
			A를 B로 되돌리기(AB생성자에 FAKEA넣어서)
			BA생성자에 A넣기(동일성손실)
			AB생성자에 B넣기(동일성손실)
			
			
			판별자훈련막고
			A판별자에 FAKEA넣어서 변환된이미지 검증
			B판별자에 FAKEB넣어서 변환된이미지 검증
			
			모델 합치기(인풋=이미지A,B 아웃풋=판별자검증A,판별자검증B,되돌리기A,되돌리기B,동일성손실A,동일성손실B)
			연결모델컴파일(LOSS=MSE MSE MAE MAE MAE MAE,LOSSWEIGHTS=1,1,사이클가중치,사이클가중치,동일성가중치,동일성가중치)
		
	3.생성자와 판별자	
		다운샘플링층과 업샘플링 층 만들고
		다운샘플링
			CONV2D(스트라이드2)
			leakyRelu
			기호에따라 샘플정규화
		업샘플링
			upsampling2d
			conv2d
			기호에따라 드롭아웃
			정규화
			concatenate 스킵층이랑 계산값 합치기
		
		
		생성자
			인풋
			d1다운샘플링(초기채널값)
			d2다운샘플링(초기채널값x2)
			d3다운샘플링(초기채널값x4)
			d4다운샘플링(초기채널값x8)
			
			업샘플링(d3과연결,초기채널값x4)//d3은스킵연결,기본적으로 연결되는건 시퀸셜임
			업샘플링(d2과연결,초기채널값x2)
			업샘플링(d1과연결,초기채널값)
			
			upsampling2d(size=2)//출력전작업으로 일반업샘플링,얘는 학습하지않고 단순하게 최근접 이웃 보간 함
			conv2d(이미지채널값(rgb면 3),스트라이드1, acti=tanh)
		
		
		판별자
			인풋
			다운샘플링(초기채널값)
			다운샘플링(초기채널값)
			다운샘플링(초기채널값)
			다운샘플링(초기채널값)
			
			conv2d(1,strides=1)//리턴값
		
		
	4.훈련
		기본적인 순서는
			판별자훈련
				각 데이터셋에서 랜덤이미지의 미니배치를만듬(ab둘다)
				생성자로 a를 b로 변환하고 b를 a로 변환
				진짜a와 가짜a를 판별자가 구분
				가짜b와 진짜b를 판별자가 구분
				둘을 더해서 판별자 전체손실을 얻음(그래프그릴때사용)
				
			생성자훈련
				연결모델을 사용
					a와 b의 이미지를 입력하고
						a와b의 유효성
						a와b의 재구성
						a와b의 동일성 매핑
					을 출력하고
				사이클손실,동일성손실,적대손실을 사용해 생성자의 파라미터를 업데이트함
				판별자확률은(유효성,적대손실) mse사용
				재구성과 동일성은(사이클과 동일성)mae사용
				
				
		코드로보면
			진짜정답생성(배치사이즈만큼)//적대손실 정답
			가짜정답생성(배치사이즈만큼)
			
			에포크만큼 반복
				배치수만큼반복
					AB생성자로 판별자훈련용데이터 생성
					BA생성자로 판별자훈련용데이터 생성
					
					A판별자 진짜데이터랑 진짜정답으로 훈련
					A판별자 가짜데이터랑 가짜정답으로 훈련
					로스 둘다 절반씩 더하기
					
					B판별자 진짜데이터랑 진짜정답으로 훈련
					B판별자 가짜데이터랑 가짜정답으로 훈련
					로스 둘다 절반씩 더하기
					
					로스 둘다 합쳐서 절반더하기(판별자총합손실)//그래프용
					
					생성자 훈련([이미지A,이미지B],[진짜(1),진짜(1),이미지A,이미지B,이미지A,이미지B])//인풋과 Y값
					
	
		
	
7.사이클GAN확장버전
	증식 사이클GAN(생성과정을 조정할수있음,즉 CGAN에서처럼 클래스를 넣을수있음)
	
	근데 요즘은 스타일GAN쓰는듯
	세상빨리변함
	
	



////여기서부턴 별로 안중요한내용

10.적대샘플
	gan과 기본 딥러닝을 포함한 머신러닝은,요즘기준으로는 일반적인상황에선 사람근처까지 성능이 왔지만 그건 정상적인훈련에서 그렇고,
	악의적으로 만들어진 샘플로 훈련을 망가트릴수있음(오차를 최대화하게 만들어진 샘플)
1.예측,나쁜예측,분포
	특히 이미지분류작업에서는 엄청나게 많은픽셀을 가지고있기떄문에 엄청난 경우의수가 나오게됨(희소공간)
	그래서 알고리즘은 일반화를 해야하는데,이게 일반적인상황에선 좋은예측을 하지만,일부러 헷갈리게만드는것에 엄청취약함
2.올바른훈련과 잘못된훈련
	보통 훈련을 할때는 sgd기반의 기울기를 사용하는데,
	오히려 내려가지않고 올라가게 샘플을 만들면 적대샘플임,
	이게 훨씬 더 쉬움(만드는게 부수는거보다 어려움)
	
	사진에 단순잡음을 적용시키기만해도 결과값이 크게달라짐
	
3.신호와 잡음
	단순하게 np.random.normal의 가우스잡음만 써도 엄청쉽게 고장남
4.희망
	그래도 뭐 보통 모델은 훈련이 끝난상태로 예측만 하고,일부러 저런짓까지 해서 넣을일은 잘 없음
5.gan과 적대샘플
	gan으로 적대샘플을 만들수도있고(이미지를 조금 수정해서 분류기를 속이려하는 생성자,속지않으려하는 판별자)
	적대샘플을 사용해서 모델의 안정성을 올릴수도있음















	
	
	
	
	


		
		