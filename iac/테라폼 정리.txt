앤서블,치프등은 이미 만들어진 인프라에 소프트웨어를 설치하고 관리하는데 사용됨(db,서버,네트워크등 )
여기서 가장 중요한건 멱등성이 있어서,실행할때마다 변경사항만 적용된다는것

도커,베이그란트는 컨테이너의 이미지를 만드는것

테라폼,클라우드포메이션은 프로비저닝을 하는데 사용됨(즉 실제로 ec2같은걸 할당받는거)

테라폼의 장점은 여러 플랫폼(aws,gcp,azure)에 똑같이 사용할수있다는것,즉 플랫폼종속성이 없음

테라폼도 선언적으로 작동하고,선언을 하면 거기서 바뀐거만 추가하거나 삭제해서,멱등성이 있음

테라폼은 hcl언어를 사용함

hcl은 기본적으로
	<block> <parameters>{
		키1=밸류1
		키2=밸류2
	}
로 구성됨
만약 파일을 만들거면 만들폴더로 이동해서
	resource "local_file" "pet"{
		filename="/root/pets.txt"
		content='abcd'
	}
여기서 리소스는 키워드임,블록으로 리소스타입을 지정하고,그뒤에(로컬파일)원하는 리소스타입을 적음
로컬파일은 로컬과 파일 2개의 정보인데,앞의 로컬은 프로바이더고(원하는곳)뒤의 파일은 리소스타입임
그뒤의 pet는 리소스이름임

그리고 안의 키밸류들은 아규멘트임
기본적으로 저건 리소스 유형에따라 달라지고,정확한 이름에 따라 거기에 값이 들어가는형태
여기서 파일네임은 이름을 정하고,컨텐츠는 그안에 들어갈 값을 정함
만약 ec2에선 
	resource "aws_instance" "webserver"{
		ami= "ami-0c2f25c1f66a1ff4d"
		instance_type= "t2.micro"
	}
이런식으로 적고,저런 아규멘트를 받아먹음
s3버킷에선
	resource "aws_s3_bucket" "data"{
		bucket="webserver-bucket-org-2207"
		acl="private"
	}
이런식

보통 간단한 테라폼의 워크플로는
	구성파일작성
	terraform init
	terraform plan
	terraform apply
이런식으로 감

여기서 init는 구성파일을 확인하고 그 디렉토리를 초기화하고,리소스에서 작업할수있게(aws같은 클라우드에서 작업할수있게)플러그인을 받음
이때 선언한 리소스에 맞는 플러그인을 자동으로 받음
plan은 이 구성파일을 적용하면 수행할 작업을 미리보기함,여기엔 적용되는 아규멘트들같은거도 다표시되고,전과 바뀐게 뭔지같은게 표시됨
여기서 +기호는 이번적용에 추가된다는거고 -는 빠진다는것 ~는 업데이트,업데이트가있으면 삭제하고 다시생성됨(변경할수없는인프라의경우)
그리고 apply로 적용하면됨
만약 삭제하고싶으면 terraform destroy하면됨

그리고 terraform show로 만든 리소스의 세부정보를 볼수도있음(플랜에서 표시되던거와 같음)
그리고 저기서 리소스타입과 아규멘트는 종류마다 다르니까(aws랑 구글이랑 아주레랑) 테라폼공식도큐가서 찾아서쓰래

init할때 프로바이더엔 
	공식프로바이더(aws,구글같은 큰데,로컬프로바이더),
	검증된프로바이더(해쉬코프랑 파트너맺은 작은곳),
	커뮤니티프로바이더(개인이올린거,검증안됨)
가 있음
이때 보이는 플러그인이름도 기본적으론 조직이름/타입(플러그인이름) 으로 적힘
	hasgicorp/local
이때 그 앞에 호스트네임이 붙을수있음(레지스트리이름)이건 기본값레지스트리가 아닐경우 붙음
	terraform.io/hasgicorp/local
기본적으론 최신버전을 받지만,당연히 여기도 버전명시해서 고정으로받는게 좋음


테라폼은 지정폴더에 있는 모든 tf파일을 실행함,그리고 단일tf파일에 여러개의 리소스가 들어갈수도있음




프로바이더엔 뭐 이상한거 다있는데,랜덤도 있음
	resource "random_pet" "mypet"{
		prefix="Mrs"  //접두사,앞에 붙음
		separator="."//접두사와 이름사이 구분기호
		length="1" //펫이름길이
	}


변수를 사용할땐,변수파일을 만들어두고
	variable "변수명"{default="디폴트값"}
	
	filename=var.변수명
으로 불러오면됨
이때 변수의 파라미터엔 3개가 있음
	variable "변수명"{
		default="디폴트값"
		type=string  //타입,옵션이긴한데 있는게좋음,
		description //주석,옵션임
	}

타입은
	string
	number
	bool
	any
	list  //["a","b","c"]  filename=var.변수명[1]으로 참조가능,list(string)이런식의선언도 가능
	map   //{"a":1,"b":2,"c":3}  filename=var.변수명["a"]로 참조가능  map(string)도 가능
	set   //["a","b","c"]이건 리스트랑 비슷한데 중복이 불가능함,수학에서 집합이라보면됨
	object//객체임,여러값을 가지고있는 단일객체를 넣을수있음
			type=object({
				name=string
				color=string
				age=number
				food=list(string)
			})
	tuple  //[string,number,bool] ["cat",2,true]이렇게 여러타입을 묶어서 하나로쓸수있음
를 지원함	
안적으면 any들어감(아무거나다되는거)

그리고 terraform apply뒤에 -var "변수명=값"으로 그 변수명의 값을 바꿀수있음
	terraform apply -var "filename=/root/ppt.txt" -var "content=abcd"
아니면
	export TF_VAR_변수명="abcd"
	terraform apply
할수도있음
그리고 이런걸 terraform.tfvars나 terraform.tfvars.json,*.auto.tfvars,*.auto.tfvars.json에 넣어두면 자동으로 로드해서 적용함
	terraform.tfvars안에
		filename="abcd"
		content="fff"

자동적용을 원하지않으면,*.tfvars로 만들고 terraform apply -var-file 파일이름.tfvars로 적용할수도있음
그리고 아예 기본값을 안주고 타입만 줄수도있는데 이러면 파일명을 안받으면 에러나게 할수있음

그리고 변수의 적용순서는
	export로 적은거
	tfvar에 적힌변수
	*.auto.tfvars에 적힌변수(알파벳순)
	-var로 apply에 수동입력한거 
순으로 덮어씌워짐

중요한건,tfvars는 값을 넣는거지,변수를 선언하는게 아니라서 변수를 선언하는건 꼭 필요함(.tf에 변수선언)

그리고 만약 어떤 리소스가 다른리소스에 종속성을 가지게하려면(그리소스의 특정값을 가져간다던가)
이경우엔
	${리소스유형.리소스이름.가져갈값}
	${random_pet.my_pet.id}
	content="my ff is ${random_pet.my_pet.id}"
이런식으로 하면됨

이렇게되면 종속성을 주는(값을 주는)쪽부터 먼저 만들고 그값을 받는애를 그 뒤에 만들게됨
삭제할때도 역순으로 함
이렇게 생기는 종속성이 암시적 종속성임
아예 이걸 명시적으로 줄수도 있음
	resource "local_file" "pet"{
		filename="/root/pets.txt"
		content='abcd'
		depends_on=[
			random_pet.my-pet
		]
	}
	depends_on으로 종속항목을 추가할수있음
	이건 리소스가 다른 리소스에 간접적으로 의존할때만 사용함(직접 명시적으로 적을수없을때 이거로 강제로 종속성을 박음)
	즉 거기서 무슨값을 가져오는건 아닌데,그게 있어야 존재할수있을때



그리고 뭘 출력하고싶으면
	output 이름{
		value=출력할값,참조표현식이어야함
		description="설명"
	}
으로 출력할수있음
이걸 tf파일에 넣으면,apply할떄 outputs에 표시됨
terraform output으로 저거만 볼수도있음 
특정값만 보려면
	terraform output 변수명
으로 특정값만 볼수도있음
저거로 원하는값을 빼서 쉘스크립트나 엔서블에 줘서 그쪽에서 보고 대응하는식으로 사용함

테라폼은 apply로 변경할때,변경점이 있는지 없는지 알려고 terraform.tfstate파일을 같은디렉토리에 생성함
그걸보고 변경점이 있는지,아니면 아예 처음만드는건지 등등을 알아봄
만약 변경점이 있으면,그 리소스를 디스트로이하고 다시 크리에이트함,그래서 id값이 바뀜
사라진게 있으면 스테이트에서 삭제하는식

테라폼에선,일단 스테이트파일을 만들거나 업데이트하고,그걸가지고 적용함,일단 스테이트파일생성이 우선이고 그걸 적용하는식임
이렇게하면 대용량리소스생성에선 많이느려서,terraform plan --refresh=false하면 파일을 생성하지않음(스테이트를 사용하지않음)
이건 plan에만 적용됨
그리고 show같은거로 보는거도,사실은 저 상태를 보는거임

상태를 만들면 좋은건,모든사람이 최신의 형태를 가지고 작업하게된다는것(파일에 의존하니까)
물론 이렇게하려면 깃저장소같은곳에서 작업을 해야함(aws의 s3버킷같은곳이라든가)

그리고 스테이트파일엔,민감한정보(비밀번호같은)들이 들어있기때문에 조심해야함,그래서 깃퍼블릭을 쓰지말고,s3나 깃프라이빗을 쓰는게 좋음
그리고 기본적으로 tfstate파일을 직접 편집하면 안됨
만약 편집해야하면 Terraform State명령으로 해야함

terraform validate는 그폴더의 파일들이 문법적으로 정상적인지 확인함
문제가 있으면 그 행번호와 무슨문제인지를 표시해줌
이건 일반 문법만 검사하지,종속성은 검사하지않음

terraform fmt는 현재폴더에서 변경된 파일을(apply했을때 변화가있는)표시해줌

terraform show는 현재 스테이트를 표시해줌,만약 생성을 안했으면(apply안하면)아무것도안나옴
terraform show -json으로 json으로 뽑을수도있음

terraform providers는 현재 폴더내에서 사용중인 모든 프로바이더를 표시함
이건 파일과 상태 둘다 따로 표시됨
terraform providers mirror 다른디렉토리/123/ 으로 다른디렉토리로 현재플러그인을 복사할수도있음

terraform output은 아웃풋값을 볼수있음
terraform output 아웃풋이름 으로 특정아웃풋만 볼수도있음 

terraform refresh는 테라폼이 바꾸지않은 값이 바뀌었을때,상태를 거기맞춰서 업데이트할때 사용함
만약 다른사람이 aws에 테라폼으로 업데이트를 했을때,그 상태에 맞춰서 현재 내 상태를 업데이트하는(다운로드받는)명령어임
이걸 사용하면 스테이트는 업데이트되지만,tf파일등은 업데이트되지않음

terraform graph는 종속성을 시각적으로 표시해줌
이거자체론 알아보기힘든데,다른 시각화소프트웨어(graphviz)등으로 전달해서 쉽게 볼수있음
terraform graph | dot -Tsvg > graph.svg



만약 인프라가 변경불가능한 인프라일경우,삭제후 재생성하고,변경가능한 인프라일경우 바뀐부분만 바꿈
윈도우 재설치와 윈도우 업데이트라고 생각하면됨
변경불가능한 인프라는 안에 들어있던 모든게 날아가고,변경가능한 인프라는 남아있음

configration drift는 구성파일이 다른것과 달라지는것(3개서버가 있을때 2개서버가 1.19고 한개가 1.18일떄)
변경가능한 인프라에서 업데이트를 실패했을때 이런일이 생길수있음
그래서 변경불가능한 인프라를 써서,롤링업데이트하는식으로 쓰는게 보통임
그러다가 한개가 실패하면 백업한거 롤백하던가 하는식

테라폼은 기본적으로 삭제후 생성을 하는데,생성후 삭제를 하게하려면 리소스내에
		resource "local_file" "pet"{
			filename="/root/pets.txt"
			content='abcd'
			lifecycle{
				create_before_destroy=true
			}

		]
	}
이건 주의점이,만약 생성과 삭제가 파일같은 같은디렉토리에 두개이상 같은이름으로 존재할수없을땐,덮어씌우고 삭제를해버림
그래서 파일같은게 아닌 논리적으로 메모리에 들어있는거만 써야함

만약 특정 리소스의 삭제를 못하게하려면
	lifecycle{
		prevent_destroy=true
	}
하면 삭제를 막을수있음,단 이건 apply를 통한 변경을 막는거라서 terraform destroy는 막을수없음

그리고 테라폼 외부에서 상태를 수정하면(aws대시보드에서 이름을 바꾼다던가)
그걸 원래대로 되돌리려고 하는데 테라폼은(테라폼에 적힌상태대로 돌릴려고함),그걸 막으려면
	lifecycle{
		ignore_changes=[
			바꿔도되는값(이름같은)
		]
	}
저기 들어가있는건 바뀌어도 그냥 무시됨
이건 리소스가 계속 뭘해서 뭘 만든다던가 할떄(변경사항이 계속있을떄)유용함
저기 ignore_changes안에 all을 넣으면(ignore_changes=all)모든 변경사항을 무시함


테라폼에서 데이터소스를 사용하면,리소스에서 속성을 읽을수있으며,제어범위를 벗어난 프로비저닝이 가능해짐
이걸 사용하는방법은
	data "local_file" "리소스이름"{
		filename="abcd/aa.txt"
	}
이렇게 하면 이미 만들어진 리소스의 값을 가져다쓸수있음
가져다쓸떈 data.local_file.리소스이름.content 이렇게 리소스를 불러서 값을가져오면됨
datasource는 readonly라서,그냥 읽기만할수있고 변경점을 줄순없음

테라폼에서 같은리소스의 여러파일을 만들때는 메타아규멘트를 사용함
이건 depends_on,lifecycle과 같은 테라폼자체의 시스템적인?키워드임

정확히는 count를 사용함
이건 그냥
	resource "local_file" "pet"{
		filename="/root/pets.txt"
		content='abcd'
		count =3
	
이렇게 카운트를 넣어주면됨
이렇게 만들면 배열에 3개를 넣어서 만드는데(local_file.pet[0~2]),
문제는 파일을 생성한다던가 하는 유일성을 가지는 객체를 생성할경우엔(파일생성같은),그냥 같은걸 3번만들어서 다 덮어씌워짐
이경우엔 여러해결방법이 있는데,파일네임같은 변수에 배열로 넣어주던가
	variable "변수명"{
		default=["abc.txt",""bcd.txt,"cdf.txt"]

	}
	resource "local_file" "pet"{
		filename=var.filename[count.index]
		content='abcd'
		count =3

이렇게되면 딱 카운트갯수에 맞는 정적값으로 들어가게됨
이걸 변수에 선언된 디폴트값의 갯수로 하려면
	count=length(var.filename)
으로 할수있음
근데 이건 문제가,만약 0번을 지우고싶어서 지우면 그냥 1번과 2번이 앞으로 땡겨져서 그자리를 차지하는데,
이때 앞에있는걸 땡기면 리플레이스되면서 다 디스트로이되고 재생성되는게 문제임
즉 0번은 1번으로 바뀌고 1번은 2번으로 바뀌고 2번이 디스트로이됨,원한건 0번만 디스트로이인데

그래서 대신 사용하는게 foreach임,이건 0번부터 반복문돌리는게 아니라,목록에 있는거를 가지고 반복문을 돌려서 없어진거만 체크할수있음(딴데foreach랑같음)
이건 카운트자리에 그대로쓰면됨
	resource "local_file" "pet"{
		filename=each.value		
		for_each=var.filename
근데 그냥 이렇게하면,foreach는 리스트를 받아먹을수가 없어서 에러가남,그래서 변수의 타입을 set(string)처럼 집합으로 설정해줘야함
	variable "변수명"{
		default=["abc.txt",""bcd.txt,"cdf.txt"]
		type=set(string)

	}
그냥 리스트로 두고싶으면 for_each쪽에서 set으로 바꾸는방법도있긴함
	for_each=toset(var.filename)
	
이렇게 for_each를 쓰면,값이 리스트가 아닌 맵으로 저장되게됨
즉 리소스가 인덱스로 식별되지않고 키:밸류로 식별됨

테라폼에서 특정플러그인에 무슨버전이 있는지는,테라폼 레지스트리사이트가서 검색하면 나옴
테라폼에서 init로 플러그인을 받을때,버전을 명시하려면
	terraform{
		required_providers{
			local={
				source="hasgicorp/local"
				version="1.4.0"
			}
		}
	}
이걸 tf파일 맨위에 넣으면됨
여기서 버전은
	version="!=1.4.0"(저게아닌 가능한 최신버전)
	version="< 1.4.0"(1.4.0보다 작은버전)
	version="> 1.4.0"(1.4.0보다 큰버전)
	version="> 1.2.0,<2.0.0,!=1.4.0"(1.2.0보다 크고 2.0.0보다 작은 1.4.0이 아닌버전)
	version="~> 1.2.0"(1.2.0에서 0에다가 숫자붙은 패치를 허용한다는것(1.2.3 이런거))
	version="<= 1.4.0"(1.4.0보다 같거나 작은버전)
저 조건을 만족하는 가장 큰값으로 버전이 붙음(최대한 최신버전에 가까워지려고함)



뭐 aws에서 iam그룹을 꼭 사용해야하고, 루트계정을 사용하지마래
루트계정은 첫 iam사용자를 만들기위해서 사용하는거라는 그런소리

iam은 글로벌로 한번생성하면 모든리전에서 사용할수있음
그리고 유저를 생성할때,액세스타입을 고를수있는데 프로그래머식(코드로 접근)과 콘솔로 접근 둘중 하나이상(둘다도됨)선택하면됨
콘솔로 접근할땐 패스워드가 필요하니까 비밀번호를 설정할수있음
근데 이건 별로 필요없고,만들고나면 액세스키아이디랑 액세스키패스워드가 나오는데 이걸로 터미널에서 접근할수있음
그리고 권한에서 *은 와일드카드로 전부허용이라는뜻

그리고 그룹을 만들수도있는데,그 그룹에 적용할 정책은 기본값으로 보통 다 있고,필요하면 만들수도있음

롤을 만들땐,어떤거에 연결할지(서비스나 aws어카운트나)를 고르고,어떤리소스를 사용할지 고르고,거기에 따른 정책(폴리시)를 적용하면됨

터미널에서 aws iwc계정에 연결하려면
	aws configure
를 치고 액세스키 아이디 패스워드를 넣고 리전을 적고 yaml이나 json등 아웃풋형식을 뭐로할지 선택하면됨

이값은 .aws/config/config에 있으니까 거기가서 값바꿀수있고(리전과 아웃풋)
로그인값은 .aws/config/credentials에 있음(액세스키 액세스패스워드)

기본적으로 awscli는 aws 커맨드 서브커맨드 옵션    으로 이루어짐 
	aws 커맨드   서브커맨드          옵션
	aws iam create-user --user-name lucy
이런식

aws --version은 버전보기
aws iam은 권한관련
aws iam list-users는 iam유저를 전부 나열

그리고 접근경로를 줄땐 --endpoint옵션으로 주면됨
	aws --endpoint http://aws:4566 iam list-users
이런식,그리고 vi에서 페이지이동은 f,g로 움직일수있음

어떤 유저에 정책 적용방법은
	aws --endpoint http://aws:4566 iam attach-user-policy --user-name mary --policy-arn arn:aws:iam::aws:policy/AdministratorAccess
attach-user-policy를 써서 유저네임으로 유저특정하고 policy-arn으로 정책특정하면됨

그룹 생성은
	aws --endpoint http://aws:4566 iam create-group --group-name 그룹명
	
그룹에 사람추가는
	aws --endpoint http://aws:4566 iam add-user-to-group --user-name 유저명 --group-name 그룹명
	
그룹에 정책추가는
	aws --endpoint http://aws:4566 iam attach-group-policy --group-name 그룹명 --policy-arn 정책명

그룹의 정책 보기는
	aws --endpoint http://aws:4566 iam list-attached-group-policies --group-name 그룹명
개인의 정책보기는
	aws --endpoint http://aws:4566 iam list-attached-user-policies --user-name 유저명


테라폼에서 aws_iam쓸땐
	resource "aws_iam_user" "admin-user"{
		name="이름"
		tags={
			Description="주석"
		}
	}
name은 필수인수
그리고 plan날리면 리전을 입력하라고 나옴,그리고 자격증명도 없다고나옴
이걸 해결하려면 리소스위에(파일 맨위에)
	provider "aws"{
		region="us-west-2"
		access_key="키값"
		secret_key="패스워드값"
	}
을 넣으면됨
이거말고 좀 안보이게 하고싶으면(tf파일은 다보이니까).aws/config/credentials에 적어두면(키값) 거기서 알아서 가져옴
말고 다른방법은 export AWS_ACCESS_KEY_ID와 export AWS_SECRET_ACCESS_KEY_ID를 앞에 먼저 적어두면되긴함
리전도 export AWS_REGION=us-west-2 이렇게할수있음

이런식으로 엔드포인트를 줄수도있음
	provider "aws" {
	  region                      = "us-east-1"
	  skip_credentials_validation = true
	  skip_requesting_account_id  = true

	  endpoints {
		iam                       = "http://aws:4566"
	  }
	}

테라폼에서 aws iam policy쓸땐
	resource "aws_iam_policy" "adminUser"{
		name="AdminUsers"
		policy=<<EOF
		{
			json내용
		}
		
		
		EOF
	}
여기 폴리시에 json파일을 제공하는건 저렇게 직접적을수도있고 파일로 연결할수도있음
	policy=file("admin-policy.json")

그리고 유저와 폴리시를 연결하는건
	resource "aws_iam_user_policy_attachment" "lucy-admin-access"{
		user=aws.iam.user.admin-user.name
		policy-arn=aws_iam_policy.adminUser.arn
	}
이렇게 연결하면됨




aws s3는 객체기반 스토리지임
얘는 비디오,사진,텍스트같은걸 넣는용도지,여기는 os나 db를 넣는곳이 아님
얘는 버킷단위로 생성되는데,그 버킷이 객체임

버킷은 모든리전에서 동일하게 접근할수있고,각 계정별로 이름은 당연히 별도임(계정끼리는 이름겹칠수있고,계정내에선 이름못겹침)
그리고 버킷의 이름은 dns와 호환되어야함
	대문자가 아니어야하고,밑줄사용금지(-(대쉬) 사용),3자~63자까지 제한이 있음
버킷의 최대크기는 5tb임

버킷의 접근은
	https://버킷이름.s3.리전.amazonaws.com
임
버킷내 파일은 
	https://버킷이름.s3.리전.amazonaws.com/abc.txt

기본적으론 버킷에 버킷소유자를 제외한 아무도 접근할수없음
거기서 정책을 추가해서 접근가능하게 만들수있음
	{
		V
	}

테라폼에서 s3버킷생성은
	resource "aws_s3_bucket" "abcd"{
		bucket="finanace-21092020" //버킷의 실제 이름,옵션임,이게없으면 랜덤한 이름으로 알아서 생성함
		tags={
			description="주석"//주석,옵션
		}
		acl="public-read-write" //버킷 접근 가능조건
  
	}
이렇게 사용함 기본적으로
테라폼에서 버킷에 업로드는은
	resource "aws_s3_bucket_object" "abcd123"{
		source="업로드할파일주소"
		key="파일이름"
		bucket=aws_s3_bucket.abcd.id
		
	}
이렇게 사용해서 업로드할수있음

aws에서 이미 만들어둔 그룹을 테라폼에 가져오려면
	data "aws_iam_group" "abcddata"{
		group_name="그룹이름" //내계정의 특정그룹을 가져옴
	}
테라폼에서 버킷정책을 적용할떈
	resource "aws_s3_bucket_policy" "abcd-policy"{
		bucket=aws_s3_bucket.abcd.id
		policy=file("정책파일.json)
	}
이렇게 id와 정책을 줘서 적용할수있음
그리고 정책파일내에서도
	"AWS":[
		"$(data.aws_iam_group.abcddata.arn)"
	]
으로 위의 변수같은걸 참조할수있음


dynamoDB는 awsdb임
얘는 기본적으로 nosql임(키밸류로 저장함)

이 디비에서 하나의 로우를 아이템이라고 부름
여기서 저장은
	{
		"a":"1",
		"b":"2",
		"c":"3",
		"d":"4",
		
		
	}
	{
		"a":"5",
		"b":"6",
		"c":"7",
		"d":"8",
		
		
	}
이런식으로 저장됨
a=5인 아이템을 가져와서 값을 받는식(보통 프라이머리키를 사용)
당연히 프라이머리키는 비어있으면 안되고,나머지는 당연히 비어있어도됨

aws콘솔에서의 db생성은 그냥 테이블이름만들고 프라이머리키 지정하면 일단 만들수있음
그리고 크리에이트아이템으로 항목들을 추가하면됨(rbms가 아니니까 그렇게 빡빡하지않음)
그리고 항목마다 컬럼이 다를경우,일단 모든 컬럼을 표시하고 그 아이템에 없는컬럼은 null임
그리고 검색할땐 필터로 검색하면됨


테라폼에서 dynamoDB를 생성할땐
	resource "aws_dynamodb_table" "abcd"{
		name ="테이블이름"
		hash_key="serial"//프라이머리키 이름
		billing_mode="PAY_PER_REQUEST"//요금청구방식
		attribute{  //실제 넣을 컬럼,프라이머리키는 필수임,여기서 넣는건 필수로 들어가는애들만 넣으면됨,나머지는 아이템넣을때 맘대로넣으면됨
			name="name"
			type="S"
	
	}
만약 들어가는걸 전부넣고싶으면 인덱스도 같이 설정해야하는데
	attribute{
		name="serial"
		type="S"
	}
	global_secondry_index{
		name="serial"
		hash_key="serial"
		projection_type="ALL"
	}
이렇게 인덱스를 걸어줘야함,정확히는 저기에서 인덱스를 만들수있어서,필수 프라이머리키와 인덱스만들 컬럼만 나열하는것	
아이템을 넣을떈
	resource "aws_dynamodb_table_item" "car"{
		table_name=aws_dynamodb_table.abcd.name
		hash_key=aws_dynamodb_table.abcd.hash_key
		item= file(item.json) //EOF로 안에다 하드코딩할수도있음
	}
여기서 아이템에서 기대하는건 json형식에 타입:값으로 묶어지길 바라기떄문에,그거로 바꿔줘야함
	
	{
		"name"={"S":"abcdde"}
		"serial"={"S":"1122aaa"}
		"birth"={"S":"19221110"}
		"age"={"N":"32"}//n도 스트링처리해줘야함
	}




기본적으로 연습할떄말고 팀에 들어가서 관리할떈,tfstate를 로컬에 두면 안되고 클라우드같은 공용위치에서 상태가 변화하게 해야함
컨피그파일(tf파일)은 로컬이나 깃헙같은데서 버전관리하면서 있으면되지만,state는 공용위치에 있어야한다는것
일단 상태가 통일된다는게 첫째,스테이트파일의 민감한 정보가 클라우드에 박혀있어서 안전하다는게 둘째임(깃헙같은거로 스테이트공유못하는이유)

이렇게 하려면,제일쉬운방법은,로컬에서 작업을하고 tfstate가 나온뒤 그걸 자동으로 s3버킷같은데 업로드되게 하고,tf파일은 깃헙에 업로드되게할수 있긴함
근데 이거의 문제는 여러명이 작업을할때 동시에 작업을하면 무슨문제가 생길지 모른다는게 첫째
tf파일의 정보가 git에 올라간다는게 두번째임
일단 테라폼에서 동시에 작업되는걸 막아주긴함(트랜잭션같은느낌)이걸 state locking라고 부름
그리고 최신버전을 까먹고 git에서 안가져왔으면 그냥 예전버전에다가 했으면 작업한거 다날리고,혹은 리소스가 삭제될수도있음

그래서 tf파일도 공유스토리지(s3버킷같은)곳에서 작업을 함(변경사항있으면 자동저장되게,그리고 얘네들은 스테이트록킹을 지원해서 중복이 안일어나게만듬)

이렇게하면 테라폼은 공유스토리지에서 tf파일을 읽어서,그걸 적용시키고 state로 만듬
그러니까 s3버킷 2가지가 필요함(스테이트와 tf파일)


이렇게 하려면,로컬에있는 main.tf의 위에 테라폼 백엔드블록을 넣으면됨
	terraform{
		backend "s3"{
			bucket="버킷이름" //필수
			key="abcd/abcd.tfstate"//스테이트파일 저장할위치 필수
			region="us-west-1"//필수
			dynamodb_table="state-locking"//옵션
		}
	}
근데 관행적으로 이건 main.tf에 저장하지않고 terraform.tf에 저장함

이걸 사용하고 init를 하면 기본 상태파일을 로컬에 만들고, 로컬 상태파일을 원격s3로 복사해넣음,그리고 로컬 스테이트를 삭제하면됨
그리고나서 plan이나 apply를 하면 s3버킷에 있는 스테이트가 잠기고 s3버킷에서 스테이트를 메모리에 받고 변경해서 다시 업로드하고(apply만) 삭제함
plan은 받아서 확인만하고 삭제함


state파일은 텍스트에디터로 수정하면 안됨
state를 수정하는건
	terraform state 서브커맨드 
로 수정을 해야함

스테이트를 보려면
	terraform state show 리소스종류.리소스이름

state 커맨드엔
	list
	mv
	pull
	rm
	show
5개가 제일 주로쓰이고,나머지몇개가 있음


terraform state list는 현재 스테이트파일의 모든 리소스를 나열함
이건 리소스종류.리소스이름만 출력하고 나머지는 출력하지않음

있는지 없는지 볼때
	terraform state list 리소스종류.리소스이름
하고 리턴이 있으면 있는거고,없으면 없는거임

특정 리소스의 세부정보를 보고싶으면 
	terraform state show 리소스종류.리소스이름
하면됨

스테이트를 이동시킬땐(이름변경이나,리소스를 한단계 아래나 위처럼 이동시키고싶을때)
이름변경은
	terraform state mv 출발지리소스종류.리소스이름 도착지리소스종류.리소스이름
단계이동은
	terraform state mv abc.worker qqq.ivv.abc.worker
아예 모듈째로 자식으로 넣을수도있음
	terraform state mv module.app module.parent.module.app
근데 이럴거면 그냥 tf파일 바꾸고 업데이트하면되지않나?


원격저장소에서 스테이트파일을 땡겨오고싶을땐
	terraform state pull
이렇게하면 그위치의 스테이트파일을 땡겨오는데, 
	terraform state pull | jq ...
로 json을 파싱해서 원하는거만 볼수도있음 


스테이트의 리소스를 삭제하고싶으면
	terraform state rm 리소스종류.리소스이름
하면 삭제됨

기본적으로 state명령어들은 현재폴더의 스테이트파일이나,tf파일의 테라폼블럭에 있는 스테이트저장위치(pull의경우)를 보고 작동함
그리고 rm같은건 잘 사용하지않고,리스트와 show로 다른 tf파일에서 다른곳에 생성된 리소스의 정보를 가져올때 사용하는듯
그리고 아웃풋을 참조하고싶을때는
이경우엔
	${data.terraform_remote_stste.리소스이름.리소스아웃풋이름}



aws에서 가장 메인이되는건 ec2임
얘는 기본적으로 리눅스나 윈도우로 배포되는데
용도는 db서버,웹서버 앱소프트웨어 배포용임 대표적으로
이거말고도 이거나저거나 다사용가능함

ec2에서 매번 나오는 AMI는 Amazon Machine Image임,즉 사용할 os 고르는거
그리고 Instance Types는 ec2의 종류(gpu가 달렸냐,cpu의 성능 등)를 고르는거
기본은 general purpose임
여기서 (제너럴에서) 또 나뉘는데
	T2
	T3
	M5
로 cpu등급이 나뉘고
그안에서 T2의 경우(t2.namo같은)
	nano    cpu1 메모리 0.5gb
	micro   cpu1 메모리 1gb
	small   cpu1 메모리 2gb
	medium  cpu2 메모리 4gb
	large   cpu2 메모리 8gb
	xlarge  cpu4 메모리 16gb
	2xlarge cpu8 메모리 32gb
로 세분됨
그리고 이 컴퓨터에 ebs볼륨을 연결해서 하드디스크로 사용함
ebs의 종류는
	io1  가장빠른 ssd
	io2  좀 빠른 ssd
	gp2  기본(general purpose)
	st1  가격싼 hdd
	sc1  제일싸고느린 hdd

그리고 ebs는 생성중인 인스턴스에 사용자데이터를 미리 넣어둘수도있고,스크립트를 실행할수도 있음(쉘스크립트같은거로 미리 설치)

ec2가 배포되면 리눅스는 ssh키로 접근할수있고,윈도우는 유저네임/패스워드로 접근할수있음

기본적으로 ec2는 관리콘솔에서 가장 간단하게 만들수있음
aws management console에서 ec2를 찾거나 launch a virtual muchine누르면됨
그러면 ec2 콘솔로 넘어가지는데,거기서 리전을 확인하고(상단오른쪽)
런치 인스턴스를 누르면 ami를 선택하라고 나옴
거기서 os를 선택하면 

인스턴스 타입을 선택하라고 나옴
거기서 자기가 쓸만큼 큰걸 고르면됨

그러면 디테일세팅창이 나옴(vpc같은),그냥 기본값으로 줘도됨 일단
네트워크가 vpc선택이고
서브넷은 서브넷(vpc내의 서브넷)
그리고 맨밑에보면 유저데이터가 있는데(어드밴스드 디테일),
여기에서 쉘스크립트를 넣어서 엔진엑스같은걸 설치하면됨(그냥 바로 유저데이터에 쉘스크립트내용 복사하면됨 #!bin/bash로 시작하는)

그리고나면 스토리지 추가가 나옴
일단 기본값 쓰면됨(gp2)

그리고나면 태그를 달수있음

그리고 보안그룹설정을 함,여기서 ssh설정을 하면됨
일단이름을 만들고,타입을 ssh로 바꾸고,소스를 자기의 ip대역에 맞추면됨(0.0.0.0이면 퍼블릭임)

그리고나면 마지막으로 확인하고,런치누르면 됨
그러면 키페어를 선택하라고 나오는데,키페어를 만들거나 있는거 선택하면됨
없으면 크리에이트 키페어로 만들고 다운로드받으면됨,이건 ssh말고 다르게접속할때 사용됨

그리고 인스턴스에 들어가면,id나 ip,vpc등을 볼수있음
인스턴스의 시큐리티탭에는 시큐리티정보,
네트워크에는 퍼블릭ip,프라이빗ip,
스토리지엔 ebs볼륨을 볼수있음

ssh로 접속할땐
	ssh -i ~/다운로드받은키페어.pem ubuntu@퍼블릭ip  
로 접속하면됨,저 우분투는 os마다 바꿔주면됨
그리고 권한에러나면
	chmod 400 ~/다운로드받은키페어.pem
로 권한주면됨




테라폼에서 ec2를 생성할땐
	resource "aws_instance" "abcdserver"{
		ami="ami-0edab43b6fa892279"//필수
		instance_type="t2.micro"   //필수
		tags={ 						//옵션
			abc="aaa"
			bcd="bbb"
		}
		user_data=<<-EOF            //옵션
			#!/bin/bash
			스크립트내용
		EOF
		key_name =aws_key_pair.web.id  //사용할키
		vpe_security_group_ids=[aws_security_group.ssh-access.id]
		
		
	}
	resource "aws_key_pair" "web"{
		key_name="aaabbb"//옵션,이게있으면 다른데서 참조할때 리소스나열할필요없이 이거로참조가능
		public_key=file("퍼블릭키파일의 위치/퍼블릭키이름.pub")
	}
	resource "aws_security_group" "ssh-access"{
		name="생성할 그룹이름"
		description="주석"
		ingress{
			from_port= 22
			to_port= 22
			protocol="tcp"
			cidr_blocks=["0.0.0.0/0"] //내가 사용할 ip대역
		}
		
	}
	output publicip{
		value=aws_instance.abcdserver.public_ip
	}
여기서 ami는,os값으로,aws도큐맨트에서 값을 찾아다써야함 해당os에 맞는값을
그리고 인스턴스타입은 사용할 머신성능이고
밑에 tags={abc="aaa"}처럼 태그를 달수도있음
그리고 유저데이터는 file()로도 가능함

aws_key_pair는 생성된 ec2에서 키에 접근할수있게 만드는 리소스임
파일형태도 되고,당연히 스트링형태도 됨
저기서 key_name을 지정하면 aws_instance에서 key_name="정해둔키네임"으로 짧게적을수도있음


aws_security_group은 생성된 ec2에 접근할 포트와,허용할 ip대역을 만드는 리소스임

아웃풋은 생성된 인스턴스의 퍼블릭 ip를 리턴함

이걸 apply하면됨




그리고 이 생성한 ec2에 접근하려면
	ssh -i /아까정한키파일있는폴더 ubuntu@리턴받은퍼블릭ip
하면 접속됨




테라폼에서 리소스내에
	resource "aws_instance" "abcdserver"{
		ami="ami-0edab43b6fa892279"//필수
		instance_type="t2.micro"   //필수
		tags={ 						//옵션
			abc="aaa"
			bcd="bbb"
		}
		provisioner "remote-exec"{
			inline=[
				"sudo apt update",
				"sudo apt install nginx -y"
			]
		}
		key_name =aws_key_pair.web.id  //사용할키
		vpe_security_group_ids=[aws_security_group.ssh-access.id]
		
		
	} 

이렇게 프로비저너를 넣어서 원격으로 스크립트를 실행시킬수도 있음
프로비저너의 종류엔
	local-exec  //로컬에서 스크립트실행
	remote-exec //원격에서 스크립트실행 
	chep        //원격에서 치프실행
	file        //원격리소스로 파일복사
등이 있음
그런데 리눅스의경우 로컬시스템과 원격인스턴스간에 네트워크로 연결이 되어야함(그 ssh로 연결가능한 ip랑 그거)
윈도우의경우 리소스생성시 설정한 시큐리티그룹으로 가능함

리눅스에선 리소스내에 
	resource "aws_instance" "abcdserver"{
		ami="ami-0edab43b6fa892279"//필수
		instance_type="t2.micro"   //필수
		tags={ 						//옵션
			abc="aaa"
			bcd="bbb"
		}
		connection { 
			type ="ssh" 
			host =self.public_ip 
			user="ubuntu" 
			private_key = tls_private_key.example.private_key_pem  //file()도 가능
		}
		provisioner "remote-exec"{
			inline=[
				"sudo apt update",
				"sudo apt install nginx -y"
			]
		}
		key_name =aws_key_pair.web.id  //사용할키
		vpe_security_group_ids=[aws_security_group.ssh-access.id]
		
		
	} 

저렇게 커넥션이 들어가야함,저게 프로비저너 하위에 있으면 그 프로비저너에만 영향을미치고,리소스하위에있으면 그 리소스내의 모든 프로비저너에 영향을줌
그리고 inlile는 커맨드를 적는거고,파일을 쓰고싶으면 script="파일주소/파일명.sh" 쓰면됨

이렇게 어플라이하면 커맨드에 remote-exec가 작업하는게 나옴



그리고 리소스없이 프로비저너를 쓰고싶으면 null_resource를 쓰면됨
	resource "null_resource" "ssh"{
		provider "local-exec"{
			script="파일주소/파일명.sh"
		}
	}


그리고 aws리소스내에서 local-exec를 써서
	provisioner "local-exec"{
		inline=[
			"echo ${aws_instance.abcdserver.public_ip}>>/tmp/ips.txt"

		]
	}
이런식으로 값을 뺴오거나,로그저장하는거도 가능함

그리고 프로비저너는 값이 파괴될때 실행하는거도 가능함
	provisioner "local-exec"{
		when=destroy
		inline=[
			"echo ${aws_instance.abcdserver.public_ip}>>/tmp/ips.txt"

		]
	}
그리고 프로비저너가 에러났을때의 대처도 가능
	provisioner "local-exec"{
		on_failure=fail
		inline=[
			"echo ${aws_instance.abcdserver.public_ip}>>/tmp/ips.txt"

		]
	}
on_failure이 continue면 오류를 무시하고 하던일을 함
abort면 생성또는 삭제를 중단함,이미처리한건 롤백함 //fail과 같은듯,기본값

그리고 이 프로비저너는 가능한 마지막수단으로 사용하고,어지간하면 공급자가 제공하는 옵션(aws ec2에선 user_data)를 쓰래



aws_eip는 유동적ip리소스임,얘를 써서 고정 퍼블릭ip를 받을수있음  
그리고,아웃풋을 받든 하는걸로 만들어진 인스턴스의 주소를 받는게 가능함(dns를 받을수있음 )
사용법은 그냥 
	resource "aws_eip" "elasticip"{
		instance=aws_instance.리소스이름.id
	}
하는걸로 끝임

테라폼에서 가능하면 프로비저너를 사용하지 마라는 이유는,
	프로비저너를 사용하면 구성이 복잡해짐(리소스내에 블록이 들어가니까)
	
	커넥션블록을 따로 적어야함(user_data같은건 알아서처리해서 그런거안해도됨)
	
	그리고 아예 그게 설치되어있는 ami를 쓰는게 제일편함(nginx가 설치된 ami-XYZ같은)
	즉,커스텀ami를 사용하면됨






테라폼에서 taint는,특정개체가 이상하니까 현재스테이트에 상관없이 그걸 재생성하라는소리임
가장 빠른예는 프로비저너를 써서 에러가났는데 on_failure이 fail이면 그 리소스는 테인트가 걸려서 생성이 안됨
그리고 수동으로 테인트를 걸수도있는데
	terraform taint 리소스종류.리소스이름
하면 테인트가 걸리고
	terraform untaint 리소스종류.리소스이름
하면 테인트가 풀림
요즘은 안쓰고
	terraform apply -replace="리소스종류.리소스이름"
이렇게한다고함



테라폼에서 디버깅을위해 로그를 보는건
	export TF_LOG=로그레벨
	export TF_LOG=TRACE
여기서 로그레벨은 순서대로 (INFO,WARNING,ERROR,DEBUG,TRACE)가 있음
이걸 설정하고 plan이나 apply를 하면 로그가 쭉나옴
로그를 따로 파일로 빼고싶으면
	export TF_LOG_PATH=/로그경로/로그파일.log
하면됨
이걸 다시 비활성화하려면
	unset TF_LOG_PATH
하면됨



테라폼에서 원래 있던 리소스를 코드로 만드는건 import를 쓰면됨
기본적으론 테라폼으로 다만들지만(이상적으로는),다른 프로비저닝툴로 만들수도있고,aws콘솔로 만들수도 있는데,
그걸 코드화시켜서 다시 업데이트권한을 테라폼쪽으로 가져올수있음

임포트 쓰는 방법은
	terraform import 리소스타입.리소스네임 애트리뷰트(aws의 경우 리소스의 instanceid값같은,아니면 arn써도됨)
	terraform import aws_instance.abcdserver i-026e13be10d5326f7//id값


그리고 이건 파일을 생성하지않기때문에,tf파일을 만들고 빈 리소스를(위 기준으로 aws_instance.abcdserver가 있는)만들어야함
그러면 거기에 덮어씌워서 업데이트만 함
빈 tf파일엔 필수아규멘트같은거도 없어도됨
이걸 사용하면 state에  업데이트가 됨

그리고 import를 쓴다고 main.tf의 리소스정보에는 변화가 절대 없음,그래서 코드로 만들고싶으면 plan써서 비교해가면서 뽑아야함
왜냐면  import는 aws의 모든걸 분석하는게 아니라,일부만 분석하기때문
이때 같은개체인지 확인하려면,plan해서 replace가 아니고 변화없음나올때까지 복붙하면됨
이때 그냥 terraform state show 리소스종류.리소스네임 해서 다 복붙한후,에러뜨는거 다지워가면됨
이건 그냥 테라포밍쓰면 알아서 바꿔줌(aws만 되지만),이것도 안되는부분있긴함

awscli에서 현재생성된 리소스보는건
	aws ec2 describe-instances --endpoint http://aws:4566



테라폼에서 모듈은,다른 언어에서의 함수처럼 리소스들을 묶어둔거
이건 aws에서 특히 똑같은게 계속필요한데 계속 반복적으로 쓰여서 잘 사용됨
이렇게하면 함수처럼 수정할때도 편하고,코드의 반복이 없어서 줄도 줄어듬,그리고 가장 중요한건,재사용이 엄청편해짐
이 모듈은,그냥 다른 디렉토리에 있는 tf파일임,그거 그냥 가져다쓰는거임

기본 사용법은
	module "붙일이름"{
		source="/모듈경로"(상대경로하고싶으면 "../모듈폴더이름(현재같은디렉토리에 폴더가있어야함 루트모듈과)")
	}
이러면 자동으로 현재디렉토리가 루트모듈이 되고,불러온 모듈경로가 차일드모듈이 됨
기본적으로 모듈은 한곳에 폴더별로 몰아두고,거기서 가져다쓰는게 편함

이때 모듈에서 사용하는 값들은,하드코딩하면 안되고 var로 받아다 써야함
이때 모듈의 variable.tf의 값은,default가 필요없는건 그냥 type만 명시하고,(그냥 원래하던대로 똑같이하면됨,같은폴더에있다고 생각해도됨)
모듈을 가져다쓰는곳에서 값을 넣으면됨

	module "붙일이름"{
		source="../module/모듈폴더이름"
		app_region="us-east-1"//모듈의 variable.tf파일의 값 매핑
		ami="ami-3425mfdsf2221"//모듈의 variable.tf파일의 값 매핑
	}
이때 절대 안바뀌는건,그냥 모듈에서 하드코딩해버리는게 편함(db아이디같은거)
그리고 모듈을 쓸거면,다시 init해서 모듈플러그인을 받아야함

이렇게 모듈을 사용하면,그냥 모듈불러와서 변수만넣어주면 끝이라 엄청편함

모듈의 리소스주소는
	module.모델이름.리소스타입.리소스이름



모듈에는,내가 만든모듈도 있지만,다른사람이 만들어두거나,테라폼자체에서 지원하는 모듈들도 있음
공용 모듈들은,테라폼 레지스트리의 모듈칸에서 찾아볼수있음(프로바이더찾던곳과 같음)
이거도 검증된모듈과,커뮤니티모듈 두개로 나눠짐
그리고 거기안에 서브모듈을 보면,종류별로 많은 모듈들이 있는데,거기서 필요한거 가져다쓰면됨

이거 사용하는 방법은
	module "붙일이름"{
		source="terraform-aws-modules/security-group/aws/modules/ssh"//사용할모듈을 선택
		version="3.16.0"//사용할버전선택
		vpc_id="vpc-gdg4332"//필수인수나 옵션인수 넣기,사용할vpcid값
		ingress_cidr_blocks=["10.10.0.0./16"]//필수인수나 옵션인수 넣기,연결가능하게 할 ip대역
		name="ssh-access"//필수인수나 옵션인수 넣기//시큐리티그룹이름
		app_region="us-east-1"//모듈의 variable.tf파일의 값 매핑
		ami="ami-3425mfdsf2221"//모듈의 variable.tf파일의 값 매핑
	}	




테라폼에서 함수들을 썼는데,
	file()//특정파일 가져오기
	length()//특정 변수의 길이(배열같은경우 배열의갯수)
	toset()//(리스트를 집합으로 바꿈,즉 중복허용안하고 순서가없는집합으로 변경)
	
	max()//안에 들어있는거중 가장 큰값리턴
	min()//가장 작은값
	cell()//올림
	floor()//내림
	
	split()//구분자로 문자열을 잘라서 리스트화함
	lower()//대문자를 소문자로 변경
	upper()//소문자를 대문자로 변경
	title()//각 단어의 첫문자만 대문자로 변경
	substr()//문자열 자름
	join()//리스트의 문자열을 모두 합침
	
	index()//리스트에서 특정 문자열이나 값의 순서를 줌
	element()//리스트에서 특정 인덱스의 값을 줌
	contains()//리스트에 특정 값이 있는지없는지 tf로 확인해줌
	
	keys()//맵에서 키만 나열
	values()//맵에서 값만 나열
	lookup()//맵에서 키의 값 리턴,없으면 에러
	lookup(배열,찾을값,없을시값)//맵에서 키의 값 리턴,없으면 3번째인수리턴

이 함수들을 테스트해보는법은
	terraform console//테라폼 대화형콘솔 진입,기본적으로 현재 디렉토리의 tf파일내의 리소스값을 출력할수도있음
	file("파일경로/파일명")//이러면 cat처럼 출력이 나옴
	length(var.region)   리턴값 3//  var.region=[a,b,b]
	toset(var.region)    리턴값[a,b]
	max(1,3,4,100,-10)   리턴값 100
	min(1,3,4,100,-10)   리턴값 -10
	max(var.num...) //변수와 같이 쓰려면 뒤에 ...붙여야함
	cell(10.2)           리턴값 11
	cell(10.7)           리턴값 11
	floor(10.2)           리턴값 10
	floor(10.7)           리턴값 10
	split("," , "abc bcd,fee,ttt")리턴값 ["abc bcd","fee","ttt"]
	split(",", var.ami)
	lower(var.ami)
	upper(var.ami)
	title("abc-xyz,aaa-bcd,afs-fff") 리턴값 "Abc-Xyz,Aaa-Bcd,Afs-Fff"
	substr("abc-xyz,aaa-bcd,afs-fff",0,7) 리턴값 "ami-xyz"//7번부터 7개
	substr("abc-xyz,aaa-bcd,afs-fff",8,7) 리턴값 "aaa-bcd"//8번부터 7개
	join(",",["abc bcd","fee","ttt"])  리턴값 abc bcd,fee,ttt//맨앞은 구분자
	index(["abc bcd","fee","ttt"],"ttt") 리턴값 2
	element(["abc bcd","fee","ttt"],2)  리턴값 "ttt"
	contains(["abc bcd","fee","ttt"],"ttt") 리턴값 true
	contains(["abc bcd","fee","ttt"],"TTT") 리턴값 false
	keys(var.ami)//리스트로 키배열리턴
	values(var.ami)//리스트로 값배열리턴
	lookup(var.ami,"abc")  리턴값 qqq  //abc:qqq일때,만약 값이 없으면 에러뜸
	lookup(var.ami,"abc","ivv") 리턴값 ivv //만약 abc가 없으면 3번째인수인 ivv리턴,에러안뜸


spilt count 같이쓸땐 
	 split(":",var.cloud_users)[count.index]
이렇게 써야함,element쓰면 에러남




테라폼에서 console의 함수테스트가 콘솔의 유일한 용도는 아님
저걸 써서 자동및 논리적 작업을 테라폼이 해볼수있음
	terraform console
	1+2  리턴값 3
	5-3  리턴값 2
	3==5  리턴값 false
	3=="3" 리턴값 false
	3!=5 리턴값 true
	5>7  리턴값 false
	5>4  리턴값 true
	5>=5 리턴값 true
	3<=4 리턴값 true
	
	8>7 && 8<10 리턴값 true //앤드
	8>9 || 8<10 리턴값 true //or
	var.special 리턴값 true
	! var.special 리턴값 false //var.special=true일때
	! (5>7) 리턴값 true
	
	var.a>var.b 리턴값 true
	var.a+var.b 리턴값 70

이걸사용해서 조건에 따라 동작하게 할수있음
	resource "random_pet" "pet11"{
		length =var.length<8?8:var.length
	}
이때  저 식은  논리연산자로 나온 tf값 ? 참일때값:false일때값
그리고
	terraform apply -var=length=5 
하면 length는 8이되고,
	terraform apply -var=length=30
하면 length는 30이됨 




기본적으로 테라폼은,디렉토리 기반으로 작동함,근데 이러면 복제같은거할때 실수하기도쉽고(뭐 바꿔야하는데 까먹거나)
그래서 사용하던게 모듈같은거
워크스페이스는 한 디렉토리에 2개이상의 프로젝트를 같이 넣어두고,apply할때 구분해서 들어가는것
하는법은
	terraform workspace new 프로젝트1
으로 만들고
	terraform workspace list
로 볼수있음
	terraform workspace select 프로젝트2
로 전환가능
기본적으로 default는 있고,밑에 내가만든게 쌓이는데,*붙은건 현재스페이스임
이걸 사용하는법은,
	모든 main의 하드코딩된값을 제거
	그리고 모두 변수에 박아넣음
	그리고 스페이스별로 나눠지는건 map으로 워크스페이스이름=값 으로 넣음(안나눠지는건 그냥 디폴트에넣으면됨)
	그리고 terraform.workspace로 현재 워크스페이스값을 받을수있는데,이걸로 if문써서 구분하면됨


	resource "aws_instance" "projectA"{
		ami= lookup(var.ami,terraform.workspace)
		instance_type=var.instance_type
		tags={
			Name=terraform.workspace
		}
	}
이런식
이렇게하면 각 작업공간마다 하나씩의 tfstate영역이 있는,tfstate.d폴더내의 작업공간명파일로 생성이 됨


끝














