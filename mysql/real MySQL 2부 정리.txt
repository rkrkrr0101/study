11.쿼리 작성 및 최적화
	필요없는건 스킵
	앞부분에 5.7이랑 8.0이랑 호환설정같은거 있으니 책 참고(안시쿼리호환설정도있음)
	
	테이블은 항상 대문자나 소문자로 통일해서 만들기
	예약어인지 확인할떈,해당이름으로 테이블만들어서 만들어지면 예약어아니고,안만들어지면 예약어임
	이때 역따옴표를 붙이면 테스트가 안되고,기본적으로 테이블생성시 역따옴표를 안쓰는게좋음
	
	mysql 메뉴얼에서
		대문자는 키워드
		이탤릭체는 토큰(테이블명,칼럼명,표현식)
		대괄호는 선택사항
		파이프는 하나만 선택가능
		중괄호는 괄호내에서 반드시 하나를 선택해야함(필수사항)
		...은 앞에 명시된 키워드나 표현식의 조합이 반복될수있음을 의미함
	이거알면 대충볼수있음
	
1.mysql연산자와 내장함수
	문자열은 ''와 ""를 혼용가능,예약어충돌은 ``쓰면되는데 안쓰는게좋음 가능하면
	숫자는 그냥 넣으면되고,문자열과 숫자를 비교하는건 가능하면 안하고 통일시키는게좋음 타입을
	날짜타입은 date고 스트링도 포맷만 맞으면 날짜랑 비교를 할수있음
	불리언타입은 있긴한데,이건 그냥 tinyint임,그래서 이거쓰지말고 enum쓰는게좋음
	
	연산자는
		= 동등비교(null=null   -> null)
		<=> 널을포함한 동등비교(null<=>null -> true)
		<>,!=부정비교
		not,! 부정연산(tf연산을 뒤집음)
		and(&&),or(||) 연산결합,기호대신 문자쓰는게 가독성좋음
		/,div 나누기
		%,mod 나머지
		regexp 정규식일치확인
		rlike 정규식 라이크
		like 부분일치(인덱스타려면 aaa%식으로 써야함 %aaa는 못탐),%와 _를 사용할수있음
		between 양쪽사이의 값(이건 인덱스타기 힘드니까 인덱스 작업범위결정조건용 조건을 앞에 넣어두는게좋음),가능하면 in으로 바꾸는게 성능상좋음
		in 여러값에 대해 이퀄연산
	등이 있음	
	
	내장함수에는
		ifnull():널이면 다른값으로 변경
		isnull():널인지 아닌지 확인
		now():현재시간반환,정확히는 트랜잭션을 시작한시간을 반환함
		sysdate():사용금지
		date_format():datetime타입을 스트링으로 반환
		str_to_date():스트링을 datetime타입으로 변경
		date_add():날짜시간을 지정한만큼 추가
		date_sub():날짜시간을 지정한만큼 감소
		unix_timestamp():1970년1월1일 00:00:00로 부터 경과된 초를 반환(디폴트는 현재,해당데이트타임넣으면 그때의 타임스탬프반환)
		rpad():해당문자열의 오른쪽을 해당길이만큼 해당문자로 채워줌
		lpad():해당문자열의 왼쪽을 해당길이만큼 해당문자로 채워줌
		rtrim():해당문자열의 오른쪽의 공백을 지워줌
		ltrim():해당문자열의 왼쪽의 공백을 지워줌
		trim():해당문자열의 양쪽의 공백을 지워줌
		concat():여러문자열을 합쳐서 리턴(숫자를넣으면 문자열로 바꿔서더함)
		concat_ws():여러문자열을 합쳐서 리턴,중간에 구분자넣기도 가능(숫자를넣으면 문자열로 바꿔서더함)
		group_concat():그룹바이된 결과의 문자열들을 다 더해줌,구분자넣기도 가능,이때 메모리버퍼쓰는데 제한이 1kb니 시스템변수에서 늘릴수있음
		case when구문:스위치문임,보통 서브쿼리의 필요없는 동작을 막을때 사용(어짜피 버리는데 돌아가는거 막는다던가)
		cast():해당타입으로 변형
		convert():해당타입으로 변형 or 해당문자열의 인코딩형식 변경
		hex():해당숫자를 16진수스트링으로 변경
		unhex():16진수스트링을 바이너리로 변경
		md5():암호화함수,해시할때 사용하기도함
		sleep():쿼리를 해당시간동안 멈출수있음,보통 디버깅에사용
		benchmark():해당쿼리를 n번 실행시켜서 평균실행시간 리턴,단 계획수립은 1번만하니 이건 주의(두쿼리를 비교분석할때 사용하면됨)
		inet_aton():스트링ip주소를 바이너리타입으로 변형
		inet_ntoa():바이너리타입을 스트링ip주소로 변형
		json_pretty():json칼럼의 가독성을 좋게해줌
		json_storage_size():json칼럼의 바이트크기를 리턴해줌
		json_extract():json에서 특정값을 추출해옴,따옴표붙어있음,->연산자와 같음
		json_unquote():json에서 특정값을 추출해옴,따옴표없음,->>연산자와 같음
		json_contains():json전체,혹은 해당위치의 아래에 해당json필드가 있는지 확인
		json_object():해당칼럼들의 값으로 json을 생성
		json_objectagg():group by함수,칼럼들의 값으로 json을 생성
		json_arrayagg():group by함수,칼럼들의 값으로 json배열을 생성
		json_table():json값들을 모아서 rdbms테이블로 만들어서 반환함(임시테이블)
	등이 있음	
	
2.select
	셀렉트 문장은 조회 전체를 말하고,셀렉트절은 조회칼럼선택을 말함
		select절:select *,count(e.name) as cnt
		from절:from qwetable q inner join emp e on e.emp_no=q.emp_no
		where절:where a in 1
		group by절:group by q.emp_no
		having절:having avg(q.money>1000)
		order by절:order by avg(q.money)
		limit절:limit 10
	이런구성임
	이떄 실행순서를 알아야하는데,
		1.select,from,where절로 인덱스를 사용해서 데이터를 가져오고 조인함
		2.group by
		3.distinct
		4.having
		5.order by
		6.limit
	순으로 진행됨,또한 인덱스를 사용할수있을땐 order by와 group by는 생략됨(어짜피 정렬됐고 그대로 쭉 긁어서 그룹바이하면되니까)
	예외적으로,order by만 있고 group by가 없을땐
		1.1.select,from,where절로 인덱스를 사용해서 데이터를 가져옴
		2.order by함
		3.정렬된 데이터를 조인함
	이런순서로 진행됨
	
	만약 이런순서를 벗어나고싶으면 서브쿼리를 사용한 인라인뷰를 사용해야함(from절 서브쿼리로 임시테이블을 생성해서 거기서 진행)
	
	where나 order by,group by가 인덱스를 사용하려면 만족해야하는 조건은
		인덱스된 칼럼의 값을 절대 변형하면안됨(substr,a*10=100),가능하면 우항쪽으로 옮겨야 인덱스탈수있음,해싱같은경우 가상컬럼사용
		where절의 경우,양쪽의 데이터타입이 일치해야함(이거도 값을 변형하면안된다는거랑 사실같은소리)
	가 일단 전제조건임
	
	where에서 인덱스를 사용하는 방법은 작업범위결정조건과 체크조건 두가지가 있고,가능하면 작업범위결정조건을 늘려야함
	이때,인덱스에서의 왼쪽부터 조건이 하나씩 들어있을수록 효율성이 올라감(반대로말하면,왼쪽이 없으면 인덱스풀스캔을 함)
	그리고 딱히 where안에서의 순서와,인덱스의 순서는 상관없음
	이건 and조건이고,
	or조건은 전혀 데이터를 줄여주지못하고,오히려 해당조건으로 한번 더읽어야해서 풀테이블스캔의 확률을 높임
	가능하면 or은 빼고,넣더라도 and로 감싸서넣어야함
	
	group by에서 인덱스는,여긴 따로 작업범위결정조건과 체크조건같은게 없고,단순하게 group by에 있는 칼럼들의 순서와 인덱스의 순서만 같으면됨
	이때
		group by에 명시된 칼럼이 인덱스칼럼과 순서가 같아야함
		인덱스의 앞쪽에 있는걸 생략할순없음(뒤에있는건 생략가능)
		group by에 인덱스에 명시되지않은 칼럼이 하나라도 있으면 인덱스를 전혀 못탐
	가 있음,
	추가적으로,where조건절에 인덱스의 앞에있는칼럼을 이퀄로 비교했을경우,이걸 대신사용해서 인덱스를 타는경우도 있음
	즉 group by와 where 이퀄비교를 합쳐서 생각해도됨
	물론 where가 대신해줄수있는건 맨앞이 비어있을때뿐임,즉 group by의 맨앞에 where의 이퀄비교들이 있다고 보면됨
	
	order by는 group by와 거의비슷한데,정렬방식이 인덱스와 같거나 정반대여야한다는 추가조건 하나만 더있음
	
	쿼리에 where절이나 groupby,orderby가 동시에 있을경우에도 서로 같은 인덱스를 사용해야함(제약조건)
	이때(여기서 groupby와 orderby를 치환해도 똑같음)
		where절과 orderby가 같은인덱스를 사용:둘다 조건을 만족할때 가능,제일빠름
		where절만 인덱스를 사용:orderby는 파일소트로 정렬해야함,where로 많이 거를수있을때 효율적
			where로 임시테이블을 만들고 그안에서 정렬한다고 생각하면됨
		order by절만 인덱스를 사용:orderby를 인덱스로 처리하면서 where를 전부 체크조건으로 사용함,레코드가 아주 많은걸 정렬해야할때 사용함
			인덱스 풀테이블스캔으로 정렬하면서 where도 겸사겸사 처리하는느낌
	이렇게됨
	양쪽다 인덱스를 사용하려면,where절의 이퀄칼럼과 orderby의 칼럼들이 순서대로 빠짐없이 인덱스의 왼쪽부터 일치해야함
	중첩되는건 상관없는데,둘중 하나라도 빠지는칼럼이 있으면 동시사용은 불가능,이떈 보통 where이 인덱스를 탐
	
	group by와 order by가 동시에 인덱스를 타려면,양쪽이 모두 명시된 칼럼의 순서와 내용이 완전히 같아야함
	이때 둘중 하나라도 인덱스를 못타면,양쪽다 인덱스를 못타니까 주의해야함(즉 양쪽이 인덱스타는건 연대조건임)
	
	where와 orderby,groupby가 전부 동시에 인덱스를 타려면
		where이 인덱스를 사용할수있는가?
		groupby가 인덱스를 사용할수있는가?
		groupby와 orderby가 동시에 인덱스를 사용할수있는가?
	이 3개를 다 만족해야함
	즉
		3개다 만족하면 3개다 타는거고
		1번을 만족못하고 나머지는 만족하면 groupby,orderby만 타는거고
		1번을 만족하고 2,3번중 하나라도 만족못하면 where만 타고
		1번을 만족못하고 2,3번중 하나라도 만족못하면 인덱스 사용불가
	이렇게됨
	
	
	where에서 비교조건(이퀄)을 사용할때 주의해야할건
	null은 비교불가값이라 a=null 사용하면 tf로 안나옴,이떈 a is null이나 isnull(a)써야함
	그리고 isnull(a)쓸때 그냥 저대로 던지면됨
		isnull(a)=true //이렇게쓰면안됨
	이렇게 쓰면 안됨,변형일어났으니 풀테이블스캔함
	
	문자열이나 숫자를 비교할땐,반드시 그타입에 맞는 상숫값을 사용해야함,즉 문자열이면 문자열과 비교,숫자면 숫자와 비교
	
	date와 datetime과 문자열을 비교할땐,문자열을 자동으로 datetime으로 변환해서 수행하고,이때는 인덱스 타니까 신경안써도됨
	당연히 왼쪽의 칼럼을 스트링으로 변형하는거도 안됨
	날짜를 빼거나 더해서 비교할떄도,좌항은 그대로두고 우항쪽에서 빼고더하고를 거꾸로해서 처리해야함
	
	date와 datetime끼리 비교할땐,자동으로 date를 datetime으로 변형해서 사용하는데,
	이떄도 인덱스는 똑같이씀(왼쪽에 변형일어나도 인덱스씀,예외케이스)
	
	date,datetime과 timestamp를 비교할땐 주의해야함,실행계획도 레인지스캔하는거같은데 아님
	칼럼이(우항이) datetime이라면 from_unixtime()로 timestamp를 datetime으로 변환해야하고,
	칼럼이(우항이) timestamp라면 from_timestamp()로 datetime을 timestamp로 변환해야됨(now를 써도됨)
	이래야 인덱스를 탐,타임스탬프는 mysql에선 단순 상수로 취급되기때문에 변형을 해줘야함
	
	mysql도 Short-Circuit Evaluation(if문에서 앞에서부터 체크하고 나가리면 뒤에거 체크안하고 넘어가는거)가 있기때문에
	where의 조건의 순서가 성능에 영향을 미침(근데 cpu쪽부하라서 크진않은듯)
	그리고 where에서 인덱스에 관련된 조건이 있으면 그걸 맨앞으로 떙겨서 처리함(그래서 where에서 인덱스순서랑 조건순서랑 맞출필요없는거)
	일단 서브쿼리로 뽑아오는거나 그런건 맨뒤에 배치하면될듯
	
	distinct는 1권참고
	
	limit는 항상 마지막에 실행되고,중요한건 리미트에 표시된 레코드건수만 준비되면 바로 쿼리가 종료됨,
	그래서 groupby나 orderby에서도 약간의 성능향상이 있긴하고,where에서도 약간의 성능향상은 있음
	distinct의 경우엔 정렬은 안해도되고 유니크하기만 하면되니까 많은 성능향상이 있음
	풀테이블스캔이라도 따로 처리가 없으면 굉장히 빨리끝남
	그리고 리미트에서는 인자로 표현식이나 서브쿼리를 넣을수없음
	추가적으로 페이징을 위해 리미트를 쓰는건(limit 100,10),페이지가 커질경우에 비효율적이됨(앞에있는페이지를 다 읽고 가야하기때문에)
	그래서 페이지가 무한정 늘어날거같으면,where로 위치를 찾고(키값이나 날짜인덱스사용,81p참고),거기서 고정된 limit를 읽는게좋음
	
	count는 결과레코드의 건수를 반환함
	이떄 count(1)과 count(*)은 같음
	이노디비는 카운트를 쓸때 무조건 데이터나 인덱스를 읽어야(풀테이블스캔)하기때문에 주의해야함
	그리고 count쿼리에서는,order by와 left join같은건 넣으면안됨
	보통 페이징처리를 위해 사용할때가 많은데,이때 쓸데없는 부하임 이건
	order by는 어떤경우에도 필요없고(8.0부터는 무시하긴함),left join은 레코드수의 변화가 없으면 빼버리는게 성능상 좋음
	그리고 count함수에 칼럼명이나 표현식을 인자로 사용하면,거기서 널이 아닌거만 세는거도 주의해야함
	카운트쿼리는 부하가 엄청나기때문에,가능하면 빼는방향으로 가는게 좋음
	
	
	join작업을 할때,드라이빌테이블을 읽을땐 인덱스탐색을 한번만 하고,그뒤로는 스캔만 하면됨
	근데 드리븐테이블에서는 인덱스탐색작업과 스캔작업을 드라이빙테이블에서 읽은 레코드건수만큼 반복해야함
	그래서 드리븐테이블을 읽는게 훨씬 큰 부하를 차지함
	그래서 옵티마이저는 항상 드리븐테이블을 최적으로 읽을수있게 실행계획을 짬
	이때 각 테이블별로 인덱스가 있고없고에 따라
		양쪽다 인덱스있음:신경안써도됨 알아서잘함
		한쪽만 인덱스있음:일반적으로 인덱스있는쪽을 드리븐으로 잡음
		양쪽다 인덱스없음:인덱스만들생각부터 하자,어케하든 망했음
	이렇게 잡음
	그리고 조인조건(on)에서도 데이터타입의 변형없이,데이터타입의 타입을 서로 맞춰줘야 인덱스를 탈수있음(이쪽은 양변이 다 변형없어야함)
	
	이너조인은 조인대상테이블 양쪽에 모두 존재하는 레코드만 결과집합으로 반환함
	그래서 아우터조인(left join)을 자주 사용하게되는데,이건 이너조인보다 비효율적임
	그래서,한쪽 테이블에 존재하는 사원중에 반대쪽테이블이 null인 레코드를 반드시 반환해야하는게 아니면 이너조인쓰는게좋음
	이게 왜 비효율적이냐면,아우터조인을 쓰면 대상테이블은 절대 드라이빙테이블이 될수없어져서,옵티마이저가 성능을 좋게할 건덕지가 없어짐
	
	그리고 추가적으로,아우터조인을 하면서 아우터조인테이블에 대한 조건을 where에 넣으면안됨,이 조건은 on절에 들어가야함
	예외적으로,안티조인을 쓸때만 where에 조건을 넣을수있음
	
	그리고 db에서 외래키는 참조무결성을 위한거지 조인과는 전혀상관없음
	
	
	일반적으론 조인쓰면서 groupby와 orderby를 쓰면 알아서 최적화를하는데,만약 못한다면 조인을 끝내고나서 그룹바이나 오더바이를 처리함
	이때 조인이 실행되기전에 그룹바이나 오더바이를 처리하면 효율이 올라가는데,이게 지연된 조인임
	보통 이건 limit가 있는 쿼리에서 효과가 좋음
	이건 어떻게하냐면,메인쿼리의 from절에 원래쿼리에서 조인뺴고 오더바이랑 그룹바이를 친 결과물을 서브쿼리로 넣고,거기다가 조인을 하는거임
	이걸 하기위한 조건은
		left join일경우 1:1 또는 n:1이어야함
		inner join일경우 1:1 또는 n:1임과 동시에 양쪽테이블에 모두 존재해야함
	보통 페이징쿼리를 이런식으로 하면 성능차가 좀 남(조인갯수도 줄이면서 그룹바이나 오더바이를 처리할레코드수도 줄이니)
	
	
	8.0부터는 래터럴조인을 사용해서 특정그룹별로 서브쿼리를 실행해,그 결과와 조인하는게 가능해졌음
	즉 서브쿼리로 임시테이블을 만들고 그거와 조인거는거(이때 프롬절내부의 서브쿼리가 외부의 칼럼을 참조할수있음)
	이건
		let join lateral(서브쿼리) on ...
	이렇게씀
	이 lateral이 들어가야 from안에서 외부칼럼을 접근할수있음
	이 lateral서브쿼리는 조인순서상 후순위로 밀리고,결과로 외부테이블이 생성되기때문에 성능에 주의해야함(꼭 필요할때만 사용)
	
	그리고 조인쓰면 정렬된거처럼 보일수도있는데,orderby가 없으면 정렬에 대한 보장이 되지않으니,정렬이 필요하면 반드시 명시적으로 넣어줘야함
	드라이빙테이블이 바뀌거나 그러면 머리아파짐
	
	
	group by가 사용된 쿼리에선,그룹필된 그룹별로 소계를 가져올수있는 rollup기능이 있음(총합을 표시해줌)
	즉 그룹바이를 친 칼럼으로,나머지 칼럼들은 다 null로 적히고 카운트에 총합이 있는 형태임,이건 항상 해당그룹의 마지막에 나타남
	이 null을 바꾸고싶으면,grouping()함수를 사용해서 기본값을 바꿀수있음
	
	case when end를 사용하면,레코드를 칼럼으로 변환하거나(99p쿼리참고),
		SUM(CASE WHEN dept_no='d001' THEN emp_count ELSE 0 END) AS count_d001
	하나의 칼럼을 2개이상의 칼럼으로 변환할수있음(100p쿼리참고)
		SUM(CASE WHEN e.hire_date BETWEEN '1980-01-01' AND '1989-12-31' THEN 1 ELSE 0 END) AS cnt_1980
	이걸 with rollup과 같이쓰면 더 쓸만함
	
	
	order by는 정렬할때쓰는데,만약 이게 없다면
		인덱스를 사용하면 인덱스에 정렬된순으로 가져옴
		풀테이블스캔은 프라이머리키 순서대로 가져옴
		임시테이블을 거치면 아무도모름
	이런식으로 출력됨
	보통 정렬이 필요하다면,반드시 명시적으로 orderby를 넣어주는게 좋음,만약 인덱스타면 무시되니까 성능이슈도 글케없음
	근데 인덱스를 못탈경우엔 파일소트를 써야해서 많이 느려질수있으니,인덱스를 만들거나 정렬을 무시해도되면 무시하는방법도 있음
	이 orderby를 쓸때,숫자를 넣으면 해당위치의 칼럼(select절의 순서대로)으로 정렬,문자열을 넣으면 무시됨
	그래서 쌍따옴표를 넣으면 문자열이라서 무시되니까 주의
	
	하나 또는 여러칼럼의 연산결과를 사용해 정렬할수도 있음,이때 함수기반의 인덱스를 사용하면 인덱스도 탈수있음
	
	
	서브쿼리는 서브쿼리를 사용하면 단위처리별로 쿼리를 독립적으로 작성할수있음
	이건 select from where에 보통 사용할수있는데,위치에 따라 쿼리의 성능영햑과 최적화방법이 완전히 달라짐
	
	select절은 별로 신경쓸거없고,인덱스만 사용하는지 보면됨(따로 임시테이블만들거나 그런게없어서)
	그리고 주의해야할건 select절의 서브쿼리는 항상 칼럼과 레코드가 하나인 결과를 반환해야하는데,mysql에선 이거 체크가 좀 느슨함
		쿼리결과가 0이면 null반환
		쿼리결과가 2레코드이상이면 에러
		쿼리결과가 2칼럼이상이면 에러
	이런식임
	그리고 서브쿼리보단 조인이 조금 더 빠르니,가능하면 조인쓰는게 더 좋음
	그리고 래터럴조인을 사용하면,select절에 같은 서브쿼리를 칼럼만 바꿔서 여러번 던질필요없고,한번에 처리할수있음(107p)
	
	from절 서브쿼리는,8.0이전에선 항상 서브쿼리결과를 임시테이블에 저장하고 읽고그랬는데,좀 최적화가 돼서 괜찮아졌음
	서브쿼리를 외부쿼리와 병합하는방식으로 알아서 최적화를 해줌
	이때
		집합함수사용(sum,min,max,count등)
		distinct
		groupby
		limit
		union
		select절 서브쿼리
		사용자변수사용
	을 하면 이렇게 최적화를 못하니 주의해야함
	
	where절 서브쿼리는
		이퀄 or 크다작다비교
		in비교
		not in비교
	3가지로 나눠짐
	
	이퀄비교(대소비교도 동일)는 8.0부터는 서브쿼리를 먼저 돌려서 상수로 바꾸고,그걸가지고 나머지쿼리를 처리함
	단 단일값비교(a_col=(서브쿼리))가 아닌 튜플비교((a_col,bcol)=(서브쿼리))를 하면,
	서브쿼리가 먼저처리되긴하는데 외부쿼리는 인덱스를 사용하지못함
	
	in비교는 5.5이전까진 금기였는데,이후부터는 괜찮아졌음,이떈 세미조인을 사용해서 최적화함
	
	not in비교는 안티세미조인인데,이건 최적화할 방법이 많지않아서 가능하면 피하는게좋음(where에 이거만있으면 풀테이블스캔을 피할수없음)
	
	
	
	cte는 이름있는 임시테이블로,쿼리내에서 한번이상 사용가능하고(재사용가능) 쿼리가 끝나면 자동으로 삭제됨
	이건 재귀여부를 기준으로 non-recurisive와 recurisive로 나눔
	사용방법은 재귀여부에 상관없이
		with cte1 as (select ...) select,delete,update문
	이렇게씀,서브쿼리도 마찬가지로 괄호안에 제일앞에 쓸수있음
	
	cte는 with절로 정의하고,그뒤에 이름을 붙이고 쿼리를 붙이면됨
	이때 여러 임시테이블을 같이사용할수있고,물론 이 cte를 메인쿼리에서 가져다쓸수있고,다른cte에서 가져다쓸수도있음
	즉 임시테이블과 조인하는식으로 쓰면됨,from절 서브쿼리의 친척이라고 생각하면됨
	from서브쿼리에 비해 장점은
		재사용가능
		다른cte에서 참조가능
		임시테이블부분과 사용부분의 코드분리가능
	이라는 장점이 있음
	
	재귀cte는 비재귀적쿼리파트와 재귀적파트로 구분되며,이 둘을 반드시 union all해줘야함
	재귀적파트는 쿼리결과가 없을때까지 반복실행됨
		WITH RECURSIVE cte (no) AS (
			SELECT 1
			UNION ALL
			SELECT (no + 1) FROM cte WHERE no < 5
		)
		SELECT * FROM cte;	
	이런느낌임(WITH RECURSIVE로 시동)
	여기서 select 1이 재귀파트의 입력이고,그걸 where로 걸러서 쿼리결과가 없을때까지 반복하는거임
	이때,재귀를돌떄의 입력값은 바로 직전의 출력값이 그대로 입력됨(레코드 한줄이기만하면 칼럼이 몇개든 상관없음,as로 이름붙여서 가져다쓰면됨)
	
	일단 재귀니까 무한루프 돌수도 있어서,이거 제한기본값이 1000인데 이 기본값은 너무 크고 10으로 낮춰두는게 좋음
	그리고 꼭 필요한 쿼리에선 set_var힌트로 저 숫자를 그 쿼리에서만 변경하는게좋음(121p)
	
	이건 쓰기좋아보이니 나중에 다시한번보자
	
	
	윈도우함수는 현재 레코드를 기준으로,groupby연산같은걸 따로 레코드를 안건드리고 실행함
	즉 레코드는 그대로 출력되는데,거기서 groupby의 값을 가져다붙일수있는거임
	그래서 특정조건별 평균값을 모든 레코드를 보면서,거기다가 붙일수있음
	이 윈도우함수에서 주의할건,
		where,from,groupby,having
		윈도우
		select절,orderby,limit
	순으로 실행된다는거임
	그래서 윈도우함수를 그룹바이칼럼으로 사용할수없고,where절에도 사용할수없음
	그리고 limit를 붙여봐야 효과가 없기때문에,from절을 서브쿼리로 돌리고 그안에서 limit를 걸어야함
	이건
		함수() over(파티션바이 오더바이 프레임) as 별칭
	순으로 사용하면됨(파티션과 오더바이는 생략가능,안넣으면 각 개별레코드로 진행)
	파티션바이는 해당조건으로 묶는다는거,group by와 똑같이 동작(저기서만 쓰일뿐)
	적용순서에서 알수있는거처럼 where로 거른다음에 윈도우가 돌아가니까,테이블전체가 아닌 검색된 결과내에서 윈도우집계가 돌아감
	
	그리고 윈도우함수의 파티션안에서도 연산을 수행할 소그룹을 지정할수있는데 이게 프레임임
	이건 지정하지않으면 알아서 선택하고,명시적으로 지정하면,현재 레코드를 기준으로 어디까지 읽을건지를 정할수있음(앞뒤1개나 전체나 이런느낌)
	묵시적선택의 경우엔 orderby가 있냐없냐에 따라 결과가 달라짐
	그리고 일부 윈도우함수들은 프레임이 고정되어있는데,이때 프레임을 넣으면 무시되고 에러는 안나니까 주의
	
	이 윈도우함수엔 집계함수와 비집계함수가 둘다 있음
	집계함수는 groupby에 쓰는거고,얘들은 over없이 단독으로도 쓸수있고 over넣고 쓸수도있음
	비집계함수는 반드시 over절이 있어야함
	집계함수엔
		count,max,min,sum,avg
	등등이 있고(대표적인거만 적음)
	비집계함수엔
		first_value(파티션의 첫번째값반환),Rank(랭킹반환,갭있음),dense_rank(랭킹반환,갭없음),row_number(파티션내 레코드순번반환)
	등이 있음
	
	rank나 dense_rank나 둘다 orderby기준 순위반환인데,
	rank는 동률등수가 있으면 다음을 한칸미루고(공동1등 2명이면 다음등수 3등)
	dense_rank는 동률등수가 있어도 다음을 미루지않음(공동1등 2명이면 다음등수 2등)
	row_number은 동점에대한 고려없이 그냥 오더바이순서대로 1,2,3적음
	
	이 윈도우함수는 8.0부터 도입됐고,아직 인덱스를 이용한 최적화가 안될때가 있으니 explain해보면서 써야함
	그래서 윈도우함수에 크게 의존하진 않는게 좋지만,어짜피 where로 거르기때문에 잘걸러서 레코드양을 줄일수있으면 걍 써도됨
	
	
	select도 잠글수있는데,for update와 for share로 잠글수있음
	for share는 select로 읽은 쿼리에 대해 읽기잠금(읽기만 가능,쓰기는 불가)을 걸고
	for update는 select로 읽은쿼리에 대해 쓰기잠금(읽기도 불가,쓰기도 불가)을 검
	둘다 트랜잭션이니,자동커밋을 끄고 트랜잭션을 시작해야 잠금이 유지됨
	그리고 서로 for update,for share가 붙은 조회쿼리끼리만 잠금이 먹히고,그냥 저게 없는애들은 잠금무시하고 읽을수있음
	
	그리고 조인을 하거나해서 여러테이블을 건드릴때도 특정 테이블에만 잠금거는거도 가능(141p)
	
	그리고 nowait와 skip locked를 사용하면,
	만약 레코드가 잠겨있을경우 기다리지않고 즉시 실패처리를 하고싶다면 nowait
	해당 레코드를 무시하고 다른레코드들만 읽고싶다면 skip locked
	를 사용할수있음,물론 for update나 for share가 있어야 적용됨,없으면 어짜피 잠금무시하니까 의미없음
		select * from abc for update nowait
	이런식으로 쓰면됨
	
	skip locked를 쓰면 비확정적인 쿼리가 되니까 이건 주의해야함
	이 nowait와 skip locked는,큐를 mysql에서 만들때(선착순쿠폰발급) 유용함
	이때 for update skip_locked limit 1로 다른애가 잠그고있는건 무시하고 다음거를 가져와서 잠그고 이름적는느낌
	이러면 순차처리가(1번트랜잭션 끝나면 2번트랜잭션...끝까지 반복),동시처리가 돼서(서로 다른 레코드를 잠그고있으니) 속도가 올라감
	
	
3.insert
	보통 셀렉트의 성능을 올리면(인덱스추가)인서트의 성능을 떨어짐
	그래도 보통 조회성능이 훨씬 더 중요한경우가 많기때문에 인덱스를 만드는게 합리적임
	
	사실 인서트에서는 특별히 쿼리로 성능을 올릴수있는방법은 없음
	그냥 몇가지 알아두면 편한기능들은 있음
	
	insert ignore는,저장하는 레코드의 프라이머리키나 유니크키가 이미 있을때,해당 레코드를 무시하고 다음레코드를 처리할수 있게 해줌
	이건 보통 여러레코드를 하나의 인서트문장으로 처리할때 유용함
	이건 단순히 유니크의 중복뿐아니라,데이터타입이 일치하지않아서 인서트가 불가능할때도,칼럼의 기본값으로 인서트를 하게 만들기도 함
	즉 낫널에서 널이 들어가면 기본값인 0으로 세팅해서 인서트하는느낌
	이게 발동되면 경고메시지가 뜸,이건 주의해서 사용하는게 좋음
	
	insert ... on duplicate key update는 중복이 발생하면 현재값으로 해당레코드를 업데이트해줌
	즉 인서트 or 업데이트임
	
	인서트의 load data는,데이터를 빠르게 적재할수있지만,단일스레드에 단일트랜잭션이라는 단점이 있음
	그래서 가능하면 인서트를 쪼개서 나눠서 던지는 방식을 취하면 더 효율적으로 던질수있음(프라이머리키 기준으로 자르면됨)
	
	인서트의 성능은 쿼리보다 테이블의 구조의 영향을 많이받음
	보통 소량을 넣는경우가 많기때문
	그리고 데이터가 정렬되어있으면 훨씬 더 저렴하게 넣을수있음
	
	그리고 오토인크리즈먼트를 키로잡으면 이게 가장 빠른 인서트를 보장해줌
	
	
4.update와 delete
	update와 딜리트에 orderby를 넣고 limit를 걸어서 정렬해서 상위몇개만 지우는방식도 가능함
	이건 너무 많은 레코드를 건드려야할때 커넥션을 끊어가면서 가기위해 사용할수있음(과부하방지+언두로그 리셋)
	단 복제소스서버에서 이렇게하면 경고메시지가 뜰수있음(바이너리로그포맷이 row면 상관없는데,statement면 그럴수있음)
	이건 orderby에 의해 정렬되더라도 중복된값의 순서가 복제소스와 원본과 다를수있기때문(프라이머리키나 유니크키 기반이면 상관없겠지만 경고메시지는 뜸)
	
	
	join update는 두개이상의 테이블을 조인해서 결과레코드를 변경 및 삭제하는걸 말함
	보통 조인된 테이블중 특정 테이블의 칼럼값을 다른테이블에 업데이트해야할때 주로 사용됨(프라이머리키가 같은 레코드중 a테이블의값으로 b테이블값을 덮을때)
	혹은 조인되는 양쪽테이블에 공통으로 존재하는 레코드만 찾아서 업데이트할때도 사용할수있음
	
	이건 조인되는 모든테이블에 대해 읽기참조만 되는 테이블은 읽기잠금이,변경이 일어나는 테이블은 쓰기잠금이 걸림
	그래서 데드락확률이 올라가니 너무 자주쓰는건 피하는게 좋지만,통계용 update나 배치프로그램에선 유용하게 쓸수있음
	이 조인업데이트도 조인을 쓰니,드라이빙테이블과 드리븐테이블의 선택에 따라 성능이 바뀜,그래서 explain돌리는게좋음
	
	그리고 조인업데이트에선 그룹바이나 오더바이를 사용할수없음,그래서 서브쿼리를 사용해서 임시테이블을 생성해서 처리해야함
	
	
	여러레코드를 업데이트할때,만약 동일한값으로 업데이트하는게 아닌,변수를 사용한 업데이트도 가능함
	values row()나 row()를사용해서 임시테이블을 생성해서 그걸 참조하는식으로 할수있음(164p)
	
	
	조인딜리트는 조인이 성공한 레코드에 대해 특정테이블에서만 그 레코드들을 삭제하는거임
	즉 조인으로 체인걸어서 외래키로 같은프라이머리키가 있는 c테이블에 특정값이 있다면,a테이블에서 레코드를 삭제하는식
	물론 delete절에 여러개를 적으면,여러테이블도 삭제할수있음
	
	
5.스키마조작	
	8.0부터는 스키마 조작의 많은부분이 온라인처리가 돼서,따른테이블같은걸 따로 잠금을 걸지않고 진행하지만,아직도 락을 잡아야하는애들이 많이있음
	그리고 테이블에서 프라이머리키를 추가하는작업같은건 데이터파일의 재배열이 필요해서 테이블리빌드가 필요함
	단순히 칼럼이름바꾸는 그런건 메타데이터만 바꾸면되니 저런게 필요없고
	이런건 버전별로 차이가 크기때문에,작업하기전에 매뉴얼과 테스트를 해보는게 좋음
	
	온라인처리가 가능한 명령들은 169p참고
	그리고 보통 테이블 리빌드가 필요하고,최종로그적용이 필요해지면 중간과정에서 실패할 확률이 올라감
	그래서 이걸 최대한 줄이는게 좋음
	실패케이스는 
		alter table명령이 장시간 실행되고,동시에 다른커넥셔에서 dml이 많이 실행되거나,온라인변경로그공간이 부족
		alter table명령이 실행되는동안 alter table이후의 테이블구조에 적합하지않은 레코드가 인서트 or 업데이트되면 실패
		스키마변경을 위해 필요한 잠금수준보다 낮은잠금옵션일경우
		lock=none라도 처음과끝은 락이 필요한데,이걸 획득하지못하고 타임아웃걸리면 실패(메타데이터락)
		온라인 인덱스생성의 경우 정렬을위해 temdir에 명시된 경로를 사용해서 정렬하는데,디스크공간부족시 실패
	가 있음	
	모든 alter table명령은,performance_schema를 통해 진행상황을 모니터링할수있음(175p)
	
	
	mysql은 1개이상의 데이터베이스를 가질수있음,mysql에서 스키마와 데이터베이스는 동격의 개념임
	이건 그냥 객체에 대한 권한을 구분하는 용도정도로만 사용됨(그래서 use 데이터베이스명을 서버접속했을때 바로쓰는거)
	
	mysql은 전통적으로 테이블별로 테이블스페이스를 사용했음(각 테이블별 저장공간)
	이걸 제너럴테이블스페이스를 사용하면(8.0부터 가능),여러테이블의 데이터를 한테이블스페이스에 저장할수있음
	이건 여러제약사항이 있긴한데,테이블갯수가 매우많을땐 도움이됨
	중요한건 아닌듯
	
	
	테이블은 사용자데이터를 가지는 주체임
	테이블의 구조를 조회할땐
		show create table 테이블명 //해당테이블을 생성할수있는 쿼리 리턴
		desc 테이블명 //테이블의 메타데이터 리턴,k8s의 describe같은거임,단 인덱스칼럼의 순서나,외래키,테이블자체속성은 보여주지않음
	테이블 구조를 변경할떈,alter table을 사용함
	이건 테이블구조만이 아닌 인덱스 추가삭제와 칼럼추가삭제에서도 사용됨
	테이블단에서 이걸 사용하는건,보통 테이블의 인코딩이나 스토리지엔진,파티션구조등을 변경할때 사용됨
	스토리지엔진은 보통 바꿀일없을거고,인코딩변경은 가끔할일이 생김
	
	테이블명을 변경할떈 
		rename table 원래테이블명 to 바꿀테이블명
		rename table db1.원래테이블명 to db2.바꿀테이블명
	이렇게함,같은 db내에서 변경은 메타데이터만 바꿔서 매우빠른데,다른 db내 변경은 파티션이 보통 다르기떄문에 다 복사붙여넣기해야해서 오래걸림
	그리고 블루그린방식같이 서로 이름을 교체할땐
		rename table a to a_old,a_new to a
	이런식으로 묶어서 처리하면 중간에 a테이블이 비는시간이 안생김(잠금대기만 발생)
	
	테이블의 정보를 볼땐
		show table status like '테이블명'
	으로 할수있음,여기선 전체레코드갯수,레코드평균크기등을 알수있음
	이정보들은 information_schema에 관리되는걸 가져오기때문에,
	저기에 직접 접근해서 mysql의 테이블들이 사용하는 디스크공간정보를 조회할수도있음
	
	데이터는 복사하지않고,테이블의 구조만 동일하게 복사할땐
		create table 새로만들테이블명 like 테이블명
	으로 인덱스까지 완전히 복사할수있음
	데이터까지 복사하려면
		create table 새로만들테이블명 like 테이블명
		insert into 새로만들테이블명 select * from 테이블명
	이 두개를 같이돌리면됨
	테이블 삭제는 drop table을 쓰고,딱히 다른테이블에 영향을 직접적으로 주진않는데
	큰테이블삭제는 부하가 크기때문에 간접적인 영향을 줄수는있음(속도감소)
	
	테이블구조변경은 대부분 칼럼을 추가하거나 칼럼타입을 변경하는 작업임
	가장 마지막에 새칼럼추가
		alter table 테이블명 add column 칼럼명 타입
	이경우엔 그냥 마지막에 넣으면돼서 instant로 즉발추가가 가능함
	근데 중간에 새칼럼을 추가할땐
		alter table 테이블명 add column 칼럼명 타입 after 추가할위치의칼럼명
	이렇게하는데,이경우엔 테이블의 리빌드가 필요해서 오래걸림
	테이블이 크다면 가능하면 마지막에 추가하는게좋음
	
	삭제는 항상 리빌드가 필요함
		alter table 테이블명 drop column 칼럼명
	이름 및 타입을 변경할땐
		alter table 테이블명 change 이전칼럼명 이후칼럼명 타입 속성 //이름변경,속성은 not null같은거 그냥적으면됨
		alter table 테이블명 modify 칼럼명 바꿀타입 속성  //타입변경,varchar길이도 똑같음
	이렇게함
	이떄 이름변경은 즉발,타입변경은 많이느리고 쓰기락,varchar 길이증가는 리빌드할수도있고 안할수도있음,varchar 길이감소는 많이느리고 쓰기락
	varchar이 리빌드 하는 조건은,255(1바이트)이하에서 256~(2바이트이상)으로 늘어날땐 리빌드를 해야하고,그안에서 놀땐 상관없음
	
	
	인덱스변경도 대부분이 온라인ddl임
	b트리인덱스추가는 뭐든 상관없이 inplace에 잠금없이 동작하고,전문인덱스와 공간인덱스는 shared잠금이 필요함
	
	mysql에서 인덱스목록을 조회할땐 
		show index from 테이블명
	을 하면 됨
	여기서
		seq_in_index:인덱스에서 해당칼럼의 위치(2개이상칼럼을쓰는경우를위해)
		cardinality:인덱스에서 해당칼럼까지의 유니크한 값의 갯수(복합칼럼의 경우 해당값까지의 유니크갯수를 보여줌)
	등만 알아두면됨
	그리고 show create table로 쿼리받아보면,여기서도 인덱스 다 나오긴함
	
	인덱스 이름 변경은
		alter table 테이블명 rename index 전인덱스명 to 변경인덱스명
	으로 할수있음
	이건 5.7부터는 메타데이터변경이라 즉발로됨
	
	인덱스 삭제는 즉발로되지만,인덱스를 실수로 삭제했으면 복구는 매우 오래걸릴수도있음
	그래서 삭제를 좀 더 안전하게 하기위해 가시성을 변경하는 옵션도있음
		alter table 테이블명 alter index 인덱스명 invisible
	풀때는 invisible을 visible로 바꾸면됨
	이건 숨길때나 풀때나 즉발로 작동하고,숨기면 해당인덱스가 없는거처럼 작동함
	그래서 삭제전에 몇일 인비지블걸어두고 안전하다싶으면 삭제하면됨
	
	인덱스삭제는
		alter table 테이블명 drop index 인덱스명
	으로 할수있음
	이건 보통은 따로 잠금필요없지만(세컨더리),프라이머리키는 shared잠금이 필요함
	
	
	인덱스 생성을 여러개해야할떈,alter를 여러번날릴수도있지만 묶어서 날리는게 더 빠르게됨(1번만 풀스캔해서 여러개를 생성함)
		alter table 테이블명 add index 인덱스명1(칼럼1),add index 인덱스명2 (칼럼2,칼럼3)
	단 두 변경작업이 서로 다른 알고리즘을 사용하면 어짜피 여러번돌아야해서 의미없음
	
	
	mysql에서 프로세스를 조회할땐
		show processlist
		show full processlist//쿼리 전부표시
	로 할수있고,여기서 현재 실행중인 스레드와 실행중인 쿼리들이 표시됨
	문제상황에서 여기서 시간이 매우길게잡히고,커맨드가 쿼리인 애들을 킬할수있음
	그리고 state가 copying이거나 sorting이 나오면 얘들도 주의해서봐야함
	이때 킬은
		kill query id //해당쿼리종료
		kill id //해당세션종료
	로 할수있음
	이렇게되면 해당 트랜잭션은 롤백처리됨
	
	쿼리뿐아니라 트랜잭션이 오래 활성상태로 남아있는거도 문제가 될수있음
	이 트랜잭션들은 203p쿼리를 복사해서 볼수있음
	이떄 트랜잭션을 종료시키고싶으면 그냥 세션자체를 kill해버리면 바로 트랜잭션이 끝남
		
	
6.쿼리 성능 테스트	
	쿼리를 작성하고나면 일단 explain을 해봐야함
	그리고 특별히 문제될부분이 없으면 직접 실행해보는게 좋음,실행계획으로 안잡히는 문제가 있을수도있으니
	이떄 눈으로만 성능을 보는건 정확하지않음
	
	쿼리성능에 영향을 미치는 요소로는
		운영체제캐시:같은데이터반복이면 캐시를 리턴해줌(단 innodb는 관계없음)
		mysql버퍼풀:mysql단에서 같은데이터반복이면 버퍼에있는값을 리턴함
		다른 프로세스의 시스템자원 점유:다른곳에서 시스템자원쓰고있으면 값이 다르게나올수있음
		쿼리테스트횟수:핫에서 테스트할지 콜드테스트할지도 고려해야함
	같은 변인들을 통제해가면서 테스트를 해야함
	그래도 실제상황보단 좀 빠르게 나오니 이것도 신경써야함(실제상황에선 쿼리들이 여러개실행되며 경합이 일어나니)
	
	

	
12.확장검색
1.전문검색
	전문검색에서의 인덱스생성은,형태소분석과 엔그램 2가지방법이 있음
	형태소분석은 난이도가 높기때문에 보통 엔그램을 사용함(mysql에 엔그램은 내장되어있기도함)
	엔그램을 사용할때,ngram_token_size로 몇글자씩 잘라서 인덱스로 등록할지 정할수있음
	보통 2나 3을 사용함(이때 변경후엔 mysql재시작해야함)
	그리고 전문검색인덱스를 생성할떄 반드시 with parser ngram 옵션을 추가해야만 엔그램토큰을 생성할수있음
	
	이 엔그램은 주의할점은,토큰사이즈보다 작은 글을 검색할수는 없음,즉 2일경우 최소 2글자를 검색해야한다는 제약이생김
	그래서 3보단 2가 더 잘 사용됨
	이걸가지고 검색할때는,검색어를 해당토큰사이즈에 맞는 토큰으로 분할해서,각각의 토큰들을 이퀄로 검색하는식으로 검색함
	
	mysql의 전문검색쿼리는 자연어모드와 불리언모드 두가지가 있고,기본값은 자연어임
	자연어모드는 검색어에 제시된 단어들을 많이 가지고 있는 순서대로 정렬해서 결과를 반환함
	이때는 그냥 자연어를 쿼리에 넣을수있는데,그러면 공백기준으로 분리한다음 엔그램토큰으로 변환해서 검색후 일치율을 계산해서 정렬하는식으로 동작함
	불리언모드는 쿼리에 사용되는 검색어의 존재여부에 대해 논리적연산이 가능함(논문검색)
	
	검색어확장은,쿼리에 사용된 검색어로 검색된결과에서,공통으로 발견되는 단어들을 모아서 한번 더 검색을 수행하는 방식임
	즉 해당 검색어를 고정으로 한 결과에서의 tf계산이라고 보면될듯
	근데 이건 아직 불안정한듯,별로 추천하진않는 늬앙스
	
	이 전문검색인덱스는 어떻게 검색될지 알기 어려운데(값을 가공해서 인덱싱하니),그래서
		set global innodb_ft_aux_table='test/tb_bi_gram';
	을 넣으면 전문검색인덱스가 어떻게 저장,관리되는지를 볼수있게해줌


2.공간검색
	공간좌표는 종이처럼 평면상에 좌표를 투영한 평면좌표계(투영좌표계)와,지구구면까지 계산한 구면좌표계(지리좌표계)로 나뉘어짐
	보통 한 나라수준으로 처리를 하면 그냥 평면좌표계써도되고,좀 글로벌하면 구면좌표계를 사용해야함
	그래서 투영좌표계의 경우 매우 많은 수가 있음(나라마다 있어도되니까)
	
	공간좌표에서 위도경도를 받을때,st_x()로 위도를,st_y()로 경도를 받을수있음
	두 점 사이의 거리를 계산할떈
		select ST_Distance(ST_PointFromText('point(0 0'),0),ST_PointFromText('point(1 1'),0)
	이렇게 하면됨,ST_PointFromText의 첫번쨰는 좌표,두번째는 사용할 공간좌표계의 id값임
	만약 평면좌표계일경우 단순하게 피타고라스로 계산한값을 돌려주고,구면좌표계일경우 실제 미터로 값을 돌려줌
	보통 넣지않으면 평면좌표계라고 계산함
	
	추가적으로 st_가 붙은 함수와 안붙은함수가 있는데,st_가 붙은게 표준이니 얘들만쓰면됨
	테이블을 만들때 좌표를 넣을땐,좌표와 srid도 같이 넣어줘야함,그러면 srid가 다른게 들어오면 튕겨낼수있음
	물론 저걸 명시하지않으면 다 받아먹을수있지만,명시적이어야 인덱스를 사용할수있음
	
	그리고 평면이 아닌 구면체상의 두 점간의 거리를 계산할땐 ST_Distance_sphere()를 사용할수있음
	
	공간인덱스를 생성할떄,해당칼럼들은 전부 not null이어야함
	그리고 특정위치를 기준으로,반경 nkm안의 데이터를 검색할땐 st_distance_sphere를 사용하게되는데,이건 인덱스를 타지못함
	그래서 mbr을 통한,st_within함수를 사용해야함
	이건 해당 원을 감싸는 가장 작은 사각형을 만들고,그안에서 검색하는거임(248p참고)




13.파티션
1.개요
	파티션은 테이블이 너무커서 인덱스의 크기가 물리적인 메모리의 크기보다 커지거나,주기적인 데이터삭제작업이 필요할경우 유용함(로그)
	인덱스는 보통 select에 사용하지만,업데이트나 딜리트처리를 위해서도 검색을 해야해서 필요함
	그래서 인덱스를 사용해야할때 메모리보다 인덱스가 크면,인덱스를 쪼개서 메모리에 넣으면 스왑을 안해도돼서 빨라지는데,이때 사용되는게 파티션임
	또한,활발하게 이용되는부분과 아닌부분을 나눌수있다면 이것도 도움이됨(쓸데없는걸 메모리에 안가져와도됨)
	
	이런 파티션은 로그를 관리할때 제일 효과적임
	대량의 데이터가 단기간에 누적되고,시간이 지나면 쓸모없어지는 특성때문에,시간을 키로 파티셔닝을 해두고,오래된 파티션을 통째로 버리는식의 운용이 가능해짐
	이러면 따로 백업,삭제작업을 고부하로 할필요도 없고 좋음
	
	이 파티션이 있는테이블에 인서트는,그냥 파티션조건보고 넣으면되고
	업데이트는 파티션키업데이트와 그외업데이트로 나눠짐
	파티션키 업데이트는 해당파티션에서 해당레코드를 삭제하고,다시 인서트하는식으로 하고
	그외 업데이트는 그냥 고쳐적음
	
	가장 중요한 select에선
		where의 조건으로 검색할파티션을 선택할수있는가?
		where의 조건이 인덱스를 효율적으로 레인지스캔할수있는가?
	에 영향을 받음
	두번째는 항상 중요한거고,첫번째가 파티셔닝을 하면 추가적으로 생기는 조건임
	파티션테이블에선 첫번째에 의해 두번째 선택사항의 작업내용이 달라질수있기때문임
	이떄
		파티션선택가능+레인지스캔:최상효율
		파티션선택불가+레인지스캔:모든파티션대상으로 각각 레인지스캔후 병합
		파티션선택가능+풀스캔:해당파티션대상으로 풀스캔
		파티션선택불가+풀스캔:최악
	3번과 4번은 가능하면 피하는게 좋고,2번은 파티션의 갯수가 많을때는 주의해야함

	파티션테이블의 인덱스는 모두 로컬인덱스임
	모든 인덱스는 파티션단위로 생성되고,전파티션 통합의 인덱스는 지원하지않음
	그래서 파티션되지않은 테이블에선 인덱스를 순서대로읽으면 그 칼럼정렬된 결과를 바로얻을수있지만,파티션테이블은 그렇지않음
	그래서 레인지스캔에서 여러파티션을 읽어야할때,원칙상으론 정렬이 안된결과를 줘야하지만,우선순위큐에 담아서 임시로 저장하는식으로 땜빵을 침
	그래서 직접 정렬만큼은 아니라도 추가비용이 발생함
	
	파티션테이블을 접근할때,접근할필요가 없다고 판단되는 파티션엔 옵티마이저는 접근하지않음
	이렇게 필요한 파티션을 골라내는걸 파티션프루닝이라고 함
	이걸 통해 옵티마이저가 어떤 파티션에만 접근하는지 알수있음(explain에서도 나옴)

2.주의사항
	파티션엔 제약사항들이 있음(태생적인 제약사항)
		스토어드루틴이나 사용자 변수등을 파티션표현식에 사용할수없음
		파티션표현식은 칼럼이나 mysql내장함수를 사용할수있는데,일부함수는 파티션생성은 되는데 프루닝은 안돼서 주의해야함
		프라이머리키를 포함한 모든 유니크 인덱스는 파티션키칼럼을 포함해야함
		파티션테이블의 인덱스는 모두 로컬인덱스이고,모든 파티션은 같은구조의 인덱스만 가질수있음(특정파티션용 인덱스생성불가)
		동일테이블의 모든 파티션은 같은 스토리지엔진을 사용해야함
		파티션테이블은 외래키 사용불가
		전문검색인덱스생성이나 전문검색쿼리 사용불가
		공간데이터저장불가
		임시테이블은 파티션사용불가
	가장 중요한건 모든 유니크인덱스는 파티션키 칼럼을 포함해야한다는것
	즉 date를 기반으로 파티셔닝을 하면,프라이머리키에 id와 date 다중칼럼인덱스가 무조건 강제된다는것임
	각 유니크키에 대해 값이 주어졌을때 해당 레코드가 어느파티션에 저장됐는지를 계산할수 있어야하기때문

3.파티션의 종류
	파티션은 파티션키를 지정하는 방식에 따라 여러가지로 나뉘는데,가장 중요한건 레인지파티션임
	이게 가장 일반적으로 사용됨
	이건 파티션키의 연속된 범위(날짜같은)로 파티션을 정의하는데,
	이건 다른 파티션방법과 달리 maxvalue키워드를 사용해 명시되지않은 범위의 키값이 담긴 레코드를 저장하는 파티션을 정의할수있음
	
	이 레인지파티션은,
		날짜를 기반으로 누적되고,날짜를 기반으로 분석 및 삭제를 해야할때(로그)
		범위기반으로 데이터를 여러파티션에 균등하게 나눌수있을때
		파티션키 위주로 검색이 자주 사용될떄
	유용함
	파티션의 장점은
		큰 테이블을 작은파티션여러개로 분리
		필요한파티션만 접근(읽기쓰기 모두)
	두가지인데,이중 두번째가 특히 중요함
	이 두가지 장점을 로그파티션테이블의 경우 다 챙기기가 쉬움
	그래서 보통 파티션쓰는거도 로그가 많은편
	그래서 레인지파티션만 알아둬도 파티션 80퍼는 넘어감
	
	레인지파티션 생성은
		create table ...
		
		...
		partition by range(year(날짜칼럼명))(
			partition p0 values less than (1991)
			partition p1 values less than (1996)
			partition p2 values less than (2001)
			partition p3 values less than (maxvalue)
		)
	이런식으로 생성함
	마지막엔 맥스밸류를 넣어서 그이후꺼 다 거기다 박다가,좀 커졌다싶으면 나중에 나누는식임
	
	파티션을 추가할땐
		alter table 테이블명
		add partition (partion p4 values less than (2011))
	이렇게하면됨,주의할건 maxvalue를 사용했을경우 에러가나는데(이미 저장된애들은 그파티션에 있으니 파티션유일원칙이 깨짐),maxvalue를 사용했을땐
		alter table 테이블명
		reoganize partition p3 into(
		partion p3 values less than (2011),
		partion p4 values less than maxvalue,
		}
	이렇게 reoganize를 사용해서 maxvalue파티션을 분할하는느낌으로 해야함
	이작업은 오래걸려서,그냥 처음에 파티션을 만들떄,미래에 사용될 파티션을 2~3개 정도 더 만들어두는형태로 테이블을 생성하기도함
	그리고 배치스크립트돌려서 파티션을 자동으로 추가하는형태
	그리고 해당 파티션의 데이터가 없다면,reoganize를 해도 o(1)로 처리되므로,
	좀 미래거를 몇개 잡아두고,하나 꺼내쓸떄마다 maxvalue를 분할하는식으로 처리해도됨
	
	파티션삭제는 drop partition을 사용하면됨
	이건 o(1)에 가깝게 처리됨(그냥 파일을 버리는거니까)
	이때 주의할건,가장 오래된 파티션 순서대로만 삭제할수있음
	즉 가장 오래된 파티션만 삭제할수있음
	
	그리고 reoganize를 사용하면,기존 중간에있던 파티션도 분할할수있음(maxvalue말고도 분리가 가능)
	이건 안에 데이터양에 따라 시간이 오래걸릴수도있고,해당시간동안 쓰기가 불가능해지니 조심
	그리고 reoganize를 사용해서 여러파티션을 하나로 병합할수도있음
		alter table 테이블명
		reoganize partition p2,p3 into(
		partion p23 values less than (2011),		
		}		
	이런식
	
	
	리스트 파티션은 레인지파티션과 비슷하게돌아가지만,여기는 파티션 키값의 범위가 아닌 키 값 하나하나가 다 파티션임
	그래서 maxvalue를 사용할수없음
	이걸 사용할때는
		파티션키값이 코드값이나 카테고리처럼 고정적일때
		키값이 연속되지않고 정렬순서와 상관없이 파티션을 해야할때
		파티션 키값을 기준으로 레코드건수가 균일하고 검색조건에 파티션키가 자주 사용될떄
	사용됨
	사용법은 281p참고,잘 사용되진않을듯,추가장점으로는,리스트라서 int가 아닌 string형태도 리스트파티션을 사용할수있음
	
	해시파티션은 해시함수의 결과로 레코드저장파티션을 지정함
	그래서 int형태의 키만 사용가능
	이건
		레인지파티션이나 리스트파티션으로 데이터균등분배가 어려울때
		모든 레코드가 비슷한 사용빈도를 가지지만,테이블이 너무 커서 파티션을 적용해야할때
	사용됨
	그래서 보통 회원테이블같은곳에 사용됨
	얘는 특성상 
		특정파티션만 삭제하는게 불가능(해시결과에 따라 분배되니 지울필요도없고 지워도안됨)
		새파티션을 추가할땐 모든데이터의 재배치가 필요
		보통 파티션의 조작과 특성과 많이 달라서 주의가 필요
	라는 특성이 있음 

	키파티션은 해시파티션과 거의같은데,해시함수대신 직접 해당 키결정함수를 넣는것,그래서 특성도 같음
	리니어 해시 및 리니어 키 파티션은,해시파티션과 키파티션에서 새파티션추가나 통합해서 개수를 줄일때,전체재분배가 필요한걸 좀 줄이기위해 나옴
	이걸사용하면 좀 더 효율적인 통합및 분배가 가능해짐(전체가 아닌 명시된 두개에 대해서만 작업이 가능함)
	단점으론,균등성이 좀 떨어져서,해시나 키파티션으로 충분하다면(파티션조정요건이 거의없다면),그거쓰는게나음
	
	
	파티션테이블에서 쿼리를 실행할때,모든파티션을 읽어야할지 특정파티션만 읽어도될지는 성능에 큰 영향을 미침
	즉 파티션프루닝을 할수있냐없냐는 매우 중요하고,이때 얼마나 프루닝할수있냐없냐가 핵심임
	보통 레인지파티션이나 리스트파티션은 파티션수가 적고(파티션명을 명시해야해서),해시나 키파티션은 매우많음(명시안해도돼서)
	프루닝을 할수없다면,파티셔닝이 되지않았다면 매우 효율적이었을 쿼리가 매우 비효율적이 되니(각 파티션마다 해당쿼리를 실행해야해서)
	테이블을 10개로 파티셔닝했을때 1~3개만 주로 읽고쓴다면 파티션이 좋지만,파티션된 10개를 균등하게 사용하면 오버헤드만 심해질수있음
	이경우엔 파티션이 아닌 샤딩을 해야함,파티션과 샤딩은 다른거임
	즉 파티션을 적용할떈,프루닝을 얼마나 할수있을지를 예측해보고,테스트한다음 적용해야함
	그리고 레인지파티션을 로그에 적용할때 말고는,파티션 쓰는거 자체를 좀 많이 고민해봐야함


14.스토어드 프로그램
1.문법
	그 프로시저라고 부르는 그거맞음 사람들이 혐오하는거
	실제로 db단에서 연산을 하는거다보니 선호되진않는듯
	db단에서 세밀한 권한제어나 해당영역의 추상화를 할수있지만,일단 성능이 낮고,db가 보통 병목인데 여기다가 추가하는게 맞냐는 근본적인 문제가있음
	어짜피 안쓸거같으니 대충 읽을수만 있을정도로 하자
	
	일단 프로시저를 돌릴때 296p를 보고 세팅을 해야함
	그리고 프로시저나 함수이름과 (사이에 모든 공백을 제거해야함
	
	스토어드 프로시저는 서로 데이터를 주고받아야하는 여러쿼리를 하나의 그룹으로 묶어서 독립적으로 실행하기위해 사용함
	즉 첫쿼리의 결과로 두번째쿼리를 실행해야할때 이럴떄 사용함
	스토어드프로시저는
		create procedure 프로시저명 (in파람,out파람)
		프로시저본문
	이렇게 구성됨,in파라미터로 값이 들어오고 아웃파라미터로 값이 출력됨
	즉 기본 반환값이 없고,파라미터를 사용해서 받아가야함
	이걸 실행할땐 call명령어로 실행해야하고,아웃파라미터를 받을 세션변수를 생성해서 넣어줘야함
	
	그리고 따로 커서를 파라미터로 전달받거나 반환할수없음
	하지만 프로시저내에서 커서를 오픈하지않거나 셀렉트의 결과를 페치하지않으면 해당쿼리결과셋은 클라로 바로 전송됨(출력을 안하면 해당쿼리가 아웃으로 나감)
	이걸통해 2개이상의 결과셋을 반환할수도있음
	
	
	스토어드함수는 하나의 sql쿼리로 작성이 불가능한 기능을 하나의 sql쿼리로 구현할떄 사용함
	예를들어 부서별로 가장 최근에 추가된 사원2명씩을 가져오는경우같을떄 사용함
	이건 반환값이 있고(return)반드시 반환값과 타입을 명시해야함
	그리고 결과셋을 리턴하지못함
	이 스토어드함수는 call이 아닌 select를 통해 실행할수있음
		select 함수명(매개변수)
	
	트리거는 테이블의 레코드가 저장,변경될때 미리 정의해둔작업을 자동으로 실행해주는데,잘사용하진않음
	이벤트는 특정시간에 스토어드프로그램을 실행시켜줌,즉 리눅스의 크론탭같은거임
	
	스토어드프로그램의 상세작성법은 317p참고

2.보안옵션
	8.0부터는 스토어드프로그램별로 권한을 설정할수있음
	만약 스토어드프로그램사용하는데 실행이 안되거나 할경우 343p참고해보면됨
	sql security옵션관련 문제때문에 실행이 안될수있음
	왜냐면,해당 스토어드프로그램을 실행할권한+각각 sql테이블의 권한을 둘다 가지고있어야하기때문
	
	그리고 추가적으로 deterministic와 non deterministic옵션도 있는데,이거 둘중에 하나를 선택해야함
	이건 입력이 같을때 결과를 확정적으로 낼거냐,시점에따라 결과를 달라지게 낼거냐임
	이게 non deterministic이면 호출시점에 해당sql을 실행하고,deterministic이면 만들때 한번 실행해서 값을 캐싱해두고,그값을 계속 리턴함
	그리고 non deterministic이면 풀스캔을 유도하는데,이게 디폴트라서  deterministic으로 바꾸는게좋음(상황따라 매번계산해야할수도있지만)
3.참고사항
	스토어드프로그램의 소스에 한글을 쓰면 깨지는경우가 있는데,이건 접속한 클라프로그램이 어떤 인코딩을 쓰냐에따라 달라짐 347p참고
	스토어드프로그램에서 declare를 사용해 로컬변수를 정의할수있음,이게 세션변수(전역변수)보다 안전함
	재귀호출을 할떄 스택의 최대수치는 max_sp_recursion_depth로 설정할수있음
	중첩루프안에서 2개이상의 커서를 열어야하면 예외핸들링에 주의



15.데이터타입
	데이터타입을 선정할땐
		저장되는값의 성격에 맞는 최적의타입을 선정
		가변길이칼럼은 최적의 길이를 지정
		조인조건칼럼은 똑같은 데이터타입으로 선정
	이 3가지조건을 만족해야함(가변길이는 좀 길게잡아도되긴함)
1.문자열
	문자열은 char과 varchar 두가지가 있는데,char은 고정길이,varchar은 가변길이임
	일반적으로 varchar이 쓰기편한건맞는데,둘다 장단점이 있음
	varchar은 최대크기가 있고(65536바이트),문자열의 크기헤더만큼 1~2바이트를 추가적으로 먹음
	그리고 값이 변경될때의 비용이 비쌈(고정크기에서 내용물만 바꾸는거랑 가변크기로 쫙 밀어야하는건 가격차이가 크니까)
	그래서 고정크기(주민번호)같은건 char을 사용하는게좋음
	그리고 문자열뒤의 숫자는 글자크기가 아닌 바이트크기라서,한글자에 영어는 1바이트,한국어는 2바이트,utf-8은 4바이트를 점유함
	
	그리고 mysql에서는 하나의 레코드가 64kb를 초과할수없음,만약 초과한다면 자동으로 text타입으로 변환됨
	
	그리고 varchar에서 칼럼의 크기를 변경할때(alter table),바이트 크기가 바뀌는수준에서의 변경이 제일 비용이 비쌈
	60짜리를 63으로 올리는건 즉발이지만,60을 64로 올릴려면 temp에 옮겼다가 다시옮겨야함
	그래서 문자열타입의칼럼을 설계할땐 좀 크게 잡는게 좋음
	
	
	mysql은 각 칼럼마다 다른 인코딩방식을 선택할수있음,물론 기본값설정도 가능함
	보통 utf8mb4쓰면됨
	mysql에서의 인코딩 시스템변수들은 여러가지가 있는데,364p참고
	
	mysql에서 쿼리를 요청했을땐 charcter_set_client변수에 들어있는 인코딩형식이라고 기본적으로 생각하고,따로 명시적으로 지정했으면 그거로 잡음
	그리고 결과를 반환할때는 charcter_set_results변수에 들어있는 인코딩형식으로 반환해줌
	
	콜레이션은,문자열칼럼의 값비교나 정렬순서를 위한 규칙을 의미함
	mysql의 모든 문자열타입칼럼은 독립적 문자집합(인코딩형식)과 콜레이션을 가짐
	즉 디폴트값설정을 따라가겠지만,따로 다 설정할수있다는것
	비교라는데서 알겠지만,이 콜레이션에 설정에따라 쿼리성능도 상당히 영향을 받음
	인코딩형식은 2개이상의 콜레이션을 가지고있는데,콜레이션을 따로 다른 인코딩형식에 사용할순없음
	즉 인코딩형식에 부속된게 콜레이션임
	이때
		인코딩형식이름_하위분류_대문자소문자구분여부
	혹은
		인코딩형식이름_bin
	이런형식으로 나옴
	여기서 하위분류는 보통 문자비교규칙같은 그런거임(e, è이런거 어케할건지 똑같이취급할건지같은)
	걍 뭐 bin쓰는게 젤 맘편하긴함
	
	그리고 조건검색은 대소문자구분없이,정렬은 대소문자를 구분해야할땐,둘중하나는 인덱스를 포기할수밖에없음
	보통 이럴땐 칼럼의 콜레이션을 ci로 만들어 조건검색을 인덱스타게하고,정렬을 깡으로하는게 일반적
	추가적인방법으론,칼럼을 하나 더만들어서 그걸로 정렬하는방법도 있긴함
	
	그리고 mysql5.7이전버전에서 만들어진 테이블들은 utf8mb4_general_ci를 사용하는데,요즘은 utf8mb4_0900_ai_ci를 사용해서
	둘을 조인을할때 에러가 발생하거나 성능이 많이떨어짐,그래서 저런테이블들이랑 같이 뭘해야할거같으면 디폴트를 utf8mb4_general_ci로 설정하는게좋음
	물론 새로시작하는 프로젝트면 기본값쓰면됨
	
	
	mysql에서 문자열칼럼을 비교할땐 char과 varchar이 거의같음,둘다 빈공간에 패딩이 채워져나오지않음
	즉
		패딩을 씌워서 비교
		trim으로 패딩제거
	순으로 진행됨,그래서 문자열뒤에있는 공백은 무시됨 
	단,like를 사용한 비교에선 공백이 유효문자로 취급되니 주의
	
	mysql에서 특수문자들을 이스케이프처리할땐 \를 사용하면되고,\t \n같은거도 사용할수있음
	그리고 홑따옴표사이에선 쌍따옴표를 이스케이프처리안해도 사용할수있고,반대도 마찬가지임

2.숫자
	숫자타입은 크게 참값(정수)와 근삿값(실수)로 나눌수있음
	보통 참값은 int계열이 잘 사용되고,근삿값은 double가 잘 사용됨
	그리고 값이 저장되는 포맷에 따라 십진과 이진으로 나눌수있음
	이진은 한바이트로 256까지 표현할수있어서 주로 사용되고(효율적),integer bigint등 대부분 사용함
	십진은 각자리마다 4바이트로 문자넣듯이 넣는거임,이건 비효율적이지만 매우큰수의경우 선택지가없어서 사용됨,decimal만 사용
	
	근삿값은 저장할때와 조회할때의 값이 정확히 일치하지않고,유효자릿수를 넘어서는 소수점이하의값은 계속 바뀔수있음
	특히 statement복제에서는 소스서버와 레플리카서버간 값이 다를수있음
	그래서 근삿값은 잘 사용하지않고
	십진표시인 decimal도 저장공간을 너무먹어서 매우큰숫자값이나 고정소수점을 저장해야하는게 아니면 잘 사용하지않음
	
	
	정수타입은 int시리즈중 최대한 작은걸 사용하면됨(자기가 사용할 범위내에서 최대한 작은거)
	그리고 unsigned도 사용해서 범위를 좀 늘릴수있음 만약 음수필요없으면 생각해볼만함
	이건 인덱스사용여부에 영향을주진않는데,값의 범위가 달라지니 조인칼럼은 서로 일치시키는게좋음
	
	부동소수점은 근삿값이라서 이퀄을 사용할수없음
	float는 정밀도명시를 하지않으면 디폴트로 4바이트를 사용해 8자리까지가 유효자릿수고,정밀도명시된경우엔 8바이트까지 사용할수있음
	double은 8바이트고정이고 최대 자릿수를 16개까지 유지할수있음
	이래저래 문제가 많아서,유효소수점의 자릿수만큼 10을 곱해서 정수로 만들어 그값을 정수타입컬럼에 저장하는방법도 생각해볼수있음
	
	만약 고정소숫점이 필요하다면(대출이자같은),decimal을 사용할수있음,이걸사용하면 저장효율은 안좋지만,정확한 소수값을 저장할수있음
	단 효율이 안좋으니 정수를 관리할때는 integer계열을 사용하는게좋음

	보통 decimal이나 부동소수점으로 칼럼을 정의할땐,타입이름뒤에 괄호로 정밀도를 표시하는데(decimal(20,5)는 정수15 소수5 총20)
	부동소수점은 저장공간크기가 고정이라서 정밀도를 조절해도 저장공간크기가 바뀌지않지만 decimal은 가변적이라서 저장공간크기가 바뀜
	근데 bigint같은애들은 이미 크기가 고정이라서 값을 제한하거나 할수없음(그냥 조건으로사용할수도없음)
	
	오토 인크리즈먼트를 사용해 인조키를 생성할수있음,
	이렇게 인조키를 생성하면 해당칼럼으로 생성되는 인덱스가 자동으로 생성되는데,이때 ai칼럼이 제일앞에 배치됨
	이 ai칼럼은 테이블당 하나만 사용할수있음
	이떄 개발용서버에서 서비스용서버로 옮길때 show create table로 옮기면,이 ai증가값까지 같이 이동할수도있으니 주의(초깃값이 개발서버의 최신값이됨)


3.날짜와 시간
	mysql에서는 날짜만 저장하거나,시간만 따로저장할수있고 같이 저장할수도있음
	보통 date나 datetime타입이 가장 많이사용됨
	그리고 time과 datetime,timestamp타입은 밀리초단위를 저장할수있게됐음
	이떄 정밀도를 얼마냐하냐에 따라 저장공간이 달라짐
	정밀도는 타입뒤에 괄호와함께 자릿수를 표기하면됨(time(6))
	now()를 통해 현재시간을 가져올떄도 now(6)하면 밀리초6까지의 시간을 가져옴,만약 넣지않으면 밀리초는 표기되지않음(0이 디폴트값)
	
	timestamp와 datetime의 차이는,timestamp는 utc로 저장되고 datetime은 그냥 클라에서 입력받은값이 그대로 들어옴
	그래서 타임존을 서버에서 변경하면 해당시간도 자동으로 바뀌어서 출력됨
	이전에는 이거말고 다른차이도 있었는데,5.7부터 없어져서 그냥 아무거나써도될듯
	
4.enum과 set
	이넘과 셋 둘다 문자열값을 숫자값으로 매핑해서 관리하는타입임
	
	이넘은 테이블의 구조에 나열된 목록중 하나의값을 가질수있음
	이거의 가장 큰 용도는 코드화된 값을 관리하는것
	이넘을 사용할때는 실제값은(숫자값) 알필요없음,그냥 스트링을 값으로 생각하면됨
	이 이넘은 아이템의 값이 길면길수록 저장공간절약이 더 효율적이됨
	
	이 이넘의 가장 큰 단점은,칼럼에 저장되는 문자열값이 메타데이터가 되면서,기존 이넘에 새값을 추가해야할때 구조를 변경해야한다는것
	이떄 이넘의 맨 마지막에 추가하면 o(1)로 처리되지만,중간에 넣으려고하면 다 값을 바꿔야해서 오래걸림
	그래서 매우 큰 이넘의 경우엔,가독성을 좀 포기해도 그냥 맨마지막에 넣는게 나은경우가 많음
	그리고 추가적으로,이넘으로 정렬할땐 문자열기준으로 정렬하고싶으면 cast를 사용해서 정렬해야하는데,이러면 당연히 인덱스를 못타니까 주의
	기본적으로는 이넘의 추가순서대로 정렬됨
	이렇게 용량을 줄이면,메모리의 사용량을 줄일수있어서,한번에 메모리에 다올려서 작업할수있어서 효율이올라감
	
	set도 테이블의 구조에 정의된 아이템을 정수값으로 매핑해서 저장하는건 똑같은데,셋은 하나의 칼럼에 1개이상의 값을 저장할수있음(list)
	이때 각 아이템값에 매핑되는 정숫값은 1씩증가하는게 아닌,2n의 값을 갖게됨,
	그래서 아이템값의 멤버수가 8개이하면 1바이트,9~16은 2바이트,이런식으로 8바이트까지 늘어남
	이 셋타입칼럼에대해 이퀄을 수행하려면,칼럼에 저장된순서대로 문자열을 나열해야만 함(순서가 중요)
	그리고 set타입칼럼에 인덱스가 있어도,이퀄을 제외하고 find_in_set()함수나 like쿼리는 인덱스를 사용할수없음
	find_in_set()은 셋칼럼안에 특정 하나의값이 있는지를 확인하는함수
	단 이게 자주사용된다면,정규화해서 별도의 테이블로 뽑아내는게 좋음(1:n테이블)


5.text와 blob
	이건 둘다 대량의 데이터를 저장하는 방식임
	이 두가지는 거의같은방식으로 동작하는데,
	차이점은 text는 문자집합과 컬레이션을 가진다는거고,blob는 이진데이터타입이라 별도의 문자집합이나 컬레이션이 없다는것
	이 두가지다 어쩔수없이 사용하는거라서 가능하면 피하는게좋음(char이나 varchar사용)

	그리고 이 두가지타입을 사용할때,쿼리문장이 매우 길어질수있는데,이러면 max_allower_packet시스템변수보다 큰문장은 에러가 나게됨
	그래서 저 변수를 조정해야할수도있음
	
	mysql은 가능하면 모든 레코드를 다른레코드들과 같이 저장하려고 노력하는데,이쪽은 너무커서(레코드의 최대길이제한)불가능한경우가 많음
	이경우엔 외부페이지로 떼서 사용함(각페이지는 체인으로 연결),이경우 각페이지의 앞쪽 768바이트를 잘라서 프라이머리키페이지에 같이 저장함

6.공간데이터타입
	공간데이터는 
	point,lineString,polygon등의 단일객체가 있고,
	multipoint,multilinestring,multipolygon등 여러객체를 저장할수있는 친구들도있음
	그리고 만약 저장공간데이터가 여러모양을 저장해야하면 geometry로 넣으면 이게 슈퍼타입이라 여러가지를 다 저장할수있음
	geometry와 모든 자식타입들은 전부 blob객체로 관리되고,전송도 blob로 전송됨,즉 geometry가 blob를 감싼형태임
	단 jdbc드라이버에서는 공간데이터를 공식지원하지않기때문에 바로쓸순없지만,orm계열에선 보통 서드파티라이브러리로 지원함
	그리고 blob라고해도 실제 저장데이터크기가 크지않으면 외부 페이지로 뽑지않기떄문에 성능걱정은 안해도됨
	
	공간데이터를 생성할떈 st_가 붙은 함수들로 생성할수있음
	조회할때도 ST_AsText()같은 함수들을 사용해서 조회할수있고,공간데이터의 각 속성을 구분해서조회하고싶으면
		st_srid(ST_pointFromText('point(좌표1,좌표2),srid값'))
		st_x(ST_pointFromText('point(좌표1,좌표2),srid값'))
		st_y(ST_pointFromText('point(좌표1,좌표2),srid값'))
		st_latitude(ST_pointFromText('point(좌표1,좌표2),srid값'))
		st_Longitude(ST_pointFromText('point(좌표1,좌표2),srid값'))
	이렇게하면 해당포인트를 텍스트로 바꾸고,거기서 필요한거만 뺴서쓸수있음


7.json타입
	json타입은 저장할떄 json이 아닌 blon(바이너리 json)으로 저장함
	그래서 깡으로 text로 저장하는거보단 효율이 좋은편임
	그리고 8.0부터는 json의 부분업데이트를 지원함
	이건 json_set,json_replace,json_remove를 통해 업데이트,삭제할떄만 적용됨
	따로 부분업데이트를 했는지 확인할방법은 없지만,꽤 성능차이가 크므로 가능하면 되게하는게좋음
	
	이때,정수필드업데이트는 보통 항상 부분업데이트가 일어나고,
	문자열필드는 저장되는 문자열의 길이에따라 부분업데이트가 사용되지않을수도있음
	특정필드의값이 작은용량을 가지면서 자주 길이가 다른값으로 변경된다면,
	해당필드가 가질수있는 최대길이의값으로 초기화해두거나 패딩해서 쓰면 부분업데이트가 잘되니까 참고
	
	json은 utf8mb4를 사용해서,대소문자를 구별하고 액센트문자도 구별함
	
	blob나 text보단 json칼럼이 json을 저장하는덴 단연 우위임
	정규화된칼럼과 json칼럼중에선,성능면에선 정규화칼럼이 낫지만,선호도에 따라서 json을 사용할수도있음
	json의 가장큰 문제는,정수값하나를 읽으려고해도 json칼럼 전체를 다 읽어야한다는것
	그렇지만 각 레코드가 가지는 속성이 너무 다양한데,
	레코드별로 선택적으로 값을 가진다면 json쓰는게 나을순있음(이떄 중요도가 낮으면,서치조건으로 잘사용되지않으면 좋음)
	그리고 정규화를 너무 빡세게해도 테이블갯수가 많아지고 응용프로그램코드도 길어져서,비정규화된 형태로 json칼럼으로 데이터를 저장하는게 좋을수있음

8.가상칼럼
	mysql의 가상칼럼은 가상칼럼과 스토어드칼럼 두가지로 구분할수있음
	둘다 다른칼럼의 값을 가지고 계산해서 새칼럼을 만드는건데,
		이때 인서트시에 값을 계산해서 실제 레코드로 저장하면 스토어드칼럼(물론 업데이트되면 같이업데이트됨)
		셀렉트시에 값을 계산해서 리턴해주면 가상칼럼임
	즉 디스크에 계산값이 저장되냐 아니냐가 가장 큰 차이임
	그래서 cpu사용량을 조금올려서 디스크부하를 조금낮출거냐,디스크사용량을 조금늘려서 cpu사용량을 조금낮출거냐 트레이드오프임




16.복제
	복제는 확장성과 가용성을 위해 사용됨
	복제란 한서버에서 다른서버로 데이터가 동기화되는걸 말하며,원본데이터를 가진 서버를 소스서버,복제데이터를 가진 서버를 레플리카서버라고 부름
	소스서버에서 데이터 및 스키마의 변경이 최초로 이루어지며,
	레플리카서버에선 이러한 변경내역을 소스서버로부터 전달받아 자신이 가진 데이터에 반영해서 동기화함
	
	이런 복제를 하는 이유는
		스케일아웃
		데이터백업
		데이터분석:분석용으로 복제서버를 둬서,통계쿼리는 여기서만 실행
		데이터의 지리적 분산:불났을때 다뻗는거방지 및 어느곳에서나 비슷한 통신속도를 줄수있음
	등이 있음 

1.복제아키텍쳐
	mysql서버에서 발생하는 모든 변경사항은 별도의 로그파일에 저장되는데,이게 바이너리로그임
	이건 데이터의 변경내역말고도 db,테이블의 구조변경,계정이나 권한의 변경정보까지 모두 저장됨
	이 바이너리로그를 레플리카에서 받아서 적용하고,또 자기자신에 릴레이로그라는 로그로 남김
	
	복제가 시작되면 3가지유형의 데이터가 생성됨
		릴레이로그:소스서버의 바이너리로그의 이벤트정보
		커넥션메타데이터:레플리케이션io스레드에서 소스서버에 연동할떄 사용하는 db계정정보 및 현재 읽고있는 소스서버의 바이너리파일명
		어플라이어 메타데이터:최근적용된 이벤트에 대해 해당이벤트가 저장된 릴레이로그 파일명등이 들어있음
	릴레이로그를 제외한 두개는 파일과 테이블형태로 저장할수있는데,보통 테이블로 저장하고 이게 디폴트임
	파일로 저장할경우 크래시났을때 머리아픈일이 좀 있대

2.복제타입
	이 복제를 할떈 바이너리로그파일기반으로 할수도있고,글로벌트랜잭션아이디(gtid)기반으로 할수있는데,보통 gtid기반으로 하는편임
	
	바이너리로그기반 복제는 예전에 쓰던방식임
	모든 서버들이 서버id를 가지고 소스서버의 로그파일을 받아다가 실행시키는거
	이때 서버id가 같은 이벤트를 만나면 무시함(자기가 실행시켰다고 생각함),그래서 이걸 잘 알고 각 서버마다 다른 서버id를 줘야함
	
	실제 세팅하는건 대충스킵하고(435p참고)
	대충 덤프떠서 데이터옮기고,다하고나서 복제를 키면됨
	그리고 만약 중간에 트랜잭션이 제대로 실행되지못하고 에러가 발생해서 복제가 멈출때,해당트랜잭션을 스킵해도되면 스킵하는방법도있음(442p)
	보통 중복키에러가 자주이럼
	물론 스킵하면 안되면 짤없이 다시 레플리카서버 처음부터 구축해야함
	
	gtid는 현재 모든 서버들끼리 각각 id를 가지고 글로벌로 유일한 트랜잭션을 만들어서,
	복제된 서버마다 동일한 이벤트에 대해 서로 다른식별값을 가지게하는거임
	이건 장애가 발생했을때 복구과정에서 매우 유용함,바이너리로그기반일때
		소스서버가 뻗으면 레플리카중 하나가 소스서버가 되는데,
		다른레플리카가 원래소스서버의 최신까지 동기화를 못했으면 얘는 그냥 죽은서버가 되버림
	이때 gtid를 사용하면,다른 레플리카에 있는 로그에서 해당시점부터 트랜잭션을 가져와서 실행해버리면됨(어짜피 글로벌로 트랜잭션명이 같으니 같은트랜잭션임)
	이래서 장애복구가 훨씬 더 안전해짐
	
	gtid는 해당서버내에서도 고유하고,그서버가 속한 복제토폴로지내 모든서버에서도 고유함
	gtid는 커밋되어 바이너리로그에 기록된 트랜잭션에 한해서만 할당되며,데이터읽기만 수행하는 select쿼리같은건 할당되지않음
	이건 소스id:트랜잭션id로 구성됨,즉 서버아이디를 트랜잭션id앞에 붙이는식
	그리고 이런 gtid는 매 트랜잭션이 커밋될때마다 저장되는데,많이쌓였다싶으면 시작시간과 종료시간을 묶어 여러레코드들을 묶어버림(압축)
	이건 뭐 별로 신경쓸필요없음
	
	gtid를 활성화하는것과 gtid기반 복제를 사용하는건 별개임
	gtid복제를 쓰려면
		모든 서버들을 gtid활성화로 만들어두고
		각 서버의 id 및 server_uuid가 유일해야함
		소스서버에 복제계정을 만들어두고
		데이터를 덤프떠서 레플리카에 복사(455p참고)
		그리고 복제를 시작하면됨(이떄 source_auto_position이 들어가면 gtid기반임 458p참고)
	이렇게 하면됨
	
	gtid기반에서 트랜잭션을 건너뛰려면,해당 트랜잭션명으로 수동으로 빈트랜잭션을 생성해서 커밋하는식으로 넘어갈수있음
	
	non-gtid기반복제에서 gtid기반복제로 변경할땐,5.7.6이상이면 그냥 온라인으로 할수있고,이하면 껐다켜야함
	이건 그냥 시스템변수만 바꾸면됨(463p)필요해지면보자


3.복제 데이터 포맷
	바이너리로그의 데이터포맷에는 실행된 쿼리를 바이너리로그에 기록하는 statement와 변경된데이터 자체를 기록하는 row방식 두가지가 있고,
	이둘을 혼합한 형태도 있음
	
	statement는 단순히 실행된 쿼리들을 저장하는 방식임
	이러면 데이터를 저장하는게 아닌 쿼리를 저장해서 저장공간에 대한 부담이 적고,원격서버들과 통신할떄도 부담이적어짐
	단점으로는 비확정적(rand,orderby없이 limit사용)쿼리가 실행됐을때 복제시 소스와 레플리카의 값이 달라질수있음
	추가적인 단점으로 row포맷으로 복제될때보다 데이터에 락을 더 많이건다는게 있음(결과물이 아닌 쿼리를 저장하니까 쿼리가 실패하는지성공하는지를 기다려야함)
	추가적인 제한으로,트랜잭션격리수준이 repeatable-read이상이어야함,어짜피 이렇게 보통잡으니 상관없을듯
	
	row기반은,데이터변경이 발생했을때 변경된값을 바이너리로그에 기록하는 방식임
	이건 statement보다 좀 더 안전해서 일단 이게 디폴트값임
	이건 rand같은 비확정적쿼리를 실행시켜도 결과값을 저장하기때문에 안전하게 복제를 할수있고,결과값만 바꾸기때문에 락이 덜걸림
	단점으로,결과물을 다 저장하기때문에 디스크비용이 많이 커지고,바이너리로그를 보고 무슨쿼리가 실행됐는지 알기어려움(다른프로그램쓰면 비슷하게나오긴함)
	
	이 둘을 섞은 mix기반도 있음,기본적으론 statement로 저장하다 비확정적쿼리를 만나면 row기반으로 저장하는식으로 동작함
	근데 무조건 이게 좋은건아니고,실제 사용자의 예상과 다르게동작할수도있어서 다른거도 쓸이유가 있음
	
	row포맷을 망설이는 가장 큰 이유는 로그파일의 용량문제임
	이거때문에 변경레코드중 일부만 기록할수도있고,압축도 지원함(대충 절반정도로 깎아주는듯)
	그리고 압축레벨도 설정할순있는데,이건 그냥 기본값쓰면됨,높으면 cpu사용량은 증가하는데 별로 효과는없대
	그리고 압축을 사용하면 소요시간이 꽤 차이가 나니,이거도 트레이드오프할때 고려해야함

4.복제동기화 방식
	소스서버와 레플리카간의 복제동기화엔 비동기방식과 반동기방식 두가지가 있음
	
	비동기는 소스가 레플리카로 데이터를 던지고나서 응답을 받지않는것
	즉 비동기방식으로 진행되고,레플리카가 받든못받았든 신경쓰지않음
	그래서 누락된 트랜잭션이 있다면 수동으로 등록해야함	
	이거의 단점은 동기화여부를 보장하지않는다는것이지만,장점은 소스서버가 각 레플리카서버에대해 영향을 거의 받지않는다는것에 있음
	그래서 레플리카서버의 댓수가 늘어나도 거의 영향을 받지않음
	또한 레플리카서버에서 무거운쿼리가 돌아가고있어도 소스서버에서는 영향을 받지않음
	
	
	반동기는 소스가 레플리카에 도착했냐까지만 응답을 받는것
	즉 소스가 레플리카에 도착하고 답변으로 ack를 받아야 트랜잭션을 커밋함
	여기서 중요한건,레플리카에 도착했냐까지를 받는거지,해당 트랜잭션이 적용됐냐를 보장하는건 아님,그래서 반동기임
	
	이때 응답을 기다리는시점을 시스템변수로 선택할수있음
		after_sync:트랜잭션을 바이너리로그에 기록한후 스토리지엔진에 커밋하기전단계에서 레플리카서버응답을 기다림
		after_commit:스토리지엔진도 커밋한후에 클라에 결과를 반환하기전에 레플리카응답을 기다림
	기본값은 after_sync고,장점은
		소스서버에 문제가 발생했을때 팬텀리드가 발생하지않음
		장애가 발생한 소스서버에 대해 좀 더 수월하게 복구가 가능
	즉 커밋을 끝내고 나면 그쪽타고 조회한값과 레플리카에서 조회한값이 다를수있어서 애프터싱크를 사용함
	반동기복제는 비동기복제보다 좀 더 느리고,네트워크속도에 영향을 많이받아서 서버들이 물리적으로 가까우면 유리함
	또한 소스서버는 모든 레플리카서버들의 응답을 기다리지않고,n대만 응답받으면 넘어가는거도 가능함
	반동기복제 설정은 490p참고
	
	
5.복제토폴로지	
	복제서버들의 형태는 다양함
	멀티소스도 5.7부터는 가능해져서 더 다양해졌음
	
	싱글레플리카는 하나의 소스서버에 하나의 레플리카서버만 연결되어있는 형태임
	이때는 보통 소스서버에서만 읽기쓰기를 다하고,래플리카서버에선 읽기도 쓰기도 하지않음(백업용도)
	왜냐면 레플리카서버에서 문제가 발생했을때,소스서버에 부담이 커지니 서비스가 장애날확률이 더 올라가기때문
	물론 서비스랑 상관없는 배치작업이나 어드민툴에서 사용하는 쿼리같은건 상관없음,쿼리가 실패해도 서비스에 영향을 주지않기때문

	
	멀티레플리카는 1대의 소스서버에 2대이상의 레플리카서버를 연결한형태임
	보통 싱글레플리카에서 이렇게 넘어오는경우가 많은데,일반적으로 읽기요청의 분산을 위해 이렇게 사용함
	그리고 배치나 통계,분석등의 여러작업이 하나의 서버내에 있는 데이터에 대해 수행되어야할때도,
	멀티레플리카형태로 복제를 구축해서 용도별로 하나씩 나누어 사용할수도있음
	여러용도로 사용하든 읽기요청분산을 하든,레플리카서버 1대는 예비용으로 두는게 좋음
	레플리카서버로 읽기요청이 들어오면 해당레플리카서버는 소스서버만큼 중요해지고,얘가 죽었을때도 즉시 대타가 들어가야하기때문
	만약 대타가없으면 소스서버로 넘어가서 소스서버도 죽어서 서비스가 전부 죽어버릴수있음

	
	체인복제는 멀티레플리카에서 레플리카서버가 너무많을때,레플리카 서버 하나를 레플리카소스로 삼아 1:M:M형태로 구축하는걸 말함
	소스서버는 레플리카서버가 요청할떄마다 계속 바이너리로그를 읽어서 전달해야함,그래서 서버가 너무많으면 여기서 부하가 발생할수있음
	이때 바이너리로그배포를 다른 레플리카서버로 책임을 넘길수있는데,이게 체인복제임
	이때 소스서버와 직접 연결되어있는애들은 빠르게 소스서버변경이 적용되니 읽기용으로 사용하고,
	레플리카를 타고 들어온애들은 느리니 배치나 통계,백업용도로 사용함
	
	이건 또 서버를 업그레이드하거나 장비를 일괄교체할떄도 많이 사용함,
	기존장비는 그대로두고 새장비에 mysql을 설치한다음 레플리카서버랑 연결해두고(체인)
	기존장비를 바라보던 ip들을 새로운 소스서버로 변경한다음,웹서버를 한대씩 롤링리스타트하면됨
	그리고 기본장비들을 복제그룹에서 제외시키면끝
	이떄 주의할건,새 소스서버에서 바이너리로그와 log_slave_updates시스템변수가 반드시 활성화되어있어야함
	그리고 체인형태일때,중간계층의 레플리카서버가 죽으면 하단도 다같이 죽으니 주의해야함(장애발생시 복잡도가 올라감)
	
	
	듀얼소스복제는 두개의 서버가 서로를 소스서버이자 레플리카로 인식하는 형태임
	이건 두 서버모두 쓰기가 가능하다는게 제일 큰 특징이고,
	서로의 서버에서 변경된 데이터는 복제를 통해 다시 각서버에 적용되므로 양쪽에서 쓰기가 발생하고 서로 동일한 데이터를 갖게됨
	이때 목적에따라 액티브-패시브 또는 액티브-액티브 형태로 사용할수있음
	액티브패시브는 하나의서버에서만 쓰기를 하는걸 말하는데,
	싱글레플리카랑 비슷하지만 쓰기작업이 수행되는서버에서 문제가 생길시 별도설정변경없이 바로 예비서버로 쓰기를 전환할수있다는게 다름
	
	액티브액티브는 두서버 모두에 쓰기를 수행하는형태로,지리적으로 매우 떨어진 위치에서 유입되는 쓰기요청도 원활하게 처리하기위해 사용됨
	이때 서로의 트랜잭션이 전달되어 완료되기전까지 두 서버가 일관되지않은 데이터를 가질수있다는걸 유의해야함
	그래서
		동일한데이터를 각 서버에서 변경
		테이블에서 오토인크리즈먼트를 사용
	이 두경우에 문제가 발생할수있음
	동일데이터를 각서버에서 변경했을땐 늦게들어온 트랜잭션이 적용되고,
	오토인크리즈먼트를 사용할떈 같은키를 사용해서 중복키에러가 발생할수있음,그래서 액티브액티브에선 uuid등을 사용해서 애플리케이션단에서 id를 넣어야함
	
	그리고 듀얼소스구성등 멀티소스복제는 쓰기성능향상에 도움을 주지않음,어짜피 양쪽다 쓰기를 해야하기때문
	그래서 잘 사용하진않고 특수목적일때만 사용함
	쓰기성능의 향상이 필요하다면 샤딩을 하는게 좋음
	
	
	멀티소스복제는 하나의 레플리카서버가 여러대의 소스서버를 갖는 형태임
	즉 
		여러 mysql서버들의 각기 다른 데이터를 하나로 통합하거나
		여러 mysql서버에 샤딩된 테이블데이터를 통합하거나
		여러 mysql서버의 데이터를 모아 하나의 서버에서 백업을 하거나
	하는 용도로 사용됨
	즉 데이터들을 모아서 통계쿼리를 날리거나 백업하거나할때 사용하기좋은구조임
	또한 샤딩을 해뒀는데 생각보다 트래픽이 낮아서 통합해서 서버댓수 줄일때도 유용함
	
	멀티소스복제를 사용할떈 각 소스서버에서 유입되는 변경이벤트들이 레플리카서버로 복제될때 충돌할부분이 없는지를 잘 살펴야함
	그리고 이경우엔 각 소스서버들의 대체로 사용할순 없으니 장애용 레플리카서버는 각 소스서버와 일대일복제로 별도로 구성하는게좋음
	
	멀티소스복제에서 레플리카서버는 자신과 연결된 소스서버들의 변경을 같은시점에 일괄병렬로 동기화함
	그래서 각 소스서버들에 대한 복제가 독립적으로 처리되고,각 소스서버들의 독립된 복제처리를 채널이라고함
	채널은 개별적 레플리케이션io스레드,릴레이로그,레플리케이션 sql스레드를 가지고,채널명은 어느소스서버와의 연결인지를 구별할수있는 식별자역할을 함
	따로 채널명을 지정할수도있고,복제시작,중지,초기화등도 가능하고 이때 내가정한 채널명을 쓸수있음(505p)
	채널명을 쓰지않고 명령을 날리면 전체복제채널에 대해 실행함
	그리고 복제채널별로 멀티쓰레드사용도 가능하고,소스서버의 변경이벤트를 필터링하는거도 가능함
	
	멀티소스복제도 구축자체는 단일소스복제와 비슷한데,한레플리카에 여러 소스서버의 백업데이터를 가져와야하는게 귀찮음
	만약 데이터가없는 초기라면 그냥 연결만하면되고,한서버만 데이터가있으면 그서버만 넣으면됨
	
	데이터를 넣을때
		데이터가 작음:mysqldump사용,이건 느리긴하지만 병합문제가 없음
		데이터가 큼:xtrabackup사용,이건 물리적으로 백업하는거라 빠르긴하지만,병합문제발생하면 해결법이없음
	507p참고해서 진행
	양쪽다 데이터가 큰경우,하나를 xtrabackup를 사용해서 덮은다음 export로 내보내고 다시 임포트하는방식을 취해야함
	
	멀티소스복제를 할떄 유의해야할건,레플리카서버에선 master_info_repository와 relay_log_info_repository가 둘다 table이어야함
	그리고 이건 바이너리로그나 gtid나 상관하지않으니 이건신경안써도됨
	실제 구축하는건 책참고하자
	
	
6.복제 고급 설정	
	그렇게 막 엄청 효율적인느낌은 아니고,필요할때 가져다쓰는용도인데 난이도높아서 대충 키워드만 적을래
	필요해지면 찾아보자
	
	지연된복제는 복제를 일정텀뒤에 복제하게하는 세팅임
	이걸사용하면 실수로 소스서버에서 테이블을 삭제했을때같은 상황에 대처할수있어짐
	이경우에도 로그복사자체는 즉발로일어나는데,그걸 실행하는걸 텀을 두고 하는식임,
	그러니 이 로그를가지고 복구를하면 지연되지않은복제와 마찬가지로 복구도 할수있음
	
	
	멀티스레드복제는 복제된트랜잭션을 멀티스레드로 처리할수있게하는 기능임
	그래서 여러 dml쿼리들을 동시에 실행해서 처리할수있어짐
	이건 데이터베이스기반과 로지컬 클락기반 두개가있음
	
	데이터베이스기반복제는 스키마기반이라고도하고,과거에쓰던방식임
	이건 mysql내의 데이터베이스를 기반으로,각 데이터베이스별로 병렬처리를 할수있게하는거
	이건 설정할때 데이터베이스수만큼 워커스레드를 만들면좋음
	그래서 데이터베이스내에서의 테이블을 각각건드리는 쿼리같은건 병렬처리를 할수없다는 단점이있음(데이터베이스가 하나뿐이면 싱글스레드임)
	그래서 이건 데이터베이스들을 균일하게 사용할때 사용할수있음
	
	로지컬클락기반 복제는 발생시각의 순서를 기반으로 멀티스레딩을 하는방식임
	즉 트랜잭션이 로그로 기록될때 각 트랜잭션별로 논리적 순번값을 부여하고,이걸기반으로 병렬로 실행할수있게하는거
	자세한건 뭐 필요해지면보자 중요하진않아보임
	
	
	크래시세이프복제는 mysql이 크래시났을때 복제가 원활하게 재개될수있는 설정들을 제공함
	크래시세이프 조건을 만족하면,레플리카의 크래시후 키중복문제같은 문제가 생기지않음(540p참고)
	대충 로그를 테이블로 관리하고(트랜잭션으로 묶을수있으니),relay_log_recovery를 켜두면(on) 됨
	단 이경우에도 운영체제의 크래시의경우엔 무용지물일수있으니 주의
	그리고 복제형태별로 설정이 좀 다르니(543p)참고
	
	
	필터링된 복제는,소스의 이벤트중 특정이벤트만 레플리카에 적용할수있게 필터링을 할수있음(보통 db나 테이블선택)
	이건 소스랑 레플리카 모두 설정이 가능한데,
		소스는 보내는양을 줄일수있는대신 재부팅을해야하고,
		레플리카는 온라인으로 되는대신 받는양은 그대로에 적용만 바뀜
	이때 특정이벤트만 기록하거나,특정이벤트를 기록하지않거나 둘다 가능함
	그리고 이벤트의 포맷(statement와 row)에따라 동작이 다르니 조심
		row포맷쓸땐 ddl은 use를 사용해서 디폴트db를 선택하고,쿼리에선 db명을 넣지않아야함
		
		statement또는 mixed포맷쓸땐 dml ddl 모두 use를 사용해야하고 쿼리에서 db명을 넣지않고,
		복제대상테이블과 복제제외대상테이블을 동시에 변경하는 dml사용금지
	이걸지켜야함
	
	
17.innoDB 클러스터	
	복제를 사용하면 쉽게 서비스의 고가용성을 실현할수있지만,현재사용중인 서버들을 복제형태로 구성해놓는다고해서 고가용성이 실현되는건아님
	소스서버의 장애발생시 레플리카를 소스로 만드는작업이 자동으로되지않기때문
	즉 페일오버를 처리해줄수있는게 필요한데,이때
		레플리카의 읽기전용모드해제
		원래소스서버의 데이터변경금지
		웹서버의 mysql ip 새로운 소스서버로 변경
	이런작업들을 수동으로 해야함
	보통 이런건 자동화하는데,예전엔 서드파티ha솔루션을 사용했지만 5.7부터는 innoDB클러스터가 생겨서 쉬워졌음
	
1.innoDB 클러스터 아키텍쳐
	이노디비 클러스터는 단순히 mysql내에서 설정할수있는 특정기능이 아닌,mysql의 고가용성실현을 위해 만들어진 여러구성요소들의 집합체임
	이건
		그룹복제:기본적인 복제+복제에 참여하는 서버들에 대한 자동화된 멤버쉽관리(새맴버 추가제거등)를 담당함
		mysql라우터:앱서버와 mysql사이에서 있는 미들웨어로,앱이 실행한쿼리를 mysql서버로 전달하는 프록시역할을 함
		mysql셸:mysql클라보다 좀 더 확장된 클라프로그램으로,sql실행+js나 파이썬등도 실행가능
	를 포함함
	
	이때 데이터가 저장되는 서버들은 그룹복제형태로 복제가 구성되고,각 서버들은 프라이머리(읽기/쓰기)와 세컨더리(읽기)중 하나로 동작하게됨
	설정에따라 프라이머리는 하나일수도 여러개일수도있음
	그리고 클러스터는 최소 3대이상으로 구성해야함(2n+1)
	
	클러스터에 쿼리를 날릴땐 mysql서버에 직접 접근하는게아닌,mysql라우터에 연결해서 쿼리를 실행함(k8s랑 똑같은느낌)
	얘는 서버들의 메타데이터를 가지고,이를통해 적절한 서버로 쿼리를 전달함,그래서 클라이언트에 대해 서버들은 추상화되고 라우터만 알면됨
	
	mysql셸은 innoDB를 쉽게 생성 및 관리할수있게 해주고,상태확인이나 설정변경등의 기능을 제공함
	셸에서 클러스터와 관련된 작업을 진행할때는 클러스터내 mysql서버에 직접연결해 작업해야하고,단순쿼리실행은 라우터로하면됨
	
	클러스터에서 서버에 장애가 발생하면,그룹복제가 이를 감지하고 자동으로 해당서버를 복제그룹에서 제외시키며,라우터는 이걸 인지하고 메타데이터를 갱신함
	즉 페일오버가 자동으로 된다는거

2.그룹복제
	그룹복제는 기존 mysql복제를 기반으로 구현되어,내부적으로 row포맷의 바이너리로그,릴레이로그,gtid를 사용함
	이 그룹복제는 기존복제와 비슷한면도 있지만,복제구성형태와 트랜잭션처리부분에선 완전히 다른 복제라고 볼수있음
	기존 소스-레플리카는 단방향복제인데(소스에서 레플리카로),그룹복제에선 모든서버들이 하나로 묶여서 양방향으로 복제할수있기때문
	그래서 소스와 레플리카가 아닌 프라이머리와 세컨더리라고 부름
	
	이때 복제방식은 일단 반동기이긴한데 좀 기존에 비해 변형됐음
	기존반동기는 그냥 받았는지만 확인했다면,여기선 그룹내 다른멤버들의 인증을 과반수이상 받아야 트랜잭션을 커밋할수있음
	인증은 대상트랜잭션이 이미 인증을 통과한 선행트랜잭션과 같은데이터를 변경했는지 충돌여부를 검사해서 문제없으면 허가가 남
	만약 트랜잭션을 처리할때 과반수이상의 응답을 받지못하면 해당트랜잭션은 롤백되고 에러를던짐
	가장 큰 차이는,기존반동기는 레플리카서버의 응답을 못받아도 소스서버에선 적용되는데,여기선 그룹멤버들의 응답에따라 트랜잭션 적용여부가 갈린다는것
	즉 트랜잭션을 던진 발의자는 큰 영향을 주지못하고,전체의 합의를 통해서 트랜잭션 적용여부를 선택하게됨
	
	물론 셀렉트같은 변경없는것들은 그냥 알아서하면됨
	
	
	그룹복제가 제공하는 대표적기능은
		그룹멤버관리
		그룹단위의 정렬된 트랜잭션적용 및 트랜잭션 충돌 감지
		자동 페일오버
		자동 분산 복구
	를 제공함,즉 클러스터의 핵심기능은 다 그룹복제임
	
	그룹복제는 별도플러그인으로 구현되어있으며,이걸 사용하려면 그룹복제 플러그인이 설치되어있어야함
	그룹복제에 참여하는 서버들은 이 플러그인을 통해 서로간에 지속적으로 통신하며 복제동기화를 처리함
	
	
	그룹복제에서는 쓰기를 처리할수있는 프라이머리의 수에 따라 싱글프라이머리모드와 멀티프라이머리모드 두개가 있음
	
	싱글프라이머리모드는 그룹내에 쓰기를 처리할수있는 서버가 한대만 존재함
	보통 그룹복제를 처음 구축할때,구축을 진행한 서버가 프라이머리로 지정되고,나머지는 읽기전용모드로 동작하게됨
	이때 프라이머리가 문제가생겨서 탈퇴하면 기준을 바탕으로 새 프라이머리를 선출함
	기준은
		mysql서버버전
		각 멤버의 가중치값(세팅할때 설정할수있음,기본값 50)
		uuid의 사전순서
	순서대로 우선순위임
	
	멀티프라이머리모드는 모든 멤버들이 전부 프라이머리로 동작하고,어떤서버로든 쓰기와 읽기요청을 보낼수있음
	그래서 모든서버에서 쓰기가 발생할수있고,이 쓰기는 그룹의 다른 모든 멤버로 전파되어 다시 처리되므로,그룹멤버간의 mysql버전통일이 매우중요함
	만약 멀티프라이머리모드인데 버전이 다르면 진짜골치아픔
	
	그룹복제에 참여하는 멤버는 그룹에 참여할때 기존멤버들과의 버전호환성을 검사하고,여기에따라 그룹참여 가능여부와 읽기모드유지여부를 가름
	이떄
		새멤버가 그룹의 가장낮은버전보다 낮은버전을 사용하면 그룹에 참여할수없음
		새멤버가 그룹에 가장 낮은버전과 같은버전을 사용하면 참여가능
		멀티프라이머리모드에선 그룹의 가장낮은 버전보다 높은버전일경우,참여는 가능하지만 읽기전용모드임
		싱글프라이머리모드에선 새멤버는 항상 읽기전용모드임
	이런식임
	이때 읽기전용변경 및 읽기쓰기모드전환은 자동이라서,한멤버가 탈퇴하면 조건이 바뀔수있고,
	바뀐조건이 그룹내에 적용돼서 읽기전용이었던애가 읽기쓰기로 바뀔수있음
	
	
	그룹복제에선 어떤멤버들이 그룹에 참여하고있는지 목록여부를 가지고있고,변경이생기면 즉시갱신함
		SELECT * FROM performance_schema.replication_group_members 
	로 확인할수있음
	이때 멤버의 현재상태,호스트명,포트,mysql버전등도 확인할수있음
	이때 그룹복제가 관리하는 멤버목록과 상태정보를 뷰라고하는데,이건 해당시점의 그룹멤버목록임
	뷰는 뷰id라는 고유식별자를 가지고,그룹멤버가 변경되면 뷰id값이 바뀜
	그래서 뷰id값을 가지고 멤버의 변경을 추적할수있음
	뷰id는
		uuid(멤버가 아예없어질때까지 고정):변경점이 있을때마다 1씩증가하는 정수
	로 구성됨
	뷰id가 변경되면 바이너리로그에 view_change라는 이벤트로 기록되는데,모든뷰변경이 기록되진않고 새맴버 추가시에만 기록됨
	
	
	그룹복제에서 트랜잭션은 합의와 인증을 거쳐서 각 서버에 적용됨
	
	합의는 그룹멤버들에게 트랜잭션적용을 제안하고 승낙을 받는과정임(그냥 살아있냐여부확인)
	이때 전파대상멤버는 정상적인 상태로 동작중인애들한테만 뿌림
	이렇게해서 그룹전체에서 절반이상에게 응답메시지를 받으면,글로벌하게 정렬되어 각 멤버들에게 모두 동일한순서로 인증을 거치게됨
	
	인증은 전달받은 트랜잭션데이터와 로컬에서의 히스토리데이터를 바탕으로,
	이미 인증단계를 거친 선행트랜잭션과 충돌여부를 확인하고 충돌이없으면 승낙을 날림
	이 트랜잭션충돌은 멀티프라이머리모드에서만 발생함
	만약 충돌이 났다면 트랜잭션은 롤백됨
	그래서 충돌이 자주난다면 싱글프라이머리로 돌리는거도 방법임
	
	인증을 거치고나면 바이너리로그에 트랜잭션을 기록하고 커밋을 완료하고,이때 클라는 커밋요청에 대한 응답을 받게됨
	
	그룹복제에서 각 멤버들은 모두 동일한 트랜잭션을 적용하지만,실제적용시점까지 완전히 일치하는건아님
	그래서 한멤버에서 쓰기를 수행후 즉시 다른멤버에서 읽었을때 변경사항이 적용되지않았을수도있음
	특히 프라이머리장애로인해 페일오버가 발생했을때,새 프라이머리가 이전프라이머리에서 발생했던 트랜잭션을 적용하던중에 변경이 일어나면,
	해당 트랜잭션에서는 오래된 데이터를 읽고쓸수있음
	보통 정상상황에서는 신경안써도되지만,매우 민감한 서비스에선 문제가 될수있음
	
	mysql 8.0.14부터는 이 트랜잭션의 일관성수준을 설정할수있게됐음(574p)
	이건
		eventual:최종적 데이터일치,기본값,별도의제약없음
		before_on_primary_failover:싱글프라이머리에서 신규프라이머리가 선출될때,새프라이머리로 유입된 트랜잭션은 이전걸 처리하기전까지 대기함
		before:읽기 및 읽기-쓰기트랜잭션은 모든선행트랜잭션이 완료될떄까지 대기함,즉 항상일치하는데이터를 받지만 처리가 지연됨
		after:트랜잭션이 적용되면 해당시점에 모든멤버들이 동기화된데이터를가짐,
			즉 모든서버가 처리할준비가 될때까지 기다렸다가 커밋을함,당연히 처리가 지연됨
			이건 쓰기요청보다 읽기요청이 많고,분산된 최신읽기가 필요할때 사용하는게좋음
		before_and_after:before+after,즉 모든 선행트랜잭션이 완료될떄까지 대기하고,모든서버가 동시에 트랜잭션을 처리함,단점도 같음
	들이 있음
	
	그리고 그룹복제에서 일부멤버가 다른멤버보다 스펙이 낮거나 대역폭이 작거나,부하가 심할경우 다른멤버보다 트랜잭션적용이 지연될수있음
	이경우엔 최신데이터가 아닌 오래된데이터를 읽을수있고,충돌위험도 커짐
	이걸위해 흐름제어라는 메커니즘이 있음
	이걸키면 약한멤버를 기준으로 쓰기를 처리해서,전체적으로 속도는 느려지겠지만 일치하는 데이터를 가질수있게해줌
	이건 각 서버별로 따로킬수있음
	
	
	그룹복제에선 일부멤버가 응답불능이 되더라도 그룹이 정상적으로 동작할수있게하는 장애감지메커니즘이 있음
	이건 일부멤버가 문제가생기면 자동으로 해당멤버를 그룹복제에서 제외시켜서,정상적인 멤버들만 구성될수있게함
	이건 멤버들끼리 주기적으로 통신을 주고받으며 서로의 상태를 확인하다,
	5초이상 응답이 없는애들이 있으면 의심하고 과반수이상이 응답을 5초(변경가능)내로 못받았으면 추방함
	멤버가 추방되고나서 다른멤버들과 통신이 되면,자기가 추방됐다는걸 알게되고 재가입을 시도할수있음(각시도당 5분 3번까지가 기본값)
	근데 통신이되지않으면 추방됐다는걸 알지못하는데,이떄 다른애들과 통신이 일정시간동안 되지않으면 스스로 탈퇴하게 할수있음(기본값은 영원히 남아있는거)
	스스로 탈퇴하게하면 이때 재가입시도를 하는데,이 재가입시도가 전부 실패하면 리드온리,오프라인모드,mysql종료중 미리 선택해둔 하나를 실행하게됨
	
	
	멤버가 그룹에 새로가입하거나 탈퇴후 재가입할때,그룹내엔 이미 처리된 트랙잭션들이 있을수있음
	이걸 모두 적용해야 같은데이터를 가지게되는데,이걸처리하는게 분산복구임
	이때 복구작업을 해주는애를 기증자멤버라고 하고,그룹내에서 모든멤버는 기증자멤버가 될수있음
	
	그룹분산복구를 할때,먼저 얘가 가입한적이있나없나를 확인하는데,가입한적이 있으면 최신거랑 쟤가가진마지막거의 사이만 적용하면되기때문
	그래서 릴레이로그를 확인함
	그후에는 기증자멤버에 연결해서 분산복구를 진행하는데,이때 바이너리로그복제와 원격클론을 적절히 혼합해서 사용함
	즉 로그기반으로 하거나,스냅숏따서 그거가져오거나임
	보통 해야할게많으면 스냅샷,별로없으면 바이너리로그를 사용함
	
	즉 분산복구는
		로컬복구:자기가 탈퇴하기전에 적용못했던 트랜잭션이 있으면 그거부터적용
		글로벌복구:탈퇴이후 누락된 트랜잭션들을 가져와서 적용,새멤버는 여기부터
		캐시트랜잭션적용:글로벌복구할동안 쌓였던 트랜잭션 적용,이후는 멤버
	를 거침,이렇게되면 뷰변경이 일어나고 뷰id의 뒷값이 +1됨
	
	분산복구중 문제가 발생해도,바로 장애감지를 해서 다시 작업을 시도함(기증자가 뻗으면 다른기증자찾기같이)
	
	
	그룹복제를 사용할땐
		이노디비사용
		모든테이블에 프라이머리키 사용
		원활한 네트워크 통신환경
		바이너리 로그 활성화
		row포맷 바이너리로그 사용
		바이너리로그 체크섬 설정
		log_slave_updates활성화
		gtid사용
		고유서버id사용
		복제메타데이터저장소 설정 table로
		트랜잭션writeset 설정 xxhash64로
		테이블스페이스암호화 모든곳에서 같은값
		lower_case_table_names모든곳에서 같은값
		멀티스레드 복제 설정(597p)
	조건을 만족해야함
	이때 
		gtid를 사용하므로 gtid제약과 같은제약이 걸리고,
		멀티프라이머리모드에서 외래키를 지원하지않고,
		멀티프라이머리모드에서 select for update를 사용할때 데드락확률이 생기고
		복제필터 사용불가(단 복제멤버가 외부와 일반복제중일경우엔 자기들끼린 상관없음)
		클러스터서버는 9대까지 가능
	같은 제약들이 생김
	
	
	
3.mysql 셸,라우터
	셸은 그냥 좀 발전한 클라툴+서버에대한 api를 제공하는툴임
	
	라우터는 k8s의 마스터노드역할을 하는애임
	즉 받은쿼리요청을 적절한 서버로 분산처리해주고,이걸 다시 앱서버로 보내주는 프록시역할을 함
	얘는 마스터노드랑 하는일도 비슷한데
		클러스터의 구성변경 자동감지
		쿼리부하분산
		자동페일오버
	를 담당함

4.innoDB 클러스터 구축
	이건 구축할때보자
	글케어렵지않음 세팅파일들이 다해줘서
	
	617p가 설정인데 여기는 좀 주의해서보자
5.innoDB 클러스터 모니터링
	cluster명.describe()로 클러스터상태를 볼수있음(k get node라고보면됨)
	cluster명.status()로 상세를 볼수있고,더 자세히는 cluster명.status({'extended':1})로 볼수있음
	
6.innoDB 클러스터 작업
	클러스터에서 프라이머리모드를 변경할땐
		클러스터.switchToMultiPrimaryMode() //멀티프라이머리모드로 변경
		클러스터.switchToSinglePrimaryMode('인스턴스명')//싱글프라이머리모드로 변경,프라이머리선택도가능
	이렇게하면됨
	
	싱글프라이머리에서 프라이머리를 변경할땐
		클러스터.setPrimaryInstance('인스턴스명')
	이렇게
	
	인스턴스를 제거할땐
		클러스터.removeInstance('인스턴스명')
		클러스터.removeInstance('인스턴스명',{force:true})
	단 제거는 제거할때 아직 적용하지못한 트랜잭션이 있을수있는데,이경우엔 설정의 타임아웃시간만큼 대기하고 그안에 처리못하면 제거가 취소되고 에러가남
	{force:true}를 붙이면 강제제거할수있음
	이렇게 강제제거하면 클러스터에 다시참가할떄 문제가될수있으니,더이상 사용하지않을때만 force를 사용해야함
	그리고 제거시점에 해당서버와 통신이 불가능하다면 제거할지말지를 묻는 프롬프트가 뜨니 거기서 y나 n치면됨
	
	클러스터를 해체할땐
		클러스터.dissolve()
		클러스터.dissolve({force:true})
	로 해체할수있음
	이러면 그룹복제가 중단되고,클러스터에 관련된 메타데이터 및 설정들이 삭제됨
	데이터는 그대로있음
	이때도 아직 적용하지못한 트랜잭션이 있다면,설정시간만큼 기다렸다가 그안에처리못하면 해체가 중단됨
	이거도 force:true로 강제로 해체할수있음
	이거도 똑같이 통신불가능하면 물어봄
	
	현재 동작중인 클러스터에 대해 설정을 온라인으로 변경할땐
		클러스터.option()
	으로 옵션을 확인하고
		클러스터.setOption(옵션명,value) //전체변경 혹은 클러스터설정변경
		클러스터.setInstanceOption(인스턴스명,옵션명,value) //인스턴스단위 변경
	로 값을 변경할수있음
	상세는 636p로 옵션들은 볼수있음
	이떄 태그라는게있는데,이중 빌트인태그라는 시스템에서 먹는 태그가 있음
		_hidden:이게 true이면 이 인스턴스로 쿼리를 전달하지않음
	이걸사용해서 버전업데이트를 하거나(롤링업데이트),백업이나 통계쿼리를 날리는곳에서 쿼리받는걸 제외할수있음
	
		
7.innoDB 클러스터 트러블슈팅
	클러스터의 인스턴스장애가 발생하면 얘는 쫒겨나게됨
	이때 문제가 해결되고나면 알아서 재가입시도를 하는데,이때 그룹복제같은 설정들이 남아있으면 괜찮은데,날아갔으면 자동참여가 불가능함
	이떈
		클러스터.rejoinInstance('인스턴스명')
	으로 수동으로 참여시킬수있음
	
	클러스터에서 정족수에 해당하는,즉 과반수이상의 인스턴스에 장애가 발생하면 클러스터는 쓰기를 처리할수없음
	이때는 인스턴스의 추가 및 제거도 불가능한데,이거도 과반수동의가 필요하기때문
	이떈
		클러스터.forceQuorumUsingPartitionOf(인스턴스명)
	으로 클러스터를 강제재구성할수있음
	이건 해당 인스턴스에 접속해서,해당인스턴스가 통신할수있는 인스턴스들로만 클러스터를 재구성하는거임
	이러면 바로 쓰기요청이 가능해지는데,이때 잘려나간애들끼리도 클러스터가 유지되어서 클러스터가 2개가 될수있으니,
	이걸 명심하고 복구할때 이렇게된거아닌지 확인하고 복구해야함
	
8.innoDB 클러스터 버전 업그레이드
	클러스터의 버전을 올릴땐
		라우터업그레이드
		셸 및 메타데이터 스키마 업그레이드//스키마는 dba.upgradeMetadata()로 할수있음
		인스턴스 업그레이드
	순서로 하는게좋음
	이떄 인스턴스는 _hidden을 사용해서 숨길수있으니,이걸사용해서 업그레이드하면좋음
	이때 세컨더리를 먼저업그레이드하고 프라이머리는 제일 마지막에 업그레이드하는게좋음
	그리고 프라이머리를 업그레이드하면 자동으로 프라이머리가 변경되니 이거도 신경써야함 원래대로돌릴지말지
	
	
9.innoDB 클러스터 제약사항
	클러스터의 제약사항은 기본적으로 그룹복제의 제약사항을 포함하고,
	추가적으로
		클러스터인스턴스들은 --default-extra-file옵션으로 추가적옵션파일을 지정해 사용할수없음
		클러스터는 인스턴스에 수동으로 구성된 별도의 복제채널을 관리하지않아서,
			이로인해 인스턴스간 데이터가 일치하지않을수있음(과반수이상이면 통과라서 1명만 오류나면 데이터가 일치하지않음)
		클러스터는 샤딩을 지원하지않고,라우터는 하나의 클러스터에 대해서만 설정할수있음
	같은 제약이 있음
	
	
	
18.performance스키마 & sys스키마	
	이건 db의 상태를 분석하고 성능을 향상시킬 튜닝요소를 찾을때 도움을 주는 정보모음임
	여기접근도 그냥 select를 통해 하면됨
1.performance스키마란?
	이건 mysql이 기본적으로 제공하는 시스템db중 하나로,performance_schema라는 이름의 db로 확인할수있음
	여기는 서버내부동작및 쿼리처리에 관련된 세부정보들이 기록되는 테이블들이 존재하고,이걸통해 서버의 성능분석,내부처리과정모니터링등이 가능함
	그리고 여기 저장되는 데이터들은 서버내 곳곳의 성능측정코드로부터 수집됨
	이건 실시간으로 데이터를 수집하고,데이터를 메모리에 저장함,그래서 이걸켜두면 메모리와 cpu를 약간 더먹는데,
	이걸 줄일려면 일부이벤트에서만 수집하게도 할수있음
	그리고 메모리에 관리되는점때문에,재부팅하면 다 날아가니 주의
	
2.performance스키마 구성	
	스키마에는 100여개의 다양한테이블이 존재하고,크게보면 performance스키마의 설정에 관련된 테이블과,
	스키마가 수집한 데이터가 저장되는 테이블로 나눌수있음
	
	setup테이블은 스키마의 데이터수집 및 저장과 관련된 정보가 저장되어있고,여기서 설정을 동적으로 변경할수있음
	
	instance테이블은 스키마가 데이터를 수집하는 대상인 인스턴스들에 대한 정보를 제공하고,인스턴스종류별로 테이블이 구분되어있음
	
	connection테이블은 mysql에서 생성된 커넥션들에 대한 통계 및 속성정보를 제공함
	이걸통해 호스트단위로 연결된애들의 id및 통계정보를 알수있음
	
	varialble테이블은 서버의 시스템변수와 사용자정의변수,상태변수정보가 들어있음
	
	event테이블은 wait,stage,statement,transaction이벤트테이블로 구분되어있음
	이건 순서대로 안에 속하는 구조임(wait는 stage에 포함되는식)
	그래서 서로간의 외래키를 가지고있고,각 이벤트들은 세가지유형의 테이블을 가짐
		current:스레드별 가장최신이벤트1개,스레드종료시 바로삭제
		history:가장최신이벤트들이 시스템변수만큼 저장됨,스레드종료시 바로삭제하고,최대갯수초과시 오래된거부터 삭제
		history_long:전체스레드에대한 최근이벤트를 모두저장,스레드종료와 상관없이 값을 유지하고,최대갯수초과시 오래된거부터 삭제
	이렇게 3개임
	
	wait는 각 스레드에서 대기하고있는 이벤트(잠금경합,io작업이 대부분)
	stage는 각스레드에서 실행한 쿼리들의 처리단계정보를 확인할수있음,
	즉 실행된쿼리가 구문분석,테이블열기,정렬등 어떤단계를 수행하고있는지,처리단계별소요시간등을 알수있음
	statement는 각 스레드에서 실행한 쿼리들에 대한 정보를 알수있음,실행한쿼리와 쿼리반환레코드수,인덱스사용유무등을 알수있음
	transaction은 각 스레드에서 실행한 트랜잭션정보를 확인할수있음,트랜잭션별로 트랜잭션종류와 현재상태,격리수준등을 알수있음	
	이 4가지 이벤트들은 계층구조를 가지므로,각 이벤트테이블에는 상위계층에 대한 정보가 저장되는 칼럼(nesting_event_ 로시작)들이 존재함
	
	
	summary테이블은 performance스키마가 수집한 이벤트들을 특정기준별로 집계한후 요약한정보를 제공함
	db계정,호스트,스레드,스키마,인덱스,이벤트클래스등으로 분류해서 통계정보를 넣어뒀음(이거말고도 많음 655p참고)
	
	lock테이블은 mysql에서 발생한 잠금과 관련된 정보들을 제공함
	
	replication테이블은 show slave status보다 더 상세한 복제관련 정보들을 제공함
	
	clone테이블은 clone플러그인을 통해 수행되는 복제작업에 대한 정보를 제공함,이건 clone플러그인이 설치될때 생성되고,삭제되면 같이 삭제됨
	
	이거말고도 다른테이블들이 있음,에러로그파일내용이나,키링키,로그파일위치등등
	
	
3.performance스키마 설정
	기본적으로 5.6.6부터는 따로설정하지않아도 자동으로 활성화됨
	세부설정은 크게
		메모리사용량설정
		데이터수집 및 저장 설정
	으로 나뉨
	퍼포먼스스키마는 수집한데이터들을 모두 메모리에 넣어두니,
	너무 크지않게 제한하는게 좋고,이러려면 모든이벤트가 아닌 사용자가 필요로하는 이벤트들에 대해서만 수집하는게 좋음
	
	메모리관련 상세설정은 663p
	보통 최대레코드수나,이벤트들의 최대레코드수들로 조절함
	
	
	데이터수집 및 저장 설정은,어떤 대상에 대해 모니터링하고,어떤이벤트들에 대한 데이터를 수집하고 얼마나 상세히 저장할것인지를 제어할수있음(671p)
	퍼포먼스스키마는 생산자-소비자패턴으로 구현되어있어서 데이터수집부분과 저장부분으로 나뉨
	여기서 가장 큰 영향은 저장레벨설정임
	이게 아예 설정안되어있으면 데이터를 저장하지않고,이거의 레벨에 따라 적절한 테이블에 수집데이터를 저장함
	
	그리고 db,테이블같은 수집대상을 설정할수도있음,이떄도 성능지표,시간측정을 수집할지말지까지 선택가능
	이때 전체 이벤트 클래스를 수집하는게 아닌,특정 이벤트 클래스들만 선택하는게 성능상 좋음
	
4.sys스키마란?	
	sys스키마는 performance스키마를 좀 더 쉽게 사용할수있게 해주는 프로시저와 뷰,함수들의 집합임
	그래서 이걸 사용하려면 performance스키마가 켜져있어야함
	그리고 퍼포먼스스키마의 현재 설정확인과,설정변경도 함수로 쉽게할수있음(685p)
	만약 현재 사용하는계정이 루트계정이면 별다른일없이 sys를 자유롭게 사용할수있지만,제한적인 계정을 가진 db계정에서는 추가권한이 필요할수있음
	
	sys스키마는 
		설정정보가 저장된 테이블 하나(innodb로 디스크에 영구저장됨)와,
		formatted-view(raw-view에서 x$빼면 보통있음)와 raw-view(x$로 시작)같은 사람이 읽을수있는뷰와 생데이터뷰,
		performance 스키마 설정변경을 위한 스토어드프로시저와 서버상태와 현재실행중인 쿼리에대해 보고서형태로 주는 프로시저,
		값의 단위를 변환하고 performance스키마의 설정 및 데이터를 조회하는등의 다양한 기능을 가진 함수(보통 뷰와 프로시저에서 사용됨)
	로 구성되어있음

5.performance스키마 및 sys스키마 활용예제
	여기는 그냥 할수있는거 소개만하고(이런거도 할수있다),필요해지면 제목보고 책 찾아가자
	쿼리가 너무 복잡해서 이해하고쓰기보단 그냥 복붙으로 쓰는게 더 효율적일거같음
	
	호스트이력 접속확인:서버가 켜진시점부터 지금까지 접속했던,접속중인 호스트들의 전체목록(ip별분류)을 얻을수있음(null은 접속실패 or 내부스레드)
	미사용db계정 확인:서버가 켜진시점부터 지금까지 사용되지않은 db계정들을 확인할수있음
	
	mysql총메모리사용량 확인:현재 mysql서버가 사용중인 총 메모리사용량을 알수있음
	스레드별 메모리사용량 확인:동작중인 스레드들의 현재 메모리사용량을 알수있음
	특정스레드 상세메모리할당확인:특정 스레드에 상세한 메모리할당을 확인할수있음
	
	미사용인덱스 확인:서버가 켜진시점부터 사용되지않은 인덱스를 알수있음
	중복된인덱스 확인:각 테이블에 존재하는 중복인덱스를 알수있음(어느 한쪽에 포함된인덱스)
	
	변경이없는테이블목록 확인:서버가 켜진시점부터 현재까지 쓰기가 발생하지않은 테이블을 알수있음
	io요청이 많은테이블목록 확인:각 테이블별 io발생량을 확인할수있음
	테이블별 작업량통계 확인:각 테이블별 데이터작업유형 및 io유형별 통계정보를 알수있음
	테이블별 auto increment사용량확인:테이블별로 ai가 어디까지 찼는지 확인할수있음
	
	풀테이블스캔쿼리 확인:풀테이블스캔쿼리를 한 테이블과 쿼리를 확인할수있음,이후 인덱스추가를 하면됨
	자주 실행되는 쿼리목록확인: 실행빈도가 높은 쿼리들을 확인할수있음
	실행시간이 긴 쿼리목록 확인:실행시간이 긴 쿼리들을 확인할수있음,슬로우쿼리로그보다 보기편함
	정렬작업을 수행한 쿼리목록확인:정렬은 cpu를 많이소모하는데,그래서 가능하면 인덱스를 추가해 정렬을 하지않게하는게 좋음
	임시테이블을 생성하는 쿼리목록 확인:실행시 임시테이블을 생성하는 쿼리를 알수있음
	트랜잭션이 활성상태인 커넥션에서 실행한 쿼리확인:트랜잭션이 정상종료가 안되고 남아있으면 언두로그로인해 성능저하가됨,이걸 확인하기 좋음
	특정세션에서 실행된 쿼리전체내역 확인:해당 세션에서 실행된 쿼리들을 볼수있음
	
	쿼리프로파일링:쿼리가 서버에서 처리될때 단계별로 소요된 시간을 볼수있음
	alter작업진행률 확인:알터를 할때 얼마나진행됐는지를 확인할수있음,
		단 이떈 알터실행전에 관련설정들이 켜져있어야함,이떄 알터를 실행시킨세션이 아닌 다른세션에서 켜야함
	메타데이터락 대기 확인:alter로 변경할때 다른세션에서 해당테이블에 대해 메타데이터락을 점유하면 알터가 대기하게됨,
		이떄 어떤세션에서 락건지를 확인할수있음,그리고 일단 알터명령에서 대기가 발생하면 빨리 알터쿼리를 취소하는게좋음,안그러면 연쇄대기가 발생할수있음
	데이터락 대기 확인:서로 다른 세션간에 데이터락 대기가 발생한경우 대기가 발생한 데이터락에 관련된 정보를 알수있음 
	
	
	
	
	
	
	
	
	
	
	
	
끝	
	
	
	
	
	
	