1.스프링 배치 종결의 서막
*1.서문
스킵
*2.배치처리란
  배치는 일일정산,데이터마이그레이션,리포트생성,데이터정제,데이터통합등 다양한 용도로 사용됨
  배치에서 중요한건 정확성과 완결성임,처리에 시간이 걸려도 완벽하게 처리하는게 목표
  웹에서는 실패시 에러를 반환하고 끝냈지만,배치는 복구를 시도해볼수있음
  
  또한 트랜잭션도 체크포인트 기반으로 할수도있고,처리할 데이터양과 특성에 따라 범위조절도 가능함
  
  그리고 청크지향이라 데이터를 나눠서 순차처리할수있고,병렬처리도 가능함

*3.사전점검
  job은 하나의 완전한 배치 처리를 의미함(일일매출집계,정기결제등)
  step은 job을 구성하는 실행단위로,하나의 job은 하나이상의 step으로 구성됨
  즉 일일매출집계 job은
    매출집계step
	  전일주문데이터 read
	  결제완료된것만 필터링 process
	  상품별로 집계후 저장 write
	알림발송step
	  집계요약정보생성후 관리자에게 전달
	캐시갱신 step
	  집계된 데이터로 캐시정보 업데이트
  이런식으로 구성됨
  
  스프링배치는 배치잡을 만들기위해 필요한 거의 모든걸 제공함
  우리는 이 뼈대위에 스프링배치가 제공하는 컴포넌트들을 @configuration으로 구성만 하면됨
  즉 스프링배치를 스프링배치가 제공하는영역과 개발자가 제어하는 영역으로 나눠보는게 쉬움
  보통 잡과 스탭,잡런처,잡레포,ItemReader구현체,writer구현체등이 스프링 배치가 제공하는 영역임
  우리는 Job과 Step의 구성을 해야하고(configuration),기본적으로 제공되지않는 영역의 로직을 만들어야함(보통 processor은 제공하지않음)
  
  추가적으로 배치에선 시스템 시작의 결과를
    SpringApplication.run(abcApplication.class, args);
  이게 아닌
    System.exit(SpringApplication.exit(SpringApplication.run(abcApplication.class, args)));
  이런식으로 exit로 처리하는게 권장됨
  이러면 배치작업의 성공실패를 exit코드로 외부에 전달할수있어서 배치모니터링과 제어에 필수적임
  
  잡은 잡빌더를 통해 생성되는데,이때 잡의 이름과 잡레포지토리가 파라미터로 들어감
  또한 잡레포지토리와 트랜잭션매니저또한 자동으로 주입받을수있음
  잡이 스탭을 실행시키면,스탭은 순서대로 실행되고,이전스탭이 성공해야지만 실행됨
  
2.스프링 배치 시작
*1.스탭의 두가지 유형
  스탭은 크게 청크지향처리와 태스크릿 지향처리 두가지로 나눠짐
  1.태스크릿
	태스크릿은 가장 기본적인 처리방식으로,복잡하지않은 단순작업을 실행할때 사용함
	즉 대량데이터처리가 아닌,단순히 실행에 초점을 맞춘 오래된로그삭제,이동,알림발송등을 할때 사용됨
	즉 함수호출 하나로 끝날만한걸 할때 사용하면됨
	이걸 쓸떈 그냥 execute()에 원하는로직을 구현하고,구현체를 배치에 넘기기만 하면됨

	또한 RepeatStatus를 사용해서 반복을 할수있음(FINISHED, CONTINUABLE)
	FINISHED는 스탭이 종료됐다는거고,CONTINUABLE는 아직 더 진행해야한다는것
	물론 내부에서 반복문을 쓸수도있지만,이렇게 처리하는 이유는 짧은 트랜잭션을 사용해서 안전하게 배치처리를 하기위해서 이런식으로 처리함
	이러면 실패해도 한번에 처리하는양만큼만 실패하지,전체를 다시할필요는없음

	태스크릿을 구현했다면,이걸 스텝에 테스크릿으로 등록하면됨
	이건 @configuration파일에서 태스크릿과 스탭 빈을 만들고,이걸 잡 빈에 넣으면됨
	이떄 트랜잭션매니저와 잡레포지토리가 필요한데,만약 태스크릿작업이 트랜잭션이 필요없다면 ResourcelessTransactionManager을 사용할수있음
	이건 그냥 해당 클래스를 직접 new로 생성해서 스탭의 태스크릿넣는곳에 같이 넣어주면됨

	ResourcelessTransactionManager를 빈으로 만들고싶을땐 주의가 필요함
	이걸 빈으로 만들어버리면 메타데이터관리 트랜잭션에서도 저걸써버리기때문에 별도의 트랜잭션매니저구성을 해야함

	태스크릿을 사용할때,간단한작업이라면 그냥 스탭에서 람다식으로 정의해도되고,좀 복잡하다싶으면 별도클래스로 빼는게 나음
	보통 태스크릿작업을 할땐 태스크릿에서 생성자di로 처리할때 사용할 파라미터(레포지토리나 파일경로등)을 받아서 처리하는경우가 많은듯
	그리고 포인터같은걸 둬서 일정단위로 밀어내면서 처리하고,빈거만나면 끝내고 이런식
	
	즉 태스크릿은 단순하고 명확한 작업을 수행할때 사용되는 step이고
	  단순작업에 적합(알림발송,파일복사,오래된데이터삭제등)
	  Tasklet 인터페이스 구현후 이를 StepBuilder.tasklet()에 전달
	  RepeatStatus로 실행제어
	  트랜잭션지원(execute단위로 트랜잭션이 걸림)
	이런 특징들이 있음
  2.청크
    일반적으로 배치를 처리할때 사용하는 읽기-처리-쓰기를 할땐 청크지향 처리를 사용하면됨
	청크랑 데이터를 일정단위로 쪼갠 덩어리를 말함(백만데이터를 백개단위로 쪼개서 처리 이런느낌)
	이렇게 처리해야 메모리관리,가벼운 트랜잭션(작은실패)등이 가능해짐
	
	배치에서 읽기-처리-쓰기 패턴은 딱 3가지로 나뉘어짐
	이게 ItemReader,ItemProcessor,ItemWriter임
	
	1.ItemReader
	  이건 한번에 하나씩(db 한 row씩) 읽어서 반환하고,읽을데이터가 없다면 null을 반환함
	  이 null을 반환하는게 청크지향처리스탭의 종료시점임
	  
	  또한 이미 아이템리더의 경우 표준구현체들이 많이있음(FlatFileItemReader,JdbcCursorItemReader등)
	2.ItemProcessor
	  이건 데이터를 원하는 형태로 깎아내는,즉 실제 로직을 처리함
	  이것도 리더처럼 데이터 하나하나씩 입력받아서 반환함
	  얘는 보통
	    데이터가공(입력데이터를 출력데이터의 형태로 변환함)
		필터링(null을 반환해서 해당데이터를 처리흐름에서 제외시킴)
		데이터검증(입력데이터의 유효성을 검사,조건에 맞지않는 데이터를 만나면 예외를 발생시켜 잡을 중단시킴)
	  이런 작업을 처리하고,꼭 프로세서가 있을필요는없음,즉 스탭에서 직접 데이터를 읽고바로쓰게할수도있음
	
	3.ItemWriter
	  이건 프로세서의 결과물을 받아서 원하는방식으로 최종저장/출력함
	  이건 청크단위로 한번에 데이터를 쓰고,이단위로 트랜잭션에 묶임
	  이것도 다양한 구현체들이 이미 만들어져있음(FlatFileItemWriter,JdbcCursorItemWriter 등)
	
	이런식으로 크게 3개단위로 분리해서 처리되는게 기본패턴인데,이걸통해
	  완벽한 책임분리
	  재사용성극대화
	  높은 유연성(데이터소스가 바뀌면 리더만,데이터형식이 바뀌면 프로세서만 변경하면됨)
	  대용량처리의 표준
	를 얻을수있음
	
	이 청크지향스탭을 조립할때도 StepBuilder를 사용하면됨
	이때 
	  return new StepBulder("스탭명",jobRepository)
	    .<리더의반환타입,프로세서의반환타입>chunk(청크사이즈,트랜잭션메니저)
		.reader(itemReader())
        .processor(itemProcessor()) 
        .writer(itemWriter())
		.build()
	이런식으로 하면됨
	이떄 스탭의 동작방식은,
	  청크갯수만큼 리더가 읽어서 청크를 구성하고(단일호출로 n개의 데이터를 가져와 하나의 청크를 생성)
	  구성된 청크의 내용물을 하나하나 프로세서가 처리해서 처리완료된 청크로 만들고(단일처리는 맞음,즉 청크크기가 10이면 한 청크를 처리할때 10번호출)
	  처리완료된 청크를 라이터가 저장(이건 청크 전체를 한번에 처리함)
	이런 방식으로 진행됨
	이걸 더이상 읽을데이터가 없을때(read가 null을 반환할때)까지 반복함
	즉 청크크기만큼 read하고,청크크기만큼 process한다음 한번 write해서 저장하는게 한 청크처리임
	
	청크지향처리에서 트랜잭션관리는 각 청크단위로 진행됨
	즉 실패시 해당 청크만 롤백된다는것
	이떄 청크사이즈는 트레이드오프와 업무요구사항,데이터양을 고려해서 적절히 골라야함
	이때 트레이드오프는
	  청크사이즈가 클때
	    메모리에 많은데이터를 한번에 로드함
		트랜잭션범위가 커져서 롤백데이터양이 많아짐
	  청크사이즈가 작을때
	    롤백데이터가 최소화됨
		읽기쓰기io가 자주발생하게됨
	이런 문제가 있음
  
*2.JobParamater
  1.잡파라미터란?
    잡파라미터는 처리대상과 조건등 배치작업에 전달되는 입력값임 
	이걸 사용해서 같은 잡을 입력값만 바꿔서 유연하게 실행할수있음
	물론 -D로 프로퍼티전달을 할순있지만,목적이 서로 다름
	
  2.프로퍼티와 잡파라미터의 결정적 차이
    1.입력값 동적 변경
	  단순한경우 프로퍼티로 충분하지만,웹요청에 전달된값을 Job의 매개변수로 주입하려는등은 프로퍼티로 해결하기힘듬(배치 프로그램을 띄워두고 잡을 실행시키는형태일떄)
	  프로퍼티는 앱 시작시 한번 주입되고 끝이기때문
	
	2.메타데이터
	  스프링 배치는 잡파라미터의 모든값을 메타데이터 저장소에 저장하고,이걸통해
	    Job인스턴스 식별 및 재시작 처리
		Job 실행이력추적
	  등을 할수있음
	  
	  이때 메타데이터는 JobRepository를 통해 Job과 Step의 실행이력을 저장소에 저장하고,
	  여기엔 잡과 스탭의 시작/종료시간,실행상태,처리레코드수 등이 포함됨
	  
	  반면 프로퍼티는 메타데이터로 저장되지않아서 관리가 불가능해,배치운영과 제어를 제한하게됨
	  즉 재시작이나 처리이력관리등이 안되게됨
  3.JobParameters 전달하기
    1.커맨드라인(CLI)
	  커맨드라인에선
	    ./gradlew bootRun --args='--spring.batch.job.name=dataProcessingJob inputFilePath=/data/input/users.csv,java.lang.String'
	  이런식으로 
		 --spring.batch.job.name=실행잡이름 파라미터1이름=값1,파라미터타입 파라미터2이름=값2,파라미터타입
      이렇게 전달하면됨
	  
	  이때 파라미터타입은 DefaultJobParametersConverter를 통해 적절한 타입으로 변환되는데,
	  기본적인 타입과 LocalDateTime등 시간관련타입등 다양한 타입을 지원함
	2.프로그래밍방식
	  이경우엔 JobParametersBuilder컴포넌트를 사용해서 잡 파라미터를 만들고,이걸 JobLauncher에 넣어서 잡을 실행시킬수있음
	  이때 addJobParameter()의 체이닝을 통해 잡파라미터를 추가하고,toJobParameters()로 빌드를 할수있음
	  이것도 
	    addJobParameter(파라미터명,파라미터값,타입)
	  즉
		JobParameters jobParameters = new JobParametersBuilder()
          .addJobParameter("inputFilePath", "/data/input/users.csv", String.class)
          .toJobParameters();
	  이렇게 넣으면됨
	  
	  여기서 JobLauncher는 잡을 실행하는데 사용되는 핵심도구로,잡파라미터를 입력받아 잡의 실행컨텍스트를 생성하고,잡이 성공적으로 실행되게 관리하는역할을 함
	3.잡파라미터 직접 접근
	  잡파라미터에 직접 접근하려면,어디서 잡파라미터가 관리되는지를 알아야함
	  스프링배치에선 JobExecution이 잡의 실행정보를 쥐고있음,즉 잡파라미터도 이안에있음
	  스탭에서 잡파라미터를 찾으려면 이 JobExecution을 통해서 찾아야함
	  테스크릿에서 잡 파라미터를 찾을땐 
	     public RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) {
         JobParameters jobParameters = chunkContext.getStepContext()																			            
            .getStepExecution()																				      
            .getJobParameters();
	  이런식으로 컨텍스트에서 익스큐션을 찾고,거기에 잡파라미터를 찾아야함
	  이때 잡익스큐션이 아닌 스텝익스큐션을 사용하는데,스텝익스큐션안에 부모잡의 잡익스큐션을 참조하고있어서 이렇게 찾는거
	  
  4.다양한 타입의 잡파라미터
    1.기본데이터타입
      기본적으로 잡파라미터를 받아서 사용할땐 di로 하게되는데
	     @Bean
         @StepScope //@Value로 잡파라미터를 전달받을떈 @StepScope등을 선언해줘야함
	       public Tasklet terminatorTasklet(
	  	     @Value("#{jobParameters['terminatorId']}") String terminatorId, 
	  	     @Value("#{jobParameters['targetCount']}") Integer targetCount
	       ) { 
	  이런식으로 di받으면됨
	  그리고
	    ./gradlew bootRun --args='--spring.batch.job.name=processTerminatorJob terminatorId=KILL-9,java.lang.String targetCount=5,java.lang.Integer'
      이런식으로 넣으면되는거
	2.날짜와 시간 타입
	  또한 날짜의 경우도 같은방식으로 di받고 
	    executionDate=2024-01-01,java.time.LocalDate startTime=2024-01-01T14:30:00,java.time.LocalDateTime
	  이런식으로 받으면됨
	  이떄 주의점은 LocalDate는 ISO_LOCAL_DATE,LocalDateTime은 ISO_LOCAL_DATE_TIME형식으로 전달해야한다는점
	  다른것도 마찬가지임 java.util.Date는 ISO_INSTANT 형식으로, java.time.LocalTime은 ISO_LOCAL_TIME형식으로 전달해야함
	  
    3.Enum타입
	  enum의 경우엔 받을땐 똑같이
	    @Value("#{jobParameters['questDifficulty']}") QuestDifficulty questDifficulty
	  이렇게하면되고,줄떈
	    questDifficulty=HARD,com.system.batch.killbatchsystem.TerminatorConfig$QuestDifficulty
	  이렇게하면되는데,이때 $는 중첩클래스일땐 저렇게 표시해야함,만약 중첩클래스가 아니라면 그냥 똑같이 경로설정해주면됨
	
	4.POJO를 활용한 잡파라미터주입
	  만약 여러 Job파라미터를 효율적으로 관리해야한다면,별도의 클래스를 만들어 파라미터를 관리하면 구조화와 재사용성이 높아짐
	  즉 잡파라미터 관리용 컴포넌트를 만들고,여기에 StepScope를 붙인다음 여기서 잡파라미터를 다 주입받은다음에 이걸 가져다가 쓰는거
	  어짜피 싱글톤으로 실행되니까
	
	5.기본파라미터 표기법의 한계
	  문제는,기본파라미터에서 쉼표(,)가 파라미터값에 포함되게되면 문제가 발생함 
	  그래서 사용되는게 Json기반의 파라미터표기임
	6.Json기반 표기법
	  기본적으론
	    implementation 'org.springframework.boot:spring-boot-starter-json'
	  이 의존성이 필요함
	  그리고나서 JsonJobParametersConverter빈을 직접 등록해줘야함
	  그리고나서 잡파라미터로
	    ./gradlew bootRun --args="--spring.batch.job.name=terminatorJob infiltrationTargets='{\"value\":\"판교서버실,안산데이터센터\",\"type\":\"java.lang.String\"}'"
	  이렇게 json을 넘겨주면됨
	  받는건 똑같이
	    @Value("#{jobParameters['infiltrationTargets']}") String infiltrationTargets
	  이렇게받으면됨(파라미터명으로)
    7.커맨드라인 파라미터는 어떻게 실제 Job으로 전달될까?
	  배치를 스프링부트3이랑 쓰면,앱이 시작될떄 JobLauncherApplicationRunner라는 컴포넌트가 자동으로 동작함
	  이건 스프링부트가 제공하는 어플리케이션러너중 한 종류로,얘는 커맨드라인으로 전달된 잡파라미터를 해석하고 이걸바탕으로 실제 잡을 실행하는 역할을 맡음
	  얘는
	    잡목록준비:등록된 모든 잡타입 빈을 자동주입받음
		유효성검증:잡타입빈이 여러개인데 잡네임이 없을경우 검증실패,만약 하나라면 생략가능
		명령어해석:커맨드라인으로 전달된 값(잡파라미터)들을 파싱함,
		  여기서 DefaultJobParametersConverter나 JsonJobParametersConverter을 사용해 문자열을 적절한 잡파라미터로 변환함
		Job실행:첫단계의 잡리스트에서 해당이름의 잡을 찾고,해당잡을 잡파라미터를 넣어서 실행시킴,이과정에서 JobLauncher라는 잡실행컴포넌트가 사용됨
	  이런식으로 동작함

  5.JobParametersValidator
    이건 말그대로 잡파라미터 밸리데이터,즉 검증도구임
	이 인터페이스는 단순하게 하나의 검증메서드만 있음 
		public interface JobParametersValidator {
			void validate(@Nullable JobParameters parameters) throws JobParametersInvalidException;
		}	
    말그대로 잡파라미터를 받아서 검증한후 아니다싶으면 예외를 던지면됨
	이건 잡을 등록할때 JobBuilder에서 validator로 등록해주면됨,이러면 잡실행시점에 호출되어 파라미터검증을 진행함
	
	물론 매번 만들긴 귀찮으니까  DefaultJobParametersValidator를 사용할수도 있는데
	이건 그냥 파라미터의 존재여부만 확인해줌
	이건
	  DefaultJobParametersValidator([필수파라미터명],[선택파라미터명])
	이렇게 넣어두면 검증해줌
	그리고 만약 선택파라미터에 값이 있다면,모든 잡파라미터들은 필수나 선택중 한군데에 들어가야함,만약 저기에없는 파라미터가 들어오면실패함
	선택파라미터에 값이 없다면,그냥 자유롭게 허용함
	
*3.배치 Scope  
  1.Job과 Step의 Scope 이해하기
    배치의 스코프는 스프링의 기본 스코프인 싱글톤과 다른 특별한 스코프를 제공함
	JobScope와 StepScope임
	
	얘들이 선언된 빈은 어플리케이션 구동시점에는 프록시로만 존재하다가,잡이나 스탭이 실행된후에 프록시객체에 접근하면 그때 실제빈이 생성됨
	이러면 이점이 뭐냐면,런타임에서 잡파라미터가 결정되어서 실행시점에 정확하게 주입받을수있고,
	동시에 여러잡이 실행되더라도 각각 독립적인 빈을 사용하게되어 동시성문제도 해결됨
	또한 잡이나 스탭의 실행이 끝나면 해당빈도 같이 제거되므로 메모리적으로도 효율적임
  
  2.@JobScope
    잡스코프는 잡이 실행될때 실제 빈이 생성되고 잡이 종료될떄 함께 제거되는 스코프임
	즉 JobExecution과 생명주기를 같이함
	
	이게 붙은 빈은 구동시점에는 프록시만 생성됨
	그래서 어플리케이션 실행중에 잡파라미터가 변경되거나,잡을 실행 직전에 잡파라미터를 만들어서 잡을 실행시키는등의 일이 가능해짐
	또한 잡이 실행될때 실제 빈이 생성되니까 병렬처리도 가능해짐
  
  3.@StepScope
    스텝스코프는 잡스코프와 유사하지만 스텝레벨에서 동작하는 스코프임
	이건 스텝의 실행범위에서 빈을 관리함
	즉 각각 스텝의 실행마다 새로운 빈이 생성되고,스텝이 종료될때 함께 제거됨
	그래서 동시성이슈가 터지지않음

  4.JobScope와 StepScope사용시 주의사항
    1.프록시대상의 타입이 클래스라면,반드시 상속가능한클래스여야함
	  cglib기반의 프록시생성이기떄문에 상속가능해야함
	2.Step빈에는 @StepScope와 @JobScope를 사용하지말라
	  스텝에 StepScope를 달면 스텝빈생성과 스코프활성화시점이 맞지않아 오류가발생함
	  배치는 스텝실행전 메타데이터관리를 위해 스텝빈에 접근해야하는데,이시점엔 스텝이 실행되지않아 스텝스코프가 활성화되지않은상태임
	  그래서 스코프없이 프록시에 접근하니까 안되는거
	  
	  마찬가지로 @JobScope도 스텝에 선언하면안됨
	  단순한 배치에선 문제가 없지만,복잡한 상황에선 예상치못한 문제가 발생함
	    JobOperator을 통한 Step실행제어
		Spring Integration(Remote Partitioning)을 활용한 배치확장기능등
	  이런거
	  
	  그런데 스텝에서 잡파라미터를 쓸땐 스코프가 필요함
	  이럴땐 스텝단위로 스코프를 받는게 아닌,Tasklet에서 스코프를 달아서 파라미터를 받으면됨
	  또 생기는 문제는 잡빌더에서 컴파일시점에 없는값을 참조할때 생기는 문제임
	  스텝에서 받는 잡파라미터는 컴파일시점엔 값이 존재하지않음
	  가장 깔끔한 방법은 스텝을 빈으로 등록하고 이걸 생성자주입받는것
	  
	  그런데 만약 직접 스탭을 호출해야한다면,해당자리에 null을 넣으면 알아서 잡이 실행될때 입력받은 잡파라미터값으로 교체함(지연바인딩)
	  
  5.ExecutionContext
    잡익스큐션과 스텝익스큐션은 시작시간,종료시간,실행상태등의 메타데이터를 관리하는데,이런 기본적인 정보만으로는 시스템을 완벽하게 제어하기 부족할때가 있음
	비즈니스로직 처리중 발생하는 커스텀데이터를 관리할 방법이 필요한데,이때 사용하는게 ExecutionContext라는 데이터컨테이너임
	기본적으로 잡파라미터는 잡의 실행시점에서 바뀌지않는데(불변),그래서 추가적인 데이터저장수단이 필요한것
	
	얘를 쓰면 커스텀컬렉션의 마지막처리인덱스같은 데이터를 저장할수있고,이건 잡이 중단된후 재시작할떄 특히 유용함
	배치가 재시작할때 이걸 자동으로 복원하기때문(이것도 메타데이터저장소에서 관리함)
	
	JobScope와 StepScope에서 ExecutionContext에 접근할때도 @Value로 접근할수있음
	  @Value("#{jobExecutionContext['previousSystemState']}") String prevState
	  @Value("#{stepExecutionContext['targetSystemStatus']}") String targetStatus
	이런식
	단 jobExecutionContext와 stepExecutionContext는 서로 다른 범위를 가지는데,
	jobExecutionContext는 해당 잡에 속한 모든 컴포넌트에서 접근할수있지만,stepExecutionContext는 해당 스텝에 속한 컴포넌트에서만 접근할수있음
	
	즉 스텝의 ExecutionContext에 저장된 데이터는 jobExecutionContext로 가져올수없고,다른 스탭의 stepExecutionContext데이터를 가져올수없음
	이렇게 스텝간 데이터 독립성이 완벽하게 보장됨
	만약 이전스텝의 처리결과를 다음스텝에서 활용해야한다면 jobExecutionContext에 담아서 사용해야함
	즉 jobExecutionContext는 job재시작시 복원과 step간 데이터공유수단으로도 사용됨
  
	
*4.Spring Batch Listener
  리스너는 배치의 주요순간들에 후킹해서 각 시점에 동작을 끼워넣을수있는 도구임
  잡이 시작하기 직전,완료직후,스텝시작직전,완료직후,청크단위,아이템단위등 다양한 위치에 로직을 끼워넣을수있음
  이때 로깅,모니터링,에러처리등 다양한 작업을 할수있음
  1.리스너 종류  
    1.JobExecutionListener
      이건 잡실행의 시작과 종료시점에 호출되는 인터페이스임
	  잡의 실행결과를 로깅,이메일전송하거나 잡 시작전에 필요한 리소스를 준비하고 끝난후에 정리하는등의 작업을 할수있음
	  afterJob은 잡 실행정보가 메타데이터 저장소에 저장되기전에 호출됨
	  그래서 잡의 실행결과를 완료에서 실패로 변경하거나,그 반대로 처리하는등의 작업도 가능함
    
    2.StepExecutionListener
      이건 스탭의 시작과 종료시점에 호출되는 리스너 인터페이스임
	  스텝의 시작시간,종료시간,처리데이터수를 로그로 기록하는등의 사용자정의작업을 추가할수있음
	  또한 afterStep에선 ExitStatus를 반환하는데,이걸통해 스텝의 실행결과상태를 직접 변경할수있음
    
    3.ChunkListener
      청크지향처리는 청크단위로 아이템읽기쓰기를 반복하는데,ChunkListener는 이런 하나의 청크단위처리가 시작되기 직전,완료된후,에러가 발생했을때 호출됨
	  즉 청크단위로 모니터링하거나 로깅할수있음
	  여기서 afterChunk는 트랜잭션이 커밋된후 호출되고,
	  청크처리중 예외가 발생하면 afterChunkError이 afterChunk대신 호출되는데,이땐 트랜잭션롤백이후 호출됨
    
    4.Item[Read|Process|Write]Listener
      아이템리스너는 아이템의 읽기,쓰기,처리작업이 수행되기 직전,직후,에러발생시점에 호출됨
	  여기서 주의점은
	    ItemReadListener.afterRead()는 read호출이후 호출되지만,null을 반환할떈 호출되지않음
	    ItemProcessListener.afterProcess()는 process가 null을 반환하더라도(필터링하더라도) 호출됨
	    ItemWriteListener.afterWrite()는 트랜잭션이 커밋되기전,그리고 ChunkListener.afterChunk()가 호출되기전에 호출됨
    
  2.배치 리스너, 이런 것들을 할 수 있다
    배치 리스너에선
	  단계별 모니터링과 추적:각 잡이나 스탭의 실행전후 로그를 남길수있고,이떄 언제시작하고 언제끝났는지,몇개데이터를 처리했는지등을 기록하고 추적할수있음
	  실행결과에 따른 후속처리:잡과 스텝의 실행상태를 리스너로 직접 확인하고 그에따른 조치를 할수있음(잡이 실패했을떄 다시돌린다든가)
	  데이터 가공과 전달:실제 처리로직 전후에 데이터를 추가로 정제하거나 변환할수있음
	    StepExecutionListener나 ChunkListener를 사용해서 ExecutionContext의 데이터를 수정하거나 필요한 데이터를 추가하는등
		다음 처리에 필요한내용을 미리 준비할수있음
	  부가기능분리:주요처리로직과 부가로직을 깔끔하게 분리할수있음(aop처럼)

    1.배치리스너 구현방법
      리스너 구현법은 두가지가 있음
	  전용 리스너 인터페이스를 구현하던가,어노테이션을 붙이던가
	  가장 일반적인 방법은 그냥 리스너 인터페이스를 구현한 후에 Builder에서 .listener()에 넣어주면됨
	  이떄 JobExecutionListener는 JobBuilder에,나머지 빌더들은 StepBuilder에 넣으면됨
	  
	  더 간단한방법은 어노테이션기반구현임
	    @BeforeJob, @AfterJob, @BeforeStep, @AfterStep //이런느낌,밑에는 모든 어노테이션들
	    @AfterChunk, @AfterChunkError, @AfterJob, @AfterProcess, @AfterRead, @AfterStep, @AfterWrite, @BeforeChunk, @BeforeJob, @BeforeProcess, @BeforeRead, @BeforeStep, @BeforeWrite, @OnProcessError, @OnReadError, @OnSkipInProcess, @OnSkipInRead, @OnSkipInWrite
	  그냥 리스너클래스를 상속없이 만든다음,저 어노테이션을 붙인 메서드를 만들고,이걸 위에처럼 Builder에 넣으면됨
    
    2.JobExecutionListener와 ExecutionContext를 활용한 동적 데이터 전달
      만약 잡파라미터만으로 전달할수없는 동적데이터가 필요할땐 JobExecutionListener의 beforeJob()를 사용해서 동적데이터를 각 스텝에 전달할수있음
  	  저기에다가 
	    jobExecution.getExecutionContext().put(데이터)
	  이런식으로 데이터를 집어넣는식
	  그리고 스탭에서 값을 꺼내다가 쓰면됨

    3.왜 JobParameters가 아닌 ExecutionContext를 사용할까?
	  잡파라미터는 한번 생성된 이후 변경될수없음(불변)
	  이걸통해 배치의 재현가능성과 일관성을 스프링배치는 보장함
	    재현가능성:같은 잡파라미터로 실행된 잡은 항상 같은결과를 생성해야함,중간에 변경될경우 이를 보장할수없음
	    추적가능성:배치작업의 실행기록과 잡파라미터는 메타데이터저장소에 저장됨,이게 변경가능하다면 기록과 실제작업간 불일치가 발생할수있음
	  그래서 동적으로 생성되거나 변경되어야 하는 데이터는 ExecutionContext를 통해 관리해야함
	
	  단,동적으로 전달하는건 유용하긴하지만 잡파라미터만으로 충분히 처리할수있다면 그걸로 처리하는게 좋음
	  만약 beforeJob에서 localDate.now등으로 현재날짜를 넘긴다면 그날데이터를 재처리하는등의 작업이 불가능해짐
	  이런건 외부에서 파라미터로 받는게 나은방식임
	  즉 가급적 잡파라미터로 di받고,외부에서 값을 받을수없는경우에만 동적으로 생성하던가 하면됨
	
	  그런데 잡수준의 ExecutionContext에선 모든스탭에서 공유되지만,스탭수준의 ExecutionContext에선 다른 스탭과 공유가 불가능함
	  그래서 스탭의 컨텍스트에서 값을 가져와서,잡의 컨텍스트로 밀어넣는 작업이 필요해지는데,이게 코드가 너무 많이필요하니까 배치에서 만들어둔 리스너가 있음
	  ExecutionContextPromotionListener임

    4.ExecutionContextPromotionListener를 활용한 스탭간 데이터 공유
      이건 스탭수준의 컨텍스트데이터를 잡수준 컨텍스트로 등록시켜주는 구현체임
	  즉 스탭데이터를 잡데이터로 프로모션(승격)시켜주는거임
	
	  이걸 리스너로 스탭에 등록해두면,거기에 세팅된 데이터의 키를 바탕으로 자동으로 승격처리를 시킴
	    @Bean
		public ExecutionContextPromotionListener promotionListener() {
			ExecutionContextPromotionListener listener = new ExecutionContextPromotionListener();
			listener.setKeys(new String[]{"targetSystem"});
			return listener;
		}
	  이런식임
	
	  단 가급적이면 각 스텝은 가능한 독립적으로 설계하는게 재사용성과 유지보수성이 올라감
	  불가피하지않다면 스텝간 데이터의존성은 최소화하는게 좋음

    5.Listener와 @JobScope, @StepScope 통합
      리스너와 스코프를 활용하면 리스너에서 잡파라미터를 쉽게 다룰수있음
	   @JobScope
	   public JobExecutionListener systemTerminationListener(
			   @Value("#{jobParameters['terminationType']}") String terminationType
	   ) {  
	  이렇게 받고
        return new JobBuilder("killDashNineJob", jobRepository)
	      .listener(systemTerminationListener(null))  // 파라미터는 런타임에 주입
	  컴파일시점에(빌더에) null을 넘겨주면됨
    
	  이때 JobExecutionListener라면 @JobScope를 붙여야함(잡의 실행과 생명주기를 같이하니까)
	  이렇게 주입받은 파라미터는 리스너의 어느메서드든 자유롭게 사용할수있음

  3.Listener 마지막 훈련: 성능과 모범 사례
    1.리스너를 효과적으로 다루는법
	  범위와 목적에 따라 적절한 리스너를 선택해야함
	    JobExecutionListener:잡의 시작과 종료를 통제
		StepExecutionListener:스탭의 단계를 통제
		ChunkListener:시스템을 청크단위로 제어하거나,반복의 시작과 종료시점을 통제
		ItemLintener:개별아이템 식별 통제
    2.예외처리는 신중하게
	  beforeJob과 beforeStep에서 예외가 발생하면 잡이나 스탭이 실패한걸로 취급되고,
	  afterJob이나 afterStep에서 예외가 발생하면 무시됨
	  만약 before쪽에서의 예외가 중요하지않다면 잡아서 무시할수있음
	
	3.단일책임원칙 준수
	  리스너에선 로깅 모니터링등 각 리스너별 책임만 담당하고,메인로직은 분리해야함
	  리스너가 너무 많은일을하면 유지보수가 어려워지고 시스템동작파악이 어려워짐
	
	4.성능최적화를 위한 경고
	  1.실행빈도를 고려하라
	    JobExecutionListener/StepExecutionListener의 경우엔 잡이나 스탭별로 한번씩만 실행되니까 작업이 좀 무거워도됨
	    그런데 ItemReadListener/ItemProcessListener는 매 아이템마다 실행되니까 치명적인 문제가 될수있음
      2.리소스사용을 최소화하라
	    db연결,파일io,외부api호출을 최소화하고,리스너내 로직은 가능한 가볍게 유지하는게 좋음
		특히 아이템단위리스너에서 더더욱 중요함
  
3.파일처리배치
*1.FlatFileItemReader
  1.청크지향처리
    데이터처리는 단순히 읽어서 가공하고 쓴다 딱 3개임
	청크처리도 마찬가지임
	  데이터읽기(ItemReader):데이터를 하나씩 읽어들임,청크사이즈만큼 반복실행
	  데이터가공(ItemProcessor):읽어들인 데이터를 원하는대로 가공,필터링도 수행
	  데이터저장(ItemWriter):청크단위로 모아진 데이터를 한번에 처리
	이렇게 3개가 다임
  2.파일기반 배치처리
    개발자가 직접 파일처리를 구현한다면 보일러플레이트도 많이생기고 귀찮아짐
	그래서 스프링배치에서는 파일기반 아이템리더와 라이터를 제공해줌
	이걸쓰면 io작업,데이터파싱,유효성검사,예외처리까지 다 처리해줌
	
	1.FlatFile
	  플랫파일이란 단순하게 행과 열로만 구성된파일,즉 csv같은거임
	  얘들은
	    각라인이 하나의 데이터 로우,\n이 레코드의 끝을 의미함
		쉼표나 탭,스페이스등으로 필드를 구분할수있고 고정길이로 구분할수도있음
		거의 모든시스템에서 읽고쓸수있는 표준형식,엑셀,db등 다양한 도구와 호환되고 사람이 읽기도 쉽고 대용량처리도 쉬움
	  이런 특징이 있음
	2.FlatFileItemReader
	  이건 플랫파일로부터 데이터를 읽어오는 클래스임
	  얘는 파일을 한줄씩 읽어서 지정한 도메인객체로 변환해서 반환함
	  즉
	    파일을 한줄씩 읽어온다
		읽어온 한줄의 문자열을 우리가 사용할 객체로 변환해 리턴한다
	  이런식으로 동작함
	  
	  이때 한줄의 데이터를 변환할땐 LineMapper이라는 컴포넌트 인터페이스를 사용하는데,
	  이건 단순하게 구분자로 분리해낸다음 각 분리한 데이터를 각 지정된 객체의 프로퍼티에 정확하게 매핑해야함
	  물론 이 인터페이스를 우리가 구현할필요는 없음
	  DefaultLineMapper이라는 기본구현체를 제공하고있기때문
	  
	3.DefaultLineMapper
	  이건 크게 두단계로 동작함
	    1.토큰화:하나의 구분자나 고정길이단위로 잘린 문자열을 각 토큰단위로 분리함//LineTokenizer사용하고,여기서도 인터페이스로 구분자나 고정길이별 구현체존재
		2.객체매핑:분리된 토큰을 도메인객체의 프로퍼티에 매핑함//FieldSetMapper사용하고,기본값은 BeanWrapperFieldSetMapper사용
	  즉 단순하게 토큰으로 만든다음 매핑하는걸 담당함
	  이때 매핑의 기본값인 BeanWrapperFieldSetMapper는 자바빈규약을 따르는 객체에 데이터를 매핑해줌
	  그래서 필드의 이름과 매핑객체의 프로퍼티명이 동일해야하고 setter가 필요함
	
	4.구분자로 분리된 형식의 파일 읽기
	  이걸 사용할땐 단순하게 빈으로 등록한다음 사용하면됨
		@Bean
		@StepScope
		public FlatFileItemReader<SystemFailure> systemFailureItemReader(
				@Value("#{jobParameters['inputFile']}") String inputFile) {
			return new FlatFileItemReaderBuilder<SystemFailure>()
					.name("systemFailureItemReader")
					.resource(new FileSystemResource(inputFile))
					.delimited()
					.delimiter(",")
					.names("errorId",
							"errorDateTime",
							"severity",
							"processId",
							"errorMessage")
					.targetType(SystemFailure.class)
					.linesToSkip(1)
					.build();
		}	  
	  이렇게 빌더로 
	    아이템리더 식별자를 넣고,
		타겟위치(파일위치)를 넣어주고
		구분자와 필드명을 넣어주고,
	    타겟클래스를 저장해주고,
		맨첫줄이 필드명이라면 스킵도 넣어주고 
		빌드한후 
	  스탭에서 가져다쓰면됨
	  또한 제네릭은 컴파일시점의 객체타입을 지정하고,타겟클래스는 런타임시점의 객체타입을 지정함
	  그리고 FlatFileItemReader는 #을 기본적으로 주석으로 인식하는데,만약 다른식으로 주석을 썼다면 comments("//")로 지정해줄수도있음
	  
	  그리고 파일 누락시 예외를 발생시키는걸 컨트롤하려면 .strict(true/false)를 사용하면됨
	  기본적으로는 true고 false로 하면 아이템리더가 null을 바로 반환하는식임
	  또한 라인토크나이저에서도 true면 한 row의 토큰리스트의 갯수가 전달된 객체프로퍼티(names)와 다르면 예외를 발생시키고,false면 자동으로 보정함
    
	5.고정길이형식의 파일 읽기
	  고정길이파일은 각 필드가 고정된길이로 맞춰진 텍스트파일임
	  이땐 각 필드의 길이를 스프링배치에 알려야함
		@Bean
		@StepScope
		public FlatFileItemReader<SystemFailure> systemFailureItemReader(
			   @Value("#{jobParameters['inputFile']}") String inputFile) {
		   return new FlatFileItemReaderBuilder<SystemFailure>()
			   .name("systemFailureItemReader")
			   .resource(new FileSystemResource(inputFile))
			   .fixedLength()
			   .columns(new Range[]{
				 new Range(1, 8),     // errorId: ERR001 + 공백 2칸
				 new Range(9, 29),    // errorDateTime: 날짜시간 + 공백 2칸
				 new Range(30, 39),   // severity: CRITICAL/FATAL + 패딩
				 new Range(40, 45),   // processId: 1234 + 공백 2칸
				 new Range(46, 66)    // errorMessage: 메시지 + \n
			   })
			   .names("errorId", "errorDateTime", "severity", "processId", "errorMessage")
				.targetType(SystemFailure.class)
			   .build();
		}
      이런식으로 구분자랑 거의 비슷한데,fixedLength()로 표시한후 .columns로 각 범위를 표시해주면됨	
	  그리고 .strict()도 true면 추가적으로 파일의 읽은길이를 엄격하게 검증함
	  파일의 읽은 라인길이가 range에 지정된 최대길이(마지막필드의 끝위치)와 다르다면 예외를 발생시킴
	  또한 공백의경우 내부적으로 trim을 돌리기때문에 신경안써도됨
	
	6.프로퍼티 타입에 LocalDateTime을 쓰고 싶다면?
	  시간타입을 사용하고싶으면 별도의 변환기가 필요함
	  BeanWrapperFieldSetMapper는 이런 복잡한 변환까진 처리하지않는데,
	  그래서 빌더에서 customEditors()를 사용해서 커스텀 propertyEditer를 등록할수있음
	    .customEditors(Map.of(LocalDateTime.class, customEditor()))	  
	  즉 propertyEditer를 구현하고,이걸 빌더의 .customEditors를 사용해 등록하면됨 
  
  
    7.RegexLineTokenizer
	  이건 복잡한 형식의 파일을 처리할때 사용하는 도구임
	  이걸 등록하는건 아이템리더빌더에서 .lineTokenizer()을 사용하면되고,
        RegexLineTokenizer tokenizer = new RegexLineTokenizer();
        tokenizer.setRegex("\\[\\w+\\]\\[Thread-(\\d+)\\]\\[CPU: \\d+%\\] (.+)");
	  이런식으로 정규식을 사용해서 토크나이저를 할수있음
    8.fieldSetMapper()
	  마찬가지로 fieldSetMapper도 커스텀을 등록할수있음(필드 매핑하는클래스)
		.fieldSetMapper(fieldSet -> new LogEntry(fieldSet.readString(0), fieldSet.readString(1)))
	  단 이걸 사용할땐 targetType를 사용하면안됨
	
	9.PatternMatchingCompositeLineMapper 
	  만약 하나의 파일안에 여러형식의 라인이 혼재되어있다면 이걸 사용할수있음
	  이건 패턴매칭을 지원해서,각 라인의 패턴을 먼저 파악한후,해당 패턴에 맞는 토크나이저와 필드매퍼를 적용할수있음
		@Bean
		@StepScope
		public FlatFileItemReader<SystemLog> systemLogReader(
				@Value("#{jobParameters['inputFile']}") String inputFile) {
			return new FlatFileItemReaderBuilder<SystemLog>()
					.name("systemLogReader")
					.resource(new FileSystemResource(inputFile))
					.lineMapper(systemLogLineMapper())
					.build();
		}
	  등록은 이렇게 등록한후에
		@Bean
		public PatternMatchingCompositeLineMapper<SystemLog> systemLogLineMapper() {
			PatternMatchingCompositeLineMapper<SystemLog> lineMapper = new PatternMatchingCompositeLineMapper<>();

			Map<String, LineTokenizer> tokenizers = new HashMap<>();
			tokenizers.put("ERROR*", errorLineTokenizer());
			tokenizers.put("ABORT*", abortLineTokenizer());
			tokenizers.put("COLLECT*", collectLineTokenizer());
			lineMapper.setTokenizers(tokenizers);

			Map<String, FieldSetMapper<SystemLog>> mappers = new HashMap<>();
			mappers.put("ERROR*", new ErrorFieldSetMapper());
			mappers.put("ABORT*", new AbortFieldSetMapper());
			mappers.put("COLLECT*", new CollectFieldSetMapper());
			lineMapper.setFieldSetMappers(mappers);

			return lineMapper;
		}
	  이렇게 각 종류에 맞는 토크나이저와 매퍼를 등록하면됨(앞에있는게 조건임)
	  여기선 맨앞의 값으로 구분했지만 패턴이니까 패턴만 맞추면 어떤형식이든 가능
	
	10.RecordFieldSetMapper: Record 매핑 지원
	  만약 targetType을 record타입으로 잡는다면 자동으로 BeanWrapperFieldSetMapper 대신 RecordFieldSetMapper를 사용함
	  동작자체는 비슷하니까 신경안써도됨
	
	11. MultiResourceItemReader:여러 파일 읽기
	  여러파일을 읽어야할때(여러서버의 로그파일들을 통합분석등),각 파일마다 스탭을 만드는건 비효율적임
	  이때 사용하는게 MultiResourceItemReader임
	  이건 여러파일들을 순차적으로 읽게 해주는 ItemReader구현체임
	  그냥 말그대로 여러파일들은 순서대로 읽음
	  
	  얘가 직접 읽진않고,위임대상 ItemReader에게 실제 읽기를 맡기고,걔한테 일주는일을 담당함
	  그래서 이걸 사용할땐 두가지 구성이 필요함
	    실제로 사용할 ItemReader
		읽어들일 파일의 목록
	  그래서 이런식으로 구성됨
		return new MultiResourceItemReaderBuilder<SystemFailure>()
		  .name("multiSystemFailureItemReader")
		  .resources(new Resource[]{
			  new FileSystemResource(inputFilePath + "/critical-failures.csv"),
			  new FileSystemResource(inputFilePath + "/normal-failures.csv")
		  })
		  .delegate(systemFailureFileReader())
		  .build();	 
	  resources로 파일들을 지정해주고,delegate로 실제 사용할 리더를 넣어주는식
	  단 여기서 중요한건,systemFailureFileReader() 빈생성시에 resource가 없어야함(그건 우리가 넣어줘야하니까),나머진 동일함
	  또한 resources의 파일읽기순서는 파일명의 알파벳순서로 기본적으로 읽고,이걸 바꾸고싶다면 comparator()메서드로 원하는 정렬기준을 지정할수있음
	
*2.FlatFileItemWriter 	  
  이건 데이터를 플랫파일형식으로 쓰는작업을 담당함,즉 도메인객체를 문자열로 변환해서 파일에 써내려감
  이것도 리더랑 거의비슷하게 선언해서 빈등록하면됨
  
  얘가 하는일은 필드추출과 문자열결합 두개로 나눠볼수있고,필드추출은 FieldExtractor,문자열결합은 LineAggregator이 담당함
  1.필드추출과 라인결합
    필드추출은 도메인객체에서 필드를 추출하는역할을 함
	즉 T를 받아서 object[]를 내보내는 역할을 함
	
	이것도 당연히 기본구현체가 있는데 BeanWrapperFieldExtractor 와 RecordFieldExtractor 임
	BeanWrapperFieldExtractor는 빈객체로부터 필드를 추출하는거고,RecordFieldExtractor는 레코드객체에서 필드를 추출함
	배치는 파일의 도메인타입에 따라 이 두개중 하나를 자동선택함
	
	문자열결합은 추출한 데이터들을 하나의 문자열로 결합하는 역할을 함
	이것도 구분자기반으로 읽던가 고정길이로 읽던가가 나뉜거처럼,여기도 2개로 나뉘는데
	DelimitedLineAggregator는 구분자로 구분하는거고 FormatterLineAggregator는 고정길이를 포함한 다른형식으로 쓸때 사용함
	이거 선택은 직접 라이터빌더설정에서 delimited()와 formatted()를 사용해서 선택할수있음
	
	또한 내부적으로는 LineAggregator가 FieldExtractor를 합성한 형태로 구성되어있음
	그래서 객체를 문자열로 변환하는 전과정은 LineAggregator가 담당함
	
	기본적으로 단일객체를 이렇게 바꾸고,라이터는 청크단위로 동작하니까 각 아이템마다 이걸 반복해서처리함

  2.구분자형식의 파일쓰기
    아이템 라이터는 기본적으로
	    @Bean
		@StepScope
		public FlatFileItemWriter<DeathNote> deathNoteWriter(
				@Value("#{jobParameters['outputDir']}") String outputDir) {
			return new FlatFileItemWriterBuilder<DeathNote>()
				.name("deathNoteWriter")
				.resource(new FileSystemResource(outputDir + "/death_notes.csv"))
				.delimited()
				.delimiter(",")//구분자
				.sourceType(DeathNote.class)
				.names("victimId", "victimName", "executionDate", "causeOfDeath")
				.headerCallback(writer -> writer.write("처형ID,피해자명,처형일자,사인")) //파일헤더
				.build();
		}
	이런형태로 만들어짐
	FieldExtractor를 전달할때는 빈등록을 하던가 빌더의 fieldExtractor()메서드로 직접 넣어주면됨
	그리고 FieldExtractor가 객체로부터 어떤 필드를 추출할지를 알려줘야하는데,이게 .names()임
	단 이때 지정한순서대로 쓰여지니까 순서조심해야함
	그리고 names()는 자동구성방식에서만 사용되고,fieldExtractor()메서드로 직접 커스텀 fieldExtractor를 넣었을경우엔 무시됨
	RecordFieldExtractor를 사용할땐 names가 무시되는 버그가 있으니 조심
	Record타입을 sourceType으로 전달할경우에 자동으로 RecordFieldExtractor 가 사용됨
	커스텀FieldExtractor의 경우엔 setNames으로 필드명을 지정할수있음
		
	이때 스텝의 청크는
	  .<DeathNote, DeathNote>chunk(10, transactionManager)
	이런형태로 리더의 출력,라이터의 입력타입을 넣어주면됨

  3.커스텀 포맷 형식으로 파일 쓰기
    커스텀포맷을 사용할땐 FormatterLineAggregator를 사용할수있음
		@Bean
		@StepScope
		public FlatFileItemWriter<DeathNote> deathNoteWriter(
				@Value("#{jobParameters['outputDir']}") String outputDir) {
			return new FlatFileItemWriterBuilder<DeathNote>()
					.name("deathNoteWriter")
					.resource(new FileSystemResource(outputDir + "/death_note_report.txt"))
					.formatted()
					.format("처형 ID: %s | 처형일자: %s | 피해자: %s | 사인: %s")
					.sourceType(DeathNote.class)
					.names("victimId", "executionDate", "victimName", "causeOfDeath")
					.headerCallback(writer -> writer.write("================= 처형 기록부 ================="))
					.footerCallback(writer -> writer.write("================= 처형 완료 =================="))
					.build();
		}	
	이런식으로 formatted()를 사용한후 format로 형식을 지정해주고, .names()의 순서대로 집어넣으면됨

  4.파일 처리 옵션
    현재 
	  .resource(new FileSystemResource(outputDir + "/death_note_report.txt")) 
	이런식으로 하면 실행할때마다 파일이 계속 덮어쓰기됨
	그래서 동작방식을 선택할수있는데,
		shouldDeleteIfExists: 기존 파일의 삭제 여부(FlatFileItemWriterBuilder.shouldDeleteIfExists()를 사용해 지정)
		append: 기존 파일에 데이터 덧붙이기 여부(FlatFileItemWriterBuilder.append() 메서드를 사용해 지정)
		shouldDeleteIfEmpty: 빈 결과 파일 처리 여부(FlatFileItemWriterBuilder.shouldDeleteIfEmpty() 메서드를 사용해 지정)
	이런식으로 여러 옵션들이 있음
	
	shouldDeleteIfExists는 기본값이 true로,겹치는파일이 있다면 삭제하고 새로 파일을 생성함
	만약 false라면 겹칠때 예외를 던짐
	
	append는 기본값이 false로,true로 설정하면 shouldDeleteIfExists는 자동으로 false로 설정되고,기존파일에 데이터를 추가함
	
	shouldDeleteIfEmpty는 기본값이 false로,파일에 헤더와 푸터를 제외한 데이터가 하나도없으면 파일을 삭제할지여부를 나타냄 	
	여기서 주의할건,해당파일에 얼마나 데이터가 있냐가 아닌,이번에 얼마나 데이터를 썼냐가 기준이라 append를 true로 설정해뒀는데 아무것도 안썼으면 지워버리니 주의
	
  5.FlatFileItemWriter의 롤백 전략: 버퍼링을 통한 안전한 파일 쓰기
    파일은 db와 달리 이미 쓰여진 데이터를 롤백할수없음
	그래서 FlatFileItemWriter는 데이터를 즉시 쓰지않고 내부버퍼에 일시적으로 저장해두다가,
	트랜잭션이 커밋될때(beforeCommit()이 호출될때) 버퍼의 데이터를 파일에 씀
	즉 트랜잭션과 같은범위로 성공실패를 시킬수있음
	이건 FlatFileItemWriterBuilder의 transactional()메서드로 설정할수있고,기본값은 true임

  6.파일 쓰기와 OS 캐시: forceSync 옵션
	os는 기본적으로 매번 디스크에 파일을 쓰지않고,메모리캐시에 먼저 저장한후 파일쓰기를 하는데 이 시차때문에 유실이 발생할수있음
    forceSync()를 true로 설정하면 이 시차를 없애서 즉시 동기화할수있음
	단 잦은동기화로 성능저하가 발생할수있음,기본값은 false임

  7.대용량 파일의 분할 처리: MultiResourceItemWriter
    한파일에 적게되는 양이 너무 커질경우,파일을 나눠서 저장해야하는 필요성이 생기는데,이때 사용되는게 MultiResourceItemWriter임
	이건 이름그대로 여러 리소스에 데이터를 분배하는 ItemWriter구현체임
	애는 직접 파일을 쓰지않고,쓰는작업은 쓰기를 할 ItemWriter에 위임함
	
	그래서 이걸 사용할땐
		@Bean
		@StepScope
		public MultiResourceItemWriter<DeathNote> multiResourceItemWriter(
				@Value("#{jobParameters['outputDir']}") String outputDir) {
			return new MultiResourceItemWriterBuilder<DeathNote>()
					.name("multiDeathNoteWriter")
					.resource(new FileSystemResource(outputDir + "/death_note"))
					.itemCountLimitPerResource(10)
					.delegate(delegateItemWriter())
					.resourceSuffixCreator(index -> String.format("_%03d.txt", index))
					.build();
		}
	이런식으로 delegate에 실제로 사용할 아이템라이터를 넣어주고,
	itemCountLimitPerResource로 한 파일에 저장할 갯수를 설정한다음,resourceSuffixCreator로 어떤식으로 구분할지를 적어주면됨
	
	사용은 그냥 아이템라이터처럼쓰면됨

*3.JSON 파일 읽고 쓰기
  1.커스텀 LineMapper를 활용한 json 문자열 읽기
    만약 줄마다 각각 json객체로 이루어진
	  {...} 
	  {...} 
	  {...}
	이런형태가 있다면(jsonl),그리고 만약 특정객체로 파싱해야한다면
	이럴땐 커스텀 라인매퍼를 만들어야함,간단하게는 아이템리더빌더에 람다식을 써서 만들수있음
	  .lineMapper((line, lineNumber) -> objectMapper.readValue(line, SystemDeath.class))
	기본적으로 JsonLineMapper을 제공하긴하지만 특정객체를 요구한다면 이렇게 간단하게 커스텀객체를 만들수있음
	
	그리고 각 줄마다 json객체가 있는게 아닌,제대로 포맷팅된 객체가 올수도있음(하나의 json객체가 여러줄에 걸쳐 기록된경우)
	이럴땐 리더빌더에 recordSeparatorPolicy를 추가해 하나의 레코드가 어디서 끝나는지를 결정하면됨
	  .recordSeparatorPolicy(new JsonRecordSeparatorPolicy())//이건 기본적으로 있는거임
	RecordSeparatorPolicy 인터페이스는
	  public interface RecordSeparatorPolicy {
		boolean isEndOfRecord(String line); // 해당 줄이 레코드의 끝인지 판단.
		String postProcess(String record); // 레코드가 완성된 후 추가 처리.
		String preProcess(String record); // 레코드를 시작하기 전 사전 처리.
	  }
	이런식으로 구성되고
	이걸 구현한 JsonRecordSeparatorPolicy는 여는중괄호와 닫는중괄호의 갯수가 동일하고,현재읽은라인이 닫는중괄호로 끝나면 레코드가 완료된걸로 판단함
	
	그리고 만약 Json배열로 포장된 데이터라면 
	  [{...},{...},{...}]
	JsonItemReader를 사용할수있음
	이건 resource에 json의 소스를 지정하고(파일,url등 다양한걸 지원)
	  .resource(new UrlResource("http://kill-batch-system.com/array_system_death.json"))
	JsonObjectReader구현체를 선택할수있음  
	  Jackson: JacksonJsonObjectReader
	  Gson: GsonJsonObjectReader
	즉
		@Bean
		@StepScope
		public JsonItemReader<SystemDeath> systemDeathReader(
				@Value("#{jobParameters['inputFile']}") String inputFile) {
			return new JsonItemReaderBuilder<SystemDeath>()
					.name("systemDeathReader")
					.jsonObjectReader(new JacksonJsonObjectReader<>(SystemDeath.class))
					.resource(new FileSystemResource(inputFile))
					.build();
		}
	이런식으로 오브젝트리더와 리소스위치를 넣어주고 만들어서 쓰면 알아서해줌
  2.JsonFileItemWriter	
	비슷하게 JsonFileItemWriter를 사용하면 객체를 json배열로 변환해 파일로 저장할수있음
	얘는 내부적으로 JsonObjectMarshaller를 사용해 객체를 json문자열로 변환함
	얘는 
	  WritableResource: JSON 데이터를 저장할 대상 파일을 나타내는 Spring의 WritableResource.
	  JsonObjectMarshaller: 객체를 JSON 형식으로 마샬링하는 JSON 객체 변환기
	    Jackson: JacksonJsonObjectMarshaller
	    Gson: GsonJsonObjectMarshaller
	이렇게 얘도 저장위치와 json매퍼 두가지만 넣어주면됨 
		@Bean
		@StepScope
		public JsonFileItemWriter<DeathNote> deathNoteJsonWriter(
				@Value("#{jobParameters['outputDir']}") String outputDir) {
			return new JsonFileItemWriterBuilder<DeathNote>()
					.jsonObjectMarshaller(new JacksonJsonObjectMarshaller<>())
					.resource(new FileSystemResource(outputDir + "/death_notes.json"))
					.name("logEntryJsonWriter")
					.build();
		}
	이렇게 생성하면되고
	
4.데이터베이스 배치
*1.rdbms 읽고쓰기	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
  