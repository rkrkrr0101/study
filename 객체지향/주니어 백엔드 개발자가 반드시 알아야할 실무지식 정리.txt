1.들어가며
  스킵
2.느려진 서비스 어디부터 봐야할까
*1.처리량과 응답시간
  1.응답시간
    요청이 10초이상걸리면 성능이 나쁜거임
    이때 서버성능과 관련있는 중요지표 2개는 응답시간과 처리량임
    
    응답시간은 사용자의 요청을 처리하는데 걸리는 시간임
    가장 일반적인 요청은 
      1.api요청
	    1.1번 sql실행
	    2.2번 sql실행
	  2.json 반환
    이런 순서를 가지게되는데,이떄 api요청을 호출하고 json반환을 받을때까지 걸린 시간이 응답시간임
    
    응답시간을 나눠보면
      api요청
        서버에 연결
	    서버로 데이터 전송
	  서버실행
	    sql실행
	    응답생성 등
	  api응답
	    클라이언트로 데이터전송
    이렇게 나눠짐
    서버에 연결은 tcp를 이용해서 서버와 연결하는거고,데이터전송은 프로토콜에 맞춰 데이터를 서버에 전송하는것
    또한 응답시간은 응답데이터중 첫바이트가 도착하는데 걸린시간(TTFB)와 응답데이터중 마지막 바이트가 도착하는데 걸리는 시간(TTLB)로 나눌수도있음
    이건 보통땐 상관없는데,다운로드같은거나 네트워크가 느릴떈 차이가 커질수있음
    
    응답시간은 보통 ms단위로 잼
    응답시간은 사업에 영향이 큼(100ms지연시 매출1%감소)
    
    응답시간은 api요청 전송시간,서버의 처리시간,api응답 전송 시간으로 나뉨
    서버개발자는 주로 서버의 처리시간을 확인하고,서버처리시간은 다음과 같은 요소를 포함함
      로직수행
	  db연동
	  외부api연동
	  응답데이터 전송
    이중 db연동과 api연동이 응답시간에 큰 비중을 차지함
    그래서 이걸 줄이는게 핵심임
  2.처리량
    처리량은 단위시간당 시스템이 처리하는 작업량을 의미하고,흔히 TPS(초당 트랜잭션 수)나 RPS(초당 요청 수)로 나타냄
	
	최대TPS는 시스템이 처리할수있는 최대 요청수를 의미함
	서버가 한번에 5개의 요청을 처리할수있고,요청당 처리시간이 1초라면 5임
	이걸 넘긴수의 요청이 들어오면,초과된 요청을 나중에 처리함(2초)
	
	응답시간의 증가는 사용자 이탈로 이어질수있음,그래서
	  서버가 동시에 처리할수있는 요청수를 늘려 대기시간 줄이기(배치크기 늘리기)
	  처리시간 자체를 줄여 대기시간 줄이기(속도 높이기)
	두 방법을 적용해 TPS를 높여야함
	
	모든 개선을 할때 제일 먼저해야할건 측정임
	먼저 트래픽이 많은 시간대의 TPS와 응답시간을 측정하고,이결과를 바탕으로 목표TPS와 응답시간을 설정하고 효과적인 성능개선안을 도출해야함
	이때 가장쓰기편한건 모니터링시스템임(스카우터,뉴렐릭등)

*2.서버 성능 개선 기초
  1.병목 지점
    서비스 초기에는 성능문제가 잘 발생하지않지만,서비스가 커지면서 간헐적으로 응답시간이 느려짐
	이걸 방치하면 어느순간 심각한 성능문제가 생김
	  순간적으로 모든 사용자요청에 대한 응답시간이 심각하게 느려짐
	  서버를 재시작하면 잠시 괜찮다가 다시 응답시간이 느려짐
	  트래픽이 줄어들때까지 심각한상황이 지속됨
	이게 발생하는 주된이유는,최대TPS를 넘은 트래픽이 유입되기때문
	그래서 최대TPS를 높여야함
	
	이땐 먼저 성능문제가 발생하는 지점을 찾아야하는데,가장쉬운방법이 처리시간이 오래걸리는 작업을 식별하는것
	가능하면 모니터링도구로 측정하는게 유용함(로깅도 괜찮음)
	보통 db나 api연동에서 발생하는편임
	
  2.수직확장과 수평확장
    성능문제를 일으키는 원인을 찾았다면,개선안을 빠르게 도출해야함
	근본을 해결하는것도 중요하지만,일단 급한불부터 꺼야함
	
	가장 편한건 수직확장임(스케일업),즉 현재 서버를 비싼거로 교체하는것
	클라우드서비스에선 이게 젤 빠름,db나 서버나 상관없이 올리기도 쉽기도 하고
	대신 비싸고 임시땜빵밖에 되지않음,트래픽은 계속 증가하는데,사양은 계속 올릴수없기때문
	
	그래서 사용되는게 수평확장임(스케일아웃),이건 서버를 추가해 tps를 올리는것
	이건 스테이트리스 서버를 확장할땐,로드밸런서만 추가하면 쉽게 늘이고 줄일수있다는 장점이 있고,가격도 비싸지않음	
	단,문제가 서버라면 괜찮은데,병목지점이 db라면 조심해야함
	db에 부하가 있는 상황에서 서버를 늘려버리면 더 부하가 커지고,성능문제가 악화되기때문
	또한 외부api가 문제인경우도 서버를 늘려봐야 효과가 없음

  3.db커넥션 풀
    db를 사용할땐 3가지 단계를 거침
	  db에 연결
	  쿼리실행
	  연결 종료
	그런데 이 연결을 생성하고 종료하는데 걸리는 시간이 0.5초에서 1초로 매우 길기때문에,요즘은 연결을 이미 몇백개씩 맺어두고 가져다쓰는 커넥션풀을 사용함
	
	커넥션풀을 사용할때는 다양한 설정이 있는데
	  커넥션풀 크기(최소,최대크기)
	  풀에 커넥션이 없을때 커넥션을 구할때까지 최대 대기시간
	  커넥션의 유지시간(최대유휴시간,최대유지시간)
	가 있음
  4.커넥션풀 크기
    커넥션풀 크기는 커넥션풀에 미리 생성해둘 커넥션갯수를 지정하는 설정임
	이건 가장 중요한 설정임(커넥션 갯수가 TPS와 직결되기때문)
	
	또한 요즘은 최소크기,최대크기로 TPS를 초과하는 요청이 생기면,점차 커넥션을 늘려가고,일정시간안쓰면 줄이는 방식으로 하기도함
	또한 트래픽은 시간대별로 가장 높은 시간대가 있고,이때 맞춰서 갯수를 변경할수도있음
	
	만약 트래픽이 순간적으로 급증하는 패턴을 보인다면,커넥션풀의 최소크기를 최대크기에 맞추는게 좋음
	트래픽이 점진적으로 증가하면 조금씩 늘려가는게 효과가 있지만,갑자기 튄다면 db연결시간도 성능저하의 주요원인이 될수있기때문
	
	커넥션풀을 무조건 크게하면 좋을거같지만,커넥션으로 뭘 처리하는거 자체가 db에 부하를 거는거라서,
	db에 부하가 너무 클경우에는 오히려 커넥션풀을 줄여서 db서버가 포화상태에 이르지않도록 해야함
	서버를 스케일아웃하는것도 커넥션풀크기를 늘리는것과 같은 맥락임(서버가 늘어나면 처리할수있는 커넥션갯수가 늘어나니) 

  5.커넥션 대기시간
    대부분 커넥션풀은 대기시간을 설정할수있음
	이건 풀에 사용할수있는 커넥션이 없을때 얼마나 기다릴지임
	이걸 초과하면 db연결실패 에러가 나게됨
	
	기본값은 보통 30초인데,이건 최악의경우 응답시간이 30초라는것
	그래서 이건 보통 0.5초나 3초내로 지정하고 빠르게 에러띄우는게 나음
	무응답보단 에러가 낫기때문
	
	에러를 띄우면 커넥션 요청 자체가 무효가 되지만,무응답의 경우 사용자가 계속 새로고침하면 횟수마다 요청이 계속 쌓이게됨
	즉 계속 에러를 띄우면서 요청자체를 처리하는게 훨씬 더 응답처리시점에선 낫다는것

  6.최대유휴시간,유효성검사,최대유지시간
    보통 일정시간이상 상호작용이 없으면 자동으로 연결을 끊는 기능을 db들은 제공함
	그래서 커넥션이 일정이상 사용되지않으면 db와의 연결이 끊어지게됨
	이걸 방지하기위해
	  최대유휴시간 지정
	  유효성검사
	기능을 커넥션풀은 제공함
	
	최대유휴시간은 사용되지않은 커넥션풀을 유지할수있는 최대시간을 의미함
	이걸 30분으로 설정하면 30분이상 사용되지않은 커넥션은 종료됨
	즉 db의 비활성화시간보다 짧게 설정하면됨
	최대 유지시간은,커넥션은 이 시점까지만 존재할수있고 이게 지나면 유효하든말든 풀에서 제거됨
	
	유효성검사는 커넥션이 정상적으로 사용할수있는 상태인지를 커넥션을 가져올때나,주기적으로 검사하는 기능임
  7.서버 캐시
    db서버의 확장은 비용이 많이들고,처리량은 늘어나지만 실행시간을 줄어들지않음
	그래서 사용되는게 캐시임
	
	보통 캐시에서 읽는게 db보다 빨라서 자주 사용됨
	이건
	  캐시에서 키에 해당하는 값 조회->있으면 값 사용
	  없으면 db에서 조회
	  키값을 캐시에 저장
	  값사용
	이런식으로 사용됨
	복잡한 계산결과나 외부api 연동결과도 캐시에 보관해서 응답시간을 줄일수있음

  8.적중률과 삭제 규칙
    캐시가 얼마나 효율적으로 사용되는지는 적중률로 판단할수있음
	  적중률=캐시에 존재한 건수/캐시에서 조회를 시도한 건수
	이걸 높이는 가장 간단한 방법은 캐시에 최대한 많은 데이터를 저장하는거지만 현실적으로 메모리땜에 불가능함
	그래서 lru나lfu fifo같은 캐시데이터 삭제방법을 사용함
	또한 캐시에 유효시간을 넣는 방법도 자주사용됨(최신영상이 예전영상보단 자주보는 이런느낌으로)

  9.로컬 캐시와 리모트 캐시
    로컬캐시는 서버프로세스와 같은 메모리를 캐시저장소로 쓰는거고,리모트캐시는 별도 프로세스를 캐시저장소로 사용함
	
	로컬캐시는 간단하고 속도가 빠르지만,용량에 한계가 있고,스케일아웃을 해서 서버가 여러개일때와,서버를 재시작했을때에 캐시가 초기화되는 문제가 있음
	리모트캐시는 캐시크기를 유연하게 확장할수있고 서버를 재시작해도 남아있지만,속도가 느리고(통신해야하니) 뭘 추가해야하니 구조가 복잡해짐
	
	캐시가 작고 변경빈도가 낮다면 로컬캐시로 충분함
	데이터규모가 크다면 리모트캐시를 사용해야함(쇼핑사이트같은거)
	또한 배포가 잦다면 리모트캐시사용을 적극적으로 고려해야함

  10.캐시 사전 적재
    트래픽이 순간적으로 급증하는 패턴을 보인다면,캐시에 미리 데이터를 저장해두는것도 생각해볼수있음
	특정날에 요금정보를 푸시를 날리는데,캐시저장을 이달동안 요금조회를 했어야 저장해두는식이면 캐시적중률이 0%니까 미리 저장해두는 방법도 있음
	이러면 db부하도 줄어들고,적중률도 99%에 가깝게 올릴수있음

  11.캐시 무효화
    캐시를 쓸때 가장 주의해야하는건,유효하지않은 데이터를 적절한 시점에 캐시에서 삭제하는것임
	원본이 바뀌었는데 캐시에 저장된 데이터가 변경되거나 삭제되지않으면 오래된 잘못된 정보를 확인하게됨
	
	캐시에 저장된 데이터의 특성에 따라 캐시무효화시점을 달리해야함
	가격,게시글내용같은 민감한 데이터는 변경즉시 무효화해야하고,이런건 로컬캐시가 아닌 리모트캐시에 보관해야함(다른서버의 로컬캐시관리가 안되니까)
	
	변경에 민감하지않고 데이터가 작다면 유효시간을 설정해서,주기적으로 갱신하는방법을 사용해도됨
	최근 인기글 같은건 좀 늦어도 되니까 만료시간넘기면 갱신되게 해도됨

  12.가비지컬렉터와 메모리 사용
    gc가 있는 애들은 메모리관리를 우리가 안해도되지만,스탑더월드같은 일이 생김
	또한 메모리를 많이사용하고 생성된객체가 많으면 gc가 오래걸림
	
	또한 한번에 대량으로 객체를 생성하는것도 주의해야함
	실질적으로 사용하는 메모리가 현재 총 메모리를 초과해버리면 gc를 해도 계속 메모리가 부족하기때문
	이건 조회범위를 제한해서 한번에 생성되는거 자체를 막아야함
	그래서 사이트들이 구매목록을 3개월,1년단위로 끊어서 보여주는거
	또한 다운로드같은건 스트림을 사용해서 처리해야지,한꺼번에 메모리에올리면 안됨

  13.응답데이터 압축
    응답시간엔 데이터전송시간이 포함됨
	이건
	  네트워크 속도
	  전송데이터 크기
	에 영향을 받음
	서버는 사용자의 네트워크속도를 제어할순없지만,전송되는 데이터크기는 제어할수있음
	그래서 사용되는게 압축임
	압축을하면 응답시간+비용에도 영향을 줘서 적극검토해볼수있음
	
	이 압축은 html,css,js,json같은 텍스트 형식은 효과적이지만,이미지같은 이미 압축된 데이터는 효과가없으니 주의
	또한 방화벽이 압축을 풀수도있는데,서버에서 압축설정을 했는데도 압축이 안되면 방화벽설정을 확인해야함

  14.정적 자원과 브라우저 캐시
    동적자원이 아닌 정적자원의 경우 브라우저 캐시를 사용해서 한번 가져간다음 재사용시키면 트래픽도 줄고 화면도 빨리나옴

  15.정적자원과 CDN
    또한 직접 서버에서 받아가는게 아닌,CDN을 거쳐서 CDN에서 뿌리게하면 훨씬 더 효과적임
	즉 리버스프록시로 cdn을 사용하는거임,cdn은 일정시간마다 오리진서버에서 값을 갱신하고
	
	그리고 cdn과는 상관없지만,정적파일을 관리할때 크기를 주의해야함,특히 이미지같은거 30mb이런거 올리면 비용 개비싸지니까 주의
  16.대기처리
    사용자가 순간적으로 폭증할때(이벤트 등),서버는 증설할수있지만 DB는 증설하기힘듬(늘린다음 다시 줄이기가 힘듬)
	이렇게 잠시 빤짝했다가 다시 트래픽 줄어들면 늘리면 개손해니까..
	
	그래서 그냥 대기표뽑아서 한번에 수용할수있는만큼의 트래픽만 받고 나머지 대기처리해서 순차처리하는게 나음
	이러면
	  서버를 증설하지않고 서비스를 안정적으로 제공가능
	  사용자의 지속적인 새로고침으로 인한 트래픽폭증도 방지할수있음(새로고침하면 순번이 뒤로밀리니까)
	또한 대기제어는 이미 여러 솔루션도 있어서 빠르게 도입도 할수있음
3.성능을 좌우하는 db설계와 쿼리	
*1.성능에 핵심인 db
  풀스캔을 조심하자
*2.조회 트래픽을 고려한 인덱스 설계
  보통은 조회의 실행비율이 가장 높고,이걸 최적화하기위해 인덱스를 사용함
  이때도 트래픽의 규모와 사용되는 패턴(조회기능)에 맞게 인덱스를 추가해야함
  
  예를들어 게시판에서 공지같은 카테고리에 인덱스가 없다면 공지를 찾으려고 매번 풀스캔을 때려야함
  또한 내가 작성한 글 목록 보기같은경우도,글쓴이 인덱스가없다면 매번 풀스캔을 해야함
  
  이런식으로 풀스캔을 피하는게 최우선임
  또한 특정 단어로 검색같은경우 %aaa%라 일반적으로는 풀스캔을 피할수없지만,전문검색기능이나 엘라스틱서치같은걸 쓸수있음

  1.단일인덱스와 복합인덱스
    케이스에 따라 쌓일만한 row의 수를 미리 계산하고,거기에 맞게 인덱스의 규모를 맞춰야함
	단일인덱스 기준으로도 감당이 불가능할정도로 많다면 결국 복합인덱스를 써야함
	즉 사용자기준으로 단일인덱스를 썼는데,이게 ~1000건정도 잡히면 걍 단일인덱스써도 되는데,32000건 잡힌다면 복합인덱스로 범위를 줄여야한다는것
	이떄 주로 추가로 사용되는게 보통 날짜임 

  2.선택도를 고려한 인덱스 칼럼 선택
    인덱스를 생성할땐 일반적으로는 선택도가 높은 칼럼을 골라야함
	즉 여자와 남자같은 성별보단,id같이 유니크의 갯수가 높은걸 고르는식
	물론 카테고리나 배치작업의 상태(대기중인 조회 검색)같이 유니크갯수가 낮아도 조회패턴에 맞다면 고를수있음

  3.커버링인덱스 활용하기
    커버링인덱스는 특정 쿼리를 실행하는데 필요한 칼럼을 인덱스에 전부 넣어두는거임
	이러면 메인테이블 안가도되서 효율이 높음
	
  4.인덱스는 필요한만큼만 만들기
    인덱스를 만들면 
	  반드시 쓰기성능이 나빠짐
	  반드시 메모리와 저장공간을 사용함
	  사용가능하다면 읽기성능이 좋아짐
	그러니 무지성으로 인덱스를 만들면 안됨,사용할거만 만들어야함
	
	또한 새로 추가할 쿼리가 기존인덱스를 타지않는다면,요구사항을 약간 변경해서 타게 할수있을지를 검토해봐야함
	즉 다른 인덱스를 탄다음 그 인덱스에서 스캔을 떄리는방식
	
	또한 같은칼럼을 사용하는 인덱스를 2개추가해봐야 의미없고 낭비니까 지우자

*3.몇가지 조회 성능 개선 방법
  1.미리 집계하기
    조회수나 설문조사결과같은 집계가 필요한건 반드시 정확한 값을 사용자에게 보여줄필요가 없음
	즉 집계를 일정간격마다 미리 해두고,그값을 보여주면됨
	이 방법은 비정규화를 사용하고,약간의 무결성을 포기해서 성능을 올리는 패턴임
	
	또한 추가적으로,현재값에+1하는등의 쿼리를 실행할땐 동시성문제(원자성)를 트랜잭션격리수준에서 원자적으로 처리하는지를 반드시 검증해야함

  2.페이지 기준 목록 조회 대신 id기준 목록 조회방식 사용하기
    페이징시에 limit offset으로 조회를 한다면 가면갈수록 풀스캔을 때려야함(처음에는 그냥 주면되는데,나중엔 그위치까지 가서 줘야하니까)
	
	그래서 게시글id에 인덱스를 걸고,
	페이지를 조회할때 현재 페이지의 마지막 게시글의 id를 기준으로 그것보다 작은거로 조건을 걸고 limit를 사용하면 인덱스를 타고 쉽게 조회할수있음
	또한 다음데이터가 있는지를 알려면,한개를 더읽고 갯수를 세면됨

  3.조회범위를 시간기준으로 제한하기
    자주 쓰이는 방법중 하나는,시간기준으로 조건을 걸어서 인덱스를 사용하는방식이 있음
	보통 기사조회나,주문내역조회(사용자id,주문일자 로 이루어진 인덱스)등에 주로사용되는 패턴임
	이건 페이지 목록조회나 id목록조회보다 쿼리도 단순해지고 성능문제도 안생김
	
	또 다른 패턴으로는,최신 1개만 조회하는것
	이건 청구서나 공지사항등에 주로 사용됨
	이런식으로 줄일수있다면 담당자와 협의해서 기능을 줄이고 구현을 단순화할수있음

  4.전체 개수 세지 않기
    목록을 페이징해서 표시할떈 갯수를 함께 표시하는경우가 많은데,이러면 카운트함수가 들어가야해서 성능이 나빠짐
	꼭 필요한게 아니라면 이걸 실행하지않는방법을 찾아야함(인덱스를 타더라도 조건에 걸린 모든걸 찾아야하고,인덱스를 안타면 풀스캔)
  
  5.오래된 데이터 삭제 및 분리보관하기
    로그같은 쌓이는 데이터는 일정 시간 이후엔 삭제하거나,아니면 분리해서 외부로 빼내는게 좋음
	이러면 데이터개수도 일정하게 유지할수있어짐
	
	이런거의 대표적인예가 로그인시도내역등임

  6.DB장비 확장하기
    DB에 부하가 증가해 성능문제가 발생한다면,일단 스케일업을 하고나서 생각할수있음
	
	그리고나서 스케일아웃도 고려는 할수있음
	이땐 보통 데이터변경은 주DB로,조회는 복제DB로 실행하는식으로 주로 함
	이때 복제DB간 시간차같은거땜에 문제생길수있으니 주의

  7.별도 캐시서버 구성하기
    트래픽이 급격히 증가하면,DB만으로 모든 트래픽을 처리하기 어려워질수있음
	이땐 캐시서버를 구성하는걸 고려해봐야함
	
*4.알아두면 좋을 몇가지 주의사항  
  1.쿼리 타임아웃
    응답시간은 처리량에 큰 영향을 줌
	동시사용자가 증가할때 응답시간이 길어지면 처리량이 감소하는데,거기서 끝나는게 아님
	사용자는 재시도를 할수있고,이거때문에 응답의 갯수 자체가 뛰어버림
	
	이런 상황을 방지하는 방법중 하나는,쿼리실행시간을 제한하는것
	쿼리실행시간을 5초로 제한하면,이걸 넘어가면 에러가 뜨게되는데,이건 사용자입장에선 에러지만,서버입장에서는 해당요청을 정상적으로 처리한것
	이러면 동시요청수의 폭증을 막을수있음
	
	단 이때,기능의 특성에 따라 시간은 다르게 설정해야함
	글조회같은 중요하지않은건 짧게,상품결제같은 중요한건 길게 잡아야함
	결제가 타임아웃나면 후속처리와 정합성이 꺠질수있기때문
  2.상태변경기능은 복제db에서 조회하지않기
    메인-복제 db를 구성했다고 무조건 모든 조회를 복제에서 하면 안됨
	특히 메인으로 변경쿼리를 날리고 나서,그걸 다시 조회할땐 메인에서 해야지,복제db에서 하면 복제까지 걸리는 시간때문에 제대로 갱신되지않을 확률이 있음
	
	또한 트랜잭션문제가 발생할수있음
	
	즉 변경후 조회는 무조건 메인으로 날리기

  3.배치쿼리 실행시간 증가
    한번에 조회하고 집계하는 데이터가 많아질수록 일괄처리 실행시간도 증가함
	문제는 몇시간이 지나도 쿼리가 끝나지않아(메모리사용량이 특정범위를 넘어가서 가상메모리를 사용하게될때 이럼),24시간을 지나서 쿼리가 2개되는 이런경우도 있음
	
	이런문제를 예방하려면 배치쿼리를 지속적으로 추적하고,갑자기 큰폭으로 실행시간이 증가했다면,문제가 되는쿼리를 발견해서 원인을 찾아 해결할수있음
	이때 근본을 해결하기전에 가장 쉽게 땜빵하는게 스케일업이지만,이게 반드시 가능한건 아님
	그래서 사용되는 다른 방법으로는
	  커버링 인덱스 활용
	  데이터를 일정크기로 나눠서 처리
	집계대상칼럼이 인덱스에 포함되어있다면 커버링인덱스를 해서 메인테이블에 접근하지않고 끝낼수도있음
	
	또한 데이터를 날짜같은 범위로 쪼개서 집계한후,그 집계된 데이터를 모아 다시 집계하는식으로 처리할수도 있음

  4.타입이 다른 칼럼 조인 주의
    타입이 다른 칼럼끼리 조인을 할때,타입이 다르다면 인덱스를 타지 못할수도있음
	그래서 이경우엔 두 칼럼의 타입을 맞춰서 비교해야함
	또한 문자열이라도 칼럼의 캐릭터셋이 다르다면 인덱스못탈수있으니 주의

  5.테이블 변경은 신중하게
    데이터가 많은 테이블에 새칼럼을 추가하거나,기존열거칼럼을 변경할땐 매우 주의해야함
	mysql등은 테이블변경시에 새 테이블을 생성하고,원본테이블데이터를 복사한후,복사가 완료되면 새 테이블로 교체함
	이동안은 업데이트,인서트,델리트가 허용되지않기때문에 복사시간동안 서비스가 멈춤

  6.db최대연결개수
    db의 최대 커넥션 갯수를 넘는 api서버의 증설은 아무의미없음,이경우엔 db의 커넥션 갯수부터 늘리고 서버를 늘려야함
	주의할건 db서버가 cpu사용률이 이미 높다면(70%이상) 연결갯수를 늘리면안됨
	이경우엔 캐시서버나 쿼리튜닝등으로 부하를 낮춘다음 갯수를 늘려야함
	
	
*5.실패와 트랜잭션 고려하기
  비정상상황에서의 트랜잭션 처리는 반드시 고려되어야함
  안그러면 일관성에 문제가 생길수있음
  
  자주 발생하는 실수는,트랜잭션없이 여러 데이터를 수정하는것,실수로 트랜잭션을 빼먹거나 했을때 이럴수있음
  db관련코드를 작성할땐 트랜잭션의 시작과 종료 경계를 명확히 설정했는지 반드시 확인해야함
  
  추가적으로,비중없는 사이드이펙트에 해당되는 기능은(회원가입의 가입축하메일발송),실패하더라도 성공시켜야하는경우도 있음
  이렇게 외부api연동과 db작업이 섞이면 트랜잭션처리가 복잡해짐
  
4.외부연동이 문제일때 살펴봐야 할 것들
  연동하는 서비스에 장애가 발생하면 우리 서비스도 영향을 받음
  서비스간 연동이 많아질수록 연동시스템의 품질도 함께 신경써야함
  물론 문제를 완전히 차단하긴 어렵지만,영향을 줄일수는 있음
*1.타임아웃
  외부연동에서 가장 중요한 설정은 타임아웃임
  사람들은 안되면 재시도를 해서 부하를 더 키우기때문
  그래서 요청이 안될거같으면 빠른시점에 종료를 때려야함
  
  일단 외부api로 가는 부하는 어짜피 거기서 문제가 생겼으니 해결되지않을거고
  문제는 내쪽 서버도 요청이 계속 쌓여서 부하가 늘어나서,해당 기능 말고 다른 기능들도 같이 문제가 생기게됨
  
  그래서 사용자요청에 대해 스레드풀같은 자원이 포화되기전에 타임아웃이라도 응답해서,연동서비스문제가 다른기능에 주는 영향을 줄일수있음
  
  1.연결 타임아웃,읽기 타임아웃
    연결 타임아웃은 연결시도 자체가 오래걸리는경우에 나는 타임아웃임
	즉 상대서버에서 시작도 하지않은거
	
	일단 연결이 되면 요청을 전송하고 응답을 기다리는데,이때 타임아웃은 읽기 타임아웃임
	
	연결 타임아웃은 3~5초로 짧게 잡고,읽기 타임아웃은 5~30초로 길게 잡는게 좋음
	또할 읽기타임아웃의 경우,해당 요청은 이미 처리중이기때문에 타임아웃이 난 이후에 처리를 잘 해야함
	애초에 이런일이 잘 안생기게 길게잡는게 좋고
  
*2.재시도  
  외부연동이 실패했다면 처리방법중 하나는 재시도가 있음
  간헐적으로 실패한다면 이걸 사용할수있음
  1.재시도 가능 조건
    단 이때,연동 api를 다시 호출해도 되는 조건인지를 확인해야함
	재시도가 가능한 조건은
	  단순 조회 기능
	  연결 타임아웃
	  멱등성을 가진 변경기능
	임
	
	단순 조회기능은 재시도를 통해 성공확률을 높일 수 있음
	연결타임아웃도 애초에 요청이 안갔으니 괜찮음
	
	단 읽기타임아웃은 이미 요청이 처리되고있는중이기 때문에 중복처리가 될수있음
	그래서 멱등성을 가진 요청만 읽기타임아웃 재시도를 할수있음

  2.재시도 횟수와 간격
    재시도를 무한정 할수는 없음,재시도횟수만큼 응답시간이 증가하는거기때문
	대부분 1~2회정도가 적장함
	
	또한 간격도 바로 날리는거보단,좀 5초정도 뒤에 날리는게 성공확률이 더 높아짐
	여러차례를 할땐 간격을 점진적으로 늘리기도함

  3.재시도폭풍 안티패턴
    재시도는 연동서비스엔 더 큰 부하를 줄수있음
	요청이 n배로 뛰기때문
	재시도를 검토할떈 연동서비스의 성능상황도 함께 고려해야함
	
*3.동시 요청 제한
   연동서비스가 한번에 처리할수 있는 동시요청수보다 더 많은 요청이 들어온다면,내쪽에서 그걸 차단해서 임계치까지의 요청만 보내는게 나음
   나머지는 에러응답을 때리는거임(503)
   이게 벌크헤드 패턴임
  
*4.서킷 브레이커
  외부api가 정상상태가 아니라면,거기로 요청을 보내지않고 바로 에러를 보내는게 나음
  이러면 부하가 줄어드니까
  즉
    연동서비스가 장애라면 바로 에러 응답
	정상화됐다면 연동 재개
  임
  
  서킷브레이커는 누전차단기처럼 동작함
  과도한 오류가 발생하면 연동을 중지시키고 바로 에러를 응답함
  얘는 닫힘,열림,반열림 3개의 상태를 갖고,
    평소엔 닫힘 상태다가,
    실패갯수가 임계치를 넘기면 열림으로 변경
	열림상태에서 일정 차단시간이 지나면 반열림으로 변경
	반열림에서 일부 요청을 보내보고 문제없으면 답힘으로,문제있다면 열림으로 다시 변경
  이런 순서로 동작함	
  
  이렇게 실패를 빠르게 감지하고 문제가 있는 기능을 실행하지않고 중단시키는걸 빠른실패라고 함

*5.외부 연동과 db연동
  1.외부연동과 트랜잭션 처리
    db연동과 외부연동을 같이 처리해야할땐 어떻게 처리할지 알맞게 판단해야함
	  외부연동에 실패했을때 트랜잭션을 롤백
	  외부연동은 성공했지만 db연동에 실패해 트랜잭션을 롤백
	대표적으로 이런 패턴이 있음
	
	트랜잭션 범위안에서 외부연동에 실패했다면,트랜잭션을 그냥 롤백시킬수있음
	단 이때도 읽기타임아웃으로 실패했다면,이걸 따로 보상트랜잭션처럼 어케 처리를 해야함
	이때
	  일정주기마다 두 시스템의 데이터가 일치하는지 확인하고 보정(수동이든 자동이든)
	  성공확인 api가 지원된다면 성공확인 api를 호출(읽기 타임아웃의 경우)
	  취소 api가 제공된다면 취소 api를 호출
	세가지 방법을 사용할수있음
	
	외부연동은 성공했지만 db연동에 실패했다면,취소api로 외부연동을 이전상태로 되돌려야함
	db연동에 실패했기때문에 성공확인api같은건 의미가없음
	만약 그런게 없거나,취소에 실패할수도 있기때문에,일관성이 중요하다면 일정주기로 데이터가 맞는지 비교하는 프로세스를 갖추는게 좋음

  2.외부연동이 느려질때 db커넥션풀 문제
    외부연동이 느려지면,한 요청이 커넥션풀을 오래 점유하게됨
	이러면 커넥션풀이 바닥나기 쉬워짐
	
	만약 db와 무관하게 외부연동을 처리할수있다면,커넥션을 사용하기 전이나 후에 외부연동을 시도할수있음
	단,이경우 외부연동이 트랜잭션밖에서 이뤄지기때문에 트랜잭션커밋이후 외부연동이 실패할경우 롤백이 불가능해지니까,실패한 외부연동에 대한 후처리를 반드시 고민해야함
	보상트랜잭션이나,기능특성에 따라 후보정을 할수도있음
	  
*6.HTTP 커넥션 풀
   HTTP연결도 db처럼 커넥션풀을 사용하면 연결시간을 줄일수있음
   이때 고려할 설정은
     HTTP 커넥션풀의 크기
	 풀에서 커넥션을 가져올때까지 대기하는 시간
	 커넥션을 유지할 시간
   이렇게 3가지임
   
   풀 크기는 연동할 서비스의 성능에 따라 결정해야함
   연동서비스의 성능을 생각하지않고 무턱대고 늘리면,순간적으로 트래픽이 몰릴때 응답시간이 급격하게 느려질수있음
   그래서 우리서비스까지 느려질수있고
   
   대기시간은 커넥션풀을 바로 확보하지못했을때 대기시간인데,보통 1~5초정도 잡으면됨
   
   커넥션 유지 시간은,연동서비스에 맞춰 적절히 설정해야함(Keep-Alive헤더등으로 지정됨)
   이걸 보고 저거보다 좀 작게 해야함
  
*7.연동 서비스 이중화
  서비스가 대량트래픽을 처리할만큼 성장했다면,연동서비스의 이중화를 고려해야함
  이러면 한곳에 장애가 발생해도,다른서비스를 이용해 계속 진행할수있음
  
  물론 이중화는 개발유지비용이 증가하게됨,그래서 연동서비스를 이중화할지 여부를 결정할땐
    해당기능이 핵심기능인지
	이중화비용이 감당가능한 수준인지
  를 따져봐야함
  
  즉 쇼핑의 결제같은정도여야 할만함
  또한 재정적으로 이중화를 감당할수있어야,즉 장애로 인한 손실보다 이중화에 드는 비용이 더작아야함
  
  
5.비동기 연동,언제 어떻게 써야할까 
  
  
  
  
  
  
  
  