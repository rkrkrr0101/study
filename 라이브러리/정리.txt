2.주피터명령어
	%run으로 외부파이썬프로그램을 실행시킬수있음(.py)
	%timeit로 실행시간체크가능(1000회루프평균)
	%time은 단일실행시간체크
	1.매트랩
		%matplotlib inline:아웃풋에 plt.plot로 바로출력가능
	
3.파이썬명령어	
	속성과 메서드는 getattr(객체,'메서드명')으로 스트링으로 접근할수도잇음
	
	만약 순회가 가능한(for문으로 집어넣어서 뺼수잇는)거면 iter(객체)해서 확인가능
	
	임포트할땐 그냥 같은디렉터리안에있으면 import abc 해서(abc.py파일)사용가능
	
	두참조변수가 같은값가리키는지 확인하려면 a is b하면 tf로 뱉음
	즉,딥카피했을때 ==로 같은게 a is b 하면 false가 나올수있음
	a is None는 변수비어있는지 확인할때 자주씀

	문자열과 튜플은 변경불가능한(상수)객체임
	
	만약 문자열에 역슬래시같은 특수기호 많이들어가면 문자열앞에 r붙여서 (r'\'fds') 그냥 생으로 처리가능
	
	문자열.format은'a{0:s}{1:1f}{2:d}'이건 뒤에 나오는 변수를 저기대입하라는거(순서:형식)
	문자열.format('a',1,1)하면 aa11리턴됨
	즉 문자열파싱해서 저거대입함
	
	날짜와 시간쓸떈 datetime임포트해서 쓰면됨
	그냥 date()time()쓰면 datetime객체로 리턴되고,strftime()하면 스트링으로 리턴되는데 그냥 date로받아서 스트링으로 변환해도됨
	strptime는 스트링을 datetime객체로 변형시켜줌
	timedelta객체를 datetime에 더하거나 빼거나해서 변형시킬수있음
	
	pass는 if문이나 그런 블럭안에 비어있을때 넣어두면 그냥스킵하고지나감(비워두면 블록에러뜸 공백문자땜에)
	
	range는 마지막숫자 바로앞까지(range(8)이면 0~7까지)반복
	
	삼항표현식은 a=트루값 if 조건 else 펠스값
	으로 if문 좀 편하게적게해줌
	
4.자료구조등
	튜플:상수화시킨 리스트
		튜플을 한번확정하면 거기에 추가나 제거불가능
		단 내부개체가 리스트처럼 객체일경우 참조하고있는곳에 추가제거는 가능
		튜플을 곱하면 튜플의 복사본이 반복되어 늘어남
		
		튜플과 같은표현의 변수의 갯수를 맞춰서 =해주면,튜플이 분리되서 변수에 들어감
		ex) a=(1,2,3)
			b,c,d=a
			print(b,c,d)#1 2 3
		중첩된튜플의경우
		ex) a=(1,2,(3,4))
			b,c,(d,e)=a
			print(b,c,d,e)#1 2 3 4	
		
		스왑도 그냥
			a,b=b,a
		하면 스왑됨
		
		for문같은거도(중첩된리스트나 튜플 순회할때)
		저렇게 한덩어리씩 빼서 내부값 사용가능
		ex) a=[(1,2),(3,4),(5,6)]
			for b,c in a:
			...
		
		만약 *변수를해서 꺼내면,뒤에있는값 전부를 받아옴     ☆
		ex) a=(1,2,3,4,5,6,7)
			b,c,*d=a
			print(b,c,d)#1 2 [3,4,5,6,7]	
			
		튜플.count('a') a갯수세기
	리스트:크기내용변경이 가능한 참조객체
		append로 맨뒤에추가,insert(위치,내용)으로 원하는위치에 추가(값은 인서트가 더 비싸니까 어지간하면 어펜드(순서안중요하면))맨앞에추가하려면 deque쓰자
		remove로 맨앞삭제 pop(위치)로 원하는위치삭제
		
		in으로 리스트에 어떤값 있는지 확인가능 (TF로 리턴)
		리스트.extend()로 여러값 추가가능(기존리스트에 추가)
		리스트를 +로 이어붙이면 새 리스트를 생성하고 값을복사하니까,코스트생각해야되면 extend로 기존값 추가하는게 더 쌈
	
	사전(dict):키 밸류로 이루어진 해시객체
		리스트처럼 값에 접근하거나 값을 넣을수있고,추가할수있음
		밸류는 기본적으로 하나지만,리스트같은 참조객체가 들어간경우 그안엔 여러개가 들어갈수있음
		삭제는 del이나 pop메서드로 함
		update로 사전을 합칠수있음(만약 같은키가 있으면 이거로 덮어씌워짐)
		그냥 인서트는 사전[키]=밸류 하면 추가됨
		
		사전.keys와 사전.values는 키이터레이터와 밸류이터레이터를 반환하니까,리스트캐스팅해서 보면됨
		정렬은 안되어있긴한데,keys와 values의 순서는 같음
		
		리스트2개를 사전으로 합치려면 for문돌려도되지만,a=dict(키배열,값배열)하면 사전나옴
		
		안에서 값 뽑을때는 get하면 안의값이 안사라지고 리턴되고(a.get(키))pop하면 안의값이 사라지고 리턴됨(a.pop(키))
		
		만약 키가 없으면 get은 none리턴,pop는 예외발생시킴
		
		내장 collections모듈에 defaultdict(int,list등 자료형)을쓰면 쉽게만들수있음
			a=defaultdict(list) #이러면 기본값이 리스트인 사전생성
			for word in 다른리스트:
				a[word[0]].append(word)#워드맨앞걸 키로 그거 추가
	
		사전의 값은 뭐든되는데,키는 바뀔수없는값(해시가능한값)이어야함(정수,실수,문자열,튜플(내부도 리스트같은거있으면안됨))즉 리스트안됨
	
	집합(set):
	집합은 원소만담은 정렬되지않은 자료형
	생성은 {}쓰거나 set()하면됨
	집합은 합집합,교집합,차집합등을 지원함
	집합|집합은 합집합
	집합&집합은 교집합
	집합-집합은 차집합
	집합^집합은 대칭차집합(합집합-교집합)
	add pop 지원하고 clear은 전체삭제 remove(x)는 x제거
	
	집합원소들도 사전처럼 내부에서 변경이 일어나면안됨(리스트 사용불가)참조객체필요하면 튜플로 전환해서넣어야함
	
	어떤집합이 부분집합인지 확대집합인지 알고싶으면
	a.issubset()
	a.issuperset()
	하면 tf로 나옴
	
	리스트 표기법:
	리스트를 반복문돌려서 새리스트를 만드는거
	a=[b(넣을값,함수적용가능) for b in 리스트 if 조건  ]
	ex) a=[b+1 for b in range(5) if b<3]
	리스트에서 인덱스,벨류로(enumerate써서)사전만들기같은거도 가능
	ex)a=[b:c for b,c in enumerate(리스트)]
	
	2중첩이상 리스트쓸땐 for문 두번쓰면됨
	a=[b for c in list for b in c if 조건]
	
		
	정렬:객체.sort() 객체.sorted()하면 정렬된게 리턴됨
	
	이진탐색:import bisect
		bisect는 정렬된 리스트에만 써야함(이진탐색이니),정렬체크는 안하고 이진탐색하니까(오류없이돌아가니까 정렬안해도) 정렬된거에만 쓰자
		bisect.bisect(객체,추가할값)으로 추가가능
		
	
	슬라이싱:리스트나 그런거[1:3]이런식으로 자르는것
		슬라이싱은 start에서 시작해 end-1까지 동작함
		[1:3]하면 리턴은 1과 2 2개 [2:3]하면 2 1개(0,1,2,3,4일때)
		슬라이싱된거에 리스트를 대입하는거도 가능함
		생략하면 맨앞,혹은 맨뒤[3:]이면 3번부터끝까지 [:3]이면 맨앞부터2번까지
		음수색인은 뒤에서부터 시작함
		[-1:]이면 맨뒤하나
		[-5:-2]면 맨뒤부터 5번째부터 맨뒤부터 2번째까지(역순은 0부터시작안하니까 그대로 2번째까지임)
		
		두번째콜론뒤에 숫자는 간격
		[::2]이면 하나걸러 하나씩 고르라는소리
		ex) a=[1,2,3,4,5,6,7,8]
			b=a[::2]
			print(b)#[1,3,5,7]
			
		기본리스트에선 2차원배열이상의 슬라이싱을 지원하지않고,넘파이를 써야함
		
	
	내장순차자료형함수
		enumerate:순차자료형에서 현재아이템의 인덱스를 같이뱉는함수
		for문에서 
			for value,index in enumerate(객체):
		하면 값과 인덱스를 같이뱉음
		
		zip:여러리스트를 하나로 합치거나(a=zip(b,c)),
		한리스트의 컬럼로우를 바꿀수있음(a,b=zip(*리스트) [[1,2],[3,4],[5,6]]을 [1,3,5][2,4,6]으로)
		
		reversed:reversed(a)하면 리스트 역순으로 생성해서 리턴함
		
	
	함수
		함수에선 리턴값이 몇개가되든 상관없음
		return a,b,c 된다는말
		
		기본적으로 함수내에선 지역스코프를 보지만,global로 전역으로 선언된변수는 참조가능
		함수내에서도 전역으로 선언하면 외부에서도 참조가능(정확히는 함수가 끝나고 사라지지않음)
	
		함수도 파이썬에선 객체취급이니까,리스트에 담아서 사용할수있음 
			fun=[함수1,함수2,함수3]
			for function in fun:
				v=fun()
		이런식으로사용가능
		
		람다:짧게 함수를 만드는거
			(lambda x:x*2 )이런식으로 씀,저거 하나가 함수객체하나(x를 받아서 x*2를 리턴)
			그냥 어렵게생각하지말고 함수 짧게만들고,맨앞에있는거만 받아서 연산후 바로리턴한다생각하자
		
		커링:람다를 써서 기존함수에서 특정패러미터를 상수로 바꾸는거
				add_five=lambda a:add_number(5,a)
			이렇게 특정값을 고정으로 바꿀수있음
		
			functool의 partial을쓰면 더쉽게할수잇대
		
		제너레이터:
			이터레이터를 나태하게 만드는 방식
			콜이 들어와야 다음으로 넘어감
			제너레이터를 생성하려면 return대신 yield씀
			
			더쉽게 만드려면 리스트표현식에서 괄호를쓰면 제너레이터가 생성됨(리스트표현식)
			제너레이터는 리스트를 받는 모든곳에서 사용가능
			
			
			itertools에 다양한 제너레이터함수들이 있음
			
			combinations(반복가능객체,길이) 객체에서 순서를 고려하지않고 길이가 k인 모든조합생성
			permutations(반복가능객체,길이) 객체에서 순서를 고려해서 길이가 k인 모든조합생성
			groupby(반복가능객체,[,키함수]) 객체에서 키에따라 그륩생성
			product(반복가능객체,repeat) 객체에서 카테시안곱(두개를 모두 곱함,sql조인에서 조건없을때 나오는거)을 리턴 
	
	
		예외처리:
			try except finally로 처리
			
	
	
	
	파일처리
		f=open(패스(상대경로나 절대경로))로 열어서
		f.close()로 닫아줘야함
		open(패스,'w')하면 쓰기모드
		
		이미지열거면 import Image로 열면됨
	
	
5.numpy
	넘파이배열에서 스칼라값(정수 실수등 값하나)를 연산하면,배열전체에 같은연산을 하고
	배열끼리 곱하거나 더하거나 하면 같은위치의 원소끼리 연산함
	그두개의 크기(shape)는 같아야함
	
	배열생성은 np.array()에 리스트같은거 넣거나,np.zeros,np.ones,np.full(인자로 채울거받아서 그거로채움)등으로 생성
	
	배열.dtype로 타입볼수있음
	넘파이 타입은 알아서 추론하는데,타입이 하위레벨에 맞춰져있어서 c같은거랑 연동쉽고 하드에서 받아올때도 코스트가낮음
	
	배열.astype(np.int32)이런식으로 배열전체의 형변환 가능,실수를 정수로바꾸면 소수점 다 버려짐
	숫자문자열('1.0')을 숫자로 바꿀수도있음
	
	만약 변환실패하면 valueerror예외발생함
	
	
	벡터화
		넘파이배열은 for문을 쓰지않고 데이터를 일괄처리할수있음
		이렇게쓰면 연산도 엄청빠름
		
		배열에 스칼라값하면 전체에 연산,배열끼리연산하면 그위치에 연산,같은크기배열끼리 비교하면 불리언배열 반환
		
		
	슬라이싱
		넘파이는 2차원이상의슬라이싱[:,:]이 가능
		그리고 넘파이에서 슬라이싱한건 뷰이기때문에,슬라이싱한걸 수정하면 그게 원본에도 동일하게 적용됨(데이터가 복사되지않음)
		데이터를 복사하고싶으면 arr[5:8].copy()해야함
		
		
	불리언값 선택
		배열의 인덱스[]에 불리언배열을 넣으면,그거에 해당하는거만 리턴해줌
		배열에 다른배열비교식 value[name>0] 넣으면 불리언배열로 T인거만 리턴함
		단 이러면,배열크기가 서로 달라도 에러안뜨니 주의해야함
		
		그리고 2차원이상에서 value[name>0,:2]이런식으로 선택된거 슬라이스하는거도 가능
		
		만약 이차원배열에서 value[value<3]이런식으로 넣으면,만족하는값 전부 일차원배열로 바꿔서 나옴
			123
			456  -> d[d>3] ->  array([4, 5, 6, 7, 8, 9])
			789
		
		그리고 and와 or예약어는 못쓰고,&과|써야함
		
		
	팬시색인
		팬시색인은 배열에서 여러줄을 선택할때 쓰는방법
		arr[3,4,2,8]
		하면 3번4번2번8번순으로 배열이 나옴
		
		그리고 2차원이상을 팬시색인쓰려면
		arr[[1,3,2,4],[2,1,3,4]]이렇게하면 (1,3),(3,1),(2,3),(4,4)원소가 나오고,
		슬라이싱하려면
		arr[[1,3,2,4]]][:,[2,1,3,4]]
		이런식으로 슬라이싱해야함
		
		팬시색인은 슬라이싱과 다르게 뷰가아니라 복사함
		
		
	배열전치
		배열의 모양을 바꿈
		arr.reshape()는 배열요소 전체를 1차원으로 푼다음에 그걸 다시 묶는느낌으로 동작함
		arr.T()는 배열의 가로세로를 돌림
			123	   147
			456 -> 258
			789	   369
		배열곱연산칠때 사용됨(np.dot())
		
		다차원배열은 arr.transpose()로 돌릴수있음
		배열의 축번호를 앞에서부터 순서대로 넣으면 됨(3차원일떄 (0,1,2)가 원본 ->(2,1,0))
		
	
	유니버셜함수
		유니버셜함수는 배열안에있는 원소별로 연산하는함수
		배열내 최대값,배열제곱근씌우기등
		
		유니버셜함수중 인자가 두개면(배열2개를가져가면)이항 유니버셜함수,하나면 단항유니버셜함수
		
		np.sqrt()같은게 대표적 단항유니버셜함수
		np.maximum(배열두개비교해서 둘중 큰원소 리턴,크기다르면 있는거리턴)이 대표적 이항유니버셜함수
		
		대표적으로 쓸만한게 
		np.maximum
		np.mininum
		np.mod(나머지)
		np.copysign(첫배열원소의 기호를 두번째배열원소의 기호로 바꿈)
		
	배열지향 프로그래밍
		순수파이썬쓰는거보다 배열연산으로 하는게(벡터화) 훨씬빠름
		
		배열연산으로 조건문쓰고싶으면 np.wrere쓰면됨
		np.wrere(tf배열,통과시,실패시)
		
		
		mean이나 sum엔 축을받아서 그축에대한 통계를 적을수있음
			123
			456  ->a.sum(1)= [6,15,24] a.sum(0)=[12,15,18]
			789
		
		cumsum은 0,0부터 끝까지의 누적합
			1 3 6
			101521
			283645
		cumprod는 끝까지 누적곱
		
		그리고 배열로 불리언배열로 만든상태(arr>0)에서 sum같은 메서드를 쓸수있음
			(arr>0).sum()
		any는 t가 하나이상있으면 트루 all은 전부트루면 트루
		any,all은 불리언배열이 아니라도 동작하는데,0이면 flase 0이아니면 true
		
		정렬은 arr.sort()로 할수있음
		arr.sort(axis= )axis로 축으로 정렬할수있음
		2차원에서 0넣으면 세로축끼리 비교해서 정렬함
			
	
		np.unique(배열)하면 배열내 있는 값 하나씩 정렬해서 리턴함 
		np.in1d(x,y)하면 x의 원소가 y에 포함되어있는지 불리언배열을 리턴함 
		
		
	배열 파일입출력
		np.save와 np.load로 배열데이터를 디스크에 저장하고 불러올수있음
		배열은 압축되지않은 바이너리형식으로 저장됨
		
		
	선형대수
		행렬곱하려면 x.dot(y)이런식으로 할수있음
	
	난수생성
		난수는 np.random으로 만들수있음
		np.random.normal((4,4))는 4,4크기의 표준정규분포 배열을생성 
		만약 시드를 바꾸고싶으면 np.random.seed()로 바꿀수있음
		
		기본적으로 모든난수는 동일시드값을 사용하는데,지역시드값으로 만들고싶으면
		numpy.random.RandomState(시드)로 격리된 난수 생성기를 만들수잇음
	
	
	
	
6.pandas
1.기본자료구조
	1.series
		판다스의 딕셔너리구조
		색인이있고 값이 있음
		
		색인으로 검색할때['a'] 여러개를 묶어도되고['a','b','c'] 
		슬라이스도 됨['a':'c']이땐 a부터 c까지 전부 출력됨
		불리언값도 됨arr[arr>0]
		
		색인의 순서를 바꾸고싶으면,원하는순서대로 pd.series(데이터, index=[,,])에 넣으면됨
		만약 데이터에 색인이 있으면,인덱스 순서대로 들어가고,인덱스에 없는값은 제거됨,인덱스엔있는데 데이터엔 없으면 nan됨
		
		널값 찾으려면 isnull이나 notnull으로 찾으면됨(pd.isnull(시리즈))
		
		색인은 대입하여 변경할수있음 arr.index=['q','w','e','r']
		0 a      q a
		1 b   -> w b
		2 c      e c
		3 d      r d
		
		시리즈는 name속성이 있는데 대입해서 바꿀수있음
		
	2.dataframe
		시리즈를 여러개 묶어둔,db같은느낌임
		로우와 컬럼이 있는 2차원배열
		
		생성할때 명시적으로 인덱스를 안주면,앞에서부터 묶어서 한로우씩으로 처리함
		dataframe.head()는 앞에서부터 5개만 출력하는거
		
		원하는 순서대로 컬럼 지정하면,컬럼순서를 바꿀수있음(pd.dataframe(data,columns=['a','c','b']))
		데이터에 없는값을 지정하면 nan으로 저장됨
		
		데이터를 받을땐,['year']이렇게 컬럼을 받을수도있고(인덱스랑 컬럼으로 나옴 ),frame.year 이렇게 받을수도있음
		이렇게 받으면 시리즈객체로 리턴되게되고,네임에 컬럼명이 적힘
		로우를 받고싶으면,frame.loc(인덱스명)으로 받을수있음
		
		컬럼은 대입이 가능함,대입하면 그줄 전체가 같은값이되고,이터레이터값을 주면 위부터 순서대로 들어감
		대입을할때는 대입하려는 길이가 데이터프레임의 길이와 같아야함
		시리즈를 대입하면 데이터프레임의 색인에따라 값이 대입되고(서로같은색인에 대입),존재하지않는 색인은 nan이 대입됨
		존재하지않는 컬럼을 대입하면 컬럼을 추가함,삭제는 del로 삭제
		당연하지만 컬럼에 값넣을떈 불리언값도(frame.state=='abcd')가능함,이러면 그줄의 스테이트값을 보고 tf결정함
		
		중첩된 사전으로 데이터프레임을 만들땐,밖에있는키가 컬럼이되고,안에있는키가 인덱스가 되는데,frame.T로 바꿀수있음
		묵시적으로 두면 안쪽에있는값에서 같은색인끼리 묶지만,명시적으로 색인주면 없는거무시하고 빈거 nan넣음
		
		만약 name속성을 지정하면(컬럼인덱스 모두)표시할때 그거도 같이표시됨
		
		frame.value하면 2차원배열로 저장된데이터 전부 리턴함
		만약 컬럼이 서로 다른데이터타입을 가지고있으면,배열로 리턴함
	
	3.색인객체
		색인객체는 시리즈나 데이터프레임에서,인덱스이름과 컬럼이름,name등 메타데이터를 모아둔객체임
		얘는 직접 변경이 불가능함(대입같은거안됨)
		
		그리고 판다스의 인덱스는,중복되는값이 허용됨
		중복되는값으로 선택을하면 해당값의 모든항목이 선택됨


2.핵심기능
	1.재색인
		재색인을 하면 새로운 색인배열에 맞게 객체를 새로 생성함
			frame2=frame.reindex([색인배열])
		여기서 프레임에 있는색인에 따른 값을 색인배열의 순서대로 재배열하고,존재하지않는 색인값이 있으면 nan을넣음
		
		만약 nan을 특정값으로 채우고싶으면 매개변수 method=''에 값을넣으면됨 ffill넣으면 이전값으로 채우기 bfill은 다음값으로채우기 등
		재색인 함수 인자는 여러개있으니 찾아보자(200P)
		
		reindex는 인덱스와 컬럼 둘다 변경이 가능함
		그냥 매개변수 명시하지않고 넣으면 인덱스를 재색인함
		
	2.하나의 로우나 컬럼 삭제
		로우는 frame.drop('a')로 삭제가능 여러개는 frame.drop(['a','b'])
		컬럼삭제는 frame.drop('컬럼명',axis=1)주면됨
		drop나 이런 크기나 형태변경하는 함수는,새로운 객체를 반환하는게 아닌,기존원본객체를 변경함
		
		만약 inplace옵션을 true로 주면 버려지는값을 모두 삭제함(즉각적으로 반영됨)
		
	3.색인선택
		색인선택은 조건줄수도있고,색인명선택,색인위치선택,슬라이스 다됨
		데이터프레임에서 컬럼으로 슬라이스해서 가져올수도있음
		
		색인과 컬럼을 둘다선택할수도있는데 frame.loc나 frame.iloc쓰면됨
		loc는 스트링으로 선택 iloc는 정수로 선택
			frame.loc[로우,[컬럼]]
			frame.iloc[1,[3,0,1]]
		당연히 슬라이스도 되고 단일라벨등 다됨
	
	4.정수색인
		판다스에서 색인검색할때,숫자로찾으면 라벨검색하고 그다음 정수검색하니까 버그생길수있으니까,loc나 iloc쓰자
		
	5.산술연산과 정렬
		두 시리즈나 데이터프레임끼리 연산을(+같은)하면
		두개 공통으로 가지고있는 색인에 대해서 연산을하고,한쪽이 없는건 nan으로 추가됨 
		sql에서 조건없이 join한느낌
		즉,공통되는게 아무것도없는 두 프레임을 더하면 전부 nan이됨
		
		만약 nan값을 특정값으로 채워넣고싶으면
		frame1.add(frame2,fill_value=0) 저렇게 fill_value를 넣어주면됨
		재색인할때도 fill_value를 넣을수있음
		add sub mul div floordiv 등이 있음 기본사칙연산+mod
		
		데이터프레임과 시리즈끼리 연산을 하면 로우나 컬럼중 한군데씩 잡고 쭉 밀어버림
		축선택은 프레임.sub(시리즈,axis=축선택)저렇게하면됨
		
	6.함수적용과 매핑
		판다스에도 넘파이의 유니버셜함수를 적용할수있음
			np.abs(frame) 이런식
		
		그리고 각 컬럼과 로우의 1차원배열에 함수를 적용할수도 있음
		dataframe의 apply쓰면됨
			frame.apply(적용람다함수,axis=적용축)
		
		여기서 리턴값은 스칼라값이 아니라 시리즈를 반환해도됨(배열리턴해도 된다는소리)
		
		그리고 각 원소마다 적용하고싶으면(부호바꾼다던지) 
			frame.applymap(람다함수)쓰면됨
		
	7.정렬과 순위
		정렬은 sort_index쓰면됨
			frame.sort_index(axis=정렬축,ascending=False 내림차순 오름차순 기본값 오름차순)
		하면 숫자,알파벳으로 정렬됨
		
		만약 시리즈객체를 밸류에따라 정렬하고싶으면
			sort_value()쓰면됨
		데이터프레임에서 밸류정렬하고싶으면 by=컬럼이름 주면됨
		
		기본적으로 nan은 맨 마지막에 위치함
		
		순위는 처음부터 끝까지의 순위를 리턴해줌
		처음부터 끝까지중 숫자 가장 작은거부터 큰거까지 순위매기는거(그인덱스값에 순위매겨서 리턴)
		동점일때 기본적으론 평균값인데 나타나는순서에 따라 매기려면 매개변수 method='first'하면됨

		
	8.중복색인	
		중복색인값인지 체크하려면 frame.index.is_unique()하면 중복이 있는지아닌지 리턴해줌
		그리고 중복값이 아닌걸 데이터에 접근하면 스칼라값리턴하지만,중복인걸 접근하면 시리즈객체 리턴함
		
		
		
3.통계와 요약
	판다스는 기본적으로 통계메서드가 있음
	프레임.sum하면 각 컬럼에 합을담은 시리즈를 반환하고
	axis=1주면 각 로우의 합을 반환함
	
	기본적으로 nan값은 무시되고,skipna로 무시하지 않을수있음
	
	idxmin이나 idxmax같은 메서드는,최솟값,혹은 최대값을 가지고있는 인덱스를 리턴함
	
	그외엔 cumsum(순서대로더하기)등이 있음
	
	그거말곤 describe()가 있는데,이건 여러 통계결과를 리턴함
	수치데이터일경우 카운트 평균 맥스 민 25% 50% 등등
	수치데이터가 아니면 카운트 유니크 탑 freq 등
	
	여러개있으니까 찾아보자
	
	
	pandas_datareader로 웹데이터 받아올수있음
	
	corr로 각 컬럼별 상관관계를 계산할수있고,cov로 공분산을 계산할수있음
	
	unique메서드는 중복값을 제거하고 유일값만 담은 시리즈를 반환함
	이건 정렬안되어있지만 알아서 나중에정렬하면됨
	pd.value_counts()는 그 값이 몇개있는지 내림차순으로 정렬함
	
	frame.isin([배열])은배열안의값이 프레임에 있는지없는지에 따라 불리언배열을 리턴함 
	
	
	
7.데이터입출력,파일형식
1.기본데이터입출력
	1.데이터읽기
		read_csv(파일경로나 url등) csv파일을 들고올때(쉼표로 구분된 택스트파일이면 다 됨) csv를 데이터프레임으로 받아올수있음
		read_table(파일경로)파일을 들고옴(구분자 탭) 리드테이블에 구분자 쉼표로바꾸면 리드csv임
		read_sql(sql경로,sql쿼리) 쿼리결과를 들고옴
		
		데이터 받아올떄, 옵션으로
		매개변수를 줘서 인덱스와 컬럼을 지정할수도있고,한줄무시할수도있음 기본값은 그냥알아서 추론함
		자료형 추론과 데이터를 변환(0이하인거 0으로한다던지)할수있음
		여러 컬럼에 걸쳐있는 날짜와 시간정보를 하나의컬럼에 조합해서 줄수있음
		여러파일에 걸쳐있는자료를 반복적으로 읽어올수있음
		정제되지않은 데이터를 처리할수있음(공백이나 쉼표나 주석제거같은)
		
		기본적으로 텍스트파일에는 자료형이 없으므로,타입추론을 해서 넣음
		읽어올때 names=[컬럼명]을 주면 그 컬럼명으로 들어가고,넘어가면 nan으로 됨
		인덱스를 주고싶으면 index_col=[인덱스컬럼]을 주면됨
		계층적인덱스(다른거로 바뀔떄까지 공백)을 주고싶으면 index_col=[키1,키2]주면됨 그럼 키1값이 끝나고 바뀌고 키2값도 바뀌었을때 바꿔줌
		
		누락된값을 특정값으로 바꾸고싶으면 na_values=[바꿀값]넣어주면됨
		딕셔너리로 컬럼을 키로 바꿀값 적어주면 컬럼별로 다르게 매칭할수도있음
		
		맨위를 컬럼으로 쓸지(header)몇번째부터읽을지(skiprows) 특정함수적용(converters(컬럼명:함수))앞에서부터 몇줄만 읽기(nrows)등 인자 많음
		
		큰파일할때 테스트하려고 읽을때 몇줄만 출력되게 하고싶으면,pd.options.display.max_rows=10 하면 10줄만 출력됨
		
		진짜 읽는거도 몇줄만 하고싶으면 nrows쓰면되고
		파일을 여러조각으로 나눠서읽고싶으면 chunksize=나눌조각수 주면됨
		
		리턴된값이 이터레이터를 가지고있으니까,그거잡고 for문돌리면됨 
		
	2.데이터 저장
		텍스트로 데이터프레임 저장하려면(csv같은거)
		data.to_csv(경로)주면 저장됨
		구분자 바꾸려면 sep='구분자' 주면됨
		
		기본값으론 인덱스와 컬럼이 적히는데 적기싫으면 index=False,header=False주면됨
		컬럼의 일부만 주고싶으면 columns=[줄컴럼들1,줄컬럼2]이렇게 주면되고
		여기서 순서바꾸면 순서바뀌어서 적힘
		
		시리즈도 to_csv가 있음
		
		
	3.구분자형식
		기본적으로 read_table로 거의모든 파일을 불러올수있지만 중간에 구분자가 섞여있다던가 그래서 이상하게받아지는경우도 있음
		그러면 파일을 줄단위로 쪼개서 (for문으로)리스트에 넣고 이상한거 찾아서 바꾸고 한다던가 하면됨
		필요해지면 보자
		
	4.json
		json으로 받으려면
			import json
			res=json.loads(json파일이나 경로)
		
		하면 딕셔너리형태로 리턴됨
		이걸뭐 원하는거몇개 잘라서 데이터프레임에 넣든가하면됨
		pandas.read_json으로 그냥 바로 자동으로 바꿀수도있음
		그러면 json에 담긴 각 객체를 위치에따라 로우로 간주함
		
		
	
	5.xml과 웹스크래핑
		판다스에는 read_html이 있는데 lxml같은걸 써서 html을 자동으로 파싱해줌
		그러니까 미리 lxml이나 뷰티풀수프같은게 필요함(파싱라이브러리)
		
		그리고 만약 중첩된 데이터구조일경우(내부에 같은거 반복된다던지)
		그럴떈 lxml.objectify.parse()쓰면됨
		그리고 거기서 스킵할 필드선택하고 for문돌려서 딕셔너리에 넣으면됨
	
2.이진데이터형식
	이진데이터를 저장하는 제일 간단한방법은 파이썬내장된 pickle를 쓰는 to_pickle임
	근데 pickle는 패치하면 못읽게될수도있으니까(단기간은괜찮음 한10년봣을때)
	
	다른거도있음
	
	1.hdf5
		hdf5는 사전처럼 작동함
		pd.read_hdf('파일경로')로 읽을수있고 
		객체.table로 저장할수있음
		
		만약 대용량저장이나 읽기필요해지면 보자
		
	
	2.엑셀읽기
		엑셀은 pd.read_excel로 읽을수있는데 이거쓰려면 xlrd랑 openpyxl패키지를 설치해야함
	
3.웹api랑 같이쓰기
	웹으로 뭐한거 가져다쓰려면 기본패키지인 requests쓰는게 편함
		import requests
		
		resp=requests.get(url)
		
		data=resp.json()
	한뒤에 json파일 파싱하면됨(read_json)
	
4.데이터베이스와 같이쓰기
	기본적으로 sqlalchemy로 커넥트하고 거기로 쿼리보내서 결과값을 리턴받는형태로 쓰면됨 read_sql로
	
	
	
	
	
	
	
7.데이터 정제및 준비
1.누락된데이터 처리
	na를 처리하는 방법은
	dropna()로 로우나 컬럼을 날려버리기
	fillna로 누락된데이터를 채우기(전값이나 후값,0같은 정해진값으로)
	isnull로 수동처리
	등이 있음
	
	dropna에서 
	how='all'을 주면 전부 na인것만 제거,
	axis=1주면 컬럼제거,
	몇개이상의 값이 들어있는거만 남기려면 thresh=갯수
	
	fillna에서
		fillna({컬럼:값,컬럼:값}])
	으로 컬럼마다 다른값 채울수있음
	inplace=true주면 원래객체가 바뀜
	method='ffill' 하면 전값으로 채우기
	method='ffill',limit=2하면 전값으로 채우는데 리미트2개까지만 채움
	채울값은 리턴값이 숫자만 나오면되니까 data.mean()같은거 줘도됨
	
2.데이터 변형
	1.중복제거
		중복을 확인하는(모든컬럼의 값이 같은 로우)메서드는 duplicates()(시리즈는 duplicated)
		얘는 중복인지 아닌지 tf배열을 반환
		특정컬럼 혹은 특정컬럼들을 정하고 그거만 중복확인하려면 duplicates(['컬럼1','컬럼2'])
		기본적으론 처음발견된값을 유지하는데,마지막발견을 유지하고싶으면 keep='last'
		
	2.함수나 매핑을 이용한 데이터변형
		현재있는 값가지고 매칭해서 컬럼추가하고싶으면
		data[새필드]=새데이터.map(사전)
		하면됨
		새데이터에 있는값을 사전값이랑 매칭해서 키값을 데이터의 새필드에 적음
		
	3.값치환
		fillna가 na를 치환하는거였다면,replace는 일반적인 특정값을 특정값으로 치환하는 메서드
			data.replace(바꿀값,치환한값)
		으로 바꿀수있음
		여러개를 치환하려면 배열로 주면됨
			data.replace([바꿀배열1,바꿀배열2],치환값)
			혹은 
			data.replace([바꿀배열1,바꿀배열2],[치환값1,치환값2])
		리스트대신 사전으로 키를 밸류로 바꾸는거도 가능
		
	4.축 색인 이름바꾸기
		컬럼이나 인덱스같은 축도 map으로 바꿀수있음
		data.index=바꾼값
		ex) data.index= data.index.map(lambda x: x[:4].upper)
		이건 원래객체 바꾸는거고 새객체 생성하려면 rename메서드 사용
			data.rename(index=새인덱스,columns=새컬럼)
		사전을 주면 특정값만 바꾸는거도 가능
		
	5.개별화와 양자화
		데이터를 그륩별로 나누려면 pd.cut()을 사용하면됨
		나눠야할 값을 정해주고싶으면 pd.cut(나눌데이터,나눌값배열[18,25,36,45,60])
		나눈값에 이름붙이려면 label=이름배열
		그냥 갯수주고 적당히 알아서 나눠달라고할려면 그냥 pd.cut(나눌데이터,나눌갯수(4))
		저러면 알아서 같은길이의 4개로 나눔(데이터갯수는 다르고,차지하고있는 비율로 나눔)
		
		근데 정규분포식으로 분산까지해서 같은 데이터갯수를 보장하게 나누고싶으면
			pd.qcut(데이터,나눌갯수)
		하면됨
	
	6.특이값찾고 제외하기
		data.[조건식].any(1) 하면 조건식을 만족하는 값을 가진 로우를 선택함(모든컬럼에서)
		그 찾은거 값을 바꾸려면  
			data.[조건식]=바꿀값
		하면됨
	
	7.치환과 임의샘플링
		임의적으로 로우를 섞고싶으면
			data.take( np.random.permutations(배열크기))
		하면 섞을수있음
		만약 치환없이 임의값을 선택하고싶으면(어디 샘플로 테스트한다던지)
			data.sample(n=갯수)
		하면 랜덤으로 n개만큼 리턴함
		만약 반복선택을 허용해서 표본을 치환으로 생성하려면 replace=true하면됨(5개짜리배열에서 15개 랜덤으로뽑는다던가 중복을 허용해서)
		
	8.표시자 더미변수계산
		만약 희소행렬을 만들려면 
			pd.get_dummies(data['키값'])
		하면 키속의 밸류로 희소행렬을 만듬
		만약 안의컬럼에 접두어를 추가하고,다른데이터와 합치고싶으면 prefix='접두어'를 추가하고,
			완료데이터=data[[추가데이터]].join(희소행렬)
		하면됨
		
		만약 여러카테고리에 속하면,그걸 for문으로 분리한다음에다시추가해야함
	
	
3.문자열 다루기
	문자열을 나눌땐 
		문자열.spilt('나눌문자')
	로 나눌수있고
	나눠진배열을 중간에 값두고 합치고싶을땐
		','.join(배열)
	문자열에서 특정문자나 부분문자열의 위치를 찾고싶으면
		문자열.find('찾을값')
	문자열에서 특정문자나 부분문자열의 갯수셀땐
		문자열.count('찾을값')
	문자열에서 특정문자나 부분문자열 치환하거나 삭제할땐
		문자열.replace('찾을값','바꿀값')
		
	이거말고도 많음 로워나 어퍼나 endswith(끝이 이거로끝나면 true) startswith(시작이 이거로시작하면 true)
	1.정규표현식
		정규표현식 쓰고싶으면 
			import re
		한후에 
			re.spilt()로 나누거나
			re.findall()로 패턴찾거나
			re.match()로 시작부분매칭찾거나 
			re.search()로 첫매칭찾거나
			re.sub()로 치환하거나
		할수있음
	
	2.벡터화된 문자열함수
		문자열과 정규표현식메서드는 data.map을 써서 각 값에 적용할수있지만,na를 만나면 실패함
		그거 대처하려면 정규표현식은 flags=re.IGNORECASE 하면되고
		문자열은 시리즈의 str에 있는 메서드쓰면됨
		ex)data.str.contains('a')
		str에 match()나str.get()같은거 다있음
		문자열 자를땐 data.str[:3]
		어지간한거 다있으니까 찾아보자 필요해지면
		
	
	
8.데이터 준비:조인병합변형
1.계층적색인
	판다스는 2중이상으로 인덱스를 걸수있음(생물학적 분류같은느낌)
	그러면 부분적 인덱스로 접근이 가능해짐(척삭동물문-포유강-영장목) 여기서 포유강을 선택할수도있고 영장목을 선택할수도있음
	data[포유강:양서강]같이 슬라이스할수도있음
	
	데이터프레임의 컬럼을 인덱스로 옮겨서 계층적색인이 된 시리즈로 만들수도있고(stack)
	계층적색인인 시리즈를 풀어서 데이터프레임으로 만들수도있음(unstack)
	
	계층적색인은 인덱스와 컬럼 둘다 가능함
	
	1.계층순서바꾸고 정렬하기
		계층에서 계층순서 바꾸려면 
			data.swaplevel('바꿀키값1','바꿀키값2')
		로 바꿀수있음
		당연히 데이터는 변하지않음
		계층을 정렬하려면 
			data.sort_index(level=정렬할계층)
		하면 순서대로정렬됨
		
		계층이 정렬되어있으면,탐색성능이 좋아짐
		
	2.계층별 요약통계
		계층별요약값을 보려면
			data.sum(level=계층단계)
		저렇게 통계보는메서드에 level을 주면 거기만 더해서 리턴해줌(단계대신 인덱스나 컬럼이름을 줘도됨)
		
	3.데이터프레임의 컬럼 사용
		데이터프레임에서 프라이머리키로 두개이상의 컬럼을 사용하는데,그걸 색인으로 잡고싶으면
			data.set_index(['컬럼1','컬럼2'])
		하면 컬럼이 색인으로 변하고,그걸잡고 조인하거나 서치할수있음
		기본적으론 컬럼이 삭제되고 색인으로가지만,drop=False를 주면 그대로남아있고 복사해서 색인으로감
		
		만약 계층적색인을 컬럼으로 되돌리거나 올리고싶으면
			data.reset_index()
		하면됨
			
2.데이터 합치기	
	데이터를 합칠땐 
	pd.merge()로 키기준으로 합칠수있고(join같은느낌)
	pd.concat()로 하나의 축을따라 이어붙일수도있음
	
	1.데이터베이스스타일로 합치기
		기본적으로 pd.merge를 쓰면 서로 키가 겹치지않는건 다 날아가고(inner join) 겹치는거만 추가해서 리턴함
		사용법은
			pd.merge(data1,data2,on='키이름')
			만약 키이름이 서로 다르면
			pd.merge(data1,data2,left_on='왼족키이름',right_on='오른쪽키이름')
		
		만약 레프트아우터조인이나,아우터조인을 하고싶으면
			pd.merge(data1,data2,on='키이름',how='left right outer 중 하나')
		를 넣어주면됨
		
		다대다조인은 두 로우의 곱만큼 나오는데,완전히 겹치는건 나오지않음(데카르트곱)
		
		만약 여러 키를 머지하려면 컬럼이름이 담긴 리스트를 on에 넘기면됨
			pd.merge(data1,data2,on='[키이름1,키이름2]')
		
		그리고 서로 컬럼이름이 겹칠경우 suffixes=('왼쪽','오른쪽')을 넣어주면 겹치는컬럼뒤에 저문자열을 넣어줌
		
		1.색인으로 병합
			만약 머지를 색인으로 하고싶으면 
				pd.merge(data1,data2,left_index=True,right_on='키값')
			이렇게하거나 레프트인덱스 라이트인덱스 둘다 트루주고 둘다색인으로 머지할수도있음
			
			그리고 계층색인된애들이랑 머지할땐 키값도 같은갯수로줘야함
			
			그리고 색인으로 병합할땐 join메서드를 쓸수있음
				data1.join(data2,how='outer',on='key')
			이러면 레프트아우터조인을 함(기본적으로 data1의 메서드라 레프트조인임)
			
			그리고 색인대색인으로 데이터프레임 여러개 합치려면 그냥
				data1.join([data2,data3],how=?)
			저렇게 그냥합치면됨
	
		2.축이어붙이기
			pd.concat을 쓰면 축기준으로 이어붙일수가 있음
			밑에다가 인덱스를 더하는식(axis=0일땐)
			만약 axis1일땐 서로 겹치는축이 하나도없으면 다 nan처리되고 안겹치게 늘어남(아우터조인)
			
				pd.concat([data1,data2],axis=?,join='이너 아우터 등등')
			
			만약 이너조인을 하면 안겹치는건 다 사라지고(nan이 추가된거)
				pd.concat([data1,data2],axis=?,join='이너 아우터 등등',join_axes=[['a','b']])
			이렇게 join_axes로 병합할 축을 지정해줄수있음
			
			그리고 만약 병합하기 전 축을 구분하고싶으면
				pd.concat([data1,data2],keys=['key1','key2'])
			이러면 data1에는 key1이 계층색인으로 붙고 data2에는 key2가 계층색인으로 붙음
			
			그리고 시리즈를 axis1으로 결합하면 키는 컬럼명이되고
			데이터프레임을 axis1로 결합하면 계층컬럼이됨
			
			그리고 리스트대신 사전객체를 넘기면 자동으로 키가 keys옵션으로 붙음
				pd.concat({'key1':data1,'key2':data2},axis=?,join='이너 아우터 등등')
				
			그리고 인덱스를 무시하고,그냥 단순하게 줄을 늘리고싶으면 ignore_index=True 주면됨(두개합쳐서 새로운색인생성)
	
		3.겹치는데이터 합치기
			만약 데이터를 합칠때 색인이 일부겹치거나 전체가 겹칠경우엔 
				data.combine_first(data2)
			하면됨
				data[2:].combine_first(data2[:-2])
			이런식으로 슬라이스도 당연히가능
			
			이러면 data의값이 있으면(nan이아니면) data값을 넣고,data가 nan이면 data2의 값을 넣음(인덱스로)
			그리고 정렬해서 리턴함
			
				
	즉,공통된 컬럼이나 인덱스를 기준으로 같은값을 가지는걸 찾은뒤에 n*m으로 행을 모두가지게 합치는게 merge
	동일한 인덱스나 컬럼일때 연속적으로 붙이는게 concat(좀더 그냥 단순하게 같다붙이는거에 가까움)
	
	
3.재형성과 피벗
	stack는 데이터의 컬럼을 로우로 피벗시키고,unstack는 로우를 컬럼으로 피벗시킴
	
	그리고 unstack을 할때 해당레벨의 모든값이 하위그룹에 속하지않으면,피벗할때 빈자리가 생기는데,그건 nan으로 채움
	stack는 nan값을 자동으로 걸러냄(그게싫으면 dropna=False하면 nan표시함)
	
	데이터프레임을 언스택할때 언스택레벨은 결과에서 가장 낮은(제일밑에있는 계층컬럼)컬럼이 됨
	
	1.긴형식에서 넓은형식으로 피벗하기
		데이터프레임을 피벗할떈
			data.pivot()
		을 사용함
		그러면 pivot를 사용하면
			data.pivot(로우컬럼,색인컬럼,밸류컬럼)
		안에 들어있는 로우컬럼과 색인컬럼으로 좌우를 짜고 ,로우와 색인을 표시한뒤 값을 넣어서 긴값을 넓은값을 바꿔줌
		만약
			data.pivot(로우컬럼,색인컬럼)
		을 하면 계층적컬럼을 가지는 데이터프레임을 얻을수있음
		
		즉 pivot는 set_index로 계층적색인을 만들고 unstack를 돌린것과 정확히 같음
		
	2.넓은형식에서 긴형식으로 피벗하기
		이럴땐
			pd.melt()
		를 씀
		newdata=pd.melt(data1,['키컬럼'])
		이러면 키컬럼을 계층색인으로 가지고 나머지컬럼과 밸류로 이루어진 긴형식의 데이터프레임이 됨
		
		이걸 pivot하면 다시 원래대로 돌아감
		
		그리고 데이터값으로 사용할 컬럼의 집합을 지정하려면
			pd.melt(data1,id_vars=['key'],value_vars=['val1',val2])
		이렇게 정할수있음
	



9.데이터시각화(matplot)
	매트랩 쓰려면
		import matplotlib.pyplot as plt
	기본적으로
		plt.plot(데이터)
	하면 데이터로 그래프를 그림
1.매트랩api	
	1.figure와 서브플롯
		기본적으로 매트랩에서 그래프는 피규어객체안에 존재함
			fig=plt.figure()
		피규어 안에 서브플롯을 추가하는것으로 안에 그래프가 하나씩 늘어남
			ax1=fig.add_subplot(가로크기,세로크기,가로x세로중 몇번째선택할지)
		
		여러개넣을떈
			ax1=fig.add_subplot(2,2,1)
			ax2=fig.add_subplot(2,2,2)
			ax3=fig.add_subplot(2,2,3)
			ax4=fig.add_subplot(2,2,4)
		이렇게 추가하면됨
		
		그리고 정확히는,전체크기를 가로랑 세로로 나누고,그중에서 어디선택할지를 고르는거라서
			ax1=fig.add_subplot(2,2,1)
			ax2=fig.add_subplot(2,2,2)
			ax3=fig.add_subplot(2,2,3)
			ax4=fig.add_subplot(2,2,4)
			ax5=fig.add_subplot(4,3,5)
		이거도 동작은하는데,ax5는 이상한데 들어감
		
		그리고 주피터노트북에선 셀마다 그래프가 리셋되기때문에,같은셀안에 다넣어야함
		
		그리고 plt.plot(data)를 하면 가장 가까운 서브플롯에 그리기떄문에
		여러그래프에 추가하고싶으면 
			ax1=fig.add_subplot(2,2,1)
			ax2=fig.add_subplot(2,2,2)
			ax3=fig.add_subplot(2,2,3)
			plt.plot(data)
			ax4=fig.add_subplot(2,2,4)
			plt.plot(data1)
			ax5=fig.add_subplot(4,3,5)
			plt.plot(data2)			
		이렇게하거나
			ax1=fig.add_subplot(2,2,1)
			ax2=fig.add_subplot(2,2,2)
			ax3=fig.add_subplot(2,2,3)
			ax4=fig.add_subplot(2,2,4)
			ax5=fig.add_subplot(4,3,5)
			ax1.plot(data)
			ax2.plot(data2)
		이런식으로 지정해서 넣으면됨
		
		그리고 색이나 점선처럼 선을 바꾸고싶으면
		plt.plot(data,'k--') 이런식으로 두번쨰칸에 색+모양을 문자열로 주거나(자세한사항은 검색)
		
			plt.hist(color='black') 히스토그램(막대그래프)
			plt.scatter()산점도
		등으로 그래프스타일선택가능
		안에 막대크기나 점크기같은거도 선택가능함
		
		
		서브플롯간의 간격이나 여백조절하려면
		figure객체의
			fig객체.subplots_adjust(left=None,bottom=None,right=None,top=None,wspace=0,hspace=0)
		메서드를 사용해서 설정을 바꿀수있음
	
	2.색상,마커,선스타일
		ax1.plot()는 x값과 y값,스타일문자열을 기본적으로 받음
			ax1.plot(x,y,'g--')
		이걸 명시적으로 주고싶으면
			ax1.plot(x,y,linestyle='--',color='g',marker='o')
		이렇게주면됨
		색은 rgb값을 직접줄수도있음(#CECECE)
		
		선스타일은 선말고 꼭지점에 마커를 달수도있는데,그러려면 'go--'이런식으로 적으면됨
		색,마커,라인스타일 순임
		
		범례를 달려면
			ax1.plot(x,y,'g--',label='범례달거')
			ax1.legend(loc='best')
		이렇게 라벨추가하고 레전드실행시키면됨
		만약 plt.plot하면
			plt.plot(data,label='ff')
			plt.legend(loc='best')
		하면됨
		
		
	3.눈금,라벨,범례
		그래프를 꾸밀땐 pyplot로 순차적으로 꾸미던가,api써서 객체지향적으로 꾸미던가 두가지방법이있음
		
		x축의 눈금을 변경하는 방법은
			tick=ax1.set_xticks([0,100,200,300])이렇게 하고
		눈금이름을 바꾸고싶으면
			labels=ax.set_xticklabels(['a','b','c','d'],rotation=30,fontsize='small')
		이렇게하면됨(눈금이름 0,100,200,300에 abcd들어감)
		그리고 전체 x축이름 정하고싶으면
			as1.set_xlabel('이름')
		하면 눈금밑에 라벨적힘
		
		y축은 x대신 y넣으면됨
		
		
		범례를 추가하는건 각 그래프에 데이터를 그릴때 라벨파라미터를 같이주면 자동으로 그 선에맞는 범례를 추가하고,
		거기다 레전드쓰면 자동으로 생성됨
		그리고 범례위치는 loc='best'쓰면 어지간하면 괜찮게나옴
		만약 범례에서 제외하고싶은게있으면 그냥 라벨안쓰면됨
	
	4.주석과 그림
		그래프내의 주석은
			ax.annotate(라벨,xy=(x값,y값),arrowprop=dict(컬러랑 길이등 설정가능))
		기본적으로 이렇게 달수있음
		
		그리고 그래프의 특정구역을 확대하려면
			ax1.set_xlim(시작값,끝값)
			ax1.set_ylim(시작값,끝값)
		하면됨
		
		그리고 그림추가하려면
			ax1.add_patch(plt.Circle((0.7,0.2),0.15 color='b',alpha=0.3))
		이런식으로 추가함
		
	5.그래프 저장하기	
		그래프 저장하려면
			ax1.savefig('abc.svg')
		이렇게 저장할수있음 
		파일종류는 확장자로 결정되니까 pdf하면 pdf저장하고 그럼
		
	6.기본설정
		매트랩의 기본설정을 바꿀수있는데(값을안줬을때의 기본값)
			plt.rc('바꿀컴포넌트',**바꿀값사전)
		ex) plt.rc('font',**fontdic)
		이렇게 바꿀수있음
		
		
2.판다스에서 씨본으로 그래프그리기
	판다스에서 시리즈나 데이터프레임으로 바로 그림그릴수있음
	
	그리고 씨본임포트하면 매트랩의 기본컬러와 스타일이 임포트만 해도 바뀜(오버라이드)
	
	1.선그래프
		시리즈로 그래프그리려면
			s=pd.series(...)
			s.plot()
		하면 그래프그림
		시리즈의 인덱스는 x축으로 해석하고 밸류가 y축으로 해석함
		use_index=False를 해서 색인을 x축으로쓰는걸 막을수있음
		눈금과 확대는 xticks와 xlim으로 조절할수있음 (y는 y)
		
		데이터프레임의 plot는 하나의 서브플롯안에 각 컬럼별로 선그래프를 그리고 범례를 생성함
		여기서 각 컬럼마다 따로 그래프를 그릴건지,어떤컬럼만 그릴건지등도 인자줘서 선택가능함
		
		그리고 ax매개변수에 피규어를 대입하면,거기에 그림그림
		
		
	2.막대그래프
		막대그래프를 그리려면
			data.plot.bar() 수직그래프
			data.plot.barh()수평그래프
			
		데이터프레임에서 막대그래프는,각 로우의 값을 함께 묶어서 하나의 그륩마다 각각의 막대를 보여줌
		
		누적 막대그래프는 stacked=True로 생성할수있음
		누적막대그래프는 각 로우의값이 막대에 누적되어,색으로 구분되어 표시됨
		
		여기서 seaborn쓰면 좀 전처리 편해진다는데 나중에 쓸일있으면보자
		
		
	3.히스토그램과 밀도그래프
		히스토그램은 값들의 빈도를 분리해서 보여주는 막대그래프
		데이터 포인트가 분리되어 고른간격의 막대로 표현되고,데이터의 숫자가 높이로 표현됨
		
			data.plot.hist()
		로 그릴수있음
		
		밀도그래프는 추정되는 연속된 확률분포를 그린 그래프임
			data.plot.kde()
		로 만들수있음
		
		seaborn의 distplot를 쓰면 두개를 같이 볼수있음
			seaborn.distplot(시리즈,bins=100)
		
	4.산포도
		산포도는 각 데이터끼리의 관계를 나타낼때 쓰는 그래프임
			seaborn.regplot(data=데이터)
		로 그릴수있음 산포도와 선형회귀가 같이그려짐
		
		그리고 전체 데이터프레임끼리의 관계를 알아보려고 산포도그릴떄 전체한번에그리려면
			seaborn.pairplot(data,diag_kind='kde(자기자신비교할떄)',plot_kws={'alpha':0.2 개별설정값 전달})

	5.패싯그리드와 범주형데이터
		범주형데이터를 시각화할땐 패싯그리드를 사용함
			seaborn.factorplot(x=x값라벨,y=y값라벨,hue='',col='',kind='bar',data=데이터)
		
		
		
		
		
10.데이터집계와 그룹연산		

1.groupby메카닉
	그룹바이는 총 3단계로 구성됨
	분리-적용-결합
	
	먼저 분리는 그룹바이조건에따라(그룹조건) 원본데이터를 나누고
	적용은 거기에 원하는 함수를 적용시키고 새값을 얻어낸뒤
	결합은 적용된 값들을 다 합쳐서 새로운 데이터객체로 만듬
	
	즉 키로 묶어서 여러 객체를 만든뒤(분리)-그 객체마다 함수를 적용시키고(적용)결과값을 뱉고-그 결과값을 묶어서 객체로 만듬(결합)
	
	판다스에서 그룹바이를 쓰려면
		abc=data['밸류컬럼'].groupby(data['키컬럼'])
	이러면 그룹바이객체가 abc에 들어감
	키에따라 리스트식으로 묶어진 밸류들이 들어간 컬럼
	여기다
		abc.mean()
	이런식으로하면 키에따른 함수적용값이 나옴
	
		키1  0.5
		키2  0.4
	
	적용까지 마치면 시리즈객체가 나옴
	
	만약 키로 두개이상을 리스트로 주면,두개를 묶어서 키로 사용함(더많은결과값이나옴 and연산이니까)
	
	그리고 많이쓰는 연산으로
		data.groupby(data['key1']).size()
	로 각 그룹의 크기를 볼수있음
	
	그룹색인에서 누락된값은(nan) 제외된다는걸 주의
	
	1.그룹간 순회
		그룹바이객체는 이터레이터를 지원함
			for name,group in 그룹바이객체:
				...
		이러면 이름과 그룹으로 각각 출력됨
		
		만약 색인이 여러개 존재하면 name을 (name1,name2)이렇게 나눠받을수도있고,그냥 name하나로하면 튜플로 리턴해줌
		
		그리고 그룹바이객체를 캐스팅해서(list(data)) 리스트로 바꿀수도있고,바꾼리스트를 다시 사전형태로 바꿀수있음
		
		그리고 그룹바이는 기본적으로 axis=0에대해 만들지만 axis=1로 지정해주면 컬럼따라 묶을수있음
			abc=data.groupby(data.dtype,axis=1)
		이런식으로 컬럼의 타입따라 묶을수도있음
		
	2.컬럼이나 컬럼일부만 선택	
		그리고 그룹바이 짧게적으려면
			abc=data.groupby('키컬럼')['밸류컬럼']
		이렇게해도
			abc=data['밸류컬럼'].groupby(data['키컬럼'])
		이거랑 같은결과
		
		만약 대용량데이터를 다룰때,특정컬럼에만 함수적용시키고싶고,리턴은 데이터프레임으로 받고싶으면
			data.groupby(['key1','key2'])['data1'].mean()
		이렇게하면됨
		
		색인으로 얻은 객체는 그룹바이메서드에 리스트나 배열을 넘기면 데이터프레임그룹바이객체가 리턴되고,
			data.groupby(['key1','key2'])['data1']
		단일값으로 하나의컬럼을 주면 시리즈그룹바이객체가 됨
			data.groupby('key1')['data1']
		
	3.사전과 시리즈에서 그룹핑
		그룹바이는 따로 사전객체를 줘서 그거로 매핑할수도있음
		
			abc=data.groupby(사전객체,axis=1(컬럼끼리 묶을때))
		
		이러면 사전객체의 키값으로 매핑해서 밸류가 같은게 있으면 같은거끼리 묶어서 리턴함
		
		
	4.함수로 그룹핑
		그룹바이의 키는 함수를 줄수도 있음
		만약 len을 키로 주면 리턴값이 같은(길이가 같은)것끼리 묶어줌
			data.groupby(len)
		그리고 리턴값이 리스트로 들어가서 키값이 되니까,함수랑 키딕셔너리같은거도 묶어서써도됨
			data.groupby([len,리스트])
			
		
	5.색인단계로 그룹핑	
		계층적으로 색인된 데이터는 축 색인을 이용해서 집계할수있음
			data.groupby(level=원하는레벨이나 레벨이름)
		
		
		
2.데이터집계
	데이터집계는 mean count같은 적용시 사용하는 함수
		count,sum,mean,median(산술중간값),min,max,prod(값들의 곱)
	기본적으로 na인건 무시하고 na가 아닌것들만 연산함
	
	그리고 자기가 직접 만들수도 있음,그러려면 그룹바이객체의 agg에 배열을 매개변수로받는 함수를 넘겨주면됨
		그룹객체.agg(만든함수)
	
		
	1.컬럼에 함수적용
		만약 컬럼마다 다른함수를 쓰길 바라거나,여러함수를 한번에 적용하고싶으면
		여러 함수를 한번에 적용하려면(여러통계 한번에보려면) agg에 쓸 함수들을 원래있던함수면 문자열처리해서 넘기고,직접만든거면 그냥 리스트로 묶어서 넘기면됨
			그룹.agg(['mean','sum',myfun])
		컬럼마다 다른함수를 쓰고싳으면,agg에 컬럼이름과 함수가 담긴 튜플을 배열에 담아서 넘기면됨
			그룹.agg([('컬럼이름','count'),('컬럼이름',myfun)])
		
		그리고 데이터프레임에서 컬럼몇개선택하고,거기서 여러함수 적용하려면
			그룹객체['컬럼이름','컬럼이름'].agg(함수리스트)
		하면 계층컬럼으로 컬럼-함수명이 박힌 결과값이 나옴
		
		그리고 컬럼마다 다른함수를쓰고,추가컬럼을 넣지않고 그자리에 넣고싶으면,컬럼이키값이고 함수가 밸류인 사전객체를 주면됨
			그룹객체({'컬럼이름':'함수이름','컬럼이름':'함수이름'})
		당연히 함수이름에 리스트를 넣으면 여러개적용됨(계층구조를 가진 데이터프레임리턴)
		
	2.색인되지않은 형태로 집계된 데이터 반환
		만약 인덱스에 키값을 넣기싫으면 as_index=False하면 
		맨앞에 컬럼으로 키값이 들어가고 인덱스는 자동생성된 숫자가붙음(기본적으로 꼭넣을듯)
		
3.apply
	그룹바이객체에 
		함수명(데이터,n=갯수,column=컬럼이름):
			return 데이터프레임
	이런 그룹바이객체를받고 데이터프레임을 리턴하는 함수를 적용시키려면
		데이터.groupby('컬럼명').apply(함수)
	하면 적용됨
	그리고 apply가 추가적인 인자를 받으면,함수이름뒤에 명시해서 넘겨주면됨
		데이터.groupby('컬럼명').apply(함수,n=5,column='aaa')
	
	이러면 함수를 그룹바이 객체마다 람다식으로 적용시킨다음에,그걸 묶어서 리턴함(적용-결합)
	
	1.그룹색인 생략
		이거도 그룹색인이 필요없으면 group_keys=False 주면됨 그룹바이에서
	
	2.변위치분석
		cut와 qcut로 나눈 데이터묶음을 바로 groupby로 넘겨서 분리한다음에 함수적용할수 있음
		
	3.그룹에따른값으로 na채우기
		fillna로 람다식을 만든뒤에 그걸 그룹바이한거에 apply시켜서 채울수있음
			data.groupby('키').apply(lambda g:g.fillna(g.mean()))
		
4.피벗테이블
	피벗테이블은 데이터를 하나이상의 키로 수집해서 로우나 컬럼에 나열해서 데이터 정렬하는 메서드
		데이터.pivot_table(index=[],columns=[])
	margins=True로 주면 부분합을 포합하게 확장할수있는데,그러면 all컬럼과 로우가 추가됨
	
	그리고 집계함수를 사용하려면 aggfunc=함수이름 을 주면됨
	그리고 na값 처리하고싶으면 fill_value=채울값 주면됨
	
	1.교차일람표
		피벗테이블의 특수한형태
		데이터 묶어서 갯수셀때 가끔쓰는듯
		기억만해두고있자
		
		
		
		
		
11.시계열
	시계열데이터는 일정 규칙에따라 나열된 데이터(대표적으로 시간순으로 나열된 데이터)
1.날짜,시간,도구
	datetime객체로 시간을 딸수있고,timedelta객체로 datetime객체를 조정할수있음
	datetime끼리 연산하면 timedelta객체가 나옴
	
	1.문자열을 datetime으로 변환
	
		데이트타임을 
			str(datetime)
		하면 문자열로 바뀌고
			datetime.strptime(str,형식)
		하면 문자열을 데이트타임으로 바꿀수있음
		
		그리고 형식적기귀찮으면
		datautil에 있는 parser.parse쓰면 
			parse('2011-01-03')
		이러면 데이트타임객체로 리턴해줌
		
		판다스는 데이트타임의 리스트를 받아서 인덱스로 포장해서 쓸수있음
			pd.to_datetime(데이트타임리스트)
		널이나 na등도 들어갈수있음
		
2.시계열 기초
	인덱스로 데이트타임객체를 인덱스에 넣어서 시리즈로 만들면 시리즈객체는 timeseries가 됨
	
	다른 시리즈랑 마찬가지로 다르게색인된 시리즈끼리의 산술연산은 자동으로 날짜인덱스로 연산함
	
	1.색인,선택,부분선택
		타임시리즈는 색인도 [2]이렇게 당연히 되고 슬라이싱되고 해석가능한 날짜를 문자열로 넘겨서['20110111']이렇게도 되고
		['2011']만 하면 2011년꺼 데이터 전부 들고옴
		
		슬라이싱할때도 data[datetime(2011,1,7):]
		이런식으로나 data['2011':'2018']
		이런식으로도 슬라이싱 가능
		
		이거도 넘파이슬라이싱처럼 원본데이터에 대한 뷰를 생성함
		
		그리고 시작일부터 영업일이나 그냥 날짜나 해서 100일 이런식으로 주고싶으면
			data=pd.date_range('시작일',periods=넣을일수,freq='조건(영업일이나 그런거)')
			
		그리고 시작일 종료일 조건 넣고싶으면
			data=pd.date_range('시작일','종료일',freq='조건(영업일이나 그런거)')
		start=나 end=만 명시해서 주고,periods=로 날짜지정도 가능 
		그리고 인덱스랑 데이터 크기맞춰서 데이터프레임이나 시리즈에 넣으면됨 
			
		
	2.중복된 색인을 갖는 시계열
		데이터가 몰려있으면(색인이 유일하지 않으면)
		중복여부에따라 스칼라값을 줄수도있고,슬라이스(시리즈나 데이터프레임객체)를 줄수있음
		
		그리고 유니크하지않은 데이터를 집계할떈 groupby에 level=0을 주면됨
		그러면 겹치는 색인있는 객체는 평균냈을때 그안에서의 평균을 내서 리턴함(2011이 1,8 이 있을때 mean하면 4.5리턴)
		
		
3.날짜범위,빈도,이동
	판다스에서 이미 있는 데이터를 리샘플링하려면
		newdata=data.resample('원하는 조건문자열  D는 고정 일 빈도')
	
	만약 시간정보를 포함해서 시작날짜 종료날짜를 가지고있지만,타임스탬프를 정규화하고싶으면(일괄적으로 00시로라든가)
	pd.date_range에 normalize=True 주면됨
	1.빈도와 날짜 오프셋
		판다스에서 빈도는 기본빈도(hour이나 minute)와 숫자의 곱으로 이루어짐
		Hour(4)하면 hour과 4가 저장되는식
		그래서 보통 freq=에서 '4h'이런식으로 표현되는것
		알필요는없고 잡지식
		
		그리고 wom은 유용하게 쓸수잇는 빈도인데,월별 주차임
		월의 3번쨰 금요일 같은걸 줄수있음
			freq='WOM-3FRI'
		
	2.데이터시프트
		데이터를 시간축은 그대로 두고 
		밀거나 당길때 사용
		
			data.shift(2) data.shift(-2)
		이렇게 두칸밀거나 당길수있음
		이러면 앞뒤중 한군데에 옮긴만큼 nan이 생기는데 ,만약 빈도를 알고있으면 빈도를 넘겨서 타임스탬프가 확장되게할수있음
			data.shift(2,freq='M')
		즉 결측치가 난곳을 지우고,새로운 날짜를 생성해서 데이터넣음
		
		그리고 데이트타임객체에 
			date + 3*hour()
		이런식으로 연산하는거도 가능하고
			date+MonthEnd()
		이렇게하면 월말로 가고(11월10일이면 11월30일)
			date+MonthEnd(2)
		하면 다음달로 월말로 감
		
		이 오프셋의 메서드를 사용해서 명시적으로 앞뒤로 옮길수도있음
			off=MonthEnd()
			off.rollforward(date) // 11-30
			off.rollback(date)    // 10-31
			
		근데 제일쉬운게 resample쓰는거임
		
4.시간대 다루기
	뭐 메인값은 datetime객체에 들어있고,지역값이 들어가는형태라서 막 바꿀수도있고 원복도 됨
	난 필요없을거같으니까 나중에 필요해지면 보자 있다는거만 알아두고 
	tz매개변수나 tz_localize()메서드로 할수있음
	
5.기간연산
	며칠 몇개월 몇해 같은 기간은 period클래스로 표현할수있고 문자열이나 정수,빈도를 가지고 생성할수있음
	
		p=pd.Period(2007,freq='A-DEC')
	이런식
		
	이러면 p는 2007년 1월1일부터 2007년 12월31일까지 기간을 표현함(A-DEC가 1월부터 12일까지 년단위기간이니까)
	여기서 연산해서 옮길수도있고
		a=p+2 //period('2009',freq='A-DEC')
	둘을빼면 정수가 나옴
		a-p//2
	일반적인 기간범위는 period_range로 생성할수있음
		pd.period_range('시작점','끝점',freq=)
	문자열로 생성하는것도 가능
		a=['2001Q3','2001Q4']
	
	
	1.period의 빈도변환
		빈도는 asfreq로 다른빈도로 변환할수있음
		
			p.asfreq('M',how='start')
		
		빈도가 상위단계(년)에서 하위단계(월)로 바뀔떈,상위기간은 하위기간이 어디 속했는지에 따라 결정됨
		
		상위는 하위를 포함하고있으니까,막 바꿀수있음
		
	2.분기빈도
		분기는 회계연도의 끝인 12월의 마지막날이나 마지막 업무일을 기준으로 하는데,이거도 막 경우의수 여러개있음
		그래서 다르게넣을수있는데 이거도 필요해지면 보자
		
	3.타임스탬프와 기간 서로 변환하기
		타임스탬프는 data.to_period()로 기간별로 인덱스의 이름을 바꿀수있음 (2000-01-31을 2000-01로)
		막 값이 겹칠경우(1월이 여러데이터가 있을경우)인덱스가 중복해서 나옴
		
		그러니까 기간으로 바꾸고 그룹바이지으면 좀 명시적으로 보이긴할듯
		
	4.배열로 periodindex생성
		막 년도랑 쿼터나 달,일등이 여러컬럼에 나눠져서 존재할땐
			pd.PeriodIndex(year=,quarter=,freq=)
		이렇게 날짜들을 묶어서 인덱스로 넣어쓸수있음(일단 인덱스로 리턴되는데,그걸 원본데이터에 넣으면됨)
		
		
6.리샘플링과 빈도 변환
	리샘플링은 시계열의 빈도를 변환하는 과정
	상위빈도를 하위빈도로(년을 달로)하는걸 다운샘플링이라고 하고 반대를 업샘플링이라고 함
	두개 말고도 수요일집계를 금요일로 바꾸는 다운도 업도 아닌것도 있음
	
	리샘플링할때는 resample를 쓰는데
	groupby와 비슷한 매커니즘임
	
	data.resample('M').mean()
	이런식으로 월별평균을 낸다던가 하는식
	1.다운샘플링
		분단위를 5분씩 묶어서 평균을 내려면
			data.resample('5min',closed='right').sum()
		이러면 5분씩 묶는데,closed=right가 있으니까 시작값을 그룹의 오른쪽에 포함시킴
		만약 라벨을 오른쪽값으로 주고싶으면
			data.resample('5min',closed='right',label='right').sum()
		하면됨
		그리고 좀더 명확하게 하기위해서 라벨을 -1치고싶으면(04:59 이런식으로)
			data.resample('5min',closed='right',label='right',loffset='-1s').sum()
		하면됨
		
		그리고 뭐 시가고가저가종가 이런거 OHLC라고 how=ohlc하면 넣어준다는데 당장쓸일없을듯 알아만두자
	
	2.업샘플링
		하위빈도에서 상위빈도로 변환할땐 집계가 필요없음,그냥 빈자리에 na값이 들어갈뿐임
		쓰는거도 똑같이 resample쓰면됨
		
		그거로 ffill같은거로 전값 채우거나 해서 쓰는거
		
	3.기간리샘플링
		기간으로 색인된 데이터를 리샘플링하는것도 타임스탬프와 똑같음
		
		업샘플링은 값 비니까 na값나오는거도 똑같고,근데 새로운빈도에서 구간의 끝을 어디둘지는 미리 정해둬야함(convention= start나end)
		
		근데 기간리샘플링은 좀 더 엄격함
		다운샘플링은 대상 빈도는 반드시 원본빈도의 하위기간이어야하고,
		업샘플링은 반드시 상위기간이어야함
		
		
7.이동창함수
	특정부분 끼리 묶어서 연산해서 그래프그리거나(주식할떄 60일선같은거)할땐 rolling를 씀
		data.rolling(숫자).mean()
	이러면 숫자갯수만큼 그룹핑해서 연산해서 데이터프레임으로 리턴함
	
	확장창평균은 시작지점에서 창의 크기가 전체가 될떄까지 점점 늘림(전값을 가진상태로 계속 추가함)
	이걸쓰려면 expanding()쓰면됨
	
	rolling()은 고정크기의 기간지정문자열('20D')를 넘겨서 호출할수도 있음
	숫자갯수로 하면 인덱스 갯수로하고,기간지정하면 날짜지정해서 그 기간만큼 더함(중간에 비는게 있는 빈도가 불규칙한 시계열일경우 유용함)
	
	1.지수가중함수
		균등한 가중치를 가지는 관찰과,최근값에 좀 더 많은 가중치를 두는 지수가중함수가 있음
		지수가중함수를 쓰려면 
			data.ewm(span=숫자).mean()
		하면됨
		
	2.이진이동창함수
		만약 이동창에서 두 데이터간의 상관 관계를 계산하려면
			data1.rolling(60).corr(data2)
		하면됨 
		
		
		
		
12.고급 판다스
1.categorical데이터
	카테고리컬데이터는 범주형 데이터들을 이름배열을 따로 저장하고,
	원본데이터에 0,1,2 이런식으로 이름배열의 인덱스만 줘서 메모리를 아끼고,연산비용을 아끼는방식
	
	범주데이터를 카테고리로 바꾸려면 시리즈나 인덱스의 특정 컬럼의 데이터타입을 category로 바꾸기만하면됨
		data['cate']=data['cate'].astype('category')
		
	직접 카테고리컬형을 생성하는것도 가능
		my=pd.Categorical(['a','b','c','a'])
	이러면 a,b,c가 인덱스이고 0,1,2,1이 들어간 카테고리객체가 생성됨
	
	직접 만들어둔 범주와 데이터가 있으면 그거쓰는거도 가능
		my=pd.Categorical.from_codes(코드,범주)
	
	범주형으로 변경할땐 명시적으로 지정하지 않으면 특정 순서를 보장하지 않음
	
	
	그리고 카테고리화 한 데이터를 원본으로 돌릴려면 이름인덱스배열.take(데이터배열)
	
	카테고리컬객체는 categories속성과 codes속성을 가짐
	카테고리속성은 이름배열,코드는 데이터배열
	
	기본적으로 따로 명시적으로 순서를 지정하지않으면,특정순서를 보장하지 않음(데이터입력순서대로 0,1,2붙임)
	그래서 from_codes같은거 쓸때 ordered=True주면 순서대로 들어감
	
	1.categorical연산
		
	
		
		
		
		
		
		
		
		
		
		
		
		
		
		
	
	
	
	