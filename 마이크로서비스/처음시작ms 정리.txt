1.마이크로서비스란
	마이크로서비스는 단일앱을 작은규모의 서비스조합으로 나누고,서비스끼리 api를 사용해 통신하는식임
	이거의 장점은,순서대로 동작하는 작업도,api로 어떻게 들어올지만 정해두면 거기에 맞춰서 개발할수있어짐
	
	마이크로서비스를 할때 주의점은,선택하고 결과는 오랜시간이 지나야 나오기때문에 신중해야함
	그렇다고 계속 고민만 하고있을수는 없음
	그래서 사용하는게 ADR임
	
	이건 아키텍쳐 결정 기록이라고 하는데
	목표,대안,선택,영향을 다 나열하고 적는것
	
		목표는 이루고자 하는 목표(해결할문제)와 제약사항등 문제를 나열
		대안은 내가고를수있는 선택지
		선택은 내가 고른 대안
		영향은 선택에 따라 일어난일
	이걸 전부 문서화하는것(깃헙의 이슈랑 비슷함)
	
	
	
2.마이크로서비스 운영모델설계
	운영모델은 사람,프로세스,도구의 집합이고 소프트웨어를 구축할때 수행하는 모든 의사결정과 작업에 중요한 영향을 미침
	운영에서 가장 중요한건 사람임
	
	그래서 마이크로서비스팀의 인원수도 중요함
	크면 의사소통에 많은시간이 필요하고,너무작으면 일손이 부족함
	대충 8명정도로 자르는듯

	그리고 이렇게 작게자르면 팀의 갯수가 많아지고,여기서 또 의사소통땜에 시간지연되면 안됨,그래서 각팀은 가능한 독립적으로 돌아가야함
	그렇다고 완전히 독립적이면,어짜피 똑같이필요한걸 모든곳에서 만들어야하기떄문에 효율성이 떨어짐,그래서 적당히 실험해보면서 조율해야함
	1.팀 토폴로지
		팀토폴로지는 팀간 일하는 방식에 중점을두고 설계에 대해 이야기하는방식
		
		1.팀유형
			마이크로소프트의 핵심개념중 하나는 팀 유형임
			이건 조직간 의사소통관점에서 팀의 성격을 설명함
			여기에 있는 팀유형은
				스트림정렬
				활성화
				난해한 하위시스템
				플랫폼
			이 있음
			
			스트림정렬은 전달가능한 작업을 소유하고 실행함
			이팀의 주요특징은 비즈니스조직과 관련된것을 지속적으로 전달함,즉 구축한걸 직접 운영하라,만든곳에서 제품을 변경하고 개선함
			
			활성화는 다른팀의 작업을 지원함,해결사같은곳임
			
			난해한 하위시스템은 암호화같은 어려운거나 해결하는데 오래걸리는걸 전문으로 함
			
			플랫폼은 활성화처럼 다른팀의 작업을 지원하는데,여기는 사용자의 역할을 해서 qa를 해줌
			그러니까 자기자신말고 나머지 모두가 플랫폼이라고 볼수있음(자기가만든걸 소비하니)
		
		2.상호작용모드
			각 팀간에는 조정비용이 가능한 작아야함,
			그래서 상호작용도 진짜 서로 같이 일을 하거나(협력),
			다른팀이 원하는 결과를 줄수있게 하거나(촉진),
			api를 만들어서 공개하거나(xaas)
			
			이 3가지가 있음
		
	2.팀 토폴로지 설계
		팀 토폴로지는 팀 조정에 대해 이야기할수 있는 언어임
		얘는 시각적 표현으로,다이어그램을 사용해 표현함
		
		기본적으로 팀 설계와 토폴로지를 만들기위해
			시스템설계팀 구성
			마이크로서비스팀 템플릿 생성
			플랫폼팀 정의
			활성화팀 난해한 하위시스템팀 생성
			주요 소비자팀 추가
		로 순서대로 하면됨
		
		1.시스템설계팀 구성
			시스템 설계팀은 시스템비전과 행동을 구체화할수있는 사람을 그룹으로 구성함
			이팀의 책임은
				팀구조 설계:팀들을 설계함
				표준,인센티브,가드레일 설정:빡빡한 규칙말고 표준적으로 이렇게처리하고,이렇게하면 좋다,이렇게는 하면안된다 식의 간단한 규칙을 만들어야함
				지속적인 시스템 개선:팀설계와 규칙들을 측정하고,개선할수있게 관리해야함
				
			이런것처럼 팀책임은 전부 문서화해두는게 좋음 
			
		2.팀 템플릿 구축
			업앤러닝모델에선 단일팀은 여러 마이크로서비스를 소유할수있음
			여기서 중요한건,한 마이크로서비스는 책임이 한 팀에만 있어야함(소유권은 한팀에있어야함)
			
			팀 템플릿은 클래스라고 보면됨,이거대로 대충만들고 오버라이드해서 약간 수정하는식
			여기서 정해야할건
				팀유형
				팀규모
				책임
			임
			책임은 여러개를 소유할수있고,팀규모는 팀의 규모 팀유형은 팀의 유형임
			
			그리고 다이어그램에서 서로 붙어있으면 서로 상호작용이 일어난다는것
		3.플랫폼팀
			플랫폼팀은 클라우드플랫폼팀으로 쿠버네티스나 aws등을 사용해서 배포하는걸 지원함
			이팀의 책임은 네트워크 인프라설계및 개발(iac),앱 인프라설계및 개발(쿠버네티스),새환경을 빌드하기위한 스크립트제공(쉘스크립트+도커),업데이트
			가 있음
			
			이팀의 책임중 핵심은 제공한 인프라를 업데이트하는것임
			이팀은 마이크로서비스팀에 xaas서비스모델을 구현함
			
		4.활성화와 난해한 하위시스템팀
			이팀들은 핵심은 아니고,추가로 필요한것들을 처리함
			주로 전문릴리즈팀(프로덕션에 마이크로서비스를 릴리즈함)이 있음,이건 난해한 하위시스템팀임
			
			얘는 다이어그램에 마이크로서비스팀 위에 작은사각형을 그리고 거기넣음

		5.소비자팀
			소비자팀들은 모바일앱개발,웹개발,서드파티조직들이나 api사용자들임
			api팀은 마이크로서비스를 api로 다른개발팀에 노출하는 책임을 맡고있음
			예를들어 모바일앱팀은 api팀에서 만든 api로 상호작용을하지,마이크로서비스를 직접호출하지않음
			
			그래서 마이크로서비스팀이 api팀에 xaas로 상호작용을 함
			




3.seed(s)프로세스
	시드는 서비스를 통한 시스템의 컴포넌트화를 말함
	여기서 시스템 구성요소는 공개인터페이스를 정의해서 서비스로 호출함
	여기서 시드프로세스는 반복가능하고 안정적이고 신뢰할수있는 방법론을 제공해줌
	
	시드는
		액터식별
		액터가 수행하는 작업식별
		시퀸스다이어그램을 사용한 상호작용패턴 발견
		jtbd와 상호작용패턴을 기반으로 높은수준의 작업및 쿼리 도출
		개방형표준(openapi)를 사용해서 액션및 쿼리를 스펙으로 설명
		api사양에 대한 피드백받기
		마이크로서비스 구현
	순서대로 되어있음
	
	1.액터 식별
	액터는,고객에서 금전적 요소를 뺀거를 말함,즉 내 서비스를 사용하는 사람들을 말함
	액터정의로 모델링을 시작하는이유는 범위와 우선순위를 지정하기위해서임
	가장 많이 저지르는 실수가 요구사항에 대한 명확성부족과 지나친 추상화기때문에 이걸 해결하려는거
	
	여기서 해야할일은 누가 이 api를 사용하는가,혹은 고객이 필요한것은 무엇인가 를 알아야함
	이때 목표에 적합한 액터를 식별하기위한 규칙은
		1.액터는 정확하기보다 구체적이여야함,
		  액터가 누군지보다 액터를 구별하는 특성의 경계를 식별하는게 더 중요함,
		  모델링과정은 모든게 정확할수없음,
		  모든세부사항보다 현실에 관련된 우선적인거를 파악해야함
		2.겹치거나 광범위한 액터는 위험함,재사용되는 액터의 포트폴리오를 갖는건 잘못될가능성이 큼
		3.모델로서 액터정의는 각 액터에 내재된 요구사항,문제점,행동을 나타냄,액터유형을 구분하는 요구사항과 행동은 관련성이 있고,중복이 매우제한적이여야함
		4.문제영역을 설명하기위해 적은수의 개별액터를 사용해야함,서비스에 5개이상의 액터가있으면 우선순위가 사라졌거나 서비스경계가 너무넓은것
		
		
	2.액터가 수행하는 작업식별
		액터의 유형을 파악했으면,액터가 할일을 파악하는데 시간을 많이들여야함
		
		시드를 포함한 설계방법론은,api및 서비스를 제품으로 정의하고 시작함
		그래서 제품을 생산할때 제일 중요한,고객의 문제를 해결해야한다는걸 제일 중요하게생각해야함
		그래서 일시적인 도구를 완성하는게 아닌,문제해결에 집중해야함
		
		이걸위해 사용하는게 잡스토리임
		잡스토리는
			__일때,나는 __하기를 원하고 __할수있다
			상황     동기           목표
		임
		이걸 좀더 개발자편의적으로 변경하면 상호작용 다이어그램을 그릴수있음
		이때 사용되는게 plantuml같은거,어떤게 어디 포함되어있고 어디서 어디로 간다 이런식으로 기술간 상호작용식으로 표현함,필요하면보자
	3.jtbd에서 액션및 쿼리도출
		잡스토리를 실제로 api로 바꿀땐,액션과 쿼리의 집합으로 바꿀수있음
		쿼리는 사이드이펙트가 없는,단순조회를 말하고
		액션은 사이드이펙트가 메인인,즉 바꾸는게 목적인(insert같은)걸 말함
		
		쿼리는
			입력:입력변수목록
			응답:출력데이터요소목록
		액션은
			입력:입력변수목록
			예상결과:유발된 사이드이펙트에 대한 설명
			응답(선택사항):응답데이터요소 목록(존재할경우)
		식으로 표현할수있음
		잡스토리가 하나의 쿼리나 액션인건 아니고,여러개의 쿼리와 액션의 집합으로 변환될수있고,쿼리와 액션은 여러 잡스토리의 소스로 결합할수있음
		
		즉 입력값을 넣으면 출력값이 나오는 함수라고 보고,저렇게 인터페이스를 짠다음 나중에 내부구현하면됨
		액션의경우엔 입력값은 똑같이하면서 출력값은 성공하면 성공코드,실패할시 오류객체를 던지면됨
		
		이거도 복잡해지면 다른방식을써야하지만(마이크로서비스 디자인 캔버스),보통은 이거로 충분함

	4.openapi를 사용해 액션및 쿼리를 스펙으로 설명
		인터페이스를 만들었으면 openapi를 사용해서 문서화를 시켜놔야함
		그리고 보통 api는 restapi를 사용하는듯
		openapi를 작성할땐 vscode에서 플러그인을 설치하고 컨트롤알트p를 누르면됨
		
		oas(오픈api사양)의 상세는 나중에찾아보자
		대충 기본설명이랑 입출력설명정도있음

	5.api사양 피드백받기
		그리고 api사양을 만들었으면,이걸 사용할사람들한테 보여주고 피드백을 받아야함
		api와 서비스를 설계할떄 두가지 유형의 고객그룹을 고려해야함
			최종사용자
			서비스이용자(서비스를 사용해 코딩할사람들)
		순서는 seed 시작단계에선 최종사용자를 인터뷰해서 잡스토리를 뽑고,후반에는 클라이언트개발자로부터 피드백을 받으면됨
		최종사용자는 목표를,서비스이용자는 과정을 피드백해줌
	6.마이크로서비스 구현
		마지막단계는 실제로 코딩을 해서 마이크로서비스를 구현하는거임
		코딩은 제일 코스트가 많이들기때문에,최대한 다른변경사항을 없애둔뒤에 딱 한번만 하면되게 함
		
		api와 마이크로서비스는 많은게 비슷함
		둘다 http를 통해 통신하며 기능을 제공한다던지
		여기서 api와 마이크로서비스의 차이점은,api는 마이크로서비스를 모아둔 시스템의 인터페이스(파사드라고 보면됨)라고 보면됨
		즉 api를 구현하는게 마이크로서비스들의 집합임
		그리고 마이크로서비스는,서로에대해 알면 안됨,단순 입출력에 따른 결과값만 나와야함 


4.마이크로서비스의 크기조정:서비스경계
	서비스경계는 하나의 큰 코드를 서비스단위로 잘라서 분할할때의 자르는 위치를 말함
	1.경계가 중요한이유와 중요한시기, 찾는법
		마이크로서비스를 만들때 선택할수 있는 방법엔
			코드수제한(500줄)
			함수단위경계(aws람다)
			모듈식 캡슐화
		가 있음
		코드수제한은 딱봐도 별로고
		함수단위경계는,기술적 요구를 기반으로 경계를 그리는건 안티패턴이라서,
		마이크로서비스는 기술적 요구가 아닌 비즈니스기능을 중심으로 구성되어야함
		
		이때 함수단위로 경계자르는거의 문제는,너무 일찍 세분화를 해서 서비스가 엄청나게 많아지는 조기최적화의 위험때문임
		그래서 처음에는 그냥 만든다음에 거기서 최적화를하면서 마이크로서비스로 만드는식으로 하는듯
		
	2.도메인주도설계(DDD)와 마이크로서비스 경계
		마이크로서비스의 규칙은
			느슨한결합:서로를 인식하면안되고,서로 독립적이어야함(영향을주면안됨),서비스간 통신도 제한해야함
			높은응집력:서비스에 있는 기능은 관련성이 높아야하고,관련없는기능은 다른곳에 캡슐화되어야함
			비즈니스기능과 연결:기능의 수정이나 확장은 비즈니스요구에 따라 이뤄지기때문에,경계를 일치시키면 느슨한결합과 높은응집력을 만족시키기쉬움
		근데 이거는 좋긴한데 하기가빡셈,그래서나온게 DDD임
		얘는 서비스경계를 찾는 방법론임
		ddd의 주요개념은 제한된 콘텍스트임
		제한된 콘텍스트를 사용하면 더 큰 시스템의 다른부분을 구현하고 런타임에서 실행해도 시스템에 존재하는 독립적인 도메인모델을 손상시키지않으니
		제한된 콘텍스트를 기준으로 서비스를 자르자는거
		
		여기서 제한된어카운트라는건,스코프를 이야기하는데,
		함수내부에서 account라고 private하게 선언을 했을때 외부에서 접근이 불가능하니 다른곳에서도 account라고 선언할수있는데
		그러니까 어카운트의 의미가 달라지는곳을 기준으로 자르면된다는소리임
		
		ddd에서는 단일도메인모델로 복잡한 시스템을 다루지않음,오히려 시스템에 공존하는 여러 독립모델을 설계함
		그리고 이런 하위도메인들은 인터페이스를 사용해서 서로 통신함(restapi)
		이렇게 더 큰 시스템에서 다양한 도메인의 표현과 이들이 협업하는 방식을 콘텍스트맵이라고 하고,
		해당 협업을 식별하고 설명하는작업을 콘텍스트맵핑이라고 함
		
		ddd는 제한된 콘텍스트를 매핑할때 몇가지 주요유형의 상호작용을 식별함
		
		가장 기본은 공유커널임
		우연하게 두가지의 하위집합이 겹칠때,그냥 하나만 만들어서 쓰거나 합치는것
		이건 근데 마이크로서비스상에선 서로 둘다 소유를 하고있으면 조정작업이 많이필요하기때문에,한쪽을 소유자로 하고 한쪽을 기여자로 하는식으로 하는게좋음
		한쪽이 만들고 한쪽이 그냥 가져다쓰는것
		여기서 또 나눠지는데
			고객-공급자는 공급자가 만드는데 고객에 문제 안생기게 신경쓰면서 만드는것,즉 하위호환성에 문제가 생기지않게 신경써야함
			
			순응은 공급자는 전혀신경안쓰고 코드를 변경하고,고객에서 알아서 맞춰가야하는것
			이건 보통 엄청 큰(aws)걸 가져다쓸때 보통이렇게됨
			
			부패방지계층은  고객은 공급자의 인터페이스변경으로부터 자신을 보호하기위해 부패방지계층을 만들어서 사용할수있음
			
			오픈호스트 서비스는 공급자가 자신이 사용할 인터페이스를 정의하고 공개해서,거기에 맞춰서 공급자와 고객이 인터페이스를 맞춰서 사용함
			이거도 큰곳에서 작은곳할때 많이사용됨
			
		
		그리고 제한된 콘텍스트는 동기식과 비동기식으로 통합할수있음
		동기식으로 통합은 restapi고,비동기식 통합은 게시-구독 패턴을 사용함
		여기서 비동기식으로 할땐,공급자가 쿠버네티스같은데 업데이트를 시키고,고객은 업데이트된 파드에 접근해서 가져다쓰는것
		
		비동기식은 만들땐 좀복잡한데,만들고나면 어떤 기술스택에서도 가져다쓸수있어서 확장성과 탄력성,유연성이 높음
		
		ddd집합체는 외부소비자가 단일단위로 볼수있는 관련 도메인객체의 모임임
		즉 api라고 보면됨,api는 안의 여러 도메인(마이크로서비스)를 가져다가 사용하지만 소비자의경우엔 안은 관심없고 그냥 api만 보이는것과 동일함
		
			
	3.이벤트 스토밍
		이벤트 스토밍은 ddd에서 좀더 쉽게 단순화한거임
		이건 그냥 모든사람이 모여서(프로그래머말고 제품소유자,디자이너등 다같이)
			1.현재 분석중인 도메인의 주요이벤트를 작성하고
			  대략적으로 먼저발생한걸 왼쪽에,나중에발생한걸 오른쪽에 배치함(중복제거는나중에)
			2.중복을 제거하고 타임라인을 정돈함,이상하다싶은건 표시해두고 넘어감 
			3.역방향으로 이벤트를 발생시킨 명령을 식별함,
			  즉 특정 명령에 따른 이벤트들로 구분함(결제를 누르면 결제처리하고 탑승권생성하고 이메일로 보내는 3개같은)
			  이 명령들은 대부분 1대1이지만,좀 복잡한것들은 안에 여러이벤트가 포함되어있음
			4.관련된 명령들을 클래스처럼 모아둠(리워드관리나 설문조사처럼 큰틀에서 모아둠)
			5.이게 제한된 콘텍스트임,여기서 이득/노력별로 분류해서 배분함(이건옵션)

	4.범용 크기 조정 공식
		기본적으로 이런식으로 마이크로서비스의 크기를 정하기 좋음,단 마이크로서비스의 경계가 제한된 콘텍스트와의 동의어는 아님
		마이크로서비스의 경계는 시간에 따라 변할수있고,점점 더 세분화된 마이크로서비스를 따르는 경향이 있음
		그리고 일반적으로 서비스를 다시합치거나,서비스에서 다른서비스로 기능이전하는거보다 서비스를 분할하는게 더 쉽다는거도 알아야함
		그래서 크게나누고 좀 만들고나서 나누라는거
		여기에 따른 규칙은
			제한된 콘텍스트를 사용할수있는 몇개의 마이크로서비스로 시작
			앱과 서비스가 성장함에 따라 마이크로서비스간 조정이 필요하면,조정을 제거하기위해 서비스를 분할
			조정을 줄이기위한 궤적을 유지해야함,이건 서비스크기를 완벽하게 정하는지에 대한 현재상태보다 훨씬 더 중요함



5.데이터 처리
	마이크로서비스에서 가장 먼저 발생하는 문제는,데이터처리문제임
	마이크로서비스가 느슨하게 결합되고 독립적으로 배포될수있어야하면,외부에 영향을 받거나 주는게 없어야함
	근데 여러 마이크로서비스가 같은 데이터공간을 동시에 점유하고있을경우에는 서로 영향을 줘서 독립적인 코드배포가 안되게됨
	이걸 해결하는게 중요한문제임
	
	1.데이터를 포함하는 마이크로서비스
		만약 마이크로서비스가 특정 테이블의 필드유형을 변경해야하면,같은곳을 점유하는 다른 마이크로서비스들이 전부 영향을 받음
		그래서 이거떄문에 다른 마이크로서비스들도 다 수정해야하는데,이거자체가 독립배포가 안되는문제가 됨
		
		그렇다고 각 마이크로서비스마다 db1개를 할당할수도 없음
		
		그래서 나온 패턴이 데이터 포함 및 데이터 위임 패턴임
		
		모든 마이크로서비스는 직접 db를 호출하는게 아니고,중간에 api를 둬서 그쪽에다가 요청을하고,거기서 db에 접근함
		이러면 중간에 가공할수있는 장소도 생기고 db하나는 하나의 서비스가 점유하게됨
		그렇지만 이거만가지고 모든문제가 해결되진않음
		예를들어 머신러닝이나 분석,데이터트랜잭션등이 있음
		
		머신러닝이나 분석등 데이터에 대한 수정없이 읽기전용접근이 필요한경우에 일반적인 솔루션은,
		자기가 사용할때 자기공간으로 데이터를 복사해서 사용하는것
		이때 데이터를 축적할땐,따로 데이터레이크에 기록하는게 아니라,그냥 마이크로서비스들은 자기db에 계속 기록하고,
		그걸 모아서 참조하는 마이크로서비스가 데이터레이크에 참조를 넣는거임,즉 데이터레이크에 기록하는게 아닌,단순참조의 모음임
		이거로 읽기전용은 해결되는데 트랜잭션은 해결되지않음
		
		트랜잭션은 acid로 커밋이 일어나기전에 모든걸 기록하고 원복함,
		문제는 트랜잭션은 배타적 잠금으로,하나가 점유하고있을때엔 다른곳에서 접근을 할수없어져서 마이크로서비스에선 사용하기가 힘듬
		그래서 나온게 사가트랜잭션임
		이건 원래상태로 돌리는게 아닌,한 이벤트에 앞으로 진행할때와 만약 잘못되었을때(실패했을때) 해야할 이벤트를 둘다 작성해서,
		완료가 될때까지 스택에 쌓아두고 만약 실패하면 지금까지  스택에 들어있는 실패이벤트만 전부 순서대로 작동시키는거임
		
		얘는 acid와 다른건,초기상태로 돌아갈거라고 보장할순없지만,이정도면 됐다싶을정도로 프로그래머가 작성하면 거기까지 돌아갈수있음
		얘의 장점은,트랜잭션은 어디서 문제가 생겼나 알수없지만 얘는 어디서 문제가 생겼나를 알수있음
		그리고 얘는 이벤트의 순서가 중요하니까,보상하기 어려운문제를 트랜잭션 마지막단계쪽으로 이동시키는게 좋음(알람같은 한번뱉으면 되돌릴수없는것)
		
	3.이벤트소싱과 CQRS
		위의 3개가지고 어지간한건 해결할수있지만(데이터위임,데이터레이크,사가 트랜잭션),다른방법이 필요할경우도 있음
		기본적으로 관계형 데이터베이스를 사용하면 이거때문에 데이터격리와 느슨한 결합을 지원하지 못하는경우가 발생함,예를들어 조인을 하는것
		그래서 사용하는게 이벤트소싱임
		
		이건 초기상태를 미리 정해두고(템플릿),여기에서 바뀐거를 순서대로 나열해가는식임
		롤에서 리플레이 데이터를 저장하는방식임
		만약 누가 움직였다면,누가 어느방향으로 얼만큼 이동했다는거만 기록하고,현재 상태를 기록하지않는식
		이걸 계속 더해서 마지막결과값이 현재상태임
		
		그리고 이걸 계속 더하는거도 작업량 많으니까,시간단위나 갯수단위로 스냅샷을 만들어서 중간에 기록하고,그걸 다시 시작값으로 삼아서 계속 기록해나감
		
		이벤트는 
			고유식별자(전역적으로 고유함을 보장하는 id값)이 필요하고,
			이벤트 유형을 적어야 헷갈리지않음
			그리고 데이터가 있어야함
			
		그리고 현재상태를 계산할땐 프로젝션을 사용하면됨,이걸가지고 판단하고 다음 이벤트를 적을지말지 판단하고 적을수있음
		그리고 프로젝션의 코스트가 높으니까,스냅샷을 만들어서 계산량을 줄일수있음
		
		이게 이벤트소싱이고,이벤트 스토어는 그냥 파일을 저장할수만 있으면됨
		이떄 필요한 조건은
			새이벤트를 저장하고 시퀸스대로 저장한순서대로 이벤트검색가능
			이벤트에 대한 프로젝션을 생성한 구독자에게 알림을 생성하고 경쟁소비자패턴을 활성화하는 기능
			조정흐름을 위해 특정 유형의 이벤트x이후에 n개의 이벤트를 가져올수있는 기능(프로젝션이 손상된게 의심될때 다시계산)
		만 만족하면됨
		
		이때 이벤트스토어의 기본 인터페이스는
			save(x)
			getNAfterX()
		두개임
		세이브는 말그대로 저장,getNAfterX는 x이후 n개를 가져오는것(0부터 끝까지 가져오면 전체검색같이)
		그리고 추가로 필요한건 이벤트를 구독할수있게하는 알림시스템임
		이 알림시스템은 데이터 손상으로 이어지는 이벤트 중복을 방지하기위해 단일 인스턴스에 한번만 전달되어야함
		이걸위해서 두가지방법이 있음
			1.신뢰성을 보장하는 메시지큐시스템을 구현
			2.소비자가 http엔드포인트를 콜백으로 등록할수있게 허용함,즉 소비자가 계속 갱신확인하면서 가져감
		즉 이건 푸시와 풀임,둘중 아무거나 선택하면됨
		
		그리고 이벤트소싱시스템은 cqrs로 알려진 보안패턴을 사용함
		cqrs패턴의 기본개념은 쿼리와 데이터저장이 동일할필요가 없다는것에서 시작함
		위의 이벤트스토어 기본인터페이스 2개로는,이벤트에 대한 정교한 쿼리를 수행할수 없음(where을 쓸수없음)
		그렇다고 저기다가 그런거넣는건,이벤트스토어가 복잡해져서 안되니까 이벤트스토어를 구독하는 다른시스템에서 처리함
		
		즉 이벤트스토어는 기본적인거만 처리하고,다른 세분화된 문제들은 각각 따로 메인을 구독하는 시스템을 만들어서 거기서 처리하는식
		
		그리고 이벤트소싱과 cqrs는 복잡도가 높아지니까,꼭 필요할떈 좋은데 일단 다른거(관계형모델)먼저 생각해보고 마지막에쓰자
		
		
	4.마이크로서비스 외에 이벤트소싱과 cqrs활용
		이벤트소싱은 마이크로서비스말고도 여러군데서 사용할수있음
		
		가장 대표적으로,cap이론을 어느정도 이길수있음(부분별로 바꿔가면서 사용)
		이벤트스토어에서 일관성의 우선순위를 정하고,쿼리인덱스에서 가용성의 우선순위를 정할수있음
		쿼리인덱스는 복사기때문에 일관성이 깨질수있지만,필요하면 다시받아서쓰면됨
		이런식으로 일관성과 가용성을 바꿔가면서 쓰는것
		
		두번째는 감사가능성에 있음
		만약 상태만 기록하면 문제가생겼을때 히스토리가 없어서 복구할 방법을 찾을수없는데,이벤트소싱이면 그냥 그전으로 돌아가면됨
		로그를 기록할수 있긴하지만,로그가 진실의 근원이라고 보장하기가 힘듬(로그를 잘못적을경우)
		
		
6.인프라 파이프라인 구축
	여기는 그냥 테라폼설치하고 aws계정생성하고 권한주고 하는데임
	아는건 생략하고 넘어가자
	
	데브옵스랑 마이크로서비스는 엄청 많은게 겹침,데브옵스의 모든것에서 추가로 제한된서비스와 독립적인 배포관리를 추가하면 마이크로서비스임
	그러니까 데브옵스 방식을 채택하고,거기에 추가로 한두개더하면 됨
	
	데브옵스에서 중요한건
		변경불가능한 인프라:한번생성되면 바꾸려면 파괴하고 다시생성해야함
		iac:코드로적힌 인프라
		ci/cd:지속통합/지속배포,소스를 지속적으로 통합하고,그걸 자동으로 테스트하고 배포함
	가 있음
	변경불가능한 인프라의 코스트를 낮추기위해 클라우드를 사용하고,
	iac를 위해 테라폼을 사용함
	그리고 한번에 큰변화가 생기면 되돌리기 힘드니까,변화를 나눠서 자잘하게 넣기위해 ci/cd파이프라인을 사용함
	보통 ci(도커파일생성)는 깃헙액션이나 젠킨스,cd는 깃헙액션이나 젠킨스로 쿠버네티스에 던지는식으로 작성함
	
	그리고 클라우드를 사용하기위해 aws에서 iam유저를 만들고 권한주고
	터미널에서 aws configure로 키와 시크릿액세스키를 넣어주고 리전과 아웃풋포맷(json같은)을 정함
	
	그리고 테라폼의 state를 클라우드에 저장하기위해(상태는 전역에서 하나만있는게 충돌문제때문에 좋음)s3버킷을 만들면됨
	
	1.iac 파이프라인 구축
		먼저 iac용 깃레포를 하나 만들고,깃이그노어를 테라폼템플릿으로 생성
		그리고 maintf에 백엔드를 s3로 생성하고 버킷이름,키,리전을 넣음
		그리고 init plan apply하고(일단 똑같이 생성은 해뒀으니까 aws에 아마 plan에서 노체인지뜰거임)
		
		그리고 이걸 자동으로 적용하는 파이프라인은 깃헙액션으로 만들면됨
		깃헙세팉ㅇ에서 시크릿을 고르고,aws_ACCESS_KEY_ID를 생성하고 패스워드도 생성함
		그리고 태그를 트리거로
			가상머신 프로비저닝
			코드가져오기
			도구설치후 환경설정
			테라폼의 형식지정
			코드검증
			plan실행
			apply실행
			config업로드
		를 순서대로하면됨

		깃헙액션 yaml은
			on:
				create:
					tags:
					-  v*
			jobs:
				build:
					runs-on:ubuntu
					env:
						AWS_ACCESS_KEY_ID:${{secrets.AWS_ACCESS_KEY_ID}}
						AWS_SECRET_ACCESS_KEY:${{secrets.AWS_SECRET_ACCESS_KEY}}
					steps:
					-  uses: actions/checkout@v2//가져올 태그

		여기서 on은 액션 발생시기고
		잡에서 실행할 가상머신의 os와 aws아이디를 주고,uses에서 특정태그를 가져옴
		여기까지가 프로비저닝후 코드가져오기
		
		종속성 설치는
			jobs:
				build:
					가상머신프로비저닝..
				steps:
				-  uses: actions/checkout@v2//가져올 태그
				-  name:aws-iam설치
				   run: |
					mkdir ~/aws
					curl -o ~/aws/aws-iam-authenticator \
					"https://amazon-eks.s3.us-west-2.amazonaws.com/\
					1.16.8/2020-04-16/bin/linux/amd64/aws-iam-authenticator"
					chmod +x ~/aws/aws-iam-authenticator
					sudo cp ~/aws/aws-iam-authenticator /usr/local/bin/aws-iam-authenticator
		이렇게 종류별로 name으로 나눠서 설치하면되고(안나눠도되지만 나누는게보기편함)
		테라폼 적용은
			jobs:
				build:
					가상머신프로비저닝..
				steps:
				-  uses: actions/checkout@v2//가져올 태그
				-  name:aws-iam설치
				   run: |
					  대충 awsiam설치하는내용
				-  uses: hashicorp/setup-terraform@v1
				   with:
					terraform_version: 0.12.19
				-  name: fmt
				   run: terraform fmt					  
				-  name: init
				   run: terraform init
				-  name: validate
				   run: terraform validate				   
				-  name: plan
				   run: terraform plan
				-  name: apply
				   run: terraform apply -auto-approve //auto-approve는 yes안쳐도되게하는거
		이렇게하면되고
		그리고 kubeconfig 업로드하면됨
			-name: 업로드 kubeconfig
			 uses: actions/upload-artifact@v2
			 with:
				name: kubeconfig
				path: kubeconfig

		이렇게
		이러면 태그가 올라가면 자동으로 테라폼이 실행돼서 적용되게됨(중간에 테스트하는거 빠졋는데 그건 실제할때넣으면됨,테라테스트등 사용)

7.마이크로서비스 인프라 구축
	여기선 쿠버네티스설치하고 argocd모듈같으거 설치해서 배포환경을 만듬
	1.인프라구성요소
		인프라는 마이크로서비스기반 앱을 배포,관리,지원할수있는 구성요소의 집합임
		인프라는 하드웨어,소프트웨어,네트워크,도구등 많은부분을 포함해서,범위가 넓기때문에 설정하고 실행하는것도 매우 큰작업임
		그래서 클라우드를 사용해서 좀더 쉽게 할수있게(iac와 변경불가능한 인프라)했음
		
		aws에서 네트워크는,vpc라고 하는 가상네트워크의 상위객체 안에 포함됨
		이 vpc는 서브넷으로 안에서 분리를 할수있고,
		트래픽이 드나드는 방식을 지정하는 객체로,서브넷에 방식을 설정할수있음
		
		그리고 컨테이너를 사용하면 간단히 작은단위로 배포를 할수있고,그래서 쿠버네티스를 사용해서 컨테이너 오케스트레이션을 함
		
		그리고 프로덕션에 서비스를 배포할땐,보통 릴리즈팀이 하는데 이걸 돕기위해 깃옵스배포서버를 사용함
		깃옵스는 깃을 단일소스저장소로 사용하고,깃에있는 모든것은 대상시스템에 상태여야함(테라폼의 상태와 같음)
		즉 선언적으로 깃의상태를 현재 프로덕션상태와 일치시킴
		이때 사용되는게 argocd이고 이걸사용하면 깃소스를 지정하면 거기에 변경사항이 생기고 테스트를 통과하면 자동으로 대상환경에 배포함
		
	2.인프라 구현
		인프라는 테라폼을 사용해서 정의하고 깃헙액션으로 인프라를 테스트하고 적용하면됨
		그래서 인프라설계를 모듈로 나누고 이걸 호출해야함
		
		일단 로컬이나 테스트할곳(샌드박스)에 kubectl을 설치해야함
		
		그리고 테라폼에 인프라만들땐
			모듈사용:한가지역할을 수행하는 작은 함수 작성
			캡슐화:내부데이터및 구현세부사항을 숨김
			반복피하기:반복되는건 한번만구현
		3가지를 지켜서 만들면됨
		
		즉 네트워크 모듈을 만들어서 프로덕션과 샌드박스에서 둘다 불러서 쓰는식
		
		각 모듈은 자체 디렉토리를 가지고,variables.tf,main.tf,outputs.tf 3개를 가짐,각각 변수,메인코드,출력을 담당함
		이런식으로하면 모듈을 한번 정의하고,이걸 매개변수화해서 한모듈로 여러환경을 구축할수있음(클래스처럼 사용가능)
		그리고 출력변수를 가지고,얘가 뭘만드는지 알수있게 표시할수있음
		
		네트워크모듈은 aws프로바이더선언으로 시작해서 리전정하고,
		vpc_name과 cluster_name 넣어주고 
		aws_vpc리소스에 사이더(192.168.0.0/16 이거)정하고 태그로(찾기쉽게) vpc이름과 쿠버네티스 클러스터이름 정함
		이거 값들은 전부 변수로넣어줘야함,하드코딩하면안됨

		이렇게 vpc를 만들면 이제 네트워크서브넷 구성이 가능해짐
		보통 쿠버네티스쓰면 eks를 쓸텐데,이때 서브넷을 2개씩 묶어서,공개와 비공개를 하나씩 두고 서로통신할수있게하고
		공개쪽에 로드밸런서등으로 뒤쪽으로 전달하는식으로 구성하면됨
		이때 서브넷을 쓰니까 ip대역을 분할해야하는데,이거도 하드코딩말고 data를 써서 입력을 받던지 매개변수받던지하면됨
		
		이때 서브넷은 aws_subnet을 리소스로 만들면되고,
		data로 입력을 받고
			data "aws_availability_zones" "availables"{
				state="available"
			}
		vpc_id(사용할vpc)와 cidr_block(vpc의 ip대역),availablility_zone(서브넷의 ip대역),각종태그들을 넣으면됨

		그리고 인터넷에서 접근가능하게하려면(공개) 인터넷게이트웨이를 vpc에 추가해야함,이건 사설클라우드를 공개인터넷에 연결하는 aws네트워크 구성요소임
			resource "aws_internet_gateway" "igw"{
				vpc_id=aws_vpc.main.id
				tags={
					태그들
				}
			}
			resource "aws_route_table" "public-route"{
				vpc_id=aws_vpc.main.id
				
				route{
					cidr_block= "0.0.0.0/0"
					gateway_id= aws_internet_gateway.igw.id
				}
			}
			resource "aws_route_table_association" "public-association"{
				subnet_id=aws_subnet.서브넷이름.id
				route_table_id= aws_route_table.public-route.id
			}

		이렇게 공개하면됨
		그리고 사설서브넷과 공개서브넷을 연결시켜주는게 필요한데,이때 사용되는게 nat임
		nat를 생성할땐 eip라는 유동적ip를 사용함
		이거로 고정ip를 유동ip로 받을수있음
			resource "aws_eip" "nat"{
				vpc=true
				태그
			}
			resource "aws_nat_gateway" "nat-gw"{
				allocation_id=aws_eip.nat.id
				subnet_id= aws_subnet.public-subnet.id
				depends_on=[aws_internet_gateway.igw]//종속성
				태그
			}

		이렇게만들면됨
		그리고 사설서브넷에 대한 라우팅추가는
			resource "aws_route_table" "private-route"{
				vpc_id=aws_vpc.main.id
				
				route{
					cidr_block= "0.0.0.0/0"
					nat_gateway_id= aws_nat_gateway.nat-gw.id
				}
			}
			resource "aws_route_table_association" "public-association"{
				subnet_id=aws_subnet.사설서브넷이름.id
				route_table_id= aws_route_table.private-route.id
			}
		이렇게 위랑 똑같은데 게이트웨이만 nat_gateway로 바뀜
		
		그리고 네트워크모듈의 variables.tf파일엔 
			env_name,
			aws_region,
			vpc_name,
			main_vpc_cidr,
			public_subnet_cidr,
			private_subnet_cidr,
			cluster_name
		전부 변수로 받으면됨,이때 전부 스트링으로 받으면됨
		
		다만들었으면 terraform fmt로 포맷변경(들여쓰가같은거 맞춰줌)
		init,validate하고 깃에 푸시하면 모듈은 끝임
		
		그리고 모듈 가져와서 사용할땐
			module "모듈에붙일이름"{
				source="모듈경로"
				모듈의 매개변수들...
			}
		이렇게 다 적으면 끝임
		그리고 plan 하고 푸시해서 자동으로 apply하게하면됨
		
		쿠버네티스모듈도 방식은 똑같음
		outputs.tf정의하고(이건 eks의 식별자와 다른모듈에서 클러스터에 접근할떄 사용하는값들)
			클러스터id
			클러스터이름
			클러스터인증데이터
			클러스터엔드포인트
			클러스터노드그룹id
		main.tf에 aws프로바이더 추가하고
			resource "aws_iam_role" "ms-cluster"{ //iam정책
				name=local.클러스터명
				assume_role_policy=<<POLICY
				{
					정책들적히는곳
				}POLICY
				
			}
			resource "aws_iam_role_policy_attachment" "EKSPolicy"{
				policy_arn= "n:aws:iam::aws:policy/AmazonEKSClusterPolicy"//정책경로
				role= aws_iam_role.ms-cluster.name
			}
		이렇게 eks가 aws를 사용할수있게 정책열어주고
		
		네트워크 보안정책을 정의함
			rosource "aws_security_group" "ms-cluster"{
				name = local.클러스터명
				vpc_id= var.vpc_id
				
				egress{
					from_port=0
					to_port=0
					protocol="-1"
					cidr_blocks=["0.0.0.0/0"]
				}
				태그
			}
		이렇게하면 이그레스(아웃바운드)는 무제한허용,인그레스는 거부
		
		그리고 eks클러스터를 생성하면됨
			resource "aws_eks_cluster" "mscl"{
				name=local.클러스터명
				role_arn= aws_iam_role.ms-cluster.arn
				
				vpc_config{
					security_group_ids=[aws_security_group.ms-cluster.id]
					subnet_ids=var.cluster_subnet_ids
				}
				depends_on=[
					aws_iam_role_policy_attachment.ms-cluster-AmazonEKSClusterPolicy
				]
			}
		이렇게 지금까지 만들어둔거 다 연결하면됨
		이렇게 생성하면 마스터노드(컨트롤플레인)이 생성됨
		그런데 워커노드가 없으니 워커노드를 추가해야함
		
		일단 여기도 iam룰과 정책을 추가하고(위랑같음)
			정책은 
				 arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy 워커노드정책
				 arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy이건 cni정책
				 arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly 컨테이너레지스트리리드온리 정책
			쓰고 나머진똑같이하면됨(aws_iam_role_policy_attachment 3개만들면됨)
			
		그리고 노드그룹을 만들어야함
			resource "aws_eks_node_group" "ms-node-group"{
				cluster_name=aws_eks_cluster.클러스터명.name
				node_group_name= 노드그룹에붙일이름
				node_role_arn=aws_iam_role.ms-node.arn
				subnet_ids=var.nodegroup_subnet_ids //변수에있는 노드그룹서브넷
				
				scaling_config{
					desired_size= 변수에있는 원하는스케일링사이즈크기
					max_size= 변수에있는 최대스케일링사이즈크기
					min_size = 변수에있는 최소스케일링사이즈크기
				}
				disk_size= 변수에있는 디스크사이즈
				instance_types= 변수에있는 인스턴스사이즈(t2.namo같은)
				
				depends_on=[
					arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy,
					arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy,
					arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly,
					
				]
			}

	이렇게만들면됨
	그리고 마지막으로,로컬파일로 kubeconfig를 만들어서 넣어주면됨
	이 kubeconfig의 값들은 만들어진 클러스터에서 값을 가져옴,이건 나중에 할때보자,그냥 값 다 가져오는거임
	
	그리고 variables에 변수선언해주고 fmt init validate하고 깃에 푸시하면됨
	
	사용할때도 똑같이 소스넣어주고 변수 다 적어주면 끝임
	그리고 awscli로
		aws eks list-clusters
	하면 나옴
	
	
	이제 argoCD를 설치하면되는데,이거도 테라폼모듈로 설치하면됨
	얘는 쿠버네티스 프로바이더를 사용함,하는김에 헬름도 같이깔면좋음(그러면 헬름으로 아르고설치할수있음)
		privider "kubernetes"{
			cluster_ca_certificate= base64decode(var.kubernetes_cluster_cert_data)//만들어둔 클러스터의 인증데이터넣기
			host= var.쿠버네티스클러스터엔드포인트
			exec{
				api_version="client.authentication.k8s.io/v1alpha1"
				command= "aws-iam-authenticator"
				args =["token","-i","$(var.클러스터이름)"]
			}
		}
	이렇게 전부 다 변수처리해서 받아오는식으로 처리하고
	헬름설치는
		provider "helm"{
			kubernetes{
				cluster_ca_certificate= base64decode(var.kubernetes_cluster_cert_data)//만들어둔 클러스터의 인증데이터넣기
				host=var.쿠버네티스클러스터엔드포인트
				exec{
					api_version="client.authentication.k8s.io/v1alpha1"
					command= "aws-iam-authenticator"
					args =["token","-i","$(var.클러스터이름)"]
				}
			}
		}

	이렇게 똑같이 넣어주면됨 위랑
	그리고
		resource "helm_release" "argocd"{
			name= "msur"
			chart="argo-cd"
			repository= "https://argoproj.github.io/argo-helm"
			namespace= "argo"
		}
	이렇게 레포정의하고 차트넣어서하면됨
	그리고 변수파일정의하고
	실제생성떈
		module "argo-cd-server"{
			source="경로"
			
			kubernetes_cluster_id=module.aws-eks.eks_cluster_id
			kubernetes_cluster_name=module.aws-eks.eks_cluster_name
			kubernetes_cluster_cert_data=module.aws-eks.eks_cluster_cert_data
			kubernetes_cluster_endpoint=module.aws-eks.eks_cluster_endpoint
			eks_nodegroup_id=module.aws-eks.eks_cluster_nodegroup_id
		}
	이런식으로 앞에있는 모듈의 값들을 참조하는식으로 넣으면됨



8.개발자 워크스페이스
	마이크로서비스에서 중요한건,권장하는 협업방식이 직관적이고 쉬워야함
	하기 어려우면 대부분 기피해서 안함(알약같은거임)
	그래서 초기단계에서 반복적이고 예측가능한 표준화된 개발 프로세스를 만들어야함
	이때 가장유명하고,잘쓰이는게 ci/cd파이프라인개발임
	이거로 모듈화된 파이프라인을 가지고,최대한 변경없이 모든팀에서(템플릿만 가지고)사용할수있게 만들어야함
	
	이거외에도 로컬개발 워크스페이스와 팀이 코드를 생성할때 사용하는방법도 중요함
	
	1.코딩표준과 개발자 설정
		표준을 만들땐,방법을 제시하기전에 이유에대해 공감을 해야함
		이를위해서 명확한 목표를 제시하는게 중요함
		이때 추천할만한 목표는 3개임
			짧은시간내에 코드설정이 가능해야함
			새로운마이크로서비스는 빠르고,쉽고,예측가능해야함:보일러플레이트(템플릿코드)를 활용해서 코드템플릿,
											테스트및 데이터설정의 자동화
											데이터저장소구성과 같은 종속성
											기본파이프라인부트스트랩을 포함해서 
											개발자가 새 ms를 시작할때 처음부터 모든걸 파악하지않아도되게함
											그리고 이 템플릿을 사람들이 막 불필요하게 변경하지못하게해야함
			품질관리는 자동화되어야함
			
		이 목표들을 위해 기본 가이드라인을 도출할수있음,
		추천하는 가이드라인은
			1.도커를 유일한 종속성으로 만들어서,어디든 똑같이 동작하게만듬
			2.실행환경이 원격이든 로컬이든 중요하지않고,똑같이 동작해야함(이게 안되는경우 예외원인을 정리해서 문서화해야함)
			3.서로 다른 기술스택의 워크스페이스를 준비(여러코드로 서로 연결해도 문제없어야함,최소 2가지이상으로 하는게 문제덜생김 나중에,그렇다고 너무많아도안댐)
			4.단일 마이크로서비스를 실행하는것과 여러 하위시스템으로 구성된 마이크로서비스를 실행하는게 똑같이 간단해야함
			5.가능하면 db는 로컬에서 실행(환경격리를위해,그리고 클라우드로 전환하는거도 간단해야함(로컬스택참고))
			6.컨테이너화 가이드라인 구현(테스트는 간단히하고,프로덕션에올릴땐 멀티스테이지등으로 가볍게해서올림)
			7.db 마이그레이션을 위한 간단한 규칙을 정함(데이터 스키마변경은 수동작업없이 코드화해서 적용해야함)
				이떄 원칙들은
				1.스키마변경에 대한 모든 변경사항은 db마이그레이션 스크립트에 코드화되어야하고,이름을 지정해서 날짜별로 관리해야함
				2.마이그레이션은 스키마변경과 샘플데이터삽입을 모두 지원해야함
				3.마이그레이션 실행은 make start로 프로젝트시작에 포함되어야하고,반드시 실행되어야함
				4.마이그레이션 실행은 자동화되어야하고 빌드에 포함되어야함
				5.마이그레이션작업이 어떤환경에서 실행되는지(또는 생략되는지) 지정할수있어야함,프로덕션에선 샘플생성을 건너뛸수있어야함
				6.이런규칙들을 rdbms와 nosql가릴거없이 모든곳에 적용되어야함
			8.실용적인 테스트자동화 방법을 정해야함
				아예없어도 안되고,너무 거기만 매달려서도 안됨
					1.모든 코드는 메인브랜치와 병합되기전에 충분히 의미있는 테스트가 작성되어야함
					2.팀은 동일스택의 코드베이스는 같은 접근방식을 통해야하고,사람마다 다른테스트를 하면안됨
					3.외부도구를 사용해서 성능테스트나 승인테스트를 수행할수있어야함,이런 도구들은 서비스코드와 저장소에 완전히 통합되어야하고,
					  사용과 실행은 간단해야함
					4.개별 마이크로서비스의 경계를 넘는 자동화테스트는 특별한 주의가 필요함
					5.코드린팅및 정적분석도구로 스타일을 일치시키는게 좋음
			9.분기및 병합규칙을 정해야함
				1.모든 개발은 feature나 bug브랜치에서 진행하고,
				2.브랜치를 메인으로 병합하려면 모든테스트를 통과해야함
				3.그리고 풀요청중에는 코드검토자가 커밋및 푸시이후 테스트결과를 쉽게 확인할수있어야함
				4.린팅이나 정적도구에서 오류발생하면 브랜치푸시와 메인의 병합을 막아야함
			10.공통사항은 makefile에 코드화해야함
				모든 코드저장소에는 사용된 스택에 상관없이 누구나 코드를 쉽게사용할수있는 makefile이 있어야함
				이거로 make run을 하면 동작하고,make test하면 자동화테스트를 할수있어야함
				이떄 표준타겟(명령어)는
					start:코드실행
					stop:코드중단
					build:코드빌드(컨테이너화)
					clean:캐시정리하고 처음부터실행
					add-module:모듈설치
					dependencies:종속성에 선언된 모든모듈설치되어있는지확인
					test:모든테스트실행
					test-unit:유닛테스트만 실행
					test-at:승인테스트만 실행
					lint:린터실행해서 확인
					migrate:마이그레이션실행
					add-migration:새 마이그레이션 생성
					logs:컨테이너 로그표시
					exec:컨테이너내에서 커맨드입력
				을 넣으면됨
				책에보면 예제있으니까 그거대로 넣으면될듯?테스트쪽만 바꾸고
				
	2.로컬 컨테이너 환경 구성
		개발자환경에 대한 유일한 의존성은 도커뿐이여야함,그래서 도커이외의 모든건 쉽게 설치할수있어야함
		가장 간단한방법은 vm으로 리눅스켜서 거기서 돌려보는것
		이때 책주인은 멀티패스가 가볍다고 그거쓰래
		vm내부에 도커를 설치하고
		상황따라서 쿠버네티스설치해서 올려보는거(스캐폴드를 쓰면 컨테이너생성도 들어있음)


9.마이크로서비스 개발































