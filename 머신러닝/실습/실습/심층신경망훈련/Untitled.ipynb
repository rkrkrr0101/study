{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "\n",
    "mymodel=keras.Sequential()\n",
    "mymodel.add(keras.layers.Flatten(input_shape=[32,32,3]))\n",
    "\n",
    "for _ in range(20):\n",
    "    mymodel.add(keras.layers.Dense(100,activation='selu',kernel_initializer='lecun_normal'))\n",
    "    \n",
    "\n",
    "mymodel.add(keras.layers.AlphaDropout(rate=0.1))\n",
    "mymodel.add(keras.layers.Dense(10,activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainxfull,trainyfull),(testx,testy)=keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx=trainxfull[5000:]\n",
    "trainy=trainyfull[5000:]\n",
    "vaildx=trainxfull[:5000]\n",
    "vaildy=trainyfull[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=keras.optimizers.Nadam(lr=5e-5)\n",
    "earlystop=keras.callbacks.EarlyStopping(patience=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.compile(loss='sparse_categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8008), started 19:52:08 ago. (Use '!kill 8008' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e025f8a4a440ea8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e025f8a4a440ea8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "modelcheckpoint=keras.callbacks.ModelCheckpoint('mymodel.h5',save_best_only=True)\n",
    "\n",
    "rootlogdir=os.path.join(os.curdir,\"mylog\")\n",
    "\n",
    "def getrunlogdir():\n",
    "    import time\n",
    "    runid=time.strftime(\"run %Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(rootlogdir,runid)\n",
    "runlogdir=getrunlogdir()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tenboard=keras.callbacks.TensorBoard(runlogdir)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=.mylog --port=6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-014b00888674>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_learning_rate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'find_learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "rates,losses=find_learning_rate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 2ms/step - loss: 1.6255 - accuracy: 0.4130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.625525951385498, 0.4129999876022339]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history=mymodel.fit(trainx,trainy,epochs=100,callbacks=[earlystop,modelcheckpoint,tenboard],validation_data=(vaildx,vaildy))\n",
    "\n",
    "model=keras.models.load_model('mymodel.h5')\n",
    "model.evaluate(vaildx,vaildy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
