{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.4.1-cp38-cp38-win_amd64.whl (370.7 MB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.15.1-py2.py3-none-any.whl (173 kB)\n",
      "Requirement already satisfied, skipping upgrade: six~=1.15.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting tensorboard~=2.4\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Using cached wrapt-1.12.1.tar.gz (27 kB)\n",
      "Requirement already satisfied, skipping upgrade: h5py~=2.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting google-pasta~=0.2\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel~=0.35 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting gast==0.3.3\n",
      "  Using cached gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Using cached tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (50.3.1.post20201107)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached google_auth-1.27.0-py2.py3-none-any.whl (135 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.7.1-py3-none-any.whl (36 kB)Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "\n",
      "  Using cached cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.11)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=a0cf7dd8cb1c34eb2dbd3286ce27482dbf62c31934b4782af9bf5ac922839f03\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-win_amd64.whl size=33714 sha256=6661252a8c34b58960ff1bbbe842682079cbe990b40d537378fe4ba219de7638\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: protobuf, termcolor, grpcio, pyasn1, pyasn1-modules, rsa, cachetools, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, absl-py, tensorboard-plugin-wit, tensorboard, keras-preprocessing, wrapt, google-pasta, flatbuffers, gast, tensorflow-estimator, astunparse, opt-einsum, tensorflow\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.1 flatbuffers-1.12 gast-0.3.3 google-auth-1.27.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 keras-preprocessing-1.1.2 markdown-3.3.3 oauthlib-3.1.0 opt-einsum-3.3.0 protobuf-3.15.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.1 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 wrapt-1.12.1\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion=keras.datasets.fashion_mnist\n",
    "(xtrainfull,ytrainfull),(xtest,ytest)=fashion.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvalid,xtrain=xtrainfull[:5000]/255.0,xtrainfull[5000:]/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvalid,ytrain=ytrainfull[:5000],ytrainfull[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest=xtest/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames=[\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classnames[ytrain[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))\n",
    "model.add(keras.layers.Dense(300,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(300,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 328,810\n",
      "Trainable params: 328,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1=model.layers[1]\n",
    "weights,biases=hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00229219,  0.00858283,  0.06352231, ...,  0.02159511,\n",
       "        -0.02195249,  0.03112411],\n",
       "       [ 0.00537666,  0.00751166, -0.02590044, ...,  0.0360168 ,\n",
       "        -0.02126121, -0.0335156 ],\n",
       "       [-0.03818116, -0.02454917,  0.0654828 , ...,  0.03831309,\n",
       "         0.02078115, -0.01234344],\n",
       "       ...,\n",
       "       [-0.00832899,  0.06392311,  0.0126477 , ...,  0.00070278,\n",
       "        -0.06814266,  0.07268412],\n",
       "       [ 0.03088173, -0.0250668 , -0.01277936, ...,  0.06131318,\n",
       "        -0.00302766, -0.05064335],\n",
       "       [ 0.01767946, -0.05592814, -0.0496998 , ..., -0.00646421,\n",
       "        -0.0611438 , -0.00431709]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"sgd\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 1.0255 - accuracy: 0.6676 - val_loss: 0.5115 - val_accuracy: 0.8206\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.5069 - accuracy: 0.8245 - val_loss: 0.4726 - val_accuracy: 0.8354\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4485 - accuracy: 0.8405 - val_loss: 0.4385 - val_accuracy: 0.8486\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.4164 - accuracy: 0.8517 - val_loss: 0.4034 - val_accuracy: 0.8638\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3965 - accuracy: 0.8602 - val_loss: 0.3806 - val_accuracy: 0.8676\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3822 - accuracy: 0.8651 - val_loss: 0.3695 - val_accuracy: 0.8726\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3671 - accuracy: 0.8691 - val_loss: 0.3601 - val_accuracy: 0.8754\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3573 - accuracy: 0.8736 - val_loss: 0.3526 - val_accuracy: 0.8764\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3478 - accuracy: 0.8757 - val_loss: 0.3587 - val_accuracy: 0.8728\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3387 - accuracy: 0.8790 - val_loss: 0.3376 - val_accuracy: 0.8796\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3265 - accuracy: 0.8829 - val_loss: 0.3383 - val_accuracy: 0.8774\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3217 - accuracy: 0.8858 - val_loss: 0.3386 - val_accuracy: 0.8806\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3125 - accuracy: 0.8880 - val_loss: 0.3274 - val_accuracy: 0.8846\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3049 - accuracy: 0.8904 - val_loss: 0.3213 - val_accuracy: 0.8852\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3001 - accuracy: 0.8935 - val_loss: 0.3358 - val_accuracy: 0.8808\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2872 - accuracy: 0.8986 - val_loss: 0.3266 - val_accuracy: 0.8828\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2935 - accuracy: 0.8930 - val_loss: 0.3291 - val_accuracy: 0.8784\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2828 - accuracy: 0.9004 - val_loss: 0.3366 - val_accuracy: 0.8794\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2744 - accuracy: 0.9002 - val_loss: 0.3144 - val_accuracy: 0.8868\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2703 - accuracy: 0.9020 - val_loss: 0.3117 - val_accuracy: 0.8914\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2637 - accuracy: 0.9041 - val_loss: 0.3152 - val_accuracy: 0.8868\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2584 - accuracy: 0.9049 - val_loss: 0.3006 - val_accuracy: 0.8892\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2585 - accuracy: 0.9084 - val_loss: 0.3054 - val_accuracy: 0.8888\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2493 - accuracy: 0.9103 - val_loss: 0.2980 - val_accuracy: 0.8930\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2486 - accuracy: 0.9095 - val_loss: 0.2973 - val_accuracy: 0.8930\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2445 - accuracy: 0.9113 - val_loss: 0.3138 - val_accuracy: 0.8898\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2415 - accuracy: 0.9126 - val_loss: 0.3073 - val_accuracy: 0.8906\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2337 - accuracy: 0.9145 - val_loss: 0.2966 - val_accuracy: 0.8900\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2307 - accuracy: 0.9161 - val_loss: 0.3132 - val_accuracy: 0.8872\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2250 - accuracy: 0.9186 - val_loss: 0.2955 - val_accuracy: 0.8952\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(xtrain,ytrain,epochs=30,validation_data=(xvalid,yvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as  pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.3250 - accuracy: 0.8847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3249695897102356, 0.8847000002861023]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.98],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xnew=xtest[:3]\n",
    "yproda=model.predict(xnew)\n",
    "yproda.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing=fetch_california_housing()\n",
    "\n",
    "xtrainfull,xtest,ytrainfull,ytest=train_test_split(housing.data,housing.target)\n",
    "xtrain,xvalid,ytrain,yvalid=train_test_split(xtrainfull,ytrainfull)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "xtrain=scaler.fit_transform(xtrain)\n",
    "xvalid=scaler.fit_transform(xvalid)\n",
    "xtest=scaler.fit_transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.Sequential([\n",
    "    keras.layers.Dense(30,activation='relu',input_shape=xtrain.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.6735 - val_loss: 22.4910\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 929us/step - loss: 0.4344 - val_loss: 17.7341\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 899us/step - loss: 0.4071 - val_loss: 15.3439\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 844us/step - loss: 0.4114 - val_loss: 13.9443\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.4003 - val_loss: 12.9209\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.3845 - val_loss: 12.1388\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.4091 - val_loss: 11.6318\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3834 - val_loss: 10.7937\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.3776 - val_loss: 10.9875\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3618 - val_loss: 10.5019\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.3814 - val_loss: 10.2290\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 893us/step - loss: 0.3626 - val_loss: 9.8778\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.3723 - val_loss: 9.7413\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 932us/step - loss: 0.3746 - val_loss: 9.2315\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.3591 - val_loss: 9.2705\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3623 - val_loss: 8.9279\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3358 - val_loss: 8.6789\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3296 - val_loss: 8.4050\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - ETA: 0s - loss: 0.366 - 0s 934us/step - loss: 0.3634 - val_loss: 8.5271\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 908us/step - loss: 0.3379 - val_loss: 8.2131\n",
      "162/162 [==============================] - 0s 539us/step - loss: 0.4058\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer=\"sgd\")\n",
    "history=model.fit(xtrain,ytrain,epochs=20,validation_data=(xvalid,yvalid))\n",
    "msetest=model.evaluate(xtest,ytest)\n",
    "xnew=xtest[:3]\n",
    "ypred=model.predict(xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1=keras.layers.Input(shape=xtrain.shape[1:])\n",
    "hidden1=keras.layers.Dense(30,activation=\"relu\")(input1)\n",
    "hidden2=keras.layers.Dense(30,activation=\"relu\")(hidden1)\n",
    "concat=keras.layers.Concatenate()([input1,hidden2])\n",
    "output1=keras.layers.Dense(1)(concat)\n",
    "model=keras.Model(inputs=[input1],outputs=[output1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1=keras.layers.Input(shape=[5],name=\"wide\")\n",
    "input2=keras.layers.Input(shape=[6],name=\"deep\")\n",
    "hidden1=keras.layers.Dense(30,activation=\"relu\")(input2)\n",
    "hidden2=keras.layers.Dense(30,activation=\"relu\")(hidden1)\n",
    "concat=keras.layers.Concatenate()([input1,hidden2])\n",
    "output1=keras.layers.Dense(1)(concat)\n",
    "model=keras.Model(inputs=[input1,input2],outputs=[output1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.2130 - val_loss: 0.8586\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8586 - val_loss: 0.7577\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7878 - val_loss: 0.6960\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.7239 - val_loss: 0.6495\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 924us/step - loss: 0.7035 - val_loss: 0.6108\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.6486 - val_loss: 0.5755\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 881us/step - loss: 0.6083 - val_loss: 0.5463\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.5810 - val_loss: 0.5218\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.5632 - val_loss: 0.4993\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.5526 - val_loss: 0.4817\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5088 - val_loss: 0.4665\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.5251 - val_loss: 0.4591\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.4881 - val_loss: 0.4542\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.4718 - val_loss: 0.4535\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 823us/step - loss: 0.4894 - val_loss: 0.4524\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 859us/step - loss: 0.4718 - val_loss: 0.4558\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.4535 - val_loss: 0.4577\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.4561 - val_loss: 0.4653\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.4588 - val_loss: 0.4702\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.4463 - val_loss: 0.4740\n",
      "162/162 [==============================] - 0s 595us/step - loss: 0.5076\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\",optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "xtraina,xtrainb=xtrain[:,:5],xtrain[:,2:]\n",
    "xvalida,xvalidb=xvalid[:,:5],xvalid[:,2:]\n",
    "xtesta,xtestb=xtest[:,:5],xtest[:,2:]\n",
    "xnewa,xnewb=xtesta[:3],xtestb[:3]\n",
    "\n",
    "history=model.fit((xtraina,xtrainb),ytrain,epochs=20,validation_data=((xvalida,xvalidb),yvalid))\n",
    "msetest=model.evaluate((xtesta,xtestb),ytest)\n",
    "ypred=model.predict((xnewa,xnewb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4510 - val_loss: 0.4860\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.4480 - val_loss: 0.4916\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 910us/step - loss: 0.4454 - val_loss: 0.4991\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4432 - val_loss: 0.5068\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.4407 - val_loss: 0.5175\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.4388 - val_loss: 0.5260\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.4364 - val_loss: 0.5361\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.4349 - val_loss: 0.5380\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.4330 - val_loss: 0.5463\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.4311 - val_loss: 0.5614\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 891us/step - loss: 0.4296 - val_loss: 0.5654\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 870us/step - loss: 0.4284 - val_loss: 0.5663\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.4268 - val_loss: 0.5781\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.4255 - val_loss: 0.5866\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.4239 - val_loss: 0.5886\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.4228 - val_loss: 0.6043\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.4218 - val_loss: 0.6135\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.4202 - val_loss: 0.6200\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.4195 - val_loss: 0.6265\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 900us/step - loss: 0.4182 - val_loss: 0.6250\n"
     ]
    }
   ],
   "source": [
    "class Widedeepmodel(keras.Model):\n",
    "    def __init__(self,units=30,activation=\"relu\",**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1=keras.layers.Dense(units,activation=activation)\n",
    "        self.hidden2=keras.layers.Dense(units,activation=activation)\n",
    "        self.main_output=keras.layers.Dense(1)\n",
    "        self.aux_output=keras.layers.Dense(1)\n",
    "    def call(self,inputs):\n",
    "        inputa,inputb=inputs\n",
    "        hidden1=self.hidden1(input_b)\n",
    "        hidden2=self.hidden2(hidden1)\n",
    "        concat=keras.layers.concatenate([inputa,hidden2])\n",
    "        main_output=self.main_output(concat)\n",
    "        aux_output=self.aux_output(hidden2)\n",
    "        return main_output,aux_output\n",
    "checkpointcb=keras.callbacks.ModelCheckpoint('mymodel.h5')\n",
    "history=model.fit((xtraina,xtrainb),ytrain,epochs=20,validation_data=((xvalida,xvalidb),yvalid),callbacks=[checkpointcb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "rootlogdir=os.path.join(os.curdir,\"mylog\")\n",
    "\n",
    "def getrunlogdir():\n",
    "    import time\n",
    "    runid=time.strftime(\"run %Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(rootlogdir,runid)\n",
    "runlogdir=getrunlogdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4170 - val_loss: 0.6367\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.4158 - val_loss: 0.6396\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.6552\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 913us/step - loss: 0.4138 - val_loss: 0.6592\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4126 - val_loss: 0.6630\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.4117 - val_loss: 0.6695\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.6705\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 933us/step - loss: 0.4095 - val_loss: 0.6772\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.4084 - val_loss: 0.6842\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 919us/step - loss: 0.4074 - val_loss: 0.6951\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.4065 - val_loss: 0.6929\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.4055 - val_loss: 0.7053\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.4044 - val_loss: 0.7037\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 829us/step - loss: 0.4039 - val_loss: 0.7198\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 849us/step - loss: 0.4026 - val_loss: 0.7203\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 898us/step - loss: 0.4017 - val_loss: 0.7319\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 884us/step - loss: 0.4007 - val_loss: 0.7542\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 904us/step - loss: 0.3996 - val_loss: 0.7680\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 912us/step - loss: 0.3989 - val_loss: 0.7666\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 880us/step - loss: 0.3980 - val_loss: 0.7729\n"
     ]
    }
   ],
   "source": [
    "tensorboard=keras.callbacks.TensorBoard(runlogdir)\n",
    "history=model.fit((xtraina,xtrainb),ytrain,epochs=20,validation_data=((xvalida,xvalidb),yvalid),callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.7772\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.3960 - val_loss: 0.7677\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3954 - val_loss: 0.7912\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.7949\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.8052\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3928 - val_loss: 0.8003\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3923 - val_loss: 0.8175\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.3913 - val_loss: 0.8343\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3905 - val_loss: 0.8280\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 945us/step - loss: 0.3896 - val_loss: 0.8345\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.3889 - val_loss: 0.8545\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.3883 - val_loss: 0.8690\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 931us/step - loss: 0.3876 - val_loss: 0.8635\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3869 - val_loss: 0.8798\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.8935\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 922us/step - loss: 0.3853 - val_loss: 0.8939\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 871us/step - loss: 0.3846 - val_loss: 0.8806\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3840 - val_loss: 0.9158\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 906us/step - loss: 0.3833 - val_loss: 0.9130\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3827 - val_loss: 0.9274\n"
     ]
    }
   ],
   "source": [
    "checkpointcb=keras.callbacks.ModelCheckpoint('mymodel.h5',save_best_only=True)\n",
    "history=model.fit((xtraina,xtrainb),ytrain,epochs=20,validation_data=((xvalida,xvalidb),yvalid),callbacks=[checkpointcb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3821 - val_loss: 0.9341\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 984us/step - loss: 0.3815 - val_loss: 0.9448\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3810 - val_loss: 0.9509\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 929us/step - loss: 0.3805 - val_loss: 0.9509\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3797 - val_loss: 0.9394\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.3793 - val_loss: 0.9657\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.3788 - val_loss: 0.9789\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 903us/step - loss: 0.3780 - val_loss: 0.9845\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 896us/step - loss: 0.3774 - val_loss: 0.9913\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3767 - val_loss: 0.9929\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 939us/step - loss: 0.3764 - val_loss: 0.9978\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 917us/step - loss: 0.3757 - val_loss: 1.0022\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3752 - val_loss: 1.0169\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 920us/step - loss: 0.3747 - val_loss: 1.0152\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.3740 - val_loss: 1.0202\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.3736 - val_loss: 1.0549\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 868us/step - loss: 0.3730 - val_loss: 1.0509\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 891us/step - loss: 0.3723 - val_loss: 1.0566\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 962us/step - loss: 0.3720 - val_loss: 1.0600\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3713 - val_loss: 1.0651\n"
     ]
    }
   ],
   "source": [
    "ensorboard=keras.callbacks.TensorBoard(runlogdir)\n",
    "history=model.fit((xtraina,xtrainb),ytrain,epochs=20,validation_data=((xvalida,xvalidb),yvalid),callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmodel(n_hidden=1,n_neurons=30,learning_rate=3e-3,input_shape=[8]):\n",
    "    model=keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons,activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer=keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\",optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg=keras.wrappers.scikit_learn.KerasRegressor(buildmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.3323 - val_loss: 2.5123\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 799us/step - loss: 0.9482 - val_loss: 2.8230\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 905us/step - loss: 2.1609 - val_loss: 2.0409\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 876us/step - loss: 0.4872 - val_loss: 2.0544\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 782us/step - loss: 0.4803 - val_loss: 2.0934\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 831us/step - loss: 0.4763 - val_loss: 2.0993\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 895us/step - loss: 0.4470 - val_loss: 2.1053\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 846us/step - loss: 0.4306 - val_loss: 2.0820\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 815us/step - loss: 0.4161 - val_loss: 2.0897\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 799us/step - loss: 0.4279 - val_loss: 2.1176\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 848us/step - loss: 0.4201 - val_loss: 2.0716\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 850us/step - loss: 0.4225 - val_loss: 2.1001\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 816us/step - loss: 0.4229 - val_loss: 2.1025\n",
      "162/162 [==============================] - 0s 527us/step - loss: 0.4635\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000287CE80E310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "keras_reg.fit(xtrain,ytrain,epochs=100,validation_data=(xvaild,yvalid),callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test=keras_reg.score(xtest,ytest)\n",
    "ypred=keras_reg.predict(xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6401 - val_loss: 2.1280\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5936 - val_loss: 2.0326\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4498 - val_loss: 2.0527\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4153 - val_loss: 2.1737\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 0.3926 - val_loss: 2.1043\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 2.1500\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3691 - val_loss: 2.2742\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3720 - val_loss: 2.1330\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3562 - val_loss: 2.2416\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3700 - val_loss: 2.1625\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3529 - val_loss: 2.1991\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3406 - val_loss: 2.2548\n",
      "121/121 [==============================] - 0s 548us/step - loss: 0.3534\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.3745 - val_loss: 2.1405\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4662 - val_loss: 2.1471\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4016 - val_loss: 2.1045\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 2.2603\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3524 - val_loss: 2.1936\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3757 - val_loss: 2.2068\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 2.2726\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4374 - val_loss: 2.1369\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3354 - val_loss: 2.3680\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3548 - val_loss: 2.1958\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 2.2354\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 934us/step - loss: 0.3317 - val_loss: 2.2138\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3279 - val_loss: 2.2641\n",
      "121/121 [==============================] - 0s 582us/step - loss: 0.3819\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.4116 - val_loss: 2.0914\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5206 - val_loss: 2.1806\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5262 - val_loss: 2.0993\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 2.1731\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 2.1902\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3732 - val_loss: 2.1901\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3975 - val_loss: 2.2113\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3640 - val_loss: 2.2732\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3616 - val_loss: 2.2039\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3619 - val_loss: 2.1791\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3598 - val_loss: 2.3126\n",
      "121/121 [==============================] - 0s 557us/step - loss: 0.3511\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 10.1622 - val_loss: 4.5616\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 852us/step - loss: 4.1965 - val_loss: 2.9606\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 2.5286 - val_loss: 2.2877\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 882us/step - loss: 1.6570 - val_loss: 1.9985\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 1.2341 - val_loss: 1.8812\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.9674 - val_loss: 1.8441\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.8686 - val_loss: 1.8420\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.7642 - val_loss: 1.8545\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7369 - val_loss: 1.8723\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.7088 - val_loss: 1.8883\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.7068 - val_loss: 1.9029\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.6964 - val_loss: 1.9154\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.6686 - val_loss: 1.9264\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.6584 - val_loss: 1.9339\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.6457 - val_loss: 1.9386\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 896us/step - loss: 0.6591 - val_loss: 1.9425\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.6465 - val_loss: 1.9451\n",
      "121/121 [==============================] - 0s 540us/step - loss: 0.6099\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 6.1893 - val_loss: 4.4846\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3819 - val_loss: 3.3359\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 2.1281 - val_loss: 2.8254\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 1.4321 - val_loss: 2.5989\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 1.0297 - val_loss: 2.5008\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.8905 - val_loss: 2.4660\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.6916 - val_loss: 2.4575\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.6689 - val_loss: 2.4627\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.6683 - val_loss: 2.4705\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5946 - val_loss: 2.4775\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.5963 - val_loss: 2.4827\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5785 - val_loss: 2.4862\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5705 - val_loss: 2.4885\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.5231 - val_loss: 2.4877\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.5415 - val_loss: 2.4868\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5398 - val_loss: 2.4860\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5448 - val_loss: 2.4835\n",
      "121/121 [==============================] - 0s 524us/step - loss: 2.1081\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 7.8903 - val_loss: 4.5854\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 3.8996 - val_loss: 3.0975\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 2.4860 - val_loss: 2.4286\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 1.6361 - val_loss: 2.1264\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 1.1626 - val_loss: 1.9955\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.9369 - val_loss: 1.9440\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 915us/step - loss: 0.8037 - val_loss: 1.9307\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.7381 - val_loss: 1.9342\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.6627 - val_loss: 1.9438\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 916us/step - loss: 0.6494 - val_loss: 1.9542\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.6325 - val_loss: 1.9642\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.6019 - val_loss: 1.9716\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5865 - val_loss: 1.9780\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5666 - val_loss: 1.9835\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 899us/step - loss: 0.5580 - val_loss: 1.9874\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 926us/step - loss: 0.5520 - val_loss: 1.9912\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5779 - val_loss: 1.9941\n",
      "121/121 [==============================] - 0s 520us/step - loss: 0.5971\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.4186 - val_loss: 1.8483\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.6970 - val_loss: 2.0399\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.6332 - val_loss: 2.0660\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.6197 - val_loss: 2.0466\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5859 - val_loss: 2.0393\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5875 - val_loss: 2.0463\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5139 - val_loss: 2.0246\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5374 - val_loss: 2.0400\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.5084 - val_loss: 2.0503\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 975us/step - loss: 0.5063 - val_loss: 2.0416\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4783 - val_loss: 2.0838\n",
      "121/121 [==============================] - 0s 582us/step - loss: 0.4785\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.6908 - val_loss: 1.9698\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7482 - val_loss: 2.0782\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6652 - val_loss: 2.0623\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.6272 - val_loss: 2.0708\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.5864 - val_loss: 2.0629\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.5562 - val_loss: 2.0557\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5638 - val_loss: 2.0712\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5335 - val_loss: 2.0688\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 972us/step - loss: 0.5174 - val_loss: 2.0666\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5189 - val_loss: 2.0640\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5158 - val_loss: 2.0794\n",
      "121/121 [==============================] - 0s 507us/step - loss: 0.5515\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.7941 - val_loss: 1.8754\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7787 - val_loss: 2.0634\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7421 - val_loss: 2.0555\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.7161 - val_loss: 2.0404\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.6278 - val_loss: 2.0449\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.6289 - val_loss: 2.0556\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6009 - val_loss: 2.0497\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.5516 - val_loss: 2.0474\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.5437 - val_loss: 2.0334\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5100 - val_loss: 2.0522\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5169 - val_loss: 2.0488\n",
      "121/121 [==============================] - 0s 582us/step - loss: 0.5357\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 1.9246 - val_loss: 2.3739\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.9119 - val_loss: 4.5488\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 1.0322 - val_loss: 3.7814\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.9782 - val_loss: 6.0879\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.6421 - val_loss: 2.1600\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.4232 - val_loss: 2.1365\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4074 - val_loss: 2.0947\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 987us/step - loss: 0.3893 - val_loss: 2.1971\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.3795 - val_loss: 2.1384\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3482 - val_loss: 2.1886\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.3561 - val_loss: 2.1619\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.3299 - val_loss: 2.1485\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 961us/step - loss: 0.3297 - val_loss: 2.1905\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.3446 - val_loss: 2.1961\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.3395 - val_loss: 2.1393\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3443 - val_loss: 2.2017\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.3347 - val_loss: 2.1925\n",
      "121/121 [==============================] - 0s 549us/step - loss: 0.3443\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.8713 - val_loss: 2.0382\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.5931 - val_loss: 2.0163\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5462 - val_loss: 2.0160\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4559 - val_loss: 2.0281\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4862 - val_loss: 2.0338\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 991us/step - loss: 0.4678 - val_loss: 2.1055\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4255 - val_loss: 2.1157\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 0.4387 - val_loss: 2.1341\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 2.0988\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.4153 - val_loss: 2.1886\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4045 - val_loss: 2.1993\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.3960 - val_loss: 2.1409\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.4464 - val_loss: 2.1509\n",
      "121/121 [==============================] - 0s 605us/step - loss: 0.4494\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.1293 - val_loss: 2.3835\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 964us/step - loss: 0.7734 - val_loss: 4.0705\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12.5118 - val_loss: 2.1235\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.4784 - val_loss: 2.1209\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 995us/step - loss: 0.4287 - val_loss: 2.0766\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4116 - val_loss: 2.0930\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 2.1698\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.3969 - val_loss: 2.1589\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 0.3602 - val_loss: 2.1652\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.3753 - val_loss: 2.1967\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.3780 - val_loss: 2.1576\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.3718 - val_loss: 2.1943\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.3648 - val_loss: 2.1764\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.3652 - val_loss: 2.1953\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 2.1404\n",
      "121/121 [==============================] - 0s 549us/step - loss: 0.3777\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.0792 - val_loss: 7.3280\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 1.6962 - val_loss: 183.9301\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 95.5952 - val_loss: 4284.7783\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 1147.8682 - val_loss: 109240.4844\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 908us/step - loss: 104769.6999 - val_loss: 2719403.7500\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 842925.8568 - val_loss: 67411288.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 930us/step - loss: 240055956.2798 - val_loss: 1694153472.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 1858022284.8807 - val_loss: 41818959872.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 50365200347.1276 - val_loss: 1037084262400.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 1947820858346.9299 - val_loss: 25884199223296.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 116875807978196.8125 - val_loss: 652976964239360.0000\n",
      "121/121 [==============================] - 0s 582us/step - loss: 20909949714432.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.0793 - val_loss: 2.0445\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5732 - val_loss: 2.0627\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.5342 - val_loss: 2.1963\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5301 - val_loss: 2.2695\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.5418 - val_loss: 2.2925\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5515 - val_loss: 2.3078\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 904us/step - loss: 0.4904 - val_loss: 2.2884\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.4961 - val_loss: 2.3101\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5115 - val_loss: 2.3142\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5317 - val_loss: 2.3014\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5985 - val_loss: 2.3420\n",
      "121/121 [==============================] - 0s 499us/step - loss: 1.3821\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.4780 - val_loss: 25.5275\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 13.8053 - val_loss: 1010.3186\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 523.2406 - val_loss: 48222.9180\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 106722.4397 - val_loss: 2275081.2500\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 5640216.3523 - val_loss: 107109872.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 412301003.7912 - val_loss: 5066874880.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 29356043779.5226 - val_loss: 239439282176.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 355432728706.6337 - val_loss: 11309977436160.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 485025581098.1399 - val_loss: 547162492502016.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 929us/step - loss: 1075376982868844.5000 - val_loss: 25300131922313216.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 1394754458941060.7500 - val_loss: 1224194597098356736.0000\n",
      "121/121 [==============================] - 0s 665us/step - loss: 144426916802199552.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.0032 - val_loss: 2.4762\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 1.2336 - val_loss: 1.9568\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.7088 - val_loss: 1.9396\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6612 - val_loss: 1.9411\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 889us/step - loss: 0.5987 - val_loss: 1.9440\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 924us/step - loss: 0.5910 - val_loss: 1.9545\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.5803 - val_loss: 1.9475\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.5746 - val_loss: 1.9467\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 0.5799 - val_loss: 1.9483\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.5845 - val_loss: 1.9504\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.5932 - val_loss: 1.9659\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 864us/step - loss: 0.5813 - val_loss: 1.9638\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.5680 - val_loss: 1.9765\n",
      "121/121 [==============================] - 0s 527us/step - loss: 0.5366\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.0178 - val_loss: 2.5998\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 873us/step - loss: 1.2529 - val_loss: 2.1417\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 900us/step - loss: 0.7521 - val_loss: 2.0745\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.6776 - val_loss: 2.0543\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 966us/step - loss: 0.6225 - val_loss: 2.0297\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.6164 - val_loss: 2.0040\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.6013 - val_loss: 1.9815\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.5936 - val_loss: 1.9759\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5653 - val_loss: 1.9623\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.5936 - val_loss: 1.9633\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5495 - val_loss: 1.9642\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.5439 - val_loss: 1.9578\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 939us/step - loss: 0.5379 - val_loss: 1.9676\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5373 - val_loss: 1.9834\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.5349 - val_loss: 1.9873\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5113 - val_loss: 1.9958\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 2.0075\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5287 - val_loss: 2.0168\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5452 - val_loss: 2.0389\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5350 - val_loss: 2.0498\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.5130 - val_loss: 2.0553\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5259 - val_loss: 2.0727\n",
      "121/121 [==============================] - 0s 549us/step - loss: 0.8164\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.3530 - val_loss: 2.3496\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 1.2467 - val_loss: 1.9276\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.6836 - val_loss: 1.9080\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 921us/step - loss: 0.5992 - val_loss: 1.9219\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.5720 - val_loss: 1.9384\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 970us/step - loss: 0.5575 - val_loss: 1.9438\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.5818 - val_loss: 1.9562\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.5680 - val_loss: 1.9607\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.5478 - val_loss: 1.9690\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 943us/step - loss: 0.5473 - val_loss: 1.9696\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.5638 - val_loss: 1.9760\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5276 - val_loss: 1.9713\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5581 - val_loss: 1.9775\n",
      "121/121 [==============================] - 0s 565us/step - loss: 0.5647\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 7.1829 - val_loss: 3.7990\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 919us/step - loss: 3.6687 - val_loss: 2.4690\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 2.1676 - val_loss: 1.9737\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 1.4101 - val_loss: 1.8143\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 1.0297 - val_loss: 1.7862\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.8346 - val_loss: 1.8044\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.7523 - val_loss: 1.8364\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 869us/step - loss: 0.7189 - val_loss: 1.8660\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.6889 - val_loss: 1.8896\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.6686 - val_loss: 1.9092\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.6608 - val_loss: 1.9236\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.6727 - val_loss: 1.9323\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.6287 - val_loss: 1.9374\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.6215 - val_loss: 1.9400\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.6294 - val_loss: 1.9443\n",
      "121/121 [==============================] - 0s 549us/step - loss: 0.6045\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 8.2681 - val_loss: 3.8397\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 951us/step - loss: 3.2193 - val_loss: 2.6755\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 1.8452 - val_loss: 2.2485\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 1.2615 - val_loss: 2.1017\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 0.8978 - val_loss: 2.0613\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.7804 - val_loss: 2.0635\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.7097 - val_loss: 2.0771\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.6408 - val_loss: 2.0899\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 911us/step - loss: 0.6157 - val_loss: 2.1030\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 901us/step - loss: 0.6193 - val_loss: 2.1124\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5844 - val_loss: 2.1194\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5770 - val_loss: 2.1255\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.5854 - val_loss: 2.1294\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5826 - val_loss: 2.1304\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5926 - val_loss: 2.1315\n",
      "121/121 [==============================] - 0s 532us/step - loss: 0.8400\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.1257 - val_loss: 5.0143\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 2.8241 - val_loss: 3.5822\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 1.7239 - val_loss: 2.8924\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 1.1788 - val_loss: 2.5429\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.8885 - val_loss: 2.3590\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.7407 - val_loss: 2.2560\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.7137 - val_loss: 2.1972\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.6516 - val_loss: 2.1612\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.6445 - val_loss: 2.1376\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.6354 - val_loss: 2.1201\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 931us/step - loss: 0.6170 - val_loss: 2.1062\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 932us/step - loss: 0.6133 - val_loss: 2.0965\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5887 - val_loss: 2.0892\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.6428 - val_loss: 2.0821\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.6242 - val_loss: 2.0757\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.6141 - val_loss: 2.0703\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 0.5803 - val_loss: 2.0651\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5774 - val_loss: 2.0612\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 0.5959 - val_loss: 2.0571\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.5641 - val_loss: 2.0536\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5622 - val_loss: 2.0491\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5757 - val_loss: 2.0461\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5783 - val_loss: 2.0450\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 935us/step - loss: 0.5695 - val_loss: 2.0428\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 914us/step - loss: 0.5729 - val_loss: 2.0398\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 954us/step - loss: 0.5517 - val_loss: 2.0388\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5558 - val_loss: 2.0377\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 923us/step - loss: 0.5444 - val_loss: 2.0357\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 960us/step - loss: 0.5327 - val_loss: 2.0346\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.5598 - val_loss: 2.0329\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 999us/step - loss: 0.5783 - val_loss: 2.0320\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 947us/step - loss: 0.5288 - val_loss: 2.0301\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 950us/step - loss: 0.5612 - val_loss: 2.0295\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.5651 - val_loss: 2.0285\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5404 - val_loss: 2.0275\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 886us/step - loss: 0.5481 - val_loss: 2.0277\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 857us/step - loss: 0.5504 - val_loss: 2.0280\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 898us/step - loss: 0.5618 - val_loss: 2.0281\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 0.5231 - val_loss: 2.0272\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5460 - val_loss: 2.0264\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.5204 - val_loss: 2.0267\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 997us/step - loss: 0.5422 - val_loss: 2.0272\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 861us/step - loss: 0.5443 - val_loss: 2.0270\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5465 - val_loss: 2.0268\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 937us/step - loss: 0.5396 - val_loss: 2.0260\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 962us/step - loss: 0.5450 - val_loss: 2.0252\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.5498 - val_loss: 2.0249\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 0.5568 - val_loss: 2.0262\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 935us/step - loss: 0.5448 - val_loss: 2.0272\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 939us/step - loss: 0.5103 - val_loss: 2.0272\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5517 - val_loss: 2.0274\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5505 - val_loss: 2.0269\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5480 - val_loss: 2.0299\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 881us/step - loss: 0.5044 - val_loss: 2.0305\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.5117 - val_loss: 2.0306\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 2.0301\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 925us/step - loss: 0.5439 - val_loss: 2.0305\n",
      "121/121 [==============================] - 0s 556us/step - loss: 0.5525\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.9129 - val_loss: 1.9619\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5203 - val_loss: 2.1039\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4963 - val_loss: 2.1158\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4622 - val_loss: 2.0970\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4061 - val_loss: 2.0932\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3807 - val_loss: 2.1775\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 2.1885\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3792 - val_loss: 2.2670\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3596 - val_loss: 2.1682\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3649 - val_loss: 2.2469\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3487 - val_loss: 2.2499\n",
      "121/121 [==============================] - 0s 682us/step - loss: 0.3629\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.7475 - val_loss: 2.0086\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - val_loss: 2.0382\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4863 - val_loss: 2.0497\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4071 - val_loss: 2.0683\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3898 - val_loss: 2.1450\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3854 - val_loss: 2.1507\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3820 - val_loss: 2.2117\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4272 - val_loss: 2.1529\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3559 - val_loss: 2.1514\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3690 - val_loss: 2.2398\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3525 - val_loss: 2.1178\n",
      "121/121 [==============================] - 0s 582us/step - loss: 0.3666\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 1.6474 - val_loss: 2.2194\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7430 - val_loss: 2.0604\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4081 - val_loss: 2.1973\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4476 - val_loss: 2.1665\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 2.1248\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3526 - val_loss: 2.3676\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3603 - val_loss: 2.1421\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3668 - val_loss: 2.1663\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 2.2041\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3408 - val_loss: 2.2106\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3608 - val_loss: 2.2360\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3305 - val_loss: 2.1692\n",
      "121/121 [==============================] - 0s 557us/step - loss: 0.3525\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 6.1763 - val_loss: 4.0097\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 910us/step - loss: 2.7962 - val_loss: 2.7212\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 1.6246 - val_loss: 2.2128\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 1.1302 - val_loss: 2.0161\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 909us/step - loss: 0.9213 - val_loss: 1.9399\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 890us/step - loss: 0.7742 - val_loss: 1.9140\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 948us/step - loss: 0.7525 - val_loss: 1.9126\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 902us/step - loss: 0.7059 - val_loss: 1.9111\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.6799 - val_loss: 1.9138\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6956 - val_loss: 1.9173\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6381 - val_loss: 1.9199\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 952us/step - loss: 0.6498 - val_loss: 1.9223\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.6703 - val_loss: 1.9241\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 877us/step - loss: 0.6481 - val_loss: 1.9253\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.6479 - val_loss: 1.9262\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6409 - val_loss: 1.9273\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6125 - val_loss: 1.9286\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 913us/step - loss: 0.6384 - val_loss: 1.9290\n",
      "121/121 [==============================] - 0s 549us/step - loss: 0.6034\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.8350 - val_loss: 3.6005\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8413 - val_loss: 2.5742\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 868us/step - loss: 1.5467 - val_loss: 2.2284\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 985us/step - loss: 1.0443 - val_loss: 2.1280\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 955us/step - loss: 0.7609 - val_loss: 2.1093\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 840us/step - loss: 0.7107 - val_loss: 2.1201\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.6264 - val_loss: 2.1346\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.6202 - val_loss: 2.1484\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.6023 - val_loss: 2.1568\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6054 - val_loss: 2.1628\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 884us/step - loss: 0.5928 - val_loss: 2.1662\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 927us/step - loss: 0.5508 - val_loss: 2.1676\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 906us/step - loss: 0.5819 - val_loss: 2.1708\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.5592 - val_loss: 2.1738\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 915us/step - loss: 0.5764 - val_loss: 2.1757\n",
      "121/121 [==============================] - 0s 532us/step - loss: 0.8953\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.2153 - val_loss: 3.6799\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 2.5919 - val_loss: 2.5589\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 956us/step - loss: 1.4614 - val_loss: 2.1248\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.9599 - val_loss: 1.9681\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.7462 - val_loss: 1.9191\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6811 - val_loss: 1.9144\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6130 - val_loss: 1.9210\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6217 - val_loss: 1.9316\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 968us/step - loss: 0.5870 - val_loss: 1.9410\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 863us/step - loss: 0.5926 - val_loss: 1.9519\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 946us/step - loss: 0.5829 - val_loss: 1.9567\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 938us/step - loss: 0.6068 - val_loss: 1.9629\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5537 - val_loss: 1.9624\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 933us/step - loss: 0.5455 - val_loss: 1.9646\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 944us/step - loss: 0.5779 - val_loss: 1.9682\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5731 - val_loss: 1.9700\n",
      "121/121 [==============================] - 0s 598us/step - loss: 0.5996\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.5818 - val_loss: 1.8546\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3443 - val_loss: 1.6718\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 1.0053 - val_loss: 1.7586\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 0.8037 - val_loss: 1.8504\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7456 - val_loss: 1.9195\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7080 - val_loss: 1.9651\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6685 - val_loss: 1.9378\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 0.6438 - val_loss: 1.9682\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 979us/step - loss: 0.6167 - val_loss: 1.9624\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.6426 - val_loss: 1.9793\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5933 - val_loss: 1.9857\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5838 - val_loss: 1.9561\n",
      "121/121 [==============================] - 0s 582us/step - loss: 0.5689\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 2.7493 - val_loss: 2.0813\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8277 - val_loss: 2.0768\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.7419 - val_loss: 2.0670\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7168 - val_loss: 2.0314\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6603 - val_loss: 2.0254\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6383 - val_loss: 2.0110\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5836 - val_loss: 2.0179\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 981us/step - loss: 0.6067 - val_loss: 2.0101\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5728 - val_loss: 2.0208\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5678 - val_loss: 2.0073\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5704 - val_loss: 2.0132\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5395 - val_loss: 2.0215\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5469 - val_loss: 2.0248\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5313 - val_loss: 2.0344\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5083 - val_loss: 2.0321\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.483 - 0s 1ms/step - loss: 0.4836 - val_loss: 2.0323\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4863 - val_loss: 2.0450\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4919 - val_loss: 2.0504\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4840 - val_loss: 2.0445\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4716 - val_loss: 2.0523\n",
      "121/121 [==============================] - 0s 557us/step - loss: 0.5165\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 3.3187 - val_loss: 1.6064\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0034 - val_loss: 1.7398\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.7510 - val_loss: 1.8587\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6615 - val_loss: 1.9302\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 993us/step - loss: 0.6043 - val_loss: 1.9828\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 993us/step - loss: 0.5467 - val_loss: 2.0139\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 0.5488 - val_loss: 2.0225\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5275 - val_loss: 2.0460\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 989us/step - loss: 0.5027 - val_loss: 2.0512\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4979 - val_loss: 2.0506\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 964us/step - loss: 0.5148 - val_loss: 2.0684\n",
      "121/121 [==============================] - 0s 524us/step - loss: 0.5068\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x00000287D37D9520>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-b7fa4ad8e39b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mrndsearch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_reg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mrndsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxvaild\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# we clone again after setting params in case some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[0;32m    762\u001b[0m                 **self.best_params_))\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x00000287D37D9520>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param={\n",
    "    \"n_hidden\":[0,1,2,3],\n",
    "    \"n_neurons\":np.arange(1,100),\n",
    "    \"learning_rate\":reciprocal(3e-4,2e-2),\n",
    "}\n",
    "\n",
    "rndsearch=RandomizedSearchCV(keras_reg,param,n_iter=10,cv=3)\n",
    "rndsearch.fit(xtrain,ytrain,epochs=100,validation_data=(xvaild,yvalid),callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
