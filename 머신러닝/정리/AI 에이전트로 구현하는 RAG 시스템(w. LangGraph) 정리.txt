1.들어가며
  1.강의개요
    요즘쓰는 에이전트는 보통 리액트패턴임,라우터구조도 쓸수있는데 좀 섞어서쓰는듯 커서생각해봐도
    워크플로우를 설계하고,그래프를 사용해 노드와 노드를 연결하는 엣지로 구현하는 방식
    
    랭체인은 좀 복잡한 로직(에이전트같은)을 만들기는 어렵고,llm통합만을 위해,즉 api통신을 편하게 하기위해 사용됨
    랭그래프는 좀 복잡한 로직(멀티에이전트 등)을 상태기반 그래프를 통해 구현하기위해 만들어짐

2.랭체인 tool calling/agent 활용방법
  1.툴콜링 개념 이해
    툴콜링은 llm이 외부기능이나 데이터에 접근할수있게 해주는 메커니즘임
	llm이 특정 기능이 필요할때 미리 지정된 함수형태(aa(int,int))로 응답을 반환하면,
	이 응답에 해당하는 함수를 실행해서 결과값을 돌려주고 llm은 그걸 사용해서 최종응답을 만드는 기법임
	
	기본적으로 툴콜링을 사용할수있는 llm을 에이전트라고 부름

  2.랭체인 (LangChain) 내장 도구 생성하기
    랭체인은 기본적인 도구들을 가지고있음(랭체인 커뮤니티 툴)
	검색,코드인터프리터,생산성도구등이 있음
	
	무료검색에는 덕덕고가 있고,유료로는 TavilySearch가 있음
	
	툴은 4가지 요소를 가짐
	  name:툴의 이름
	  description:도구가 수행하는 작업에 대한 설명
	  json schema:도구의 입력을 정의하는 스키마(매개변수에 대한 설명,이게뭔지와 타입정도?)
	  function:실행할 함수(일반적으로는 동기,비동기도 가능하긴함)
	이렇게
	이름과 설명이 매우 중요함,llm이 고를지말지를 이거보고 정하기때문,스키마도 제대로쓰려면 잘써줘야함,특히 필수필드같은거도 표시해줘야함

  3.랭체인 (LangChain) 내장 도구 호출하기
    툴콜링을 할땐 llm에
	  llm_with_tools=llm.bind_tools(tools=[넣을,툴,배열])
	이렇게 넣고 그냥 invoke하면됨
	그러면 쿼리와 툴의 목록을 보고,툴을 쓰는게 더 편하겠다 싶은건 llm이 알아서 툴을 사용하겠다고 선언함(툴을 호출함)
	그러면 이걸보고 툴을 실행시켜주면됨(이땐 컨텐츠에는 값이 비어있고,tool_calls배열에만 값이 들어있음)
	
	이런 툴콜링을 쓸거면 gpt-4o정도의 성능이 괜찮은 모델을 써야 제대로함

  4.랭체인 (LangChain) 내장 도구 실행하기
    llm이 함수를 호출해주면 이걸 실행하는 방법이 크게 3가지정도가 있음
	기본적으로 반복문으로 ai메시지.tool_calls배열에서 하나씩 뽑아서,해당 도구로 invoke를 하는것(도구를 직접 실행)은 공통이고
	
	첫번째는 툴 메시지에서 args만 뽑아서 던지는방식
	  tool_output=web_search.invoke(tool_call["args"])
	두번째는 툴콜 메시지 전체를 직접 던지는 방식(위랑 거의같은데 args를 뽑지말고 통째로 던지는거)
	  tool_message=web_search(tool_call)
	세번째는 사용자정의한 ToolMessage를 만드는방식
	  tool_message=ToolMessage(content=tool_output,tool_call_id=tool_call["id"],name=tool_call["name"])
	세번째는 좀 정교하게 컨트롤할때 쓰고,보통은 두번째처럼 던지게됨
	
	또한 실행해야할게 여러개라면(tool_calls에 값이 여러개라면),batch로 실행하면 여러개를 동시에 실행할수있음
	  tool_messages=web_search.batch(aimsg.tool_calls)
	이렇게

  5.Tool Calling (도구 호출) 결과로 LLM 답변 생성하기
    실제로 우리가 원하는건 Tool Calling이지 도구를 뭘 실행할지 정하는게아님(근거를 검색하고 응답을 만들어내는게 목표)
	즉 도구의 실행요청을 가져와서,실행한뒤,다시 체인에 넣어서 llm을 돌려야함
	
	이떈 @Chain을 사용하는게 좋음
	대충
	  사용자 요청을 llm에 전달후 1차 응답메시지를 받음
	  1차응답메시지의 툴을 배치실행(툴실행이 있든없든 던지고,없으면 빈값리턴)
	  최종응답을 생성하기위해 사용자요청과 툴결과메시지를 messages에 담아서 llm에 다시 전달후 최종응답을 받음
	이런 루틴임
	즉 사용자요청과 무슨툴을 실행시켰는지,툴의 실행결과가 뭔지까지 전부 넣어서 최종응답을 생성하는것
	  
  6.랭체인 (LangChain) 사용자 정의 도구 활용 - Custom Tool
    도구를 직접 정의해서 쓰려면,@Tool데코레이터를 사용하면됨
	이떄 주의해야할건,명확한 입출력을 정의해야하고,단일책임원칙을 준수해야함,또한 도구설명을 도구를 명확히 이해하고 사용할수있게 작성해야함
	
	만들어진 함수에 @Tool만 붙이면 일단 되는데,이떄
	  name:함수명
	  description:docstring,함수의 최상단에 있는 스트링이 디스크립션이 됨
	  매개변수:매개변수명과 타입
	이런식으로 지정이됨

  7.LLM 모델의 Tool Calling 성능 비교 (OpenAI, Gemini, Llama 70B)
    예전모델이나 작은모델은 툴콜링을 못함(툴인식을 못함),또한 한국어를 못하는경우가 많음

  8.Runnable 객체를 도구로 변환하기
    문자열이나 dict 입력을 받는 Runnable객체를 tool로 변환시킬수있음
	이건 as_tool 메서드를 사용하면됨
	
	즉 일반함수를 RunnableLambda로 싸고,이걸 as_tool로 싸면 툴로 변환시킬수있음
	이떄 이름과 설명을 적고,입력스키마(args_schema)도 넣어주는게 좋음,필수는 아닌데 필드의 설명이 있는게 응답이 더 좋아짐

  9.LCEL 체인을 도구로 변환하기
    체인 자체도 툴로 변환할수있음,어짜피 Runnable 인터페이스니까 당연히 되는거지만
	이걸 사용하면 특정 llm요청 자체를 툴로 사용할수있어짐(요약같은)
	llm을 사용한 전처리나 후처리 자체를 툴로써 접근할수있어진다는거

  10.벡터 저장소 (Vector Store)를 도구로 변환하기
    벡터스토어 자체도 툴로 바꿀수있음
	벡터스토어에 데이터를 저장하는거 자체야 그냥 임베딩박아서 박아넣으면되니까 쉬움(임베딩모델만 연결해주면 알아서넣음)
	이떄 청크 스플릿을 칠때 그냥 딱 끊지말고 단어단위로 끊는게 좀 더 좋긴함
	
	툴로 만들땐 vectorStore.as_retriever(...)로 만들어서 Runnable로 만들어도 되고,
	그냥 @tool을 써서 함수를 만들고 그안에서 검색하고 리턴해도됨(이게 더 편함)

  11.여러 개의 도구를 사용하여 호출하기
    준 도구가 많아도 별로 다를건 없음
	그냥 사용할 툴 목록을 받아서 반복문을 돌려서 케이스문이나 if문으로 분기를 타거나 해서 메시지를 모아서 다시 던지면됨
	
  12.Few-shot 프롬프트를 활용하여 ToolCalling 성능 개선하기
    도구를 사용하는 예제들을 프롬프트에 담아두면,llm이 좀 더 잘 사용하고,내가 원하는 형태로 가이드해줄수있음
	
	이때 각 도구의 용도를 구분해서 예제로 제시하는게 좋고,랭체인에서는 메시지를 구분해서 보내주는게 좋음
	
	랭체인의 한계는,체인이 끝나고나서 결과가 제대로 나오지않았을때,이걸 평가해서 다시 돌린다던가 하는게 좀 만들기 귀찮음
	그래서 사용되는게 랭그래프임

  13.랭체인 (LangChain) 에이전트(Agent) 활용하기
    에이전트란 llm을 추론엔진으로 사용하여,어떤행동을 할지,그행동의 입력은 무엇일지를 결정하는 시스템
    이때 에이전트는 텍스트를 출력하는걸 넘어,실제 행동을 취하게 만듬
	또한 행동의 결과를 다시 피드백해서 추가행동할지,작업을 완료할지를 결정함
	
	랭체인에선 create_tool_calling_agent라는 에이전트를 생성하는 함수와,이 에이전트를 실행할때 사용하는 AgentExecutor함수가 있음
	또한 verbose=true로 하면,중간과정도 볼수있음

  14.그라디오 (Gradio) 챗봇 인터페이스 적용하기
    에이전트를 챗봇인터페이스에 붙이려면,그라디오를 사용할수있음
	이건 붙이기 매우쉬움
	  gradio.ChatInterface(함수,..)
	를 사용하면됨
	함수는 챗봇의 입력과 출력을 처리해주는 함수임
	대략
	  def echo(message,history):
	    return message
	이런 형태를 띄고,메시지는 입력,히스토리는 이때까지의 메시지흐름임(이떄 히스토리는 사람입력과 ai입력을 구분하는게 좋음,list[tuple[str,str]]로)
	즉 저렇게 리턴 메시지를 에코하는게 아닌,저기서 llm을 사용해서 메시지를 만들어내면됨
	
	또한 히스토리를 어디까지 llm에 줄건지도 선택해서 던지면됨
	
	
3.랭그래프 기본기 다지기
  1.랭그래프 개요	
    랭체인은 순차적으로 처리하는 작업에 적합하다면,랭그래프는 순차적이지않은 분기,재귀등의 복잡한 로직에 적합함
	일반적으로는 에이전트를 여러개로 나눠,각 에이전트마다 처리할 일을 정해준다음 걔한테 넘기는식으로 동작시킴
	또한 모든 에이전트는 end를 호출할수있고,이걸 호출하면 작업이 완전히 종료되고 응답이 나감

  2.상태 그래프 (StateGraph) 이해하기
    상태그래프는 상태를 기반으로 작동하는 그래프 구조임
	이건 복잡한 작업흐름을 상태와 전이로 모델링하여,유연하고 제어가능한 시스템을 구축할때 사용됨
	이건 각 노드가 특정 상태를 나타내고,엣지가 상태간 전이조건을 정의함
	
	즉 각 노드는 상태를 가지고있고,이 상태는 어떤노드가 됐든 동일한상태를 공유함
	상태는 앱의 현재 스냅샷을 나타내는 공유데이터구조임,시스템의 전체컨텍스트라고 보면됨
	노드는 에이전트의 로직을 인코딩하는 함수로,현재 상태를 입력으로 받아서 계산이나 db insert같은 사이드이펙트를 수행하고,업데이트된 상태를 반환함
	엣지는 현재 상태를 기반으로 다음에 실행할 노드를 결정하는 함수로,조건부분기를 할수도있고 고정적으로 전이할수도있음,즉 흐름제어담당임
	
	즉 노드로 작업을 하고,엣지로 다음노드로 상태를 넘기는식으로 동작하는거임
	그러다가 작업종료 end가 나오면,이 상태를 최종사용자에게 리턴하는방식임

  3.상태 그래프 (StateGraph) 구현하기
    가장먼저할건 상태를 정의하는것
	레스토랑 메뉴추천이면 
		사용자의 선호도
		추천된메뉴
		추천된메뉴의 정보
	이런식으로 각각 상황에 맞는 상태를 만들어야함
	
	그리고나서는 상태를 받아서 상태를 업데이트해주는 노드를 정의해야함
	이때 상태를 받아서 작업을 하고(llm호출이라던가) 상태를 수정한후 상태를 리턴하면됨
	상태를 업데이트할땐,상태의 필드 하나마다 노드를 하나씩 만드는게 단일책임원칙엔 나을듯,뭐 llm호출비용떄문에 묶을순있겠지만
	
	그리고나면 엣지를 만들어야함
	일단 빌더에 노드를 전부 더해주고,고정전이라면 그냥 엣지로 둘을 이어주면됨(시작과 종료는 START,END로 하면됨)
	
	또한 그래프를 시각화할떈,머메이드 라이브러리를 사용해서 
	  IPython.display(Image(그래프.get_graph().draw_mermaid_png()))
	이렇게 시각화해볼수있음
	
	또한 상태의 초기값을 넣어줄수도있고(invoke할떄 넣으면됨),안넣을수도있음

  4.조건부 엣지 함수로 분기(Branching) 구현하기
    분기를 구현할땐 상태를 보고 다음 실행할 노드를 선택하는 함수를 만들어서,해당함수를 엣지로 사용하면됨
	함수는 다음에 실행할 노드의 스트링을 리턴하면됨(즉 상태는 get만하고 업데이트는 하지않고 분기만 탐,스테이트리스라고 봐도됨)
	이땐
	  builder.add_conditional_edges(엣지명,엣지함수,리턴된 스트링과 연결할 노드리스트)
	로 엣지를 추가하면됨
	뭐 좀 정확하게 말하자면,분기만 타는 읽기전용노드를 만들고 그걸 엣지로 연결시킨다는 느낌이 더 강하긴한듯
	
	이렇게 조건부를 타려면 상태에서 카테고리 리스트나 불리언 뭐 그런거로 확인하고 전이시키는게 편함
	이거 분류할때는 llm쓰면 대충떄려박을수있고
	
	만약 챗봇처럼 계속 답변을 받아야한다면 무한루프를 돌리면서 끝낼지말지를 사용자가 선택하게 하고,종료를 선택하면 루프를 종료하는방법으로 진행할수도있음
	
4.랭그래프 기본기-리듀서
  1.리듀서 이해하기
	노드는 상태를 입력받아서 작업후 상태를 출력함
	이때 리듀서란 상태업데이트를 관리하는 함수임,즉 노드의 상태관리를 도와줌(상태관리의 추상화)
	
	기본적으로 노드의 반환값은 기본리듀서,즉 해당상태키의 이전값을 덮어쓰기로 저장함
	또한 리스트같은 상태에 새로운값을 추가할때(메시지 컨텍스트 관리할때등)는 add리듀서를 사용함
	그리고 특별한 리듀서(중복제거,정렬등)이 필요하다면 사용자정의 리듀서를 만들수도있음
	
	리듀서를 사용할떈(기본리듀서말고 다른리듀서를 쓸땐),리듀서가 사용되는 필드를
	  abcList:Annotated[List[str],리듀서명]
	  abcList:Annotated[List[str],add]
	이런식으로 선언해주면됨(즉 필드별로 리듀서를 다르게 쓸수있음)
	
	기본리듀서를 쓴다면,리턴된상태필드를 그냥 덮어쓰고,add리듀서를 쓴다면 해당하는 상태필드는 리턴된 상태 필드를 추가함(즉 필드마다 다른형식이 가능)
	
  2.리듀서 활용하기
    커스텀 리듀서는 로직이 필요할때 만들어쓸수있음(최대최소값유지 중복제거,정렬등)
	이건 그냥 해당값을 입력으로 받아(리스트같은경우 기존값과 신규값 2개의 리스트를 받아야함),해당값을 출력으로 내놓는 함수를 만들고
	  abcList:Annotated[List[str],커스텀리듀서함수]
	이렇게 쓰면됨

  3.메시지 그래프(Messages Graph) / 피드백 루프 (Feedback Loop) 이해하기
    메시지그래프는 챗모델을 위한 특수한 형태의 상태그래프임
	이건 메시지객체목록을 입력으로 처리하고,이건 대화기록을효과적으로 관리하고 활용하기위해 사용됨
	보통 챗봇형태로 할때 이게 add리듀서쓰는거보다 쓰기편해서 이걸 사용함
	
	이때 사용되는 메시지상태(Messages State)는,
	  대화기록을 그래프상태에 메시지목록으로 저장
	  메시지 객체목록을 저장하는 Messages키를 추가
	  이 키에 리듀서함수를 추가하여 메시지업데이트를 관리
	이건
	  abc_messages:Annotated[list[AnyMessage],add_messages]
	이렇게 add_messages를 리듀서로 쓰면됨
	이 리듀서는,새메시지는 기존목록에 추가하고,기존메시지업데이트도 메시지id를 추적해서 업데이트해줌
	이걸 다 만들어진 클래스(MessagesState)로도 제공함,그냥 클래스를 만들고 MessagesState를 상속받으면됨,또한 추가할키가 있으면 그냥 추가하면됨
	  class abcState(MessagesState)://파이썬에서 초기값은 def __init__ 함수를 써야함
	    ab:str
		age:int
	이런식임
	
	피드백루프란 조건부엣지(조건에 따라 분기하는 엣지)를 활용하여 평가결과를 바탕으로 다시응답을 생성하는 과정을 반복하다,만족하면 다음노드로 넘기는것
	그냥 조건을 만족하지않으면 다시 그 노드로 던지고,만족하면 다음노드로 던지면됨
	그냥 브랜치엣지랑 다를거없음

  4.메시지 그래프(Messages Graph) / 피드백 루프 (Feedback Loop) 활용하기
    피드백루프를 만들땐,횟수를 카운팅하고 횟수를 넘으면 강제종료해야함,이걸위해 상태도 추가해야하고
    
	랭체인으로 체인을 만들고,이 체인을 노드로 사용하는것도 자주 사용됨
	상태를 받아서 상태로 체인을 실행시키고,출력값으로 상태를 업데이트하는 형태
	
	답변의 품질을 높일때는,답변을 평가하는 노드가 필요함(점수와 설명을 llm으로 받으면됨)
	이걸가지고 점수를 보고 재귀를 돌리면됨
	또한 이런식으로 쓸땐,체인의 마지막 파서를
	  llm.with_structured_output(schema=리턴값 스키마클래스)
	이런식으로 with_structured_output로 Json으로 강제해주면 좋음

  5.그라디오 (Gradio) 챗봇 인터페이스 적용하기
    이거도 인터페이스씌우긴 똑같음
	
	
5.리액트 에이전트 활용하기
  1.추론-행동 기반 ReAct 에이전트 이해하기	
    리액트는 추론과 행동을 결합한 접근방식임
	추론을 한뒤 행동을 하고,행동의 결과를 가지고 다시 추론하는식으로 반복적인 구조를 사용함
	
	즉
	  행동:
	    모델이 주어진상황을 분석해서 적절한 도구를 선택
		선택한 도구를 호출하고 필요한 입력을 제공
	  관찰:
	    호출된 도구의 실행결과나 출력을 모델에 다시 전달
		에이전트가 자신의 행동결과를 이해/학습
	  추론:
	    이전단계의 관찰결과를 분석하여 다음행동을 결정
		다른도구를 호출하거나 직접응답을 생성
		현재상황을 평가하고 최선의 다음단계를 선택  //핵심
	이렇게 추론과 행동의 반복적인 사이클로 복잡한 작업을 단계적으로 해결함(피드백루프)

  2.ReAct 에이전트 준비하기 - Tool & ToolNode 설정
    랭그래프에서는 Tool Node로 도구호출을 실행할수있음
	이건
	  가장 최근의 AIMessage에서 도구호출요청을 추출(이때 AIMessage에는 tool_calls가 반드시 채워져있어야함)
	  요청된 도구를 병렬로 실행
	  각 도구호출에 대해 ToolMessage를 생성하여 반환
	이런 순서로 실행됨
	
	이건 
	  toolNode=ToolNode(tools=tool_list)//실행할 도구목록 전달
	  toolNode.invoke({"messages":llm.invoke("질문")})
	이런식으로 사용됨
	꼭 저렇게 안에다가 고차함수로 넣을필욘없고,그냥 AI메시지 리턴받아서 넣는게 더 편할듯

  3.ReAct 에이전트 구현하기 - 랭그래프 내장 함수 활용
    리액트를 쓰기 가장 편한건,내장된걸 쓰는거임
	이건
	  graph=create_react_agent(llm,tools=tool_list,state_modifier=system_prompt)
	이렇게 사용할 llm과,툴리스트,시스템프롬프트를 넣으면 생성해줌(시스템프롬프트는 필수는아니지만 넣는게 좋음)
	이러면	
	  시작-에이전트-(루프)-툴
	      |-종료
	이런식으로 그래프가 그려짐
	이러면 그냥 해당그래프를 사용해서 쿼리를 날리면,알아서 툴 반복해가면서 값을 줌

  4.ReAct 에이전트 구현하기 - 사용자 정의 조건부 엣지 함수 활용
    리액트를 직접 노드를 구축한다면 조건부엣지를 직접 정의할수있음
	대표적으로 반복횟수제어나 도구호출이 필요없는경우가 있음

  5.ReAct 에이전트 구현하기 - tools_condition 조건부 엣지 함수 활용
    tools_condition은 도구호출여부를 조건부엣지로 제어하는걸 워낙 많이 쓰다보니 자체적으로 제공하는 함수임
	이건
	  최신메시지를 검사
	  해당메시지가 도구호출인지 여부를 확인
	  아니면 end,맞으면 도구노드실행
	순서임
	즉 따로 엣지함수 구현을 하지않고 엣지추가할때 가져다쓰면되는거

  6.에이전트에 기억장치(memory) 추가하기 - MemorySaver 활용
    이건 그래프의 각 단계를 실행하고나서 자동으로 상태를 저장(체크포인트)해줌
	그래프는 이전 실행을 기억하지못하는데,
	이걸 사용하면 상태의 일시성을 해결해줌,즉 스테이트리스인걸 해결해줌(각 실행마다 초기값상태로 초기화되는걸 해결해줌)
	이건 대화가 연속성이 필요할때(멀티턴),대화를 중단후 복원해야할때,대화마다 독립적인 스레드를 관리할때 사용됨
	
	즉 각스레드별로 id를 지정해두고,이걸 키값저장소에 id:컨텍스트로 체크포인트(그래프의 각 단계 실행시)마다 저장해두는거
	그리고 스레드별로 자기 id를 검색해서 그걸 가져와서 컨텍스트에 넣는거임
	
	이걸 쓸땐,스레드id를 반드시 지정해줘야함(uuid쓰면될듯)
	이건
	  memory=MemorySaver()
	  graph=builder.compile(checkpointer=memory)
	이렇게쓰면됨,그리고 메시지 초기값으로 
	  config = {"configurable": {"thread_id": "1"}}
	  messages = [HumanMessage(content="스테이크 메뉴의 가격은 얼마인가요?")]
	  messages = graph_memory.invoke({"messages": messages}, config)
	이렇게 쓰면됨
	그리고 다음행동을 할떄도
	  config = {"configurable": {"thread_id": "1"}}
	  messages = [HumanMessage(content="둘중 뭐가 더 싼가요?")]
	  messages = graph_memory.invoke({"messages": messages}, config)	
	이렇게 같은키를 넣어주면되는거임
	
	create_react_agent도
	  graph=create_react_agent(
	    llm,
	    tools=tool_list,
	    state_modifier=system_prompt,
	    checkpointer=memory
	  )
	이렇게 체크포인터추가해주면됨

  7.그라디오 (Gradio) 챗봇 인터페이스 적용하기
    이건 또 별로 다를거없음,추가적으로 스레드id만 받으면됨
	스레드id생성은 uuid를 사용하고,이걸 그냥 추상화시켜버리는게 좋음
	클래스단위로 구현해버리면됨,클래스마다 하나의 id를 가지게하고,걔한테 호출을 시키는식
	
	
6. 다양한 에이전트 기반 RAG 구현하기	
  1.에이전트 구현 준비하기 - 실습환경 & Tool 설정
	스킵

  2.Adaptive RAG 에이전트 이해하기
    이건 질문의 복잡성에 따라 가장 적합한 검색 및 생성전략을 동적으로 선택하는 방법임
	즉 질문의 복잡성을 분석하고,해당 분석결과에 따라 그냥 llm을 쓸지,단일검색증강을 추가해 쓸지,딥리서치를 쓸지를 선택하는방식

  3.Adaptive RAG 에이전트 구현하기
    이건
	  질문입력받기
	  질문의 복잡성 분석
	  전략선택
	    단순질문:기본llm 혹은 단순웹검색
		중간복잡성:단일 단계 검색 증강 llm
		복잡한질문:반복적 검색증강 llm
	  처리 및 응답
	순으로 구성됨
	
	즉 별로 다를건없고,llm을 여러개로 나누고 조건부엣지로 어떤쪽으로 던질지를 라우팅해서 던지면되는거
	라우팅을 하기위해서는 그거전용 llm프롬프트를 만들어야함
	그거로 선택을 한뒤에,그걸가지고 그래프에 입력을 넣으면됨
	이건 파이프연산자( | )로 연결하면됨

  4.Human-in-the-Loop (HITL) 과정 이해하기
    이건 시스템의 결정이나 출력에 대해 인간이 검토하고 개입할수있는 지점을 제공하는방식임
	즉 브레이크포인트를 만들고 거기서 입력을 받아서 검토를 받고,필요하다면 수정할수있게 하는거
	이걸쓰려면 메모리세이버는 필수로 써야함(메시지 저장해야하니까)
	
	graph.get_state(스레드id)로 현재 상태값도 확인할수있고
	또한 중단점에서 다음노드가 뭔지도 확인할수있음
	계속 실행하려면,입력값을 None로 지정하면 중단점부터 다시 시작함

  5.Human-in-the-Loop (HITL) 과정 구현하기
    일단 체크포인트(메모리세이버)는 반드시 있어야하고,빌더로 그래프컴파일할때
	  builder.compile(checkpointer=memory,interrupt_before=["generate"])
	이렇게 interrupt_before를 사용해서 저 리스트 안의 노드들중 하나가 실행되기 직전에 멈출수있음
	
	계속 실행을 할땐 처음처럼 stream(None,config=스레드id)를 쓰면됨,None를 던지면 계속 실행을 함
	
	또한 이 멈추고 나서 상태를 확인후 상태를 수정(update_state(..))할수있음,이걸로 쿼리 자체를 바꿀수도있고(보통 구체화를 함)
	피드백루프를 다시 돌려서 이전상태로 돌아갈수도있고,검색을 다시한다던가 쿼리를 바꾼다던가 이런식으로 다양한방식으로 개입할수있음

  6.Self RAG 에이전트 이해하기  
    self rag는 rag에 자기반영능력을 추가한 모델임
	이건 검색,생성,자체평가를 통합하여 더 정확하고 관련성높은 응답을 생성하는게 목표임
	
	이건
	  사용자의 질문을 받아 관련정보를 검색(쿼리입력)
	  검색된 정보를 바탕으로 첫번째 응답을 생성
	  생성된 응답의 품질,관련성,정확성을 평가
	  점수가 낮을경우 추가정보검색 또는 응답 재생성을 결정(이때 쿼리를 바꿔서 다시 넣는식으로 재생성함)
	  이걸 원하는 점수보다 높아질때까지 반복
	순서대로 만드는 방식임
	
	즉,반복적 개선,자기평가,동적쿼리개선 이 3가지가 주요 구현포인트임

  7.Self RAG 에이전트 구현하기
    주요 단계로는
	  검색결정
	    입력:질문 x 또는 질문 x와 생성된 답변 y
		목적:검색기를 사용하여 n개의 청크를 검색할지 결정
		출력:yes,no,continue중 하나
		의미:시스템이 추가정보가 필요한지 판단
	  검색된 문서 관련성 평가
	    입력:질문과 검색된 청크 n
		목적:각 청크가 질문에 유용한 정보를 제공하는지를 평가,rag로 검색된 문서들을 실제로 컨텍스트에 추가할지 여부를 정함
		출력:relevant 또는 irrelevant  //true false임 사실상
		의미:관련없는정보를 필터링하여 품질을 향상
	  생성된 답변의 환각 평가
	    입력:질문,청크,생성된텍스트
		목적:생성된 텍스트가 청크의 정보에 의해 생성됐는지,즉 근거가 있는지를 평가
		출력:full support,partally support,no support
		의미:환각을 감지하고 정보의 신뢰성을 확인
	  생성된 답변의 유용성 평가
	    입력:질문과 생성된텍스트
		목적:생성된 텍스트가 질문에 유용한 응답인지 평가
		출력 1~5점
		의미:응답의 품질과 관련성을 수치화함
	가 있음
	즉 
	  검색노드
	  생성노드
	  평가노드리스트
	  쿼리재작성노드
	가 있고,이걸 반복하면서 응답의 품질이 평가노드를 전부 만족할때까지 재생성하는거임
	이때 질문이 문제가 있거나,rag에서 아무것도 검사에 통과하지못했으면 쿼리를 바꿔서 다시돌려보는거고,둘다 괜찮은데 답변이 맘에안들면 재생성시도를 하는거임
	
	그래프의 상태클래스는
	  질문
	  생성응답
	  도큐멘트(컨텍스트문서)
	  질문or답변 생성횟수//무한루프방지
	가 가장 필수적으로 필요한 상태임
	
	노드구성은
	  시작-rag검색-검색문서평가--답변생성-----------답변평가---------------------(성공)--종료
						|										|-(루프횟수초과)--실패메시지로 변경후 종료
						|										|-(환각발생)--답변생성루프
						|										|-(질문답변관련성부족)--질문개선--rag검색루프	                   
						|-(통과한 문서의 갯수가 0일때)--질문개선->rag검색루프							
	검색문서평가에서 평가에 통과한문서가 없을때는 질문을 개선하고,질문답변관련성이 부족해도 질문을 재작성함
	환각이 발생하면 답변생성을 다시함

  8.서브 그래프 (Sub-graph) 구조 이해하기
    이건 복잡한 작업을 해야하는 단일노드를 서브그래프로 쪼개는방법임
	즉 단일함수노드를 여러 함수노드로 쪼개고,이걸 그래프로 묶어서 노드처럼 사용하는방식
	
	각 서브그래프는 독립적으로 상태관리를 할수있고,메인그래프와 서브그래프간의 정보교환을 할수있음(메인그래프에 포함된 상태를 교환할수있음)
	보통 그래서 메인그래프의 상태를 상속해서 사용함
	복잡한 워크플로우를 구현할때 좋음
	또한 병렬적으로 노드를 실행할떄,랭그래프는 병렬구조로 분기해서 이뤄져서 병렬처리가 가능해짐(노드를 분기해서 처리한후 다시합칠때)
	또한 조건부엣지로 병렬노드실행도 가능함(결국 분기되고 다시모이기만하면됨)
	
	즉 단일노드로 여러 로직을 동기적으로 실행하는거보다,여러노드로 나눠서 비동기적으로 실행할수있을때 서브그래프를 사용하기좋음

  9.서브 그래프 (Sub-graph) 구조 구현하기
    서브그래프는 다중에이전트 시스템에 사용하기좋고,복잡한 의사결정 프로세스를 모듈화할수있고,HITL을 통합할때 명확하게 개입지점이 보이게됨
	즉 장점으로는
	  모듈성 향상
	  재사용성
	  유연성
	  디버깅용이성:각 서브그래프를 독립적으로 테스트하고 디버깅할수있음
	가 있음
	
	병렬실행을 할떈,보통 검색같은곳에서 한꺼번에 검색을 하고,합친후 필터링하는방식을 자주 사용함(팬아웃-팬인)
	이렇게 검색과 검증을 서브그래프로 만들고,이걸 노드로 사용하는게 주로 사용되는 서브그래프사용방식임
	반드시 같이 나오는애들끼리 묶은다음 이걸가지고 추상화해서 쓰는거

  10.서브 그래프 (Sub-graph) 구조를 메인 그래프(Main Graph)에 통합하기
    서브그래프의 상태는 메인그래프의 상태를 상속해버리면
	메인그래프에 서브그래프를 통합할땐 그냥 그래프를 가지고 이걸 노드처럼 넣어버리면됨
	
	또한 그래프를 시각화할때,xray를 true로 보면 서브그래프의 안내용을 볼수있음

  11.Corrective RAG 에이전트 이해하기
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
  