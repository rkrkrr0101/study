1.llm지도
  스킵
2.트랜스포머
  1.트랜스포머 기본 구조(적당히 아는거제외하고 요약함)
	트랜스포머의 핵심은 어텐션이고,트랜스포머의 주요 구조는 인코더와 디코더

	당연히 텍스트는 임베딩되어야하고,임베딩하는층도 모델에 포함되어있고,이것도 같이 학습됨
	또한 어텐션이니까 문장 전체에서 가중치를 가져오는건 맞지만,그래도 근처에있으면 영향을 줄 확률이 높으니 위치정보를 더해주는 층이 있음

	쿼리는 입력하는 검색어
	키는 쿼리와 관련성을 찾기위해 문서가 가진 특징
	값은 쿼리와 관련이 깊은 키를 가진 문서를 찾아 관련도순으로 정렬해서 문서를 제공할떄 문서

	즉 우리가 검색하면서 원하는건 값임
	어텐션이 동작할때,특정 단어가 쿼리로 주어졌을떄,해당 문장내에서의 관계도(키-값)에서 키는 해당 단어고,값은 임베딩값임
	이 임베딩값을 각각 위치에따라 0.x를 몇을 곱해주냐(관련도)가 어텐션의 핵심임

	그런데 동음이의어나,나는,다녀왔다 이런 단어들은 토큰 자체로만 보면 관련성을 찾기 힘듬
	그래서 트랜스포머에서는 토큰임베딩을 변환하는 가중치Wq와 Wk,Wv를 도입함
	각각 Wq는해당 쿼리단어에 대해 학습하는거고,
	Wk는 키에대해 학습하는거임
	Wv는 값을 출력할때 토큰임베딩을 텍스트로 변환할떄의 가중치임

	또한 이 어텐션을 하나만 쓰는게 아닌,여러 어텐션을 동시에 사용하고,그걸 합산한게 효과가 더 좋음(파라미터가 늘어나는효과)
  2.인코더와 디코더
    인코더는 자연어 이해를 할떄 사용하고,디코더는 자연어 생성을 할때 사용함
	두개를 같이 쓰는건 더 넓은 범위의 작업을 할때 사용함
	
	gpt같은건 디코더만 사용한모델임
	자연어를 이해하는거만 필요하다면 인코더만 사용하는 BERT같은걸 사용할수있음(리뷰이해한후 ox표시같은거)

  3.주요 사전학습 메커니즘
    인과적 언어 모델링은 문장의 시작부터 끝까지 순차예측하는 방식임,보통 gpt같은데서 사용하는 학습방법
	마스크 언어 모델링은 단어 하나를 감추고 해당 단어를 예측하는 방식임,BERT같은 인코더쪽에서 주로 사용(양방향예측이 필요할때)
	
3.허깅페이스 트랜스포머 라이브러리	
  1.허깅페이스 라이브러리
	허깅페이스 트랜스포머 라이브러리는,다양한 트랜스포머 모델을 같은 인터페이스로 사용할수있게 지원하는 오픈소스 라이브러리임
	이건 크게 트랜스포머모델과 토크나이저를 활용할떄 쓰는 transformers라이브러리와,데이터셋을 가져다쓸수있는 datasets라이브러리로 구성됨

	쓰는것도 그냥 프리트레인모델가중치를 불러오고,토크나이저를 불러오고,입력을 토큰화한후 모델에 넣으면됨(책참고)
	거의 모든 모델을 거의 같은 코드로 사용할수있음
	도커쓰는거랑 거의 비슷한느낌임
  2.허깅페이스 허브 탐색
    이건 그냥 허브사이트 들어가서 모델보는법
	모델과 데이터셋 허브가 따로있음

  3.라이브러리 사용법 익히기
    모델은 바디와 헤드로 구성됨
	바디는 은닉층이고,헤드는 최종출력층임
	즉 기본적으로 제공되지않는 헤드를 가져가 끼우려면,추가적으로 파인튜닝을 시켜야함
	또한 각 모델에는 config.json이 주어지는데,이걸 열어보면 어떤모델인지,뭘하는모델인지를 알수있음
	
	토크나이저는 텍스트를 토큰단위로 나누고,각토큰을 대응하는 토큰아이디로 변환함
	이것도 학습하면서 어휘사전을 구축하기때문에,보통 모델과 함께 저장함(그래서 같은 모델과 토크나이저를 쓰려면 같은 모델아이디로 불러오면됨)
	
	데이터셋을 사용하면 데이터셋을 가져올수있음

  4.모델 학습시키기
    허깅페이스에는 모델학습을 쉽게 할수있게 트레이너api를 제공함
	그냥 
	  데이터를 준비하고(학습,평가)
	  토크나이저를 불러오고
	  모델을 불러오고
	  학습파라미터를 넣어주고
	  트레이너를 돌리면 끝임
	즉 예전에 텐서플로로 하던방식에서,레이어를 까는작업을 그냥 불러오는거로 대체하고,학습파라미터랑 데이터셋,토크나이저를 알아서 붙여넣고 돌리면 되는식으로 바꾼것
  
  5.모델 추론하기
	이것도 그냥 파이프라인이라고 쉽게 추론할수있게 해줌
	이건
	  작업종류
	  모델
	  설정
	을 받아서 모델파이프라인을 만들고,거기에 데이터를 넣으면 값을 리턴해줌
	
	
4.말잘듣는 모델 만들기
  1.사전학습과 지도미세조정
    사전학습은 모델의 기본 체급을 만드는 과정임
	인터넷상의 다양한 텍스트데이터로 사전학습을 보통 하는데,보통 다음에 올 단어의 확률을 예측하는식으로 학습함
	
	또한 사용자의 요청에 적절히 응답하려면,요청의 형식을 적절히 해석하고,응답의 형태를 적절히 작성하고,둘이 잘 연결되어야함
	이렇게 만드는걸 지도미세조정이라고 함
	이름에 지도가 들어간거부터 알겠지만,학습데이터에 정답이 포함된 데이터로 학습하는거임
	그래서 이걸통해 llm은 사용자의 요청에 맞춰 응답하도록 학습하는데,이를 정렬이라고 함
	이때 사용되는 데이터셋은 지시데이터셋이라고 부름(지시에 맞춰 응답한 데이터셋)
	
	이런 지시데이터셋에 비해 사전데이터셋은 형식이 매우 다양하고,요청에 응답하는 형식의 데이터는 적고,특히 양질의 데이터는 훨씬 적음
	그래서 이걸 보완하기위해 지시데이터셋을 사용하는것
	
	지시데이터셋은 사용자의 요구사항을 표현한 문장임
	입력에는 답변을 하는데 필요한 데이터가 들어가고,
	출력에는 지시사항과 입력을 바탕으로한 정답응답이 들어감
	
	즉 지시데이터셋이나 사전데이터셋이나 학습과정은 똑같은데(둘다 다음단어를 예측하는 인과적 언어 모델링 사용),
	단순히 학습하는 데이터셋에 차이가 있어서 그런것
	
	지시데이터셋의 크기는 대충 1000개정도면 충분함
	크기보단 지시사항이 다양한 형태로 되어있고,응답데이터의 품질이 높은게 더 중요함
	결국 모델의 지식이나 능력은 사전학습에서 대부분 끝났고,이걸 잘 끌어내는게 지도미세조정이기때문(즉 기초모델을 잘고르면 작은 지시데이터셋써도됨)
	또한 지시데이터셋의 품질이 좋으면 성능이 많이 올라갈수있음
	즉 이미 공개된 데이터셋을 한번 더 필터링하는게 더 나을수있다는것

  2.채점모델
    a와 b중 더 좋은 데이터를 표시한 데이터셋을 선호데이터셋이라고 부름
	각 데이터에 점수를 매긴거랑 비슷한데,이런 데이터는 찾기 힘들어서 단순히 양쪽을 비교만 하는식으로 만들어진 데이터셋
	
	선호데이터셋을 통해 답변의 점수를 매기는 리워드모델을 만들고,llm의 응답을 여러개 만들게해서 리워드모델로 피드백을 먹이는식으로 강화학습을 할수있음
	이게 사람의 피드백을 활용한 강화학습(RLHF)임
	
	단 이런방식은 단순히 점수를 높게받는데만 집중하는 보상해킹이 생기기쉬워서,이게 안생기게 면밀히 만들어야함
	그때 사용하는게 ppo로,현재 응답에서 조금만 수정해서 점수를 높일수있게 하는방식
	
	근데 rlhf는 너무너무 사용하기 어려워서,보통 기피됨
	리워드모델이 성능이 좋지않아서 일관성없는 점수를 뱉으면,학습이 제대로되지않고,
	참고모델,학습모델,리워드모델 3개의 모델이 필요해지고,
	강화학습자체가 하이퍼파라미터에 민감하고 학습이 불안정해서 쓰기가 힘듬
	
  3.강화학습이 꼭 필요할까?
    그래서 사용되는게 기각샘플링과 직접선호최적화임
	
	기각샘플링은 지도미세조정을 마친 llm을 통해 여러 응답을 생성하고,그중 리워드모델이 가장 높은 점수를 준 응답을 모아서 다시 지도미세조정을 하는것
	즉 자기지도학습을 하는거임
	이러면 강화학습을 쓰지않아서 안정적이게됨
	즉 리워드모델과 ppo는 그대로 사용하고,강화학습으로 점수매기는방식이 아닌,
	학습할 llm의 응답을 받아서 그거중 좋은거만 모아서 응답을 다시먹이는식으로 하는것(뱉은거중 좋은거만 다시먹는거임)
	
	직접선호최적화(dpo)는 선호데이터셋을 직접 언어모델에 학습시켜서,리워드모델과 강화학습을 사용하지않는방식임
	즉 llm이 리워드모델의 역할도 같이(은닉층에서) 처리하는것임
	기본적으로 llm은 해당 문제를 처리할 기초체급을 갖추고있고,여기서 현재 처리하려는 문제에 대해 방향을 제시해주는게 지도미세조정임
	즉,해당 방향으로 적당한 학습률을 가지고 선호데이터셋을 먹여버리면,그쪽으로 사고를 유도할수있다 이런방식임
	
	요즘은 dpo를 가장 많이 사용함
	
	
5.gpu 효율적인 학습	
  1.gpu에 올라가는 데이터
    1.딥러닝 모델 데이터타입
      딥러닝을 돌릴때 가장 자주 만나는 에러는 oom임
	  기본적으로 gpu메모리에는 모델 자체가 올라가고,모델은 행렬곱을 위한 파라미터의 집합임
	  
	  일반적으론 한 파라미터는 16비트로 수를 표현함(부호1비트 지수8비트 가수7비트,bf16)
	  딥러닝모델은 학습이나 추론이나 gpu메모리에 전부 다 올라가기때문에,모델의 용량이 얼마인가가 매우 중요함
	  딥러닝모델의 용량은 파라미터수에 파라미터당 비트를 곱하면됨
	  즉 14b모델이 16비트(2바이트)로 저장된다면
	    14b=14*2=28GB
	  가 필요한것
	2.양자화
	  이렇게 14b만 해도 엄청나게 메모리를 잡아먹기때문에,파라미터수는 줄이기 싫은데 메모리사용량은 줄이고 싶어서 나온게 양자화임
	  이건 더 적은 비트로 모델을 표현하는것
	  양자화를 하면 모델의 용량이 줄어서 메모리 사용량이 줄어들지만,대신 정보가 소실되기때문에 모델의 성능이 저하됨
	  즉 양자화의 핵심은 더 적은 비트를 사용하면서 원본데이터의 정보를 최대한 소실없이 유지하는게 핵심과제임
	  
	  이때 가장 중요한건,변환하려는 데이터 형식의 수를 최대한 낭비하지않고 사용하는거임
	  즉 사용되지않는 비트공간을 최대한 없애고,주어진 범위 내에서 수들을 최대한 퍼트리는방법을 찾는게 핵심
	  
	  그래서 사용되는게,데이터들을 k개의 데이터를 묶은 블록으로 만들고,이 블록단위로 절대최댓값을 구해서 변환을 하는거임
	  이러면 이상치들을 최대한 억제하면서 데이터의 형식을 낭비하지않고 양자화를 할수있어짐
	3.gpu 메모리 분해
	  gpu 메모리엔
	    모델 파라미터
		그레이디언트
		옵티마이저 상태
		순전파 상태
	  이렇게 4가지가 올라가고,
	  딥러닝 학습은 간단히 말하면 순전파를 수행하고,그때 계산한 손실로부터 역전파를 수행하고,옵티마이저로 모델을 업데이트함
	  이떄 역전파를 수행하려면 순전파를 했을때의 값이 필요함(순전파상태값),또한 그레이디언트는 역전파 결과 생성됨
	  
	  이떄 최소로 필요한 메모리양은,2바이트x파라미터수(B)를 N으로 잡았을때,
	    모델파라미터=N
		그레이디언트=N
		옵티마이저 상태=2N(상태가 2개라서)
	  즉 4N이 기본적으로 필요하고,순전파상태를 저장하기 위한 메모리가 추가로 필요함
	  즉 모델을 사용하는것보다,모델을 학습시키려면 최소 4배가 필요하다는거,추가적으로 1배치사이즈의 데이터도 메모리에 올려야하고
	  
	  허깅페이스의 모델메모리 계산기를 사용해서 대략적인 메모리양을 알수있음

  2.단일 gpu 효율적으로 활용하기
    1.그레이디언트 누적
	  학습과정에서 배치크기를 크게 가져가면,더 빠르게 수렴하고 성능이 올라가지만,배치크기가 커지면 순전파상태저장에 필요한 메모리가 증가함
	  그래서 사용되는게 그레이디언트 누적임
	  이건 제한된 메모리 안에서 배치크기를 키우는것과 같은 효과를 얻는방법임
	  
	  이건 스탭을 n번 반복하고,n번의 스탭이 지나가고 나서 모든걸 합친다음 n으로 나눠서 역전파를 수행하고,모델을 업데이트함
	  이러면 배치사이즈가 n배 커진 효과를 받을수있음
	  대신 시간은 길어지겠지만
	2.그레이디언트 체크포인팅
	  역전파 계산을 하려면 순전파의 결과를 저장하고있어야함
	  가장 기본적인건 모두 저장하는거지만,이건 비효율적이고
	  가장 메모리를 많이 절약하는건 역전파에 꼭 필요한거만 저장하고,
	  나머지는 다시 계산하는방식인데,이건 한번의 역전파를 위해 순전파를 반복적으로 계산해야한다는 단점이 있음
	  
	  이 두가지를 절충하는 방법이 그레이디언트 체크포인팅임
	  중간중간에 체크포인트를 두고,거기서부터만 다시 계산하는식으로 동작시키는거임
	  이러면 메모리 사용량도 좀 줄고,그렇게 많이 계산할필요도 없음(즉 위에 두개를 반씩 합친느낌)
	  이건 쓰려면 걍 메서드에서 키기만 하면됨

  3.분산학습과 ZeRO
    1.분산학습
	  분산학습은 GPU를 여러개 활용해서 모델을 학습시키는걸 말함
	  이거의 목적은 크게 2가지로,모델 학습속도를 올리거나,1개의 gpu로 학습이 어려운 모델을 다루는것
	  
	  학습속도를 올리는건,각각의 gpu에 각각 모델을 올리고,학습데이터를 병렬로 처리해서 학습속도를 올리는것(데이터 병렬화)
	  여러 gpu에 모델을 나눠서 올리는건,모델병렬화라고 부르는데,이건 모델의 층별로 나누는 파이프라인병렬화와,한층의 모델도 나누는 텐서병렬화가 있음
	  즉 한모델을 세로로 자르냐 가로세로로 둘다 자르냐 차이임
	  
	  파이프라인병렬화는 진짜 직관적으로 이해가 되지만,텐서 병렬화는 행렬을 분리해도 같은 결과를 얻을수있게 행렬곱셈을 정렬함(자동으로 해줌)
	  트랜스포머에서는,셀프어텐션에서 쿼리,키,값 가중치행렬을 열방향으로 나눠서 행렬곱을 수행하는식
	2.데이터 병렬화에서 중복 저장 줄이기(ZeRO)
	  데이터 병렬화를 할때도 같은 모델을 여러 gpu에 올리는건 메모리낭비임
	  ZeRO는,하나의 모델을 하나의 gpu에 올리지않고,
	  모델병렬화처럼 모델을 나눠 여러 gpu에 올리고 각 gpu에서는 자신의 모델 부분만 연산을 수행하면 된다는 컨셉임
	  즉 4개로 나눠서 1의 속도로 처리하지말고,모델병렬화를 하고 4배의 속도로 처리하는게 속도도 비슷한데 메모리효율적이라는 논리

  4.효율적인 학습방법(PEET):LoRA
    기반모델의 크기가 커지면,하나의 gpu로 모든 파라미터를 학습하는 전체미세조정은 하기 어려움
	그래서 개인이 모델의 일부 파라미터만 학습시키는게 PEET임
	그중에서 가장 주목받는게 로라임
	
	로라는 모델파라미터를 재구성해 더 적은 파라미터를 학습해서 gpu메모리사용량을 줄임
	파라미터 재구성이란 행렬을 더 작은 2개의 행렬의 곱으로 표현해,전체 파라미터를 수정하는게 아닌 더 작은 2개의 행렬을 수정하는걸 의미함
	
	이건 원래 모델의 가중치는 그대로 두고,그 모델의 가로 세로 가중치(로라가중치) 한줄만 새로 만들어서,
	원래모델의 가중치와 로라가중치의 가로세로를 곱한걸 더하는방식임
	이러면 로라가중치에 대해서만 학습하면 되기떄문에 gpu사용량이 줄어듬
	이떄 어떤 파라미터위치를 선택할지는 정해야하고,보통 선형연산의 가중치를 선택함(트랜스포머에선 qkv와 피드포워드층)
	전체 선형층에 로라를 적용한게 일반적으론 성능이 가장 좋음

    1.로라 설정 살펴보기
	  로라를 사용할떄 결정해야할 사항은
	    모델파라미터에 더할 행렬 A,B를 만들떄 차원 r을 몇으로 할지
		  r이 작으면 로라의 성능이 낮아지고,높으면 gpu메모리를 많이먹음
		추가파라미터를 기존파라미터에 얼마나 많이 반영할지(알파)
		  즉 기존파라미터와 덧셈할때,가중치를 붙일수있음
		모델의 많은 파라미터중에서 어떤 파라미터를 재구성할지
	  임
	2.코드로 로라 학습 사용하기
	  쓰는건 쉬움
	  걍 허깅페이스의 peft라이브러리로 하면됨(책참조)
	  
	  로라를 쓰면 모델의 추론 메모리 사용량에 0.117%정도만 추가로 더 사용하기때문에 학습하기 쉬움
	  그러면서도 전체 미세조정과 거의 동일한 성능을 달성할수있음

  5.효율적인 학습방법(PEET):QLoRa
    Q로라는 양자화를 더한 로라임
	이건 추가적으로 페이지 옵티마이저로,cpu메모리를 가상메모리처럼 사용해서 oom을 방지하는 기능이 추가됨
	1.4비트 양자화와 2차 양자화
	  양자화를 하려는데,데이터가 순서를 사용하면 정렬해야하고,
	  어떤데이터가 몇번째순위인지를 저장해야하기때문에 연산량이 많고 순위를 저장하기위해 메모리를 사용한다는 단점이 있음
	  
	  만약 기존데이터의 분포를 알고있다면,연산없이 그냥 분포대로 순위를 정할수있음(정규분포를 따른다면 대충 위치아니까)
	  그안에서 선그어서 데이터를 균등하게 분리하는방식
	  
	  보통 모델파라미터는 거의 정규분포에 가깝기때문에,이런 방식을 사용해서 모델의 성능을 거의 유지하면서 빠른 양자화를 할수있음(NF4)
	  이게 4비트양자화이고,여기서 한발 더 나아간게 2차양자화임
	  2차양자화는 NF4과정에서 생기는 32비트 상수도 효율적으로 저장하는걸 목적으로함
	  이건 64개의 모델 파라미터마다 1개의 상수(정규분포)를 저장하는것,이때 다시 256개의 양자화 상수를 하나의 블록으로 묶어 8비트 양자화를 수행할수있음
	  이러면 32비트 256개를 8비트 256개와 양자화상수를 저장하기위한 32비트 1개로 바꿀수있음
	2.페이지 옵티마이저
	  페이지 옵티마이저는,일시적으로 메모리 사용량이 커지는 지점들에서 oom이 터지는걸 방지하기위해,페이징을 거쳐서 cpu메모리를 가상메모리로 사용하는것보다
	
	3.Q로라 활용하기
	  사용은 쉬움,그냥 bitsandbytes를 사용하면 모델을 불러올때 4비트양자화를 간단히 할수있음
	  
	
6.sLLM 학습하기	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
    
  