1.기초

머신러닝은 작업의 성능이 경험으로 인해 변하면 머신러닝 프로그램임

시스템이 학습할때 사용하는 샘플은 훈련세트
각 훈련데이터는 훈련샘플(샘플)

스팸메일분류기에서는
작업=스팸메일구분
경험=훈련데이터
성능=정확도(이건 자기가 원하는거로 직접 정해야하는데 분류에선 정확도 보통씀)

머신러닝을 통해 우리가 몰랐던 연관관계나 추세를 발견하는것은 데이터 마이닝

레이블의 종류에 따른 분류

	지도학습:훈련데이터에 레이블(정답인지 아닌지 표시)가 있는데이터로 학습하는방법

		대표적으로 분류가 전형적인 지도학습임(스팸메일분류같은)

		또 다른 예는 회귀가 있음
		회귀는 예측변수를 통해 타깃수치를 예측하는것
		예를들어 차 브랜드,주행거리등을 파라미터로 받아서 중고차값을 뱉는식
		
	비지도학습:비지도학습은 훈련데이터에 레이블이 없는상태에서 학습하는것
			대표적으로 군집,시각화등이 있음
			시각화는 레이블이 없는 데이터를 넣으면 눈으로 볼수있는 표현을 만들어줌
			예로 강아지 고양이 트럭등을 군집지어져있는걸 시각화시킨다던지 할수있음
			
	준지도학습:준지도학습은 일부만 레이블이 있는 데이터고 나머지는 레이블이 안된 데이터인상태에서 학습하는것
			예를들어서 사진여러개에서 사진들에 사람a,사람b가 사진 1,2에 있는지는 비지도학습으로 할수있지만,
			그사람이 누군지는 지도학습으로 해야하니까 
			사진에 사람abc태그하는건 비지도학습으로 하고 그 사람 이름같은거 적는건 지도학습으로 하는식
			
	강화학습:강화학습은 환경을 관찰해서 행동을 실행하고,거기따른 보상또는 벌점을 받아서 큰 보상을 따르게 행동방식을 수정하면서 반복하는것
		  게임ai나 보행로봇등에 주로 쓰임

실시간인지 아닌지에 따른 분류

	배치학습:시스템을 오프라인에서 학습 다 시킨다음에 그걸 적용하는식,온라인상에서 입력이들어와도 학습하지않고 출력만 함
		  배치학습이 새로운데이터를 학습하려면 전체데이터를 써서 처음부터 다시훈련해야함
		
	온라인학습:시스템을 하나씩,또는 일정 묶음단위로(미니배치) 주입해서 시스템을 계속 훈련시킴
		   이건 빠른 변화에 적응해야하는 시스템에 적합함
		   
		   온라인학습은 데이터를 학습하고나면 그 데이터는 필요없으니까(전으로 돌릴필요가없으면)삭제해도 됨
		   
		   그리고 메인메모리에 들어가지 않는 크기의 데이터셋을 학습할때도 이걸 사용할수있음
		   미니배치를 계속 넣는식으로 돌리면됨(외부메모리학습,배치학습인데 데이터클때 온라인학습방식으로 돌리는거)
		   
		   온라인학습에서 중요한 파라미터는 변화하는 데이터에 얼마나 빨리 적응할것인지를 나타내는 학습률
		   학습률을 높게하면 새로운 데이터에 빨리 적응하지만,이전 데이터를 금방 잊어버림
		   학습률을 낮게하면 새로운 데이터에 적응하는데는 오래걸리지만,새로운 데이터의 잡음같은거에 덜민감해짐
		   
		   온라인학습의 가장 큰 단점은 악의적데이터가 주입될때 시스템성능이 나빠질수 있다는것
		   그래서 시스템을 모니터링하거나 입력데이터를 모니터링해서 이런걸 걸러내야함

어떻게 일반화 되는가에 따른 분류
	사례 기반 학습:훈련샘플을 기억해서 유사도등을 측정해서 비교하는식으로 일반화 하는 방식
			  특성1과 특성2가 있는 그래프가 있을때,주변에 있는 값 중 가장 가깝거나 많은거로 분류하는식
	
	모델 기반 학습:샘플들의 모델을 만들어서 예측에 사용하는 방식
			  식을 만들어서  거기에 특성을 넣고 가공해서(절편을주거나,민감도를 조절하거나 해서) 대충 근처값이 나오게 하는식임
			  
			  모델이 얼마나 좋은지는 측정지표를 정해야 하는데
			  모델이 얼마나 좋은지 측정하는 효용함수나,모델이 얼마나 나쁜지 측정하는 비용함수가 있음
			  
			  선형회귀에서는 선형모델의 예측과 훈련데이터 사이의 거리를 재는 비용함수를 사용해서 
			  파라미터를 조절해 이 거리를 최소화하는게 목표임 이걸 모델을 훈련시킨다고 함
			  
즉, 머신러닝은
	데이터를 분석해서
	모델을 선택하고
	훈련데이터로 모델을 훈련시킴(비용함수가 제일 작아지는값을 찾음)
	마지막으로 새로운 데이터를 넣어서 예측을하고 잘되기를 기대함
	
머신러닝에서 문제가 되는 가장 큰 두가지는
	나쁜데이터:
		충분하지 않은량의 데이터
		
		대표성이 없는 훈련 데이터
			우리가 일반화 하기를 원하는 새로운 사례를 잘 대표하는 데이터를 넣어야함
			근데 샘플이 작으면 샘플링 잡음(우연에의한 대표성없는 데이터)
			샘플이 커도 추출방법이 잘못되면 샘플링 편향(무슨 이유등으로 한쪽에 몰린 데이터들만 추출된다거나)
			등으로 문제가 생길수있음
		
		낮은 품질의 데이터
			데이터가 에러,이상치,잡음등으로 가득하면 이상한패턴을 찾거나 패턴을 찾기 어려워하기때문에 
			데이터 정제에 시간을 투자해야함(일부샘플이 이상치인게 확실하면 지우거나,특성이 빠져있으면 샘플을 무시하거나 중간값채우거나)
			
		관련 없는 특성
			특성이 관련없는특성만 가득하거나 그러면 막 이상한값이 나올수도있음
			그래서 훈련에 사용할 좋은 특성들을 찾고,특성들을 합쳐서 더 유용한 특성을 만들어야함(특성추출)
			
	나쁜 알고리즘:
		데이터 과대적합
			훈련 데이터에 너무 잘 맞지만, 일반성이 떨어진다는 것
			세트에 잡음이 많거나 데이터셋이 너무 작을떄(샘플링잡음)잡음이 섞인 패턴을 감지하게되면(잡음의 양에 비해 모델이 너무복잡하면),
			당연히 새로운 샘플에 일반화가 안됨
			그래서 특성을 잘 골라야하고 훈련데이터의 잡음을 줄이고,훈련데이터 양을 늘려야함
			
			모델을 단순하게하고,과대적합의 위험을 감소시키기위해 모델에 제약을 가하는걸 규제 라고 함
			만약 a+bxn=c 라는 식에서 n이 특성이면,건드릴수있는건 a와 b인데 이 두개를 바꿀수 있는 자유도를 모델에 주면,(자유도2)
			모델은 직선의 절편과 기울기를 조절할수 있는데,우리가 여기서 a=0으로 고정시켜버리면 할수있는 자유도가 줄어드니까(자유도1)
			모델이 간단해지고 막 데이터에 끼워맞춘 식을 만들기 어려워지게됨
			딱 0 이렇게 안해도 수정은 할수있지만 값의 최소,최대값을 정해두면 자유도 1과 2사이 어딘가에 위치한 모델이 됨
			
			여기서 저렇게 딱 0이렇게 모델에서 변하지않고 상수로 주는걸 하이퍼파라미터라고 함
			이건 학습알고리즘에 영향을 받지않고,훈련전에 정해져있고,훈련하는동안 상수로 남아있음
			머신러닝에서 하이퍼파라미터 튜닝은 매우 중요한 과정임
			
		데이터 과소적합
			과대적합의 반대,모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할때 일어남
			이걸 해결하려면 모델파라미터를 늘리거나,더 좋은 특성을 제공하거나(특성추출등을 해서),모델의 제약을 줄여야함
		
	테스트와 검증
		
		모델이 얼마나 잘 일반화 될지 아는 방법은 가장 확실한건 실제서비스에 넣고 모니터링하는거지만,리스크가 크니까
		훈련데이터를 훈련세트와 테스트 세트로 나눠서
		훈련세트만 가지고 훈련을 한 다음에 테스트 세트를 일반화샘플처럼 사용해서 모델을 테스트함
		새로운 샘플에 대한 오류 비율을 일반화 오차라고 하는데,테스트세트로 평가해서 이 오차에 대한 추정값을 얻을수 있음
		훈련 오차가 낮지만(훈련세트에서 모델의 오차가 적지만)일반화 오차가 크다면 이건 과대적합됐다는것
		
		보통 데이터의 80퍼센트를 훈련에 쓰고,20퍼센트를 테스트용으로 떼어두는데,데이터크기에 따라 테스트데이터를 줄여도됨
		
		하지만 일반화오차를 테스트세트에서 여러번 측정하면,모델과 하이퍼파라미터가 테스트세트에 최적화된 모델을(과대적합된)만들기떄문에
		모델이 새로운 데이터에 잘 작동하지 않을수있음
		그래서 보통 홀드아웃 검증이라는 훈련세트의 일부를 떼어내서 여러 후보모델을 평가하고 가장 좋은 하나를 선택함
		이 홀드아웃세트를 검증세트라고 함
		
		구체적으로는 검증세트가 빠진 훈련세트로 다양한 하이퍼파라미터값을 가진 여러 모델을 훈련해서 프로토타입1을 만들고,
		검증세트에서 가장 높은 성능을 내는 모델을 선택해서 전체훈련세트에서 다시 훈련해 최종모델(프로토타입2)를 만들고,
		이걸 테스트세트에서 평가해서 일반화오차를 추정함
		
		이건 보통 잘 작동하는데,검증세트가 너무작으면 모델이 정확하게 평가가 안되고,검증세트가 너무 크면 훈련세트가 너무 작아지기떄문에
		최종모델은 전체훈련세트에서할건데 너무 작은데서 하면 적절하지 않음
		그래서 이걸 해결하는 방법은, 작은 검증 세트를 여러개 만들어서 사용해 반복적인 교차검증을 수행하는것
		모든 검증세트를 모든 모델에 돌린다음 값을 평균내서 고르면 훨씬 정확한 성능을 측정할수있지만,단점으로 훈련시간이 많이늘어남
		
		데이터 불일치
			만약 사진찍어서 뭔지 맞추는걸 하고싶은데 웹에서 긁어오면 엄청나게 정확한 데이터들만 있기때문에
			실제 데이터를 완벽하게 대표하지 못할수 있음
			이럴때 진짜 찍은 사진을 반반나눠서 검증세트와 테스트세트에 넣고(중복되거나 비슷한사진이 들어가면안됨)돌려야하는데
			보통 이러면 성능이 매우 나쁘게 나옴
			
			근데 이게 데이터불일치때문인지,과대적합인지 알기 어려운데 이걸 구분하는 방법은
			웹에서 긁은 데이터를 떼어내서(훈련데이터를 떼서)훈련개발세트를 만들고(훈련데이터에서 분리함)
			훈련세트에서 돌린다음 훈련개발세트에서 평가했는데 잘 작동하면 과대적합이 아니고 데이터불일치니까 데이터 전처리를 해야하고
			만약 성능이 나쁘면 과대적합이니까 규제하거나 데이터를 늘리거나 데이터정제를 해야함
			
			그래서 머신러닝은 학습용 데이터셋에서 종속변수와 독립변수의 관계를 분석해서 이거로 모델을 만드는거기떄문에
			철저하게 학습용 데이터셋에 종속됨
			
2.머신러닝 처음부터끝까지(회귀)
		
머신러닝의 순서는
	1.큰그림보기
	2.데이터 구하기
	3.데이터에서 뭘쓸지 알기위해 탐색하고 시각화하기
	4.데이터 전처리
	5.모델 선택,훈련
	6.모델 파라미터조정
	7.솔루션 제시
	8.런칭,유지보수
순서
1.큰그림보기
	
	무슨 데이터를 써서 무슨 값을 뽑을건지 알고,
	이걸 만드는 이유(이걸 최종값으로 쓸건지 다음모델에 인풋값으로 쓸건지 등) 
	이유를 알고 얼마나 정확하게 넣어야하는지 시간투자 얼마나해야하는지 등을 판단,
	현재 솔루션이 있는지,있다면 해결방법에 관한 정보랑 참고성능으로 사용할수있음
	데이터셋이 어떻게 구성된건지 
	등을 토대로 사용할 모델과 방식을 찾아야함
	
	다음으로 성능 측정 지표를 선택해야함
	회귀에서 주로 사용하는건 평균 제곱근 오차(RMSE)를 사용,만약 이상치로 보이는 구역이 많으면 평균 절대 오차(MAE)를 사용할수있음
	
	마지막으로 지금까지 짜둔 플랜을 적어서 확인해봐야됨
	만약 다음거에 값으로 들어갈줄알았는데 분류로 들어가면 아예 문제가 달라지니(회귀->분류) 확인해야함
	
2.데이터 가져오기
	
	주피터,넘파이,판다스,맷플롤립,사이킷런등을 설치하고(그냥 아나콘다 주피터노트북쓰는게 젤편할듯)
	
	1.데이터 가져오기 
		데이터 가져오는 함수 만들어두는게 편함
		
		import os
		import tarfile
		import urllib
		
		다운로드루트='url'
		저장위치=os.path.join("폴더","폴더2")
		다운로드파일=다운로드루트+"받을파일"
		
		def 데이터저장함수 (다운로드파일,저장위치):
			os.makedirs(저장위치,exist_ok=True) 저장위치로 디렉토리만들고
			저장파일=os.path.join(저장위치,"파일명") 파일저장할거 만들어두고
			urllib.request.urlretrieve(다운로드파일,저장파일) 파일 받아서 저장파일에 넣고(.tgz파일)
			파일저장=tarfile.open(저장파일)
			파일저장.extractall(path=저장위치) 파일생성(csv파일)
			파일저장.close() 닫기
		
	
	2. 데이터 읽기 
		데이터 읽기함수는
		
		import pandas as pd
		
		def 데이터읽기함수(저장위치):
			파일=os.path.join(저장위치,파일명)
			return pd.read_csv(파일)
		
		하면 데이터프레임 객체를 리턴함
		
		데이터를 받았으면 데이터를 대충 보고(값이랑 자료형같은거,오브젝트면 csv니까 문자열일거고,그게 랜덤문자인지 범주인지 확인)
		
		a=데이터읽기함수(저장위치)
		a.head() 5개만출력
		a.info() 자료형과 널이아닌값등 확인가능
		a.describe()숫자형 특성의 요약정보(max,min,평균,표준편차,25%,50%,75% 등)
		
		%matplotlib inline  주피터노트북에서 바로 출력하게 함 주피터노트북의 매직커맨드 
		import matplotlib.pyplot as plt
		a.hist(bins=50,figsize=(20,15)) 히스토그램 출력
		plt.show()
		
		히스토그램을 보고 데이터의 특이사항을 찾아야함
		데이터가 어떤식으로 스케일링 되어있는지,상한 하한이 있는지,상한하한이 있다면 어떻게 처리할것인지,한계값밖은 어떻게처리할것인지
		특성들 스케일 어떻게 맞출것인지,왼쪽이나 오른쪽이 두껍거나 그러면 종모양으로 어떻게 바꿀것인지 등
	
	
	
	
	3.테스트세트 만들기 
		대충 보고 테스트세트를 떼어놓고 나선 테스트세트는 절대 들여다보면 안됨
		막 테스트세트의 패턴보고 끼워맞추기 할수있게되기때문
		
		테스트세트 만드는 가장 쉬운방법은 랜덤으로 퍼센트만큼 꺼내는것
		
		import numpy from np
		
		def 랜덤테스트분할(데이터,테스트비율):
			데이터셔플=np.random.permutation(len(데이터))
			테스트사이즈=int(len(데이터)*테스트비율)
			테스트세트=데이터셔플[:테스트사이즈]
			트레인세트=데이터셔플[테스트사이즈:]
			리턴 데이터.iloc[트레인세트],데이터.iloc[테스트세트]
		
		트레인,테스트=랜덤테스트분할(데이터,0.2)
			
		이렇게 만들면됨
		
		단 이렇게하면 여러번 만들면(매번시드가 달라서)전체를 다 보게 되니까 
		샘플의 키값의 해시값으로 나누는게 젤 정확함(데이터가 늘어날수도있으니)
		
		from zlib import crc32
		
		def 해시체크(id,테스트비율):
			return crc32(np.int64(id))& 0xffffffff<test_ratio *2**32
		def 해시데이터분할(데이터,테스트비율,id컬럼이름):
			id=데이터[id컬럼이름]
			테스트세트=id.apply(lambda id_:해시체크(id_,테스트비율)
			return 데이터.loc[~테스트세트],데이터.loc[테스트세트]  트레이세트 테스트세트 순

		데이터프레임.loc[]는  a.loc[로우,컬럼]순으로 문자열로 검색 iloc는 인덱스로 검색
		
		만약 프라이머리키가 없어서 만들어야할때 행의 인덱스를 사용하면 새 데이터는 반드시 데이터의 끝에 추가해야하고,
		어떤데이터도 삭제되면 안됨
		이게 불가능하면 여러개를 조합해서 만들어야하는데 두개조합하면 유일성이 보장되어야함
		
		그냥 제일 편하게 분할하는건 사이킷런꺼 쓰는건데
		
		from sklearn.model_selection import train_test_split
		
		트레인세트,테스트세트=train_test_split(데이터,test_size=0.2,random_state=42) 하면 42시드로 20%만큼 분할해서나옴 
	
	
		3-2.계층샘플링
			근데 이렇게 완전히 무작위로 하면 데이터셋이 많이 크면 괜찮은데,안그러면 데이터 편향이 생길 확률이 큼
			만약 여자비율이 61퍼센트고 남자가 39퍼센트면, 여자61명 남자 39명을 뽑아야 하는데 랜덤돌리면 오차가 생겨서 여자 55명 남자 45명
			이렇게 뽑힐수가 있음(숫자가 작을때)
			
			그래서 계층에서 비율을 맞춰서 랜덤으로 뽑아야 하는데 이걸 계층적 샘플링이라고 함
			
			계층을 만드는 방법은
			
			데이터["새로만드는컬럼"]=pd.cut(데이터["목표컬럼"],
									bins[0,1.5,3.0,np.inf], 계층 범위
									labels=[1,2,3,4]) 계층별이름
			
			데이터['새로만드는컬럼'].hist() 데이터 보기
			
			이렇게 만들어서 계층샘플링을 하면 됨
			
			
			계층샘플링은 
			from sklearn.model_selection import StratifiedShuffleSplit
			
			split=StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42) 트레인세트1개 테스트사이즈0.2 시드42
			for 트레인인덱스,테스트인덱스 in split.split(데이터,데이터["새로만드는컬럼"]):
				트레인세트=데이터.loc[트레인인덱스]
				테스트세트=데이터.loc[테스트인덱스]
			
			이렇게하면 새로만드는컬럼에 있는 비율대로 랜덤하게 잘라서 트레인테스트 나눠담음
			
			그리고 나서 새로만드는컬럼을 삭제해주면됨
			
			for 세트 in (트레인세트,테스트세트):
				세트.drop("새로만드는컬럼",axis=1,inplace=True) axix는 행인지열인지 선택 1이면 열을따라동작(세로줄제거)
														  inplace는 자기자신에 바로 적용할건지 선택(세트=세트drop()안해도된다는거)
			
			
3.데이터 시각화
	1.지리적 데이터 시각화 
		일단 훈련세트떼뒀는데 건드리지 않게 복사본 만들어서 사용(훈련세트는 더이상 직접 작업하지않음 이상치제거같은거 빼곤)
		
		데이터=트레인세트.copy()
				  
		위도 경도같은게 있으면
		
		데이터.plot(kind="scatter"(종류=산점도), x="위도", y="경도",alpha=0.1(하나당 밝기=0.1)
				  s=데이터["구역인구"]/100(원의반지름=),label="구역인구"(라벨),figsize=(10,7)(차트크기),
				  c="가격"(색="가격),cmap=plt.get_cmat("jet")(색상종류뭐쓸건지),colorbar=True(옆에 바 띄울건지)
		)
		plt.legend() 범례띄우기
		이렇게 산점도로 나타내서 볼수있음
	   
	2.상관계수
		데이터셋이 별로 안크면 모든 특성간의 표준 상관계수를 corr()로 구할수있음
		
		corr값=데이터.corr()
		
		corr값["원하는컬럼"].sort_values(ascending=False)
		
		하면 원하는컬럼의 증가감소에 따른 상관관계가 나오는데,선형적인거만 알수있지 비선형적인건 알수없음(x2=y같은 2차함수이상)
		그리고 상관관계는 기울기와는 상관없이 진짜 얼마나 관계있는지가 나옴
		
		이걸 그래프로 보는 방법은
		
		from pandas.plotting import scatter_matrix
		
		원하는컬럼=["1번컬럼","2번컬럼","3번컬럼","4번컬럼"]
		scatter_matrix(데이터[원하는컬럼],figsize=(12,8))
		
		하면 그래프가 나오는데 여기서 이상치나 상관관계같은거 체크하면됨,이상치가 있으면 없애주는게 좋음
	
	
	3.특성 조합
		마지막으로 데이터를 섞어서 좀 더 높은 상관계수를 뽑아낼수 있을수도있음
		특정 지역의 방 갯수는 사람수를 모르면 주택 가격에 영향을 미치는게 낮지만,
		특성 조합으로 가구당 방 갯수를 구할수있으면 상관관계가 높아짐
		
		대충 데이터["가구당방갯수"]=데이터["총 방수"]/데이터[가구수]
		이런식으로 특성을 조합해서 추가해서 상관관계를 확인하면 좋은특성이 나올수있음
		
4.데이터 전처리
	데이터 전처리는 수동으로 하드코딩해서 하면 안되고 어지간하면 함수만들어서 자동화 해야함
	이유는
		어떤 데이터셋이 들어와도(새로운 데이터셋이) 데이터변환이 쉬움
		다른 프로젝트에 사용할수있는 변환 라이브러리를 쌓게됨
		실제 시스템에서 알고리즘에 새 데이터를 주입하기 전에 변환시킬떄 이함수를 사용할수 있음
		여러 데이터 변환을 쉽게 시도할수있고 어떤 조합이 가장 좋은지 확인하기 편리함
	
	이거도 맨처음에 훈련세트를 복사하고
	레이블값을 떼어내서 따로 넣어두고 데이터에서 레이블값을 제거함
	
	1.데이터 정제
		데이터에 누락된값(null)이 있으면 이상하게 동작하니까 이걸 처리해줘야하는데 방법은 3개임
			1.해당 로우를 제거              
			2.해당 컬럼을 제거              
			3.어떤 값으로 채우기(0,평균값 등)   
		
			데이터.dropna(subset=['원하는컬럼'])       1번
			데이터.drop('원하는컬럼',axis =1)          2번
			데이터['원하는컬럼'].fillna(0,inplace=True)3번
			
			만약 3번으로 채웠으면 저 채운값을저장해둬야 나중에 테스트세트나 실제 운영할때 새로운데이터에 있는 누락된값을 채울수있음
			
			사이킷런을 쓰면 채우기 쉬운데 중간값같은건 수치형에서만 계산 가능하기때문에 텍스트같은건 제외해서 뽑아둔다음 계산하고 합쳐야함
			
			from sklearn.impute import SimpleImputer
			
			imputer=SimpleImputer(strategy="median") 중간값으로 세팅
			데이터숫자=데이터.drop(문자열데이터컬럼들,axis=1)
			imputer.fit(데이터숫자)
			
			이러면 imputer안에 누락된값들이 다 중간값으로 채워져있음
			이걸 보고싶으면
			imputer.statistics_ 하면 각 특성의 평균값을 볼수있음
			
			이걸 넘파이 배열로 받을수도 있는데 
			
			X=imputer.transform(데이터숫자) 이러면 배열로 받아지고 다시 데이터 프레임으로 바꿀려면
			
			데이터=pd.DataFrame(X,columns=데이터숫자.columns,index=데이터숫자.index)
			이러면 데이터프레임으로 되돌릴수있음

			
			당장은 한두개특성만 비어있는칸이 있다고해도 실제 동작할때는 어떤값이 누락될지 알수없으니까 모든값에 imputer돌리는게 바람직
			그리고 물론 테스트세트에서는 훈련세트에서의 평균값을 그대로 넣어야함 테스트세트의 평균값넣으면안됨
			
	tmi)사이킷런은
		추정기:데이터셋으로 모델 파라미터를 추정하는객체를 추정기라고 부름,위에서 평균값을 알아내는 imputer은 추정기임
			추정은 fit로 이뤄지고 하나의 매개변수로 하나의 데이터셋만 전달하고,추정과정에서 필요한 다른 매개변수들은 전부 
			하이퍼파라미터로 간주되고 인스턴스변수로 저장됨
		변환기:데이터셋을 변환하는 추정기를 변환기라고 함,imputer은 변환기임
			 데이터셋을 변환할때는 데이터셋을 매개변수로 받은 transform()메서드가 수행하고 변환된 데이터셋을 반환함
		예측기:어떤 추정기들은 주어진 데이터셋에 대해 예측을 만들수가 있는데 전장에 나온 선형모델이 예측기임
			예측기의 predict()는 새로운 데이터셋을 받아 이에 맞는 예측값을 반환함
			그리고 테스트세트를 사용해 예측의 품질을 측정하는 score()메서드를 가지고있음
		보통 그래서 사이킷런으로 만들때는 pipeline를 써서 여러 변환기를 연결한다음 마지막에 추정기를 배치하는식으로 쉽게만들수있고,
		사이킷런은 대부분의 매개변수에 기본값이 있어서 어지간하면 동작함
	
	2.텍스트와 범주형특성
		범주형 특성들은 그냥 숫자로 변환시켜서 사용하는게 좋음 
		대부분 머신러닝 알고리즘은 숫자를 다루기때문
		
		숫자로 바꾸려면
		
		from sklearn.preprocessing import OrdinalEncoder
		ord=OrdinalEncoder()
		데이터2=ord.fit_transform(데이터)
		
		이러면 모든 범주형 특성들이 같은거끼리 1,2,3,4,5등으로 표시되고
		범주형특성들의 카테코리 목록은 ord.categories_를 하면 리스트가 반환됨
		
		근데 이렇게하면 알고리즘이 붙어있는거끼리 가깝다고 생각하기때문에,
		실제로 그렇지않다면 카테고리별 이진특성을 만들어 해결함(특성을 전부 만들어 두고 하나가 1이면 나머지가 다 0이되는식)
		이걸 원-핫 인코딩이라고 부름
		
		하는방법은
		
		from sklearn.preprocessing import OneHotEncoder
		
		OHenco=OneHotEncoder()
		데이터원핫=OHenco.fit_transform(데이터)
		
		이러면 원핫식으로 변환된게 나옴
	3.나만의 변환기
		변환기를 만들려면 사이킷런은 덕타이핑을 지원하므로
			fit() self를 반환
			transform()
			fit_transform()
		메서드를 구현한 클래스를 만들면 됨 
		마지막 fit_transform는 TransformerMixin을 상속하면 자동으로 생성되고
		BaseEstimator을 상속하고 생성자에 *args나 **kargs를 사용하지 않으면 하이퍼파라미터 튜닝에 필요한
			get_params()
			set_params()
		를 추가로 얻을수있음 
		
		예시로
		from sklearn.base import BaseEstimator,TransformerMixin

		rooms_ix,bedrooms_ix,population_ix,households_ix=3,4,5,6

		class CombinedAttributesAdder(BaseEstimator,TransformerMixin):
			def __init__(self,add_bedrooms_per_room=True): #생성자
				self.add_bedrooms_per_room=add_bedrooms_per_room
			def fit(self,X,y=None):
				return self
			def transform(self,X):
				rooms_per_household=X[:,rooms_ix]/X[:,households_ix]
				population_per_household=X[:,population_ix]/X[:,households_ix]
				if self.add_bedrooms_per_room:
					bedrooms_per_room=X[:,bedrooms_ix]/X[:,rooms_ix]
					return np.c_[X,rooms_per_household,population_per_household,bedrooms_per_room]
				else:
					return np.c_[X,rooms_per_household,population_per_household]
				
				
		
		
		위에서 특성 조합하는거 자동화한 함수
		init에서 베드퍼룸특성을 만들어주고 
		fit은 자기자신을 보내주는거만 하고
		트랜스폼에서 특성을 만들어서 리턴해줌
		그리고 get_params과 set_params은 파이프라인과 그리드탐색에 꼭 필요한 메소드라서 무조건 BaseEstimator를 상속해야함
		
	4.특성 스케일링
		몇가지 알고리즘을 빼면 머신러닝은 입력 숫자들의 스케일이 다르면 잘 작동하지 않음
		그래서 숫자들의 스케일링을 맞춰줘야하는데
		대표적으로
			min-max스케일링(정규화)
			표준화
		가 있음
		
		정규화는 가장 간단한데 모든값이 0과 1 범위 사이에 들어가도록 값을 이동하고 스케일을 조정하면됨
		즉,데이터에서 최소값을 빼고,최댓값-최소값의 차이로 나누면 이렇게 됨
		사이킷런에서는 MinMaxScaler변환기를 제공함
		
		표준화는 평균을 빼고 표준편차로 나눠서 결과분포의 분산이 1이되게 만듬
		표준화는 범위의 상한 하한이없어 어떤 알고리즘에선 문제가 될수있지만 이상치에 영향을 덜 받음
		사이킷런에선 StandardScaler변환기를 제공함
		
	5.파이프라인
		이렇게 막 해야할게 많고 정확한순서로 실행해야하니까 PipeLine으로 순서대로 실행할수있음
		근데 일반 파이프라인은 숫자특성만 처리할수있음
		사용법은
		
		from sklearn.pipeline import PipeLine
		from sklearn.preprocessing import StandardScaler
		
		숫자파이프라인=PipeLine([
			('빈칸채우기',SimpleImputer(strategy='median')),
			('특성추가',CombinedAttributesAdder()),
			('표준화변환기',StandardScaler()),
		
		]
		)
		데이터숫자트랜스폼=숫자파이프라인.fit_transform(데이터숫자)
		
		파이프라인은 이렇게 이름과 추정기 쌍을 입력으로 받아서(마지막단계는 변환기 추정기 둘다쓸수있지만 그전엔 전부 변환기여야함),
		전단계의 출력을 다음단계의 입력으로 넣어주고(마지막단계 전엔 fit_transform 마지막단계는 fit)
		
		그리고 범주형과 숫자형을 묶어주고싶으면

		from sklearn.compose import ColumnTransformer
		
		숫자애트리뷰트=list(데이터숫자)
		범주애트리뷰트=["범주애트리뷰트1",...]
		
		풀파이프라인=ColumnTransformer([
			('숫자',숫자파이프라인,숫자애트리뷰트),
			('범주',OneHotEncoder(),범주애트리뷰트)
			
		])
		총데이터=풀파이프라인.fit_transform(데이터)
		
		이런식으로 묶어서 받을수있음
		
		여기서 OneHotEncoder는 희소행렬을 반환하는데 숫자파이프라인은 밀집행렬을 반환함
		이렇게 두개가 섞여있을땐 최종행렬의 밀집정도를 추정해서(0이아닌 원소의비율) 밀집도가 일정수치보다 낮으면 희소행렬을 반환함
		높으면 밀집행렬을 반환
		
5.모델선택과 훈련
	1.훈련세트에서 훈련과 평가
		앞에서 전처리랑 다해놨으면 그냥
		from sklearn.linear_model import LinearRegression
		
		선형모델=LinearRegression()
		선형모델.fit(총데이터,데이터레이블)
		
		하면 끝임
		
		이제 훈련세트에 있는 샘플 몇개를 넣어보려면
		
		a데이터=데이터.iloc[:5]
		a라벨=데이터레이블.iloc[:5]
		a전처리데이터=풀파이프라인.transform(a데이터)
		선형모델.predict(a전처리데이터)
		
		하고나서 a라벨과 선형모델값을 비교해보면 됨
		
		값을 아까 봤던 RMSE로 측정해보려면
		
		from sklearn.metrics import mean_squared_error
		
		데이터예측값=선형모델.predict(총데이터)   데이터 넣고 값만 받아보기 훈련x 내부에 영향끼치지않음
		선형mse=mean_squared_error(데이터레이블,데이터예측값)
		선형rmse=np.sqrt(선형mse)
		
		하면 값이 나옴
		
		여기서 오차가 크면 과소적합된거니 더 강력한모델을 쓰거나 더 좋은특성을 넣거나 규제를 감소시켜야됨
		우리가 지금한거는 규제가 없으니 더 강력한모델이나 더 좋은특성을 넣어야함
		
		만약 더 강력한 모델을 썼는데 과대적합나면 교차검증을 사용할수있음
	2.교차검증
		사이킷런에는 훈련세트를 n개로 나눠서 n번 훈련하는데 그중 n-1개로 훈련하고 n개로 평가하는식으로 할수있는 기능이 있음
		사용법은
		
		from sklearn.model_selection import cross_val_score
		
		스코어=cross_val_score(사용모델,총데이터,데이터레이블,scoring="neg_mean_squared_error",cv=10)
		모델스코어=np.sqrt(-스코어)
		
		사이킷런의 교차검증은 클수록 좋은 효용함수기때문에 mse의 반대값인 neg_mean_squared_error를 사용하고,
		계산하기전에 -붙여서 부호바꿔줘야함
		
		결과보는법은
		print(모델스코어) 점수배열 리턴되고
		print(모델스코어.mean()) 평균 리턴
		print(모델스코어.std()) 표준편차 리턴

		
		근데 이방식은 엄청 오래걸려서 비용이 비싸니까 막 아무때나 쓸수있는건 아님
		
	tmi)여러 다른 모델들을 모아서 하나의 모델을 만드는걸 앙상블 학습이라고 함
	
6.모델 세부 튜닝
	1.그리드탐색
		가장 무식한방법은 괜찮은 값이 나올때까지 수동으로 하이퍼파라미터값 다넣어보는건데 누가 이렇게해
		
		보통 저렇게 하고싶으면 GridSearchCV를 사용함
		
		사용법은
		
		from sklearn.model_selection import GridSearchCV
		
		파라미터배열=[
			{'n_estimators':[3,10,30],'max_features':[2,4,6,8]},
			{'bootstrap':[False],n_estimators:[3,10],'max_features':[2,3,4]}
		]
		
		사용모델=모델()
		
		그리드서치=GridSearchCV(사용모델,파라미터배열,cv=5,scoring='neg_mean_squared_error',
							return_train_score=True)
		그리드서치.fit(총데이터,데이터레이블)
		
		이러면 파라미터 배열 위에있는 3x4개를 평가하고 두번째에서 부트스트랩을 false로 한다음 2x3개를 평가함
		총 18개를 5번씩 90번 훈련함
		
		여기서 만약 max_features:8 n_estimators:30 이렇게 최대값이 나왔으면 올라갈수록 점수가 향상될 가능성이 있으니까
		값을 올려서 다시돌려주는게좋음
		
		만약 최적의 추정기에 직접 접근하고싶으면
			그리드서치.best_estimator_
		하면 나옴
		
		평가점수는 
			그리드서치.cv_results_
		하면 나옴
		
	2.랜덤탐색
		랜덤으로 탐색하고 싶으면 RandomizedSearchCV를 사용하면 됨 GridSearchCV와 거의 똑같음
		특히 규제처럼 설정값이 연속형이면 랜덤탐색이 권장됨
		
		장점은 1000회반복하도록하면 파라미터마다 각기 다른 1000개의 값을 탐색함
		반복횟수를 조절하는거만으로 얼마나 오래돌릴건지를 제어하기 편함
	
	3.앙상블
		최상의 모델을 연결해보는것 최상의 단일모델보다 모델의 그룹이 더 나은 성능을 발휘할때가 많음
	
	4.최상의 모델 분석
	최상의 모델을 분석하면 좋은 특성등 좋은 통찰을 얻는 경우가 많음
	예를들어 
		그리드서치.best_estimator_.feature_importances_
	하면 특성의 상대적인 중요도가 나오는데 이걸 바탕으로 덜 중요한 특성을 제외할수있음
	
	5.테스트세트 사용하기
		이거도똑같이 예측변수와 레이블을 따고 풀파이프라인에 넣고(여기서 학습하면안되니까 fit_transform이 아니라 transform해야함)
		테스트세트에서 모델 평가하면됨
		
			파이널모델=그리드서치.best_estimator_
			
			테스트데이터=테스트세트.drop('레이블',axis)
			테스트레이블=테스트세트['레이블'].copy()
			
			테스트전처리데이터=풀파이프라인.transform(테스트데이터)
			
			파이널예측=파이널모델.predict(테스트전처리데이터)
			
			파이널mse=mean_squared_error(테스트레이블,파이널예측)
			파이널rmse=nq.sqrt(파이널mse)
		
		만약 이런 추정이 얼마나 정확한지 알고싶으면 scipy.stats.t.interval()을 써서 일반화오차 95%신뢰구간을 계산할수있음
		
			from scipy import stats
			신뢰구간=0.95
			제곱오차=(파이널예측-테스트레이블)**2
			np.sqrt(stats.t.interval(신뢰구간,len(제곱오차)-1,loc=제곱오차.mean(),scale=stats.sem(제곱오차))
			
		보통 하이퍼파라미터 튜닝을 많이하면 교차검증보다 성능이 조금낮은게 보통임
		그래도 테스트세트 점수올릴라고 하이퍼파라미터 튜닝하면 안됨 그러면 새로운데이터 일반화가 안됨
7.런칭 유지보수
	전체 전처리 파이프라인과 예측파이프라인이 포함된 사이킷런 모델을 joblib를 사용해서 저장하고,
	이거를 상용환경에서 로드하고 predict를 사용해서 예측을 만들면 됨
	웹을쓰든 뭘쓰든 저거만 연결시켜주고 rest api같은거든 뭐든 연결만 시켜주고 인풋아웃풋만 있으면 됨
	
	배포를 했으면 시스템의 성능을 체크하고 성능이 떨어졋을때 알림을 줄수있는 모니터링 코드를 만들어야함
	
	



3.분류
1.mnist
	mnist는 분류에서 제일 테스트하기 좋은 데이터셋
	받으려면
		from sklearn.datasets import fetch_openml
		mnist=fetch_openml('mnist_784',version=1)
	하면 받아짐
	보통 데이터셋의 구조는
	
		데이터셋을 설명하는 DESCR
		샘플이 있는 data
		레이블이 있는 target
	
	그리고 데이터갯수와 특성수를 확인하고싶으면
	mnist.shape
	하면 (데이터갯수,특성수)가 나옴
	
	이게 픽셀식이면 그려볼수도 있는데 그릴려면
	
		import matplotlib as mpl
		import matplotlib as plt
		
		x=mnist['data']
		y=mnist['target']
		
		샘플=x[0]
		샘플이미지=샘플.reshape(가로픽셀수,세로픽셀수)
		
		plt.imshow(샘플이미지,cmap='binary')
		plt.axos("off")
		plt.show()
	이러면 픽셀이 그려짐
	
	만약 레이블이 문자로 들어가 있으면,알고리즘은 숫자를 기대하기떄문에 정수로 바꿔줘야함
		y=y.astype(np.uint8)
	
	그리고 이제 테스트세트랑 트레인세트를 나눠야하는데,mnist는 이미 나눠뒀으니까 
	앞에 6만개 트레인으로 쓰고 뒤에 1만개 테스트세트로쓰면됨
		xtrain,xtest,ytrain,ytest=x[:60000],x[60000:],y[:60000],y[60000:]
	훈련세트는 이미 섞여있으니까 모든 교차검증폴드가 비슷하게 나옴
	그리고 어떤알고리즘들은 샘플의 순서에 민감해서 비슷한애들이 연이어 나오면 성능이 나빠짐,
	단 날씨나 주식같은 연속성있는애들은 당연히 섞으면안됨
	
2.간단한분류테스트(이진분류)	
	스팸처럼 true false 분류하는걸 이진분류기라고함
	
	확률적 경사 하강법(SGD)는 매우 큰 데이터셋을 효율적으로 처리하는 장점을 가지고있음(그래서 온라인학습에 잘맞음)
	사용법은
		from sklearn.linear_model import SGDClassifer
		
		sgd모델=SGDClassifer(random_state=시드값)
		sgd모델.fit(트레인세트,트레인레이블)
		
	그리고 사용할땐 predict쓰면됨
		sgd모델.predict([이미지])
	
3.성능측정
	1.교차검증
		분류를 cross_val_score로 교차검증하면 정확도가 막 95%이렇게 나오는데
		분류에서는 막 전부 트루주고 그래도 90퍼센트이상 나오는경우가 있기때문에,분류에서는 정확도를 성능측정지표로 잘 사용하지 않음
		특히 불균형한 데이터셋을 쓸때 특히 더 그럼
	2.오차 행렬
		그래서 교차검증말고 사용하는 방법이 오차행렬인데,오차행렬은 클래스a의 샘플이(5가)클래스b로(3으로) 분류된 횟수를 센 행렬임
		만약 5가 3으로 잘못분류된 횟수를 알고싶으면 5행3열을 보면 됨
		
		오차행렬 사용법은 
		
			from sklearn.model_selection import cross_val_predict
			
			예측값=cross_val_predict(모델,트레인세트,트레인레이블,cv=반복횟수) 
			
			from sklearn.metrics import confusion_matrix
			
			confusion_matrix(레이블,예측값)
		cross_val_predict는 cross_val_score처럼 k겹 교차 검증을 하지만 
		평가점수를 반환하지않고 각 테스트폴드에서 얻은 예측을 반환함,즉 3이 5로 예측된 수,5가 5로 예측된 수등을 묶어서 리턴함
		만약 tf만 있는걸 오차행렬로 만들면
			[진짜음성,가짜양성]
			[가짜음성,진짜양성]
		이렇게됨
		만 숫자분류기처럼 10개씩 있는건 왼쪽위부터 대각선이 제대로 들어간값이고 나머지가 오류값
		완벽한 분류기는 대각선을 제외한 모든게 0임
	3.정밀도와	재현율
		좀 더 간략한 지표는 
			양성예측의 정확도,즉 정밀도 ->정밀도= 진짜양성/(진짜양성+가짜양성)
			정확하게 감지한 양성샘플의 비율,즉 재현율->재현율=진짜양성/(진짜양성+가짜음성)
		을 사용함
		
		사이킷런에서 사용하려면
			from sklearn.metrics import precision_score,recall_score
			
			precision_score(레이블,예측값)  #정밀도
			recall_score(레이블,예측값)#재현율
			
		이거 두개를 묶은걸 f1점수라고 하는데 이건 정밀도와 재현율의 조화평균임
		
		사용법은
		
			from sklearn.metrics import f1_score
			f1_score(레이블,예측값)
		
		평균적으로 높은값을 뽑아내야하면 f1점수를 사용하면 되는데,상황에따라 정밀도가 더 중요할수도 있고 재현율이 더 중요할수도있음
		만약 애들유튜브 분류기라고하면 다른 이상한거 막 다 잡는다고 쳐도 최대한 정밀도를 높게 가져가야하고,
		도둑이미지 분석같은걸 하면 아무때나 막 알람 울려도 최대한 재현율 높게 가져가야하는거처럼 상황마다 다름
		
		둘다 높으면 좋겠지만,정밀도를 올리면 재현율이 줄고 재현율을 올리면 정밀도가 줄어듬
	
	4.정밀도재현율 트레이드오프
		
		보통 머신러닝에서 임계값을 잡아두고(이거 이상이면 양성)그걸 움직이면서 정밀도 재현율을 조절함
		사이킷런에선 임계값을 직접 정할수는 없지만 예측점수를 받아볼수는 있음
			임계값점수=sgd모델.decision_function([샘플])
			임계값점수
			
			결과::: array([2412.2434])
			
		저렇게 받아서 후처리하는식으로 조절할수는있음
			임계값세팅=8000
			임계값후처리=(임계값점수>임계값세팅)
			
			결과:::array([False])
		이런식으로 받아볼수있음
		
		우리가 적절한 임계값을 정하려면,cross_val_predict로 모든 샘플의 점수를 구해야하는데,
		이번엔 예측결과가 아니라 결정점수를 받아야함
		
			결정점수=cross_val_predict(sgd모델,트레인세트,트레인레이블,cv=3,method='decision_function')
			#method='decision_function'하면 결정점수 리턴함
		
		이 점수로 precision_recall_curve()함수를 사용하면 모든 임계값에 대한 정밀도 재현율이 나옴
			from sklearn.metrics import precision_recall_curve
			
			정밀도,재현율,임계값=precision_recall_curve(레이블,결정점수)
			
		이제 임계값으로 정밀도 재현율 그래프를 그릴수있음
			def 정밀도재현율그래프(정밀도,재현율,임계값):
				plt.plot(임계값,정밀도[:-1],'b--')
				plt.plot(임계값,재현율[:-1],'g-')
				
			정밀도재현율그래프(정밀도,재현율,임계값)
			plt.show()
			
			
		tmi)(또 다른 방법은 재현율에 대한 정밀도 곡선을 그리는거임,
			그러면 average_precision_score()를 써서 곡선의 아래면적을 계산할수있어서 
			다른 두 모델을 비교하는데 도움이됨)
			
		보면 그래프가 급격하게 꺾이는점이 있는데 그거 직전을 트레이드오프로 선택하는게 좋음
		
		물론 프로젝트성격따라 달라지는데 만약 정밀도 90% 달성하는게 목표면 
			임계값90퍼=임계값[np.argmax(정밀도>=0.90)] 
		하면 최대값의 첫번째 인덱스를(가장 재현율이 높은)반환함
		
		트레인세트에 대한 예측을 만들려면 분류기의 predict를 쓰는게 아니라 
			y트레인90퍼=(예측점수>=임계값90퍼)
		하면됨
		
		근데 막 정밀도 높이면 재현율이 엄청낮아지니까 잘생각해야함
		
	5.ROC곡선
		ROC곡선은 가짜양성에 대한 진짜양성의 그래프임
		이건 1에서 진짜음성을 뺀값과 같음(1-진짜음성을 특이도라고 부름)
		
		즉,roc곡선은 민감도에 대한 1-특이도 그래프임
		
		
		roc곡선을 그리려면 먼저 roc_curve()를 사용해서 임계값에서 재현율(tpr),특이도(tnr)을 계산해야함
		
			from sklearn.metrics import roc_curve
			
			재현율,특이도,임계값=roc_curve(레이블,예측점수)
		
		그리고나서 맷플롯립으로 tpr에대한 fpr곡선을 그리면됨
		
			def roc커브그래프(재현율,특이도,label=none):
				plt.plot(재현율,특이도,linewidth=2,label=label)
				plt.plot([0,1],[0,1],'k--')#대각선,완전랜덤분류기임
		
			roc커브그래프(fpr,tpr)
			plt.show()
		
		여기서도 트레이드오프가 있는데,재현율이 높을수록 분류기가 만드는 거짓양성(fpr)이 늘어남
		좋은 분류기는 랜덤분류기(대각선)에서 최대한 멀리 떨어져있어야함
		
		곡선 아래 면적(AUC)을 측정하면 분류기를 비교할수있음,완벽한 분류기는 1이고 완전한 랜덤분류기는 0.5임
		사이킷런에서 계산하려면
			from sklearn.metrics import roc_auc_score
			
			roc_auc_score(레이블,예측점수)
		하면됨
		
		정밀도재현율과 roc곡선중 어떤때 뭘 선택하냐면
		양성클래스가 드물거나,거짓음성보다 거짓양성이 중요하면 정밀도재현율을 쓰고,그렇지않으면 ROC를 사용함
		
		RandomForestClassifer에서 predict_proba()메서드는 샘플이 행 클래스가 열이고,
		샘플이 주어진 클래스에 속할 확률을 담은 배열을 리턴함(어떤 이미지가 5일 확률 70% 이런식)

4.다중분류		
	다중분류는 이중분류랑 다르게 둘 이상의 클래스를(숫자를 구별한다던지)구별할수있음
	알고리즘마다 여러개를 처리할수 있는 알고리즘(sgd,랜덤포레스트,나이브베이즈)들이 있고,
	이진분류만 가능한 알고리즘(로지스틱회귀,서포트벡터머신)이 있음
	하지만 이진분류기 여러개를 써서 다중클래스를 분류하는 기법도 많음
	
	만약 특성숫자 하나만 구분하는 숫자 이진분류기가 10개면 0부터 10까지 이미지분류를 할수있음,
	이미지 분류할때 가장 점수높은걸 선택하면됨,이런방식을 OvR(혹은 OvA)라고 함
	
	또 다른 방법은 0과 1구별,0과 2구별,1과 2구별 이런식으로 조합마다 이진분류기를 훈련시키는것,이걸 OvO라고 함
	클래스가 N개면 Nx(N-1)/2개가 필요함
	mnist에서 이미지 하나를 분류하려면 45개((10x9)/2)를 통과시켜서 가장 많이 양성으로 분류된 클래스를 선택함
	OvO의 가장 큰 장점은 각 분류기의 훈련에 전체 훈련세트중에서 구별할 두 클래스에 해당하는 샘플만 필요하다는것
	
	일부 알고리즘은 훈련세트크기에 민감해서 큰 훈련세트에서 몇개의 분류기를 훈련시키는거보다,작은훈련세트에서 많은 분류기를 훈련시키는게
	더 빨라서  OvO를 선호함,하지만 대부분은 OvR을 선호함
	
	분류기에서 점수=svm모델.decision_function([샘플])
	하면 분류기 클래스마다 점수를 보여줌,이 점수중 가장 높은점수를 리턴

	사이킷런에서 OvO나 OvR을 사용하도록 강제하려면 OneVsOneClassifier이나 OneVsRestClassifier을 사용하면됨
	sveone=OneVsOneClassifier(SVC())이런식으로 안에다가 알고리즘넣는식

	그리고 2장에서도 그랬지만,입력의 스케일을 조정하면(StandardScaler를써서) 정확도가 올라감
	
5.에러분석
	모델의 성능을 향상시키는 한가지 방법은 에러의 종류를 분석하는거임
	첫번째로,오차행렬을 살펴볼수있음
	아까처럼 cross_val_predict로 예측을 만들고,confusion_matrix로 오차행렬을 만들수있음
	
	보기편하게하려면
		plt.matshow(오차행렬,cmap=plt.cm.gray)
		plt.show()
	하면 오차행렬이 색으로 나옴 밝으면 많이들어갔다는거

	에러부분에 초점을 맞추려면 오차행렬의 각 값을 대응되는 클래스의 이미지갯수로(에러갯수가아님)나눠서 에러비율을 비교(갯수로하면 이미지많은
	애들이 나쁘게보임)
	
		행의합=오차행렬.max(axis=1,keepdims=True)
		나눈값=오차행렬/행의합

	여기서 주대각선만 0으로 채워서 그래프그리면됨
		np.fill_diagonal(나눈값,0)
		plt.matshow(나눈값,cmap=plt.cm.gray)
		plt.show()

	열이 밝으면 그거로 잘못 분류된 이미지가 많다는소리,오차행렬은 반드시 대칭인것은 아님
	
	오차행렬을 분석하면 성능향상방안에 대한 통찰을 얻을수있음,만약 8로 잘못분류되는게 많다면 8처럼보이지만 8이 아닌 훈련데이터를 구해서
	분류기를 학습시킬수도 있고,8분류에 도움이 될만한 특성을 추가할수도있음

6.다중레이블분류
	분류기가 샘플마다 여러개의 클래스를 출력해야할수도있음(얼굴인식 분류기면 사진마다 사람수만큼 [0,1,1,0...]이런식으로)
	이렇게 여러개의 이진태그를 분류하는 시스템을 다중레이블분류라고 함
	
	다중레이블분류를 평가하는 방법은 많지만 가장 편한건 f1점수를 모든 레이블에 대해 평균낸값임
	
	근데 다중레이블 분류에서 단순히 그냥평균내면 더 많이나온애에 대한 점수에 높은 가중치가 붙으니까,
	타깃레이블에 속한 샘플수(지지도)를 가중치로 주면(average='weighted'넣으면됨)됨
	
7.다중출력분류
	
	다중출력분류는 다중출력 다중클래스분류임,즉 다중레이블분류에서 한 레이블이 값을 두개이상 가질수 있도록 일반화한것
	예를들어 이미지에서 잡음을 제거하는 시스템이 있음,잡음이 많은 이미지를 입력으로 받고,깨끗한이미지를 픽셀의 강도를 담은 배열로 출력할때
	분류기의 출력이 다중레이블(픽셀당 한 레이블이 모인 배열)이므로 다중출력분류임




4.모델훈련

1.선형회귀
	보통 선형회귀모델은 (x_0은 1)y=a_0x_0 + a_1x_1+...+a_nx_n  이런식으로 y=n+mx식을 띄게됨
	즉,입력특성의 가중치(특성과 가중치의 곱)의 합과 편향(절편)상수를 더해서 만들어짐
	
	모델을 훈련시킨다는건 훈련세트에 가장 잘 맞도록 모델 파라미터(가중치와 편향)를 설정하는것
	선형회귀에서 가장 널리사용되는 성능측정지표는 RMSE,그렇지만 MSE가 같은결과를 내면서 간단해서 MSE씀
		MSE=모든샘플x( (가중치x특성)-레이블 )/전체샘플갯수
		
	즉 모든샘플의 각각모든 특성에 특성에 따른 가중치를 씌워서 레이블이랑 비교한후,총합해서 가장 값이 작아지는 가중치를 찾으면됨
	
	1.정규방정식
		저 비용함수를 최소화하는 값을 찾는 수학공식이 있긴한데,그걸 정규방정식이라고 함
		근데 잘안씀 쓰기도힘들고 코스트도 비싸서
		
		대충 O(n^2.8)쯤 되는거같음 역행렬쳐서 뭐시기뭐시기하는데 넘어갈래  쓰지도않는거같고
	
2.경사하강법(GD)
	경사하강법은 여러문제에서 최적의해법을 찾을수있는 일반적인 최적화 알고리즘임
	경사하강법은 비용함수를 최소화 하기위해 반복해서 파라미터를 조정해가는것
		
	즉,현재 파라미터에 대해 비용함수의 현재 기울기를 계산하고,
	기울기가 감소하는 방향으로 진행하다 기울기가 0이되면 최소값에 도달한것
	
	구체적으로는 임의의 값으로 시작해서(무작위 초기화),
	한번에 조금씩(학습률에따라)비용함수가 감소하는 방향으로 진행해서,
	알고리즘이 최소값에 수렴할때까지 점진적으로 향상시킴
	
	경사하강법에서 중요한 파라미터는 스텝(한번에 얼마나 파라미터를 바꿀지)의 크기로,학습률 하이퍼파라미터로 결정됨
	만약 학습률이 너무 작으면 알고리즘이 수렴하기위해 반복을 많이해야해서 시간이 오래걸림
	하지만 학습률이 너무 크면 그래프의 반대편으로 건너뛰어서 이전보다 더 높은곳으로 올라갈수도 있음,이러면 발산돼서 답이 안나오게됨 
	
	모든 비용함수가 2차함수그래프는 아니라서 막 기울기가 0이되는게 2군데이상 있거나,중간에 평평한곳이 있거나 그럴수 있는데,
	그러면 최소값으로 수렴하기 매우 어려워짐
	만약 지역최소값이 있고 그쪽으로 접근하면 지역최소값에 걸려서 전역최소값을 찾을수없어지고,
	평지에 걸리면 평지를 지나는데 시간이 오래걸리고 일찍 멈춰서 전역최소값에 도달할수없어짐
	
	그래도 선형회귀에서의 mse함수는 볼록함수(2차함수그래프)라서 지역최소값이 없고,하나의 전역최소값만 있고,연속된함수에,기울기가 변하지않음
	즉,학습률이 너무 높지않고 충분한 시간이 주어졌을때 경사하강법이 전역최소값에 가깝게 접근할수 있다는걸 보장함
	
	그리고 경사하강법은 특성들의 스케일을 맞춰줘야함
	특성들의 스케일이 다르면 시간이 많이 오래걸림(StandardScaler사용)

	1.배치경사하강법
		배치경사하강법은 매 스탭마다 훈련 데이터 전체를 사용해서 계산
		즉, 큰 훈련세트에서는 엄청 느려짐,하지만 특성수에는 그렇게 민감하지 않아서 특성이 수십만개면 경사하강법쓰는게좋음
		
		경사하강법을 구현하려면 각 모델파라미터에 대해 비용함수의 기울기를 계산해야함
		즉, 모델파라미터가 조금 바뀔때 비용함수가 얼마나 바뀌는지를 계산해야함 이걸 편도함수 라고 함
		이걸 모든 파라미터에 대해서 계산함
		
		경사하강법은 기울기가 0이되는 지점을 찾는거기때문에, 현재기울기가 양수면 왼쪽으로 가야하고,음수면 오른쪽으로 가야하니
				다음스탭=모델파라미터-(학습률x기울기벡터xMSE )
				그냥 일반적으로 가볍게보면
				x다음위치=x현재위치-(학습률x기울기값)
				기울기값은 최소값에 가까워질수록 줄어드니 처음엔 크게움직이고,나중엔 조금움직이는거에도 적합함
		해야함
		기울기의 반대로 가야하니 현재모델파라미터에서 빼준것
		
		경사하강법에서 반복횟수는 그리드식으로 찾을수 있지만 너무오래걸리면,
		반복횟수를 엄청크게 잡고 벡터값이 허용수치보다 작아지면 최소값에 도달했다치고 알고리즘을 종료시키면됨
	
	2.확률경사하강법
		배치경사하강법의 가장 큰 문제는 매스탭마다 전체훈련데이터를 사용해야해서 엄청느리다는것임
		그래서 확률경사하강법이라는것도 있는데,이건 매 스탭마다 하나의샘플을 무작위로 선택하고,
		그 하나의 샘플에 대한 기울기를 계산함
		이건 매 반복마다 다뤄야할 데이터가 매우 적기때문에 훨씬빠르고,
		매반복에서 하나의샘플만 있으면되니까 훈련세트가 아무리커도 상관없음
		
		하지만 확률적이기떄문에 배치보다 훨씬 불안정하고,비용함수가 최소값에 다다를때까지 위아래로 요동치면서 평균적으로 감소함
		시간이 지나면 최소값에 매우 근접하겠지만,최소값에 안착하지는 못함
		
		그리고 지역최소값이랑 전역최소값이 있으면 랜덤으로 배치하기때문에 
		확률적 경사하강법이 배치경사하강법보다 전역최소값찾을 가능성이 높음

		즉,전역최소값에 정확히 일치시킬수는 없지만 지역최소값을 피할확률은 높음
		
		이걸 해결하려면 학습률을 점진적으로 감소시키는방법을 생각해볼수있음
		
		시작할떄는 학습률을 크게하고(수렴을 빠르게하고 지역최소값에 빠지지않게함),점차 줄여서 전역최소값에 도달하게 함
		
		이렇게 매 반복에서  학습률을 결정하는 함수를 학습 스케줄 이라고 함
		학습률이 너무빨리 줄어들면 지역최소값에 갇히거나 최소값가기전에 멈출수있고,
		학습률이 너무 천천히 줄어들면 최소값 주변을 맴돌거나 훈련이 너무빨리끝나서 지역최소값에 머무를수있음
		
		확률경사하강법은 일반적으로 한반복에서 훈련세트샘플수만큼 되풀이되고,각 반복을 에포크 라고 함
		
		샘플을 무작위로 선택하기때문에 어떤샘플은 한 에포크에서 여러번 선택될수있고,어떤샘플은 전혀 선택되지못할수도있음
		
		사이킷런에서 확률경사하강법을 쓰려면 SGDRegressor을 쓰면됨
		
	3.미니배치경사하강법
		미니배치경사하강법은 전체훈련세트나 하나의 샘플이 아닌,미니배치라고 부르는 임의의 작은 샘플 세트에 대해 기울기를 계산함
		미니배치의 장점은 gpu를 사용해서 얻는 성능 향상임
		
		미니배치를 어느정도 크게하면,sgd(확률경사하강법)보다 덜 불규칙적으로 움직이고 sgd보다 최소값에 더 가까이 도달함
		하지만 지역최소값에서 빠져나오기는 더 힘들수도있음
	4.알고리즘비교
		선형회귀에서 알고리즘비교
		
		알고리즘명   샘플이클때   외부메모리학습   특성수가많을때   하이퍼파라미터수   스케일조정필요   사이킷런
		정규방정식    빠름         no        느림           0           no         없음 
		SVD       빠름         no        느림           0           no       LinearRegression
		배치경사     느림         no        빠름           2           yes      SGDRegressor
		확률적경사    빠름        yes        빠름           >=2         yes      SGDRegressor
		미니배치경사   빠름        yes        빠름           >=2         yes      SGDRegressor
		
		이알고리즘들은 훈련결과에 차이가 없고,매우 비슷한모델을 만들고 같은방식으로 예측을 함
		
3.다항회귀
	가진 데이터가 직선보다 복잡한 형태라도,즉 비선형데이터라도 학습하는데 선형모델을 사용할수 있음
	제일 간단한 방법은 각 특성의 거듭제곱을 새 특성으로 추가하고,이 특성을 포함한 데이터셋에 선형모델을 훈련시키는것
	이런걸 다항회귀라고 함(즉 제곱을 넣어서 제곱으로 선을 그리니 직선이 아닌 n차함수그래프를 만들수있음)
	
	거듭제곱을 추가하는법은
		from sklearn.preprocessing import PolynomialFeatures
		
		poly=PolynomialFeatures(degree=2(차수),include_bias=False(편향을 위한 변수 제거(상수제거)))
		xpoly=poly.fit_transform(x)
	이러면 원래특성과,특성의 제곱이 포함됨
	
	이걸 그냥 LinearRegression으로 돌리면
		linreg=LinearRegression()
		linreg.fit(xpoly,y)
	이러면 곡선형태의 그래프가 나오는데(직선이 아닌)
	이렇게 할수있는 이유는,
	PolynomialFeatures가 특성 a,b가 있고 차수가 3일때 
	a^2,b^2,a^3,b^3만이 아닌 ab,a^2b,ab^2등 교차항을 추가하기떄문
	그래서 서로간의 관계에 따른 추세도 그래프에 반영시킬수 있음
	
	보통 그래프가 2차함수그래프면 차수도 2에맞춰주는게좋고,3차함수면 3에맞춰주는게 좋음
	
	그리고 PolynomialFeatures를 쓸때 특성이 많으면 엄청나게 늘어나니까 조심해야함
4.학습곡선
	물론 몇차함수로 생성된 그래프인지 알긴 어렵고,고차 다항모델을 쓰면 훈련데이터엔 잘 맞지만,과대적합돼버림
	그래서 좀 높은 차수를 쓴다음에 규제하거나 이런식으로 하는듯
	
	모델의 성능을 추정할때 교차검증을 쓸수도있지만(훈련엔 좋지만 교차검증점수가 나쁘면 과대적합,둘다나쁘면 과소적합)
	학습곡선을 쓸수도 있음
	학습곡선은 훈련세트와 검증세트의 모델 성능을 훈련세트크기나 훈련반복의 함수로 나타냄,
	즉 rmse같은 평가함수를 y 세트반복수를 x로 잡고 그래프를 그림
	
	학습곡선에서 과소적합된 그래프는 훈련데이터의 rmse가 금방금방 상승해서 
	평평해질떄까지 시간이 얼마 안걸리고,평균오차가 크게 나아지지않음
	검증세트에서도  초창기에 엄청 크다가 금방 내려와서 훈련데이터와 비슷하게 평행해서 나감
	
	역시 과소적합되면 금방금방 붙긴하는데 그냥 에러치 자체가 높은게 문제임
	
	학습곡선에서 과대적합된 그래프는 훈련데이터의 rmse가 처음엔 아예 0이다가(차수까지는) 서서히 올라가고,
	검증세트에서는 초창기는 엄청나게 큰데,훈련데이터가 쌓일수록 내려와서, 훈련데이터가 많이 쌓였을땐 과소적합보다 오차가 훨씬 낮고
	데이터가 많아질수록 훈련세트와 검증세트의 선이 붙음
	
	
	tmi)오차는 총 3가지가 있는데
		편향(절편과다름):잘못된 가정으로 인한 오차
			데이터가 2차인데 선형으로 가정한다던지 할경우
			편향이 큰 모델은 과소적합되기 쉬움
		분산:훈련데이터의 작은 변동에 모델이 과도하게 민감해서 나타남
			자유도가 높은(차수가높은)모델이 분산이 높기쉬워서 데이터에 과대적합되는 경향이 있음
		줄일수없는오차:데이터 자체에 있는 잡음,
				  고치는법은 데이터에서 잡음을 제거하는거밖에없음


5.규제가 있는 선형모델
	과대적합을 줄이는 좋은방법은 모델을 규제하는것,
	다항회귀모델을 규제하는 간단한방법은 다항식의 차수를 감소시키는것
	대부분 규제가 있는 모델은 스케일에 민감하기때문에 스케일을 맞춰줘야함
	
	선형회귀모델에서는 보통 모델의 가중치를 제한해서 규제를 가함
	
	1.릿지 회귀
		릿지회귀는 규제가 추가된 선형회귀의 한 버전임
		규제항 a가 비용함수에 추가되는데(a*모델파라미터),
		이는 학습 알고리즘을 데이터에 맞추는것뿐만 아니라 모델의 가중치가 가능한 작게 유지되도록 노력함
		
		식은 가중치벡터의L2노름(벡터 두개의 직선거리)의 제곱을 2로 나누면 되는데 뭐 신경쓰지말고 대충이해하자
		
		규제항은 훈련하는 동안에만 비용함수에 추가되고,훈련이 끝나면 모델의 성능을 규제가 없는 지표로 평가함(보통 훈련할때쓰는 
		비용함수와 테스트에서 사용되는 성능지표는 다름,훈련에 사용되는 비용함수는 최적화를위해 미분가능해야하고,
		테스트에 사용되는 성능지표는 최종목표에 최대한 가까워야 하기 때문)
		
		a는 모델을 얼마나 많이 규제할지 조절함,a가 0이면 선형회귀랑 같고,
		a가 엄청크면 모든 가중치가 0이되고 데이터의 평균을 지나는 수평선이 됨
		즉,a가 커지면 오차에서 분산이 줄고 편향이 커짐(과소적합이늘고 과대적합이 줄어듬)
		
		그리고 편향(절편)은 규제되지않음 그러니까 y=절편+a모델파라미터 꼴이 됨
		
		확률적경사하강법에서 릿지회귀를 쓰는법은
			sgdreg=SGDRegressor(penalty='l2'(엘투))
			하고 그대로 fit해서 진행하면됨
	
	2.라쏘회귀
		선형회귀의 다른 규제버전임
		얘도 릿지회귀처럼 비용함수에 규제항을 더하지만 L1노름(각 파라미터의 차이의 절대값의 합)을 사용함 
		ex(p=(3,1,-3) q=(5,0,7)이면
		3-5 1-0 -3-7 = 2+1+10=13)
		
		라쏘회귀의 중요한 특징은 덜 중요한 특징의 가중치를 제거하려고 한다는점(가중치가 0이됨)
		즉,라쏘회귀는 자동으로 특성선택을 하고 희소모델을 만듬(즉 0이아닌 특성의 가중치가 작음)
		
		라쏘회귀(L1)는 파라미터1이 2 파라미터 2가 0.5일때,
		[1.9 0.4],[1.8 0.3] 이렇게 선형적으로 줄다가 
		[1.5 0.0]이되면 파라미터1을 0으로 보내는식으로 작동한다면(같은수치만큼 줄어듬)
		
		릿지회귀(L2)는 파라미터1이 2 파라미터 2가 0.5일때, 30%라고하면
		[1.643 0.35123], [1.2231 0.221]... [0.002 0.001] 
		이렇게 두 벡터의 직선으로 가지만 0에는 도달할수없고,
		처음엔 줄어드는값이 크지만 점점 줄어드는값이 작아짐,즉 경사하강법이 자동으로 느려지고 수렴에 도움이 됨
		그리고 a가 커질수록 원점에 가까워짐
		
		(라쏘를 쓸때 최적점 근처에서 진동하는걸 막으려면 훈련하는동안 점진적으로 학습률을 감소시키면 스텝이 작아지니까 결국 수렴하게됨)
		
		라쏘의 비용함수는 파라미터가 0일때 미분가능하지 않지만,
		서브그레이언트 벡터(대충 근처값 긁어서 중간값)를 사용하면 경사하강법을 적용할수있음
		
	3.엘라스틱넷
		엘라스틱넷은 릿지와 라쏘를 절충한 모델임
		단순히 릿지와 라쏘의 규제항을 더해서 사용하고,혼합비율 r을 조절해서 사용함
		r=0이면 릿지회귀고 r=1이면 라쏘회귀와 같음
		
		보통 규제중에서 뭘고르냐면 
		보통 규제가 약간이라도 있는게 좋아서 평범한 선형회귀는 쓰지않고,릿지가 기본이지만 사용할 특성이 몇개밖에 없다고 생각되면,
		랏쏘나 엘라스틱넷이 나음(불필요한특성의 가중치를 0으로 만들어주기때문)
		특성수가 훈련샘플수보다 많거나 특성 몇개가 강하게 연관되어있으면 라쏘가 문제를 일으키니까 엘라스틱넷을 선호함
		
		엘라스틱넷을 사용하는법은
			from sklearn.linear_model import ElasticNet
			
			eleast=ElasticNet(alpha=0.1(알파값),L1_ratio=0.5(혼합비율))
			eleast.fit(데이터,레이블)
			
	4.조기종료
		경사하강법같은 반복적인 학습 알고리즘을 규제하는 다른방식은 검증에러가 최솟값에 도달하면 바로 훈련을 중지시키는것
		이걸 조기종료라고 부름
		
		간단히 매번 RMSE 최저값이랑 세팅 저장한다음에 현재값이 그거보다 커지면 되돌리기한다음에 그거리턴하고 종료하면됨
		
6.로지스틱 회귀
	로지스틱 회귀는 분류에서 사용할수 있는 회귀임
	작동방식은 샘플이 특정 클래스에 속할 확률을 추정함(이메일이 스팸일 확률)
	보통 스팸처럼 0,1만 있는 분류기를 이진분류기라고함
	
	1.확률추정
		로지스틱회귀는 선형회귀와 같이 입력특성의 가중치합을 계산하고 편향을 더함,대신 바로 결과를 출력하지않고
		결과값의 로지스틱(0과 1사이값을 출력하는 시그모이드함수)을 출력함(1/1+exp(-t)) 
		exp는 대충 0~1만들기위한 자연로그가지고한거 t는 logodd(양성클래스확률과 음성클래스확률사이의 로그비율) 몰라도됨 
		
		그러면 y가 1부터0까지고 파라미터에 따라 1에서 0사이 어딘가에 있는 함수가 나오는데,
		임계값을 넘기면(기본임계값은 0.5) 양성,넘기지못하면 음성 이런식으로 예측할수있음
	2.훈련과 비용함수		
		즉 우리는 로지스틱회귀에서 양성샘플은 높은확률을 주고 음성샘플은 낮은확률을 주는 파라미터벡터를 찾는것
	
		로지스틱회귀의 비용함수는 로그손실이라고 부르는데,이건 따로 최소값 계산하는 해가 없는데,볼록함수니까 경사하강법을 쓰면
		전역최소값을 찾는걸 보장함
		
	3.결정 경계
		로지스틱회귀는 특성을 기반으로 선을 긋고(절편+파라미터1*특성1+파라미터2*특성2...)=0을 만족하는 x의 집합) 
		그선을 넘으면 15퍼센트로 스팸이다 50퍼센트로 스팸이다 이런식으로 함
		
		다른 선형모델처럼 로지스틱회귀도 L1 L2패널티를 써서 규제할수있음,사이킷런은 L2가 기본값임
		(사이킷런의 LogisticRegression의 규제강도는 alpha가 아니아 그 역수인 C임 C가 높으면 모델의 규제가 줄어듬)
	4.소프트맥스 회귀
		로지스틱회귀는 여러개의 이진분류기를 연결하지않고 직접 다중클래스를 지원하도록 일반화할수있음, 이를 소프트맥스회귀라고함
		
		개념은 샘플이 주어지면 소프트맥스모델이 각 클래스에 대한 점수를 계산하고,그 점수를 소프트맥스함수에 넣어서 각 클래스의 확률을
		추정함
		
		(각 클래스는 자신만의 파라미터벡터가 있는데 이벡터들은 파라미터행렬에 행으로 저장됨)
		
		소프트맥스 함수는 각 점수에 지수함수를 적용한후 정규화(모든지수함수 결과의 합으로 나눔)함
		보통 저 점수를 로그오즈(로짓)라고  부름
		
		즉 점수뽑아서 함수에넣어서 모든클래스에 대한 확률로 변형한뒤에 가장 확률이 높은 클래스를 선택함(다중클래스지 다중출력이 아님)
		
		그러니까 타깃클래스에 대해서는 높은확률,다른클래스에 대해서 낮은확률을 추정하도록 만드는게 훈련의 목적임
		여기엔 크로스엔트로피 비용함수를 잘 쓰는데,
		크로스엔트로피는 추정된 클래스의 확률이 타깃클래스에 얼마나 잘 맞는지 측정하는 용도로 잘 사용됨
		
		사이킷런의 LogisticRegression은 클래스가 둘 이상일떄 기본적으로 OvA를 쓰는데 
		multi_class='multinomial'을 넣어주면 소프트맥스 회귀를 쓸수있음
		
		소프트맥스 회귀를 쓰려면 solver매개변수에 'lbfgs'같은 소프트맥스회귀를 지원하는 알고리즘을 지정해야함
		그리고 기본적으로 C를 사용해서 조절할수있는 L2규제가 적용됨
		
		주의점은 추정경계에 가까울수록 확률이 별차이없는걸 예측할수도 있음(3개일떄 34퍼센트인걸 리턴할수있음)
	

	
5.서포트벡터머신	
1.선형svm분류
	
	서포트벡터머신(svm)은 클래스들 사이에 가장 폭이 넓은 도로를 찾는 일
	각각 클래스중 가장 가까운걸 택해서 그 두개를 기준으로 선을 긋고 그거로 나눔(라지마진분류)
	그래서 가장 가까운애한테만 영향을 받지,막 3만개가 더들어온다해도 경계선이 갱신되는게 아니면 전혀 영향을 주지않음
	즉,경계에 있는 애들한테만 영향을 받고 이런애들을 서포트 벡터라고 함
	
	svm은 특성의 스케일에 매우 민감해서,스케일조정을 해줘야함
	
	만약 모든 샘플이 바로 선으로 나눌수있게 분류 되어있으면 이걸 하드 마진 분류라고 함
	하드마진 분류의 문제는 데이터가 선형적으로 구분할수있어야하고,이상치에 매우민감함
	
	만약 상대클래스쪽에 이상치로 한개가 섞여있으면 하드마진분류가 불가능하고(선을 그을수가없음)
	그정도는 아니더라도 상대클래스에 엄청붙어있으면 도로폭이 좁아지고 그래서 일반화가 잘 되지않음
	
	그래서 도로의폭과 마진오류의 트레이드오프를 해서 한두개는 상대클래스로 넘어가도 무시하고 막 도로건너편에 있어도 무시하는걸
	소프트 마진 분류 라고 함
	
	사이킷런에서는 하이퍼파라미터 C를 조절하면 마진오류허용치를 조절할수있음
	
	사이킷런에서 쓰려면 
		LinerSVC(C=1(마진오류허용치),loss="hinge"(힌지손실))
	하면됨
	
	svm은 로지스틱회귀와 다르게 클래스에 대한 확률을 제공하지않음
	
2.비선형 svm 분류
	비선형이면 일반적으론 분류를 할수없지만,다항회귀처럼 다항특성을 추가하면(x^2라던지) 선형적으로 구분되는 데이터셋이 만들어질수있음
	
	사이킷런에선 PolynomialFeatures에 차수넣고 StandardScaler LinerSVC에 c,loss넣은거 
	파이프라인으로 연결해서 넣으면됨
	
	1.다항식 커널
		다항특성을 추가하는건 쉽고 모든알고리즘에서 다 잘 동작하지만,낮은차수의 다항식은 안나올확률이 높고,높은차수는 엄청느려짐
		
		근데 svm은 커널트릭이라는 사기스킬로(데이터를 고차원으로 매핑해서 차이를 찾음)
		특성을 추가하지않고 다항식을 많이 넣은것과 같은 결과를 얻을수있음
		
		사용법은
			SVC(kernel='poly'(무슨커널쓸건지),degree=3(차수),coef0=1(높은차수 낮은차수 얼마나 영향받을지),C=5)
		모델이 과소적합이면 차수를 늘려야하고,과대적합이면 차수를 줄여야함
	2.유사도 특성
		또 다른 방법은 특정 랜드마크와 얼마나 닮았는지 측정하는 유사도함수로 계산한 특성을 추가하는것
		이 함수는 0(랜드마크와 멀리떨어진경우)부터 1(랜드마크와 같은위치)까지 변화하며 종모양으로 나타남
	
		계산법은 랜드마크와 얼마나 떨어져있는지를 변수로잡고 유사도함수에 집어넣으면 랜드마크와 샘플이 얼마나 떨어져있는지 값이 나오는데
		이걸 토대로 선그어서 구분하는방식
		
		랜드마크값은 제일쉬운방법은 데이터셋에 있는 모든샘플위치에 랜드마크 설정하는것
		이러면 차원이 매우커지고,그래서 변환된 훈련세트가 선형적으로 구분될 가능성이 높음
		단점은 n개의 특성을가진 m개의 샘플이 m개의 특성을 가진 m개의 샘플로 변환된다는것(원본샘플제외했을때)
		즉 훈련세트가 크면 동일한크기의 아주 많은 특성이 만들어짐
		
	3.가우시안 RBF커널
	유사도도 연산비용이 많이드는데 그냥 커널트릭으로 사기칠수있음
	SVC(kernel='rbf',gamma=5(증가하면 종이 좁아져서 샘플의 영향범위가 줄어듬,즉 규제 과소면 증가 과대면 감소),C=0.001) 
	
	커널 선택은 linear을 제일 먼저 해봐야하고,훈련세트가 그렇게 크지않으면 가우시안RBF하면됨
	
	4.계산복잡도
		커널트릭을 안쓸거면 LinerSVC를 씀(훈련샘플과 특성수에 수행시간이 선형적으로 증가 O(m*n)))
		정밀도를 높이면 알고리즘 수행시간이 길어짐(하이퍼파라미터 tol)보통은 기본값두면 잘 작동함
		
		SVC는 커널트릭을 쓸때 쓰는데,시간복잡도가 O(m^2*n)이라서 훈련샘플수가 커지면 엄청나게 느려짐,
		하지만 특성은, 특히 희소특성(0이아닌특성이 몇개없는경우)에는 잘 확장됨
	
3.svm회귀
	svm은 회귀로도 쓸수있는데 회귀는 목표를 반대로 하면 됨
	즉 도로 안에 가능한 많은 샘플이 들어가게 학습시키면됨
	이거도 마진안에서는 훈련샘플이 추가되어도 예측엔 영향을 주지않음
	
	사용법은 
		svmreg=LinearSVR(epsilon=1.5(도로의폭),tol=0.001(허용오차))
	SVR은 SVC의 회귀버전 LinearSVR은 LinearSVC의 회귀버전
	
4.SVM이론
	svm은 초평면(n+1차원의 평면)인 결정함수(초평면과 데이터셋평면이 교차하는부분(결정함수의 값이 0인지점이 결정경계))
		
	커널트릭은 벡터곱을 하면 차원이 하나 더생기는것((a,b)*(a,b)=a^2 ab b^2 )을 이용한것
		


6.결정 트리		
	결정트리는 조건별로(a>10) 분기하는식으로 추론하는 모델임(스무고개같은방식)
	결정트리는 분류 회귀 다중출력 작업도 가능한 알고리즘임
	1.시각화
		 export_graphviz를 쓰면 결정트리 시각화를 할수있음
		 
		 from sklearn.tree import export_graphviz
		 
		 export_graphviz(트리모델,out_file=이미지위치,
						 feature_names=특성명(x[0]대신에 특성이름넣어줌),class_name=이게무슨클래스인지 결과값)
			
	2.예측하기
		결정트리는 루트에서 (a특성>2)같은거로 거르고,밑에서 (a특성>1)로 거르고,그밑에서 (b특성<3)으로 거르는식으로 스무고개하듯이
		분류하는 모델임(아키네이터 생각하면됨)
		
		시각화했을때 노드의 sample 속성은 훈련모델에서 얼마나 많은 훈련샘플이 지나갔는지를 센거고,
		노드의 value속성은 각 클래스마다 얼마나 많은 샘플이 있는지 적혀있고,
		gini속성은 불순도(얼마나 정확하게 들어갔는지)임
		불순도 식은 별로알필요없고 불순도가 높을수록 안좋음(0이 순수한노드임)
		
	tmi)사이킷런은 이진트리만 만드는 CART알고리즘을 쓰는데(T,F만있는) ID3같은거는 둘 이상의 자식노드를 가진 결정트리를 만들수있음

	3.클래스확률추정
		결정트리는 한 샘플이 특정클래스 k에 속할 확률을 추정할수도 있음
		방법은 그냥 샘플 노드따라 내려보내고 리프노드에서의 훈련샘플비율([0,10,10]이면 0%,50%,50%)을 출력하면됨
		
	4.CART알고리즘
		CART알고리즘은 훈련세트를 하나의특성 k의 임계값 t로 두개의 서브셋으로 나눔(ex 길이<2)
		나누는 조건은 ((왼쪽불순도*왼쪽샘플수)/샘플수)+((오른쪽불순도*오른쪽샘플수)/샘플수)가 가장 작은값으로 나눔
		성공했으면 같은방식으로(탐욕적으로)서브셋의 서브셋을 나누고 계속 나누다가 
		최대깊이가 되거나(max_depth=) 불순도를 줄이는분할을 찾을수없으면 멈춤
		
	5.계산복잡도
		결정트리는 예측을 하는건 그냥 길따라 내려가기만 하면 되니까(한노드는 한특성만 확인하니까)O(log₂(m))으로 엄청작음
		
		하지만 훈련하는건 각 노드의 모든 샘플의 모든 특성을 비교하면  O(n*mlog(m))으로 (mlog(m)은 퀵소트값)많이 큼
		만약 훈련세트가 작으면 presort=True 로 주면 미리 정렬치고 들어가기때문에 훈련속도를 올릴수있음
		그래도 훈련세트가 크면 많이 느림
		
	6.지니불순도,엔트로피불순도
		지니불순도랑 엔트로피 불순도가 있는데, 
		둘다 별차이는 없는데 
		지니불순도는 조금 계산이 빠른대신 가장 빈도높은 클래스를 한쪽으로 고립시키는 경향이 있는데,
		엔트로피는 조금 더 균형잡힌 트리를 만듬
		기본값은 지니불순도
	
	7.규제 매개변수
		결정트리는 훈련 데이터의 제약사항이 거의 없음
		
		그래서 따로 제한을 두지않으면(규제하지않으면) 훈련데이터에 딱맞추려고해서 과대적합하기 쉬움
		
		결정트리는 모델 파라미터가 훈련되기전엔 파라미터수가 결정되지 않고,이런모델을 비파라미터 모델이라고 함
		반대로 선형모델같은 모델은 미리 정의된 모델 파라미터 수를 가지니까 파라미터 모델이라고 함
		
		비파라미터 모델은 모델 구조가 데이터에 맞춰져서 고정되지 않고 자유롭지만,과대적합의 확률이 높고
		파라미터 모델은 미리 파라미터수가 정해져있기때문에 자유도가 제한되고 과대적합될 위험은 적지만 과소적합될 위험은 커짐
		
		
		결정트리에서 규제할때 제일 많이 쓰는건 max_depth=(최대깊이)임
		다른건 
			min_samples_split(분할되기위해 노드가 가져야하는 최소샘플수)
			min_samples_leaf(리프노드가 가지고있어야할 최소샘플수)
			min_weight_fraction_leaf(min_samples_leaf와 같지만 가중치가 부여된 전체 샘플 수에서의 비율)
			max_leaf_nodes(리프 노드의 최대 수)
			max_features(각 노드에서 분할에 사용할 특성의 최대 수)
		등이 있음
		보통 min으로 시작하는걸 증가시키거나,max로 시작하는걸 감소시키면 모델에 규제가 커짐
		
		
		다른 방법으로는 제한없이 결정트리를 훈련시킨다음에,불필요한 노드를 가지치기하는 알고리즘도 있음
		x^2검정같은 통계적 검정을 사용해서 순도 향상이 우연히 향상된건지 추정하고,
		이 확률이 임계값보다 높으면(기본값 5%)그 노드는 불필요한것으로 간주되고 그 자식노드는 삭제됨
		이걸 불필요한 노드가 모두 없어질때까지 계속함
		
	8.회귀
		결정트리는 회귀문제에서도 쓸수 있는데
		이거도 똑같이 TF측정한다음에 그안의 샘플의 평균값을 가지고 그래프를 그리는식임
		
		회귀에선 불순도를 줄이는대신,MSE를 최소화하도록 분할하는거 빼고는 똑같이 동작함
		
		분류에서처럼 회귀에서도 규제가 없으면 과대적합되기 쉬움
		
	9.불안정성
		결정트리에서 문제는,계단모양의 결정경계를 만들기 때문에(T,F로 분류하고 그 폭이크니까)
		그래서 훈련세트의 회전에 민감함(딱 중간기준으로 절반나누는것도 45도 회전하면 대각선으로 선그을수없으니(한특성에 대한 TF라서) 
							  중간에 뭐가 더생김)
		
		이런거처럼 결정트리는 훈련 데이터에 있는 작은 변화에도 매우 민감하다는게 문제임
		
		이런걸 해결하려고 랜덤포레스트(결정트리의 앙상블)등을 사용해서 극복할수있음



7.앙상블학습과 랜덤포레스트
	앙상블학습이란 예측기를 엄청 모아서 걔들 답을 평균내거나 가장 많은답으로 분류하는 방식임
	그중 결정트리의 앙상블을 랜덤포레스트라고 함
	
	1.투표기반 분류기
		가장 쉽게 앙상블로 분류하는 방법은 각 분류기의 예측을 모아서 가장 많이 선택된 클래스를 예측하는것
		이걸 직접투표 분류기라고 함
		
		보통 이렇게 다수결분류기가 앙상블에 포함된 개별분류기중 가장 뛰어난것보다 정확도가 높은경우가 많음
		
		앙상블은 모든 분류기가 완벽하게 독립적이고,오차에 상관관계가 없을수록 성능이 올라감
		그래서 각기 다른 알고리즘으로 학습시키면,다른종류의 오차를 만들 가능성이 높아져서 정확도가 올라갈수있음
		
		만약 모든 분류기가 클래스의 확률을 예측할수있으면,모든 예측을 평균내서 가장 확률높은 클래스를 예측할수있음
		이걸 간접투표라고 함
		이방식은 확률이 높은 투표에 비중을 두고,0.7 0.3일떄 0.3이 무시되지않기때문에 직접투표보다 성능이 높음
		간접투표를 사용하려면 voting='soft'하고,내부에 predict_proba메서드가 있는 분류기만 다 사용하면됨
		(SVC는 probability=True하면 predict_proba가 생김)
		
	2.배깅과 페이스팅
		다양한 분류기를 만드는 방법에는 각기 다른 훈련 알고리즘을 만드는방법도 있지만 
		같은 알고리즘을 써도 훈련 세트의 서브셋을 무작위로 구분해서 분류기를 각기 다르게 학습시킬수도 있음
		
		여기서 훈련세트에서 중복을 허용하여 샘플링하는걸 배깅이라고 하고
		중복을 허용하지 않고 샘플링하는방식을 페이스팅 이라고함
		
		즉,배깅과 페이스팅은 같은 훈련샘플을 여러개의 예측기에(각기 다른 알고리즘의) 사용할수 있지만,
		배깅은 한 예측기에서 같은 훈련샘플을 여러번 쓸수있고,페이스팅은 한예측기에서 반복사용은 불가능함
		
		모든 예측기가 훈련을 마치면 모든 예측기의 값을 모아서 새로운 샘플에 대한 예측을 만듬
		만약 분류였으면 최빈값(가장 많은 예측결과)이고 회귀면 평균을 계산함
		
		개별예측기는 원본훈련세트보다 훨씬 크게 편향되어있지만,수집함수를 통과하면 편향과 분산이 모두 감소함
		
		일반적으로 앙상블의 결과는 원본데이터셋으로 하나의 예측기를 훈련시킬떄와 비교해서 편향은 비슷하지만 분산은 줄어듬
		
		보통 앙상블은 모두 동시에 다른 cpu코어나 서버,gpu에서 병렬로 학습시킬수있고,예측도 병렬로 수행할수 있음
		
		사이킷런에서 배깅과 페이스팅 쓰려면
		
			from sklearn.ensemble import BaggingClassifier
			
			bagclf=BaggingClassifier(
				사용알고리즘,n_estimators=예측기갯수,
				max_samples=샘플갯수,bootstrap=True(배깅페이스팅선택),n_jobs=-1(사용할cpu코어수 -1이면 전체)
			)

		부트스트래핑(배깅)은 각 예측기가 학습하는 서브셋에 다양성을 증가시켜서 배깅이 페이스팅보다 편향이 조금 높지만,
		다양성을 추가하면 예측기의 상관관계를 줄여서 분산을 감소시킴
		
		보통 배깅이 더 나은경우가 많아서 기본값이긴한데 여유가있으면 둘다 평가해서 더 나은쪽을 선택하는게 좋음
		
		2.oob평가
			배깅을 쓰면 어떤 샘플은 한 예측기를 위해 여러번 샘플링되고,어떤건 전혀 선택되지 않을수 있음
			그래서 선택되지 않은 샘플을 oob샘플이라고 부르는데,예측기마다 남겨진 oob샘플은 모두 다름
			
			예측기가 훈련되는동안엔 oob 샘플을 사용하지 않으니까 별도의 검증세트를 사용하지 않고 oob샘플을 사용해서 평가할수있음
			앙상블의 평가는 각 예측기의 oob평가를 평균해서 얻음
			(자기예측기에서 남은거로 자기예측기에만 평가함 각 예측기마다 남은게 다르기때문)
			
	3.랜덤패치와 랜덤서브스페이스
		BaggingClassifier는 특성샘플링도 지원함
		특성샘플링은 max_features,bootstrap_features 두 매개변수로 조절됨
		작동방식은 max_samples,bootstrap과 같지만,이건 샘플이 아니고 특성에 관한 샘플링임
		즉 각 예측기는 무작위로 선택한 입력특성의 일부분으로 훈련됨
		
		그러니까 샘플대신 특성으로 예측기 여러개 만들어서 훈련시키는거임(샘플특성 둘다돌릴수도있고)
		
		이 방법은 특히 이미지같은 매우 고차원의 데이터셋을 다룰때 유용함
		
		샘플과 특성을 모두 샘플링하는걸 랜덤패치라고 하고,
		샘플은 하나쓰고 특성을 샘플링하는걸 랜덤 서브스페이스 라고함
		(bootstrap=False, max_samples=1.0, bootstrap_features=True/False max_features=0.1~1.0)
		
		특성샘플링은 더 다양한 예측기를 만들며 편향을 늘리고 분산을 낮춤
		
	4.랜덤 포레스트
		랜덤포레스트는 배깅이나 페이스팅을 적용한 결정트리의 앙상블임
		전형적으로 max_samples을 훈련세트의 크기로 지정함
		BaggingClassifier에 결정트리를 넣어만들수도있지만,
		이미 RandomForestClassifer가 최적화 다 됐기때문에 이거쓰면됨(회귀는 RandomForestRegressor)
		
		이거도 똑같이 쓰면됨
			RandomForestClassifer(n_estimators=갯수,max_leaf_nodes=최대리프수,n_jobs=-1(코어사용수))
		특정 예외를 제외하고 결정트리의 매개변수와 BaggingClassifier의 매개변수를 모두 가지고있음
		
		
		랜덤포레스트는 트리의 노드를 분할할때 최선의 특성을 찾지않고,
		무작위로 선택한 특성후보에서 최적의 특성을 찾는식으로 무작위성을 더 주입함
		이건 트리를 다양하게만들고 편향을 좀 더 손해보는대신에,분산을 낮춰서 좀 더 나은모델이 나옴
		
		1.엑스트라트리
			랜덤포레스트에서 트리를 만들때 노드는 무작위 특성을 선택하고 거기서 최적을 찾는데,더욱 무작위로 만들기위해서 
			최적의 임계값을 찾는대신 후보특성을 사용해 무작위로 분할한다음 그중에서 최상의 분할을 선택하는걸 엑스트라트리라고 함
			여기서도 또 편향을 올리고 분산을 낮춤
			
			엑스트라트리랑 랜덤포레스트랑 뭐가 더 나을지 알긴어렵고,교차검증하는게 유일한방법임
			
		2.특성중요도
			랜덤포레스트의 다른 장점은 특성의 중요도 측정이 쉽다는것
			사이킷런은 어떤 특성을 사용한 노드가(랜덤포레스트 전체트리에 걸쳐서)평균적으로 불순도를 얼마나 감소시키는지 확인해서
			특성의 중요도를 측정함
			즉,가중치평균이고 각 노드의 가중치는 연관된 훈련샘플수와 같음
			
			사이킷런은 훈련이 끝나면 이 점수를 계산하고 합이 1이되도록 정규화시킴
			이걸 보려면 랜덤포레스트.feature_importances_를 프린트해보면 특성중요도가 나옴
			
			랜덤포레스트는 특성선택해야할때 어떤특성이 중요한지 빠르게 알수있어서 매우편리함
			
	5.부스팅
		부스팅은 약한 학습기 여러개를 연결해서 강한 학습기를 만드는 앙상블임
		
		부스팅방법에는 여러개가 있는데 대표적인게 에이다부스트랑 그레이디언트부스팅임
		
		1.에이다부스트
			에이다부스트는 이전모델이 과소적합했던 샘플의 가중치를 더 높여서 학습하기 어려운 샘플에 점점 맞추는식으로 함
			
			즉 알고리즘이 기반이되는(베이직한) 첫 분류기를 돌린다음에,잘못분류된 샘플의 가중치를 상대적으로 높이고,
			두번쨰 분류기는 업데이트된 가중치로 훈련하고 예측을만들고,잘못분류된 샘플의 가중치를 높이고 이런식으로 반복함
			가중치는 학습률로 조절할수있음
			
			이런방식은 경사하강법과 비슷하게 작동함
			
			모든 예측기가 훈련을 마치면 이 앙상블은 배깅이나 페이스팅과 비슷한 방식으로 예측을 만듬
			하지만 가중치가 적용된 훈련세트의 전반적인 정확도에 따라 예측기마다 다른 가중치가 적용됨
			
			그렇게해서 새로운샘플을 넣을떈 1번예측기부터 n번예측기까지 전부 돌린다음에 
			각 예측기마다 값을 구해서 예측기가중치(나중거를 올린다던가)를 곱한다음 평균구해서 답을뽑음
			
			사용법은
				adaclf=AdaBoostClassifier(
					사용알고리즘,n_estimators=갯수,
					algorithm='SAMME.R'(에이다부스트의 알고리즘선택),learning_rate=학습률
				)
			
			만약 에이다부스트가 과대적합되면 추정기수를 줄이거나 규제를 올리면됨
			그리고 에이다부스트를 훈련할떄는 전단계가 다음단계에 영향을 미치는식이기때문에 보통 앙상블처럼 병렬처리가 안됨
			
			
		2.그레이디언트 부스팅
			그레이디언트 부스팅도 이전까지 오차를 보정하도록 예측기를 추가하지만,얘는 샘플의 가중치를 수정하지 않고
			이전 예측기가 만든 잔여오차에 새로운 예측기를 학습시켜서 전체를 예측하려고 함
			
			즉 10개중에 3개 예측못했으면 3개가지고 훈련하고 또 거기서 잔여남은거로 예측하는식으로 돌림
			사용법은 
			
				gbrt=GradientBoostingRegressor(max_depth=2,n_estimators=3,learning_rate=1.0)
			이런식으로 씀

			학습률(learning_rate)는 각 트리의 기여 정도를 조절함
			이걸 낮게 설정하면 훈련세트 학습을 위해 더 많은 트리가 필요하지만 예측의 성능은 좋아짐 
			이건 축소라고 부르는 규제방법임
			
			최적의 트리를 찾기위해선 조기종료를 쓸수있음
			
			간단하게 만들려면 staged_predict()를 쓰면됨
			
				gbrt=GradientBoostingRegressor(...)
				gbrt.fit(x,y)
				
				errors=[mean_squared_error(yval(테스트세트),ypred) 
				for ypred in gbrt.staged_predict(xval)]
				bstnestimator=np.argmin(errors)+1
				
				gbrtbest=GradientBoostingRegressor(...n_estimators=bstnestimator)

			이런식으로 에러가 올라가는지점 찾아주니까 그지점갯수를 넣으면됨
			
			아니면 예전에 조기종료햇던거처럼 직접구현해도되고
			
			GradientBoostingRegressor은 각 트리가 훈련할때 사용할 훈련샘플의 비율을 지정할수있는 subsample를 지원함
			subsample=0.25하면 각 트리는 무작위로 선택된 훈련샘플의 25%훈련샘플로 학습함
			역시 편향을올리고 분산을 낮춤,그리고 훈련속도가 올라감 이런기법을 확률적 그레이디언트 부스팅이라고 함
			
			최적화된 그레이디언트부스팅으로 XGBoost가 유명함
			


	6.스태킹
		스태킹은 앙상블에 속한 모든 예측기를 취합하는 대신,취합하는 모델을 훈련시키는 방법임
		
		먼저 훈련세트를 두개로 나누고 첫번째 서브셋을 첫번째 레이어의 예측을 훈련시키는데 사용한뒤,
		
		첫번쨰 레이어의 예측기로 두번째 세트의 예측을 만듬
		예측기들이 이 샘플들을 본적이없기떄문에 완전히 새로운 예측이 나옴

		즉 처음에 들어간 데이터들은(x,y) 첫레이어예측기 학습에만 쓰이고,
		각 예측값과 레이블로 새로운값을 만들어서 새로운 훈련세트를 만들어서(xnew,y)이거로 블렌더가 훈련함
		즉 첫레이어의 예측을 가지고 타깃값을 예측하도록 학습함(결과적으로 2번학습함)
		
		근데 뭐 잘안쓰는거같음 사이킷런에선 지원도 안하고
		
		
8.차원축소		
	만약 특성(차원)의 수가 엄청나게 많아지면(주로 샘플수보다 특성수가 커지면) 훈련이 느려지고,좋은 솔루션을 찾기 어렵게됨(차원의저주)
	그래도 특성수를 크게 줄여서 불가능한 문제를 가능한 문제로 변경할수 있는 경우가 많음
	
	mnist 같은경우 바깥에있는 픽셀은 거의 항상 흰색이니까 없어도되는정보 이런거는 완전히 제거해도 많은정보가 손실되지않음
	그리고 인접한 두 픽셀은 종종 많이 연관되어있으니까 두 픽셀을 하나로 합쳐도(두개를평균내서) 많은정보를 잃지않음
	(보통 차원축소를 하면 정보가 유실되니까 훈련속도는 올라가지만 성능이 조금 나빠질수있고,파이프라인이 복잡해지고 유지관리가 어려워짐
	그래서 훈련이 너무 느리지않으면 원본으로 돌리는게 나음)
	
	그리고 차원축소를 하면 데이터 시각화에도 매우 유용함
	보통 3차원까지만 쉽게볼수있으니까 2나 3차원으로 줄이면 고차원 훈련세트를 하나의 그래프로 그릴수있고,군집같은 시각적패턴을 감지할수있음
	
	1.차원의 저주
		고차원으로 갈수록 샘플간의 거리가 멀어져서 훈련세트의 과대적합위험이 커지는 현상
		이론적으로는 훈련세트의 크기를 키우면되지만,현실적으로 불가능함(100차원에서 특성거리를0.1이내로 만들려면 우주원자수보다 많이필요)
	
	2.차원축소방법
	
		1.투영
			보통은 훈련샘플들이 모든 차원에 걸쳐 균일하게 퍼져있지않고,모든 훈련샘플들이 고차원 공간안에 저차원 부분공간에 놓여있음
			(3차원에서 2차원 평면상에 전부 놓여있다던지)
			그러면 여기다 대고 차원을 하나 빼버려서(프레스기로 눌러서)3차원을 2차원으로 만들던가 할수있음
			(즉,부분공간에 수직으로(샘플과 평면사이의 가장 짧은직선을 따라서)투영)
			(그러면서 특성도 서로 합쳐지든가 해서 밀도높은특성으로 바뀔가능성도 있게됨)
			
			그런데 차원축소할때 투영이 언제나 최선은 아님
			롤케이크처럼 돌돌말려있는 형태의 데이터셋을 투영해버리면 그대로 다 섞여버리는데 
			우리가 원하는건 군집별로 분리된 데이터기때문에 롤을 펼쳐서 깔아야함
		
		2.매니폴드학습
			
			그래서 롤을 펼쳐서 까는작업을 매니폴드 학습이라고 함
			
			매니폴드는 국부적으로 d차원 초평면으로 보이는 n차원 공간임
			즉 롤케이크에서 롤을 펼치면 2차원(2차원 초평면)이지만 롤케이크 자체는 d차원(3차원)임
			국부적으로는 2d평면이지만 3차원으로 말려있음
			
			이런 매니폴드들을 모델링하는식으로 매니폴드 학습은 작동함
			이는 실제 고차원데이터셋이 더 낮은 매니폴드에 가깝게 놓여있다는 매니폴드 가정에 근거함
			그리고 처리해야할 작업이 저차원의 매니폴드로 표현되면 더 간단해질거라는 가정을 하는데,
			이게 꼭 그렇진않음
			
			즉 모델을 훈련시키기 전에 차원을 감소시키면 훈련속도는 빨라지지만 항상 더 낫거나 간단한 솔루션이 된다는 보장은 없음
			이건 데이터셋에 달린문제임
			
	3.PCA
		PCA는 데이터에 가장 가까운 초평면을 정의한다음,데이터를 이 평면에 투영시킴
		1.분산보존
			훈련세트를 투영하기 전에 먼저 올바른 초평면을 선택해야하는데,이 선택은 가장 분산을 최대로 보존하는 선을 찾으면 됨
			(원본데이터셋과 투영된것 사이의 평균제곱거리를 최소화하는 축)
		2.주성분
			먼저 분산이 최대인 축을 찾고,첫번째 축에 직교하고 남은 분산을 최대한 보존하는 축을 찾아서 2차원을 만듬
			이런식으로 3차원이면 두개에 직교하고 분산이 제일큰거를 고르고 이렇게 n차원까지 n번째 축을 찾음
			(PCA는 데이터셋의 평균이 0이라고 가정하는데 사이킷런은 이작업을 대신해주는데,
			다른라이브러리나 직접만들면 데이터 0에 맞춰야됨)
			
		3.d차원투영
			주성분을 모두 추출해냈으면,d개의 주성분으로 정의한 초평면에 투영해서 데이터차원을 d차원으로 축소할수있음
			이 초평면은 분산을 가능한 최대로 보존하는 투영임을 보장함
			
		4.사이킷런에서 사용법
				from sklearn.decomposition import PCA
				
				pca=PCA(n_components=차원수)
				X2d=pca.fit_transform(데이터)
			이러면 n_components의 수치만큼 줄여진 데이터가 나옴
			학습후에는 components_에 W^d의 전치가 담겨있음
			
			explained_variance_ratio_에는 주성분의 분산의 비율이 들어있음
			현재 압축한데이터의 총 분산을 1로봤을때 각 선별로 얼마나 들어있는지 나오니까 급격하게 줄어서 4차원인데 2개로 99퍼면
			2개 더 날리는식으로 할수있음
			
		5.차원수 선택
			그래서 막 저렇게 보고 줄이고 하면 귀찮으니까 몇%이상까지만 잘라서 보통 함
			코드는
				pca=PCA()
				pca.fit(x)
				cumsum=np.cumsum(pca.explained_variance_ratio_)
				d=np.argmax(cumsum>=)+1
				
				pca=PCA(n_components=d)
				
			근데 이게 더 편하고 좋음
				pca=PCA(n_components=0.95)
				xr=pca.fit_transform(x)
			
			이거말고 다른방법은 분산을 차원수에 대한 함수로 그리는것(cumsum으로 그리면됨 )
			거기서 변곡점에서 멈추면됨
		6.압축을위한 PCA
			차원을 축소하면 훈련세트가 줄어드는데 분산 95%하면 막 원본크기의 20%되고 그럼
			그리고 압축된 데이터셋에 투영을 반대로써서 원래차원수로 되돌릴수는 있는데,이미 일정량의 정보는 날아갔기때문에
			원본 데이터셋을 얻을수는 없지만 매우 비슷한 데이터를 얻을수있음
			그 원본데이터셋과 압축후 원복한데이터 사이의 평균제곱거리를 재구성오차라고 함
			
		7.랜덤PCA
			svd_solver 매개변수를 randomized 로 넣으면 랜덤pca라고 부르는 확률적 알고리즘을 써서
			처음 d개의 주성분에 대한 근삿값을 빠르게 찾음
			이건 줄일 차원수가(d가) 원래차원수(n)보다 많이 작으면 엄청빠름(O(m*n^2)+O(n^3)->O(m*d^2)+O(d^3))
			
			사이킷런의 기본값은 auto임
			m이나 n이 500보다 크고 d가 m이나 n의 80%보다 작으면 랜덤 PCA를 씀
			그게싫으면 svd_solver를 full로 주면 완전한SVD를씀
		
		8.점진적 PCA
			PCA의 문제점은 svd(특이값분해)를 쓰기위해 전체 훈련세트를 메모리에 올려야 하는데,이걸 보완하기위해
			미니배치로 나눠서 하나씩 하는 점진적 PCA가 개발됨
			이런방식은 온라인으로 PCA를 적용할수있고 훈련세트가 클떄 유용함
			
			사용법은
			
				from sklearn.decomposition import IncrementalPCA
				
				n_batches=배치수
				incpca=IncrementalPCA(n_components=n_batches)
				
				for xbatch in np.array_spilt(x,n_batches):
					incpca.partial_fit(xbatch)
				
				xred=incpca.transform(x)
			다른방법은 넘파이의 memmap를 써서 하드디스크에 있는 파일을 메모리처럼 쓰는것
				xm=np.memmap(filename,dtype="float32",mode="readonly",shape=(m,n))
				
				batchsize=m//n_batches
				incpca=IncrementalPCA(n_components=배치수,batch_size=batchsize)
				incpca.fit(xm)
	
	4.커널PCA
		PCA도 커널트릭을 써서 사기칠수있는데 n차원을 n+3차원 이런식으로 늘린후에 쉬운걸 찾아서 그거선택하는식으로 사기칠수있음
		이걸 커널PCA(KPCA)라고 함
		
		이건 투영된 후의 샘플의 군집을 유지하거나,꼬인 매니폴드같은걸 펼칠때도 유용함
		
		사용법은
			from sklearn.decomposition import kernelPCA
			
			rbfpca=kernelPCA(n_components=차원수,kernel="rbf(커널선택)",gamma=0.04 증가하면 종이 좁아져서 샘플의 영향범위가 줄어듬,즉 규제, 과소면 증가 과대면 감소)
			커널은 선형,rbf,시그모이드 등을 씀
		1.커널선택과 하이퍼파라미터튜닝
			kpca는 비지도 학습이기떄문에 좋은 커넣과 하이퍼파라미터선택을 위한 명확한 성능측정기준이 없음
			하지만 차원축소는 지도학습의 전처리로 활용되므로 그리드탐색으로 주어진문제에서 성능이 가장 좋은 커널과 하이퍼파라미터를
			선택할수있음
			
			사용법은
				clf=PipeLine([
				('kpca',kernelPCA(n_components=2)),
				('logreg',LogisticRegression())
				])
			
				paramgrid=[{
					"kpca__gamma":np.linspace(0.03,0.05,10),
					"kpca__kernel":["rbf",sigmoid]
				}]
				gridsearch=GridSearchCV(clf,paramgrid,cv=3)
				gridsearch.fit(X,y)
			이런식으로 그리드서치로 그중제일나은걸 선택할수있음
			가장 좋은 커널과 하이퍼파라미터는 best_params_에 저장됨
	
			완전한 비지도학습으로 가장 낮은 재구성오차를 만드는 커널과 파라미터를 선택할수도있는데 어려움
			하지만,커널트릭으로 무한차원의 특성공간에 맵핑한다음에 변환된 데이터셋을 선형PCA를 사용해 2D로 투영하는식으로 날먹할수있음
			
			축소된 공간에 있는 선형PCA를 역전시키면(복원) 재구성된 데이터포인트는 원본공간이 아닌 공간에 놓이게 되는데,
			저 공간은 무한차원이라서 계산할수없고 재구성에 따른 에러를계산할수있는데,저 포인트와 가까운 원본공간의 포인트를 찾을수있음
			이걸 재구성원상이라고 함
			원상을 얻으면 원본샘플과의 제곱거리를 측정해서 오차를 알수있는데,이걸 최소로하는 커널과 하이퍼파라미터를 선택할수있음
			
			하는법은 fit_inverse_transform=True를 넣으면됨
			
				rbfpca=kernelPCA(n_components=2,kernel="rbf",gamma=0.0433,
									fit_inverse_transform=True)
				xre=rbfpca.fit_transform(x)
				xpre=rbfpca.inverse_transform(xre)
			그다음 재구성원상오차를 계산할수있음
				
				mean_squared_error(x,xpre)
			이렇게 오차를 구할수있으니 최소화를 시키는 커널과 하이퍼파라미터를 그리드탐색으로 찾을수있음
			
	5.LLE
		LLE는 투영에 의존하지 않는 매니폴드 학습임
		LLE는 각 훈련샘플이 가장 가까운 이웃에 얼마나 선형적으로 연관되어있는지 측정한다음,
		국부적인 관계가 가장 잘 보존되는 훈련세트의 저차원 표현을 찾음
		이방법은 특히 잡음이 너무 많지 않을때 꼬인 매니폴드를 펼치는데 잘 작동함
		
		사이킷런 사용법은
			from sklearn.manifold import LocallyLinearEmbedding
			
			lle=LocallyLinearEmbedding(n_components=2,n_neighbors=찾을이웃수)
			xre=lie.fit_transform(x)
			
		써보면 펼쳐지기도 잘 펼쳐지고 지역적으로는 샘플간 거리유지가 되는데 전역적으로는 잘 유지가 안되긴하지만
		동작은 나름 잘됨
		
		lle의 작동방식은 각 훈련샘플에 대해 가장 가까운 k(n_neighbors)개의 샘플을 찾은뒤,
		이 이웃에 대한 선형함수로 훈련샘플을 재구성함(k들 거리의합이 최소화되는 가중치를찾음)
		이걸 전체에대해 반복
		
		그리고 나선 이 관계가 최대한 유지되도록 d차원(낮은차원)으로 맵핑함
		
		근데 이알고리즘은 대량의 데이터셋에 적용하긴 어려움(O에 m^2가있음)
		
	6.다른 차원축소기법
		랜덤투영
			랜덤한 선형투형으로 데이터를 저차원공간으로 투영함
			나름 잘작동하고 초기차원수에 의존적이지않다고함
			
		다차원스케일링
			샘플간의 거리를 보존하면서 차원을축소함
			
		isomap
			각 샘플을 가장 가까운이웃과 연결하는식으로 그래프를 만들고,
			두노드사이의 최단경로를 이루는 노드의수를 유지하면서 차원을축소함
			
		t-SNE
			비슷한샘플은 가까이 비슷하지않은건 멀리 떨어지도록 하면서 차원을 축소함
			데이터 시각화에 많이 사용되고,고차원공간의 군집을 시각화할때 사용됨
			
		선형판별분석
			분류임,하지만 훈련과정에서 클래스사이를 가장 잘 구분하는 축을 학습함
			이 축은 데이터가 투영되는 초평면을 정의하는데 사용할수있음
			이알고리즘의 장점은 투영을 통해 가능한 클래스가 멀리 떨어지도록 유지하므로 다른 분류기알고리즘을(SVM같은)
			적용시키기전에 차원을 축소시킬떄 좋음


9.비지도학습
	머신러닝의 난이도순은 강화학습-지도학습-비지도학습 순
	비지도학습에는 대표적으로 군집과 가우시안혼합모델이 있음
	
	1.군집
		군집은 샘플들의 위치에 따라서 묶어서 분류하는식으로 작동함
		그리고 비슷한샘플들의 집합을 클러스터라고 부름
		
		군집은 고객분류,데이터분석,차원축소,이상치 탐지,준지도학습,검색엔진,이미지분할등에 사용됨

		클러스터에 대한 보편적인 정의는 없고 대충 모여있으면 클러스터라고 부르고,알고리즘에 따라 다른 종류의 클러스터를 감지함
		k평균은 센트로이드라고 부르는 특정 포인트 주변에 모인 샘플을 찾고,dbscan은 샘플이 밀집되어 연속된 영역을 찾음
		
		1.k평균
			k평균은 클러스터의 갯수를 받아서 랜덤한 샘플위치를 센트로이드로 잡고 주변에 클러스터인덱스(비지도에서는 이걸 레이블이라고함)
			를 주고 센트로이드를 같은 클러스터에 속한애들의 중앙으로 보내고 다시 근처 애들 클러스터인덱스 주는식으로 반복해서
			변화가 없을떄까지 돌림
			
			하드군집은 샘플이 속한 클래스를 리턴하는거고 소프트군집은 클래스에 속할 확률을 리턴함
			
			일반적으로 빠르게 수렴하긴 하는데 최적의 솔루션으로 수렴하지못할수도있음(지역최적점)
			그래서 반복횟수를 줘서(n_init) 그 반복횟수 내에서 제일 좋은값을 뽑음
			비지도학습인데 성능지표가 있냐면,부정확하긴한데 있긴함
			각 샘플과 가장 가까운 센트로이드의 거리의 평균제곱거리를 모델의 이니셔라고 부르고 성능지표로 씀
			사이킷런에서 kmeans.score(훈련세트)하면 음수값 이니셔를 받을수있음(사이킷런에선 값이큰게 좋아야하기때문에 음수로바꿈)
			
			KMeans에서 그냥 돌리면 n_init번 실행해서 이니셔가 가장 낮은 모델을 선택함
			
			kmeans의 변종으로,전체 데이터셋을 사용하지 않고 미니배치를 사용해서 속도를 올리거나,
			메모리에 안들어가는 데이터셋을쓸수있음
			MiniBatchKMeans()를 쓰면됨
			근데 초기화도 여러번해야하고 가장 좋을거 직접골라야해서 할게많음
			꼭필요할때만 쓰는게편함
			그리고 미니배치가 훨씬빠르긴한데 일반적으로 이니셔는 조금더 나쁨
			
			1.클러스터 갯수찾기
				클러스터 갯수를 찾으려면 딱 몇갠지 데이터봤을때 보이면 모르겠지만,보통 이렇게하면안되니까 코드로해야하는데
				만약 이니셔를 사용해서 가장 작은 이니셔를 찾는다고 하면,
				문제가 이니셔는 클러스터 갯수가 많아질수록 좋아지기때문에(샘플과 클러스터사이 거리라서 클러스터가 늘어나면 거리가 줄어듬)
				그냥 바로 이니셔 최저인걸 쓸순없고
				이니셔 그래프의 기울기가 꺽이는 지점에서 그 지점을 택하는 방법을 쓸순있음 엉성하지만
				
				더 정확한 방법은(계산비용이 많이들지만) 실루엣점수임
				실루엣점수는 모든 샘플에 대한 실루엣 계수의 평균인데,
				실루엣 계수는 
				(자기가 속한 클러스터를 제외한 가장가까운 클러스터의 샘플까지 평균거리(a)-클러스터 내부의 평균거리(b))/max(a,b)
				임
				실루엣계수는 -1부터 +1까지 바뀔수있고,
				+1에 가까우면 자신의 클러스터 안에 잘속해있고 다른클러스터와는 멀리있다는거고
				0에 가까우면 클러스터 경계에 있다는거고
				-1에 가까우면 이 샘플이 잘못된 클러스터에 할당되었다는 의미임
				
				실루엣 점수를 계산하려면 
					from sklearn.metrics import silhouette_score
					
					silhouette_score(훈련세트,k평균.labels_)
				하면나옴
				
				여기서 그냥 실루엣점수 가장 높은거 선택할수도있고,
				각 클러스터와 계수값으로 그래프 그려서(실루엣 다이어그램) 평균적으로 높고 실루엣점수도 꽤 높은걸 선택할수도있음
				
				만약 애들이 각 클러스터의 개수에 해당하는 실루엣점수보다 낮은애들이 많으면,나쁜클러스터임
				일반적으로 다 비슷하게 높은게 막 한두개가 엄청높아서 슈퍼캐리하는애들보다 일반화가 잘됨 
				
			2.k평균의 한계 
				k평균은 속도가 빠르고 확장이 용이한데,
				단점으로는 최적이 아닌 솔루션을 피하기위해 반복을 여러번해야하고,클러스터 갯수를 정해야함
				그리고 k평균은 클러스터의 크기나 밀집도가 다르거나,원형이 아니면 잘 작동하지 않음
				원형이 아닌 타원형같은건 가우시안혼합모델이 잘 작동함
				
			3.군집을 사용한 이미지분할
				이미지분할은 이미지를 세그먼트 여러개로 분할하는 작업임(산,구름,꽃 등 같은 군집에 속한 픽셀들 분리)
				특히 이런식으로 동일한종류의 물체에 속한 픽셀을 분리하는걸 시맨틱 분할이라고 함
				시맨틱분할에서 최고수준성능을 내려면 합성곱신경망을 쓰는 복잡한모델을 써야함
				
				저런거말고 그냥 색상분할같은거 하려면 그냥 클러스터 갯수주고 픽셀들의 색으로 군집을 만든다음,그 픽셀들을 원본사이즈로
				출력하면 됨
				막 rgb/30이런거랑 다른거는,k군집은 비슷한 크기의 클러스터를 만드는 경향이 있기때문에 막 한두픽셀 색이 튄다고
				그걸 따로 잡아주지않고 크기가 작으면 다른데다가 넣어버림 클러스터갯수에따라서
				
			4.군집을 사용한 전처리
				군집은 차원축소에도 효과적임
				특히 지도학습 알고리즘을 적용하기전에 전처리단계로 사용할수있음
				
				간단히 이미지에서 사용하려면 파이프라인으로 만들어서 이미지를 클러스터n개로 모으고,
				이미지를 n개클러스터까지 거리로 바꾼뒤 회귀나 분류모델에 적용하면됨
				
				좀 더 올릴려면 클러스터 갯수를 찾는건데
				전처리로 쓸려면 명확한 성능측정기준이 있기때문에(교차검증에서 가장 좋은 분류성능을 내는값)
				GridSearchCV써서 최적의 클러스터 갯수를 찾으면됨
			
			5.군집을 사용한 준지도학습
				이경우에도 클러스터로 훈련세트를 나눈뒤에,각 클러스터마다 센트로이드에 가장 가까운 이미지를 찾아서 이런 이미지만
				따로떼서 레이블을 붙여주고,이걸 지도학습으로 돌리면 엄청 정확도가 올라감
				
				한단계 더 나아가서 동일한 클러스터 내에 있고,중앙에서 가까운 애들(20%라던가)만 레이블을 전파하고,그거만떼서 돌리면
				정확도가 더 올라감,이걸 레이블 전파라고 함 
				
				tmi(
					모델과 훈련세트를 지속적으로 향상하기위해서,
					수집된 레이블된 샘플에서 모델을 훈련하고 이 모델을 써서 레이블안된 샘플에 대한 예측을 만든후
					모델이 가장 불확실하게 예측한 샘플을 직접 레이블을 붙인다음
					레이블이 부여하는게 의미없어졋다싶을때까지 반복함
					이걸 불확실성 샘플링이라고 함
					
					다른방법으로는 모델을 가장 크게 바꾸는샘플이나,모델의 검증점수를 가장 크게 떨어뜨리는 샘플,앙상블에서 여러개의
					모델이 다른값을 내는 샘플들을 레이블 붙이는방식이 있음 
				
				)
		
		2.DBSCAN
			dbscan은 밀집된 연속된 지역을 클러스터로 잡음
			방법은
				알고리즘이 각 샘플마다 작은 거리(입실론)내에 몇개 놓여있는지 세고,이걸 입실론-이웃이라고 부름
				자신을 포함해서 입실론이웃내에 min_samples개의 샘플이 있다면 이걸 핵심샘플이라고 간주함,즉 밀집된지역에 있는샘플
				핵심샘플의 이웃에 있는 모든 샘플들은 동일한 클러스터에 속함,이웃에는 다른 핵심샘플이 포함될수있음
				즉 핵심샘플의 이웃의 이웃은 계속해서 하나의 클러스터를 형성함
				핵심샘플도 아니고 이웃도 아닌샘플은 이상치로 판단
				
			이 알고리즘은 모든 클러스터가 충분히 밀집되어있고,밀집되지않은곳과 잘 구분될때 좋은 성능을 냄
			사용법도 그냥 
				dbscan=DBSCAN(eps=0.05(입실론거리),min_samples=최소핵심샘플수)
				dbscan.fit(훈련세트)
			하면됨 
			
			일부 샘플의 클러스터인덱스가 -1나오는데,이건 이상치로 판단했다는 의미임
			
			DBSCAN은 predict를 제공하지않고 fit_predict를 제공함
			즉 새로운 샘플에 대해 클러스터를 예측할수없음
			이유는 다른 분류알고리즘이 더 좋기때문
			
			그래서 예측을 하고싶을떈 다른 예측기를 선택해야함
			만약 KNeighborsClassifier을 쓰면
			
				knn=KNeighborsClassifier(n_neighbors=50)
				knn.fit(dbscan.components_,dbscan.labels_[dbscan.core_sample_indices_]])
			하면 훈련되고
			저기다가 predict써서 예측하면됨
			즉 전처리로 사용하는게 일반적인 사용법인듯
			
			
			얘는 이상치에 안정적이고,클러스터의 모양과 갯수에 상관없이 감지할수있고,하이퍼파라미터가 두개뿐인게 장점이고
			클러스터간의 밀집도가 크게 다르면 모든 클러스터를 올바르게 잡아내는게 불가능한게 단점임
			계산복잡도는 O(m^2)임
			
		3.다른 군집 알고리즘
			1.병합군집
				병합군집은 대규모 샘플과 클러스터에 잘 확장되며,다양한 형태의 클러스터를 감지할수있고,
				특정클러스터수를 선택하는데 도움이되는 클러스터트리를 만들수있으며,어떤 짝거리와도 사용할수 있음
				하지만 연결행렬이 없으면 대규모 데이터셋으로 확장하기 어려움
				
			2.BIRCH
				BIRCH는 대규모 데이터셋을 위해 고안됨
				특성갯수가 너무 많지 않으면 배치k평균보다 빠르고 비슷한 결과를 만듬
				훈련과정에서 새로운 샘플을 클러스터에 빠르게 할당할수있는 정보를 담은 트리를 만듬
				
			3.평균이동
				이건 각 샘플을 중심으로 원을 그리고,원 안에 포함된 샘플의 평균을 구한뒤 원 중심을 평균점으로 이동시키고
				원이 안움직일때까지 반복함
				DBSCAN과 비슷한방식
				근데 O(m^2)라서 대규모데이터셋에는 적합하지않음
			4.유사도전파
				샘플은 자기랑 비슷한애한테 투표하고 걔들끼리 클러스터를 형성함
				이건 크기가 다른 여러개의 클러스터를 감지할수있지만 O(m^2)임
			5.스펙트럼군집
				샘플사이의 유사도 행렬을 받아 저차원 임베딩(차원을 축소함)을 만듬
				그리고 그 저차원에서 군집을 사용함
				이건 복잡한 클러스터구조를 감지하고 그래프컷을 찾는데 사용할수있음(소셜네트워크에서 친구의 클러스터찾기 등)
				이건 샘플갯수가 많거나 클러스터의 크기가 매우 다르면 잘 동작하지않음
				
	2.가우시안혼합
		가우시안 혼합은 샘플이 파라미터를 모르는 여러개의 혼합된 가우시안분포(종모양그래프)에서 생성되었다고 가정하는 확률 모델임
		하나의 가우시안 분포에서 생성된 모든 샘플은 하나의 클러스터를 형성함
		가우시안 혼합은 타원형에서 잘 작동함
		기본적인 사용법은 
			from sklearn.mixture import GaussianMixture
			
			gm=GaussianMixture(n_components=클러스터수,n_init=반복수)
				
		얘도 k평균과 비슷하게 동작하는데
		클러스터 파라미터를 랜덤하게 초기화하고 수렴할때까지 반복함
		
			1.샘플을 클러스터에 할당하고(기댓값)
			2.클러스터를 업데이트함(최대화)
		즉 클러스터의 중심뿐만아니라 크기 모양 방향 클러스터의 가중치까지를 넣은 K평균이라고 봐도 됨
		
		가우시안혼합은 하드클러스터가 아니라 소프트클러스터를 사용해서 확률을 뱉음
		
		즉,기댓값 단계에서 현재 클러스터 파라미터에 기초해 각 클러스터에 속할 확률을 예측하고,
		최대화 단계에서 각 클러스터가 데이터셋에 있는 모든 샘플을 사용해 업데이트됨
		
		클러스터에 속할 추정확률로 샘플에 가중치가 적용됨
		이 확률을 샘플에 대한  클러스터에 책임이라 부르고 
		최대화단계에서 클러스터 업데이트는 책임이 가장 많은 샘플에 크게 영향을받음
		
		이거도 k평균처럼 반복돌리는거라서 지역최대값으로 수렴할수있음
		
		소프트군집으로 받으려면 predict
		하드군집으로 받으려면 predict_proba
		
		가우시안 혼합모델은 생성모델이라서 이 모델에서 새로운 샘플을 만들수 있음(가우시안그래프에 대충넣으면되니까)
		그리고 주어진 위치에서 모델의 밀도를 추정할수있음 score_samples()쓰면됨
		샘플이 주어지면 그 위치의 확률밀도함수의 로그를 예측함
		
		만약 특성이나 클러스터가 많거나 샘플이 적으면 최적의솔루션으로 수렴하기 어려우니까 규제를 해야함
		그중하나는 클러스터의 모양과 범위를 제한하는거임
		covariance_type매개변수에
			spherical
				모든 클러스터가 원형이고,하지만 지름이 다를수있음(분산이 다를수있음)
			diag
				클러스터는 크기에 상관없이 어떤 타원형도 가능함,하지만 타원의 축은 좌표축과 나란해야함
			tied
				모든 클러스터가 동일한 타원모양,크기,방향을 가짐
		기본값은 full로 되어있음(제약이없음)
		
		1.가우시안혼합을 사용한 이상치 탐지
			이상치탐지는 보통과 많이 다른 샘플을 찾는것
			가우시안 혼합에서 이상치를 찾는법은 그냥 밀도가 낮은지역에 있는 모든 샘플을 이상치로 잡으면됨
			그러려면 밀도 임계값을 정해줘야되는데 이건 알아서 정하면됨(불량비율이라던가)
			
			만약 거짓양성이 많으면 임계값을 낮추고 거짓음성이 많으면 임계값을 올리면됨(정밀도재현율 트레이드오프)
		2.클러스터갯수선택
			가우시안혼합에서는 이너셔나 실루엣을 사용할수없음,클러스터가 타원형이나 크기가 다를때 안정적이지 않기때문
			그래서 BIC나 AIC같은걸 씀
			
			둘다 학습할 파라미터가 많은(클러스터가 많은)모델에 벌칙을 가하고 데이터에 잘 학습하는 모델에 보상을 더함
			보통 둘다 동일한모델을 선택하는데,선택이 다를경우 bic가 더 간단하지만 데이터에 완벽히 맞지 않을수있음
			
				gm.bic(훈련세트)	
				gm.aic(훈련세트)	
			로 값을 받을수있는데 이거로 그래프그려서 최소값인거 고르면됨
			
		3.베이즈가우시안혼합모델
			클러스터 갯수를 정하는 다른 방법은,
			클러스터를 엄청크게 잡고나서 불필요한 클러스터의 가중치를 0으로 만드는 BayesianGaussianMixture를 사용하는거임
			
			이 모델에서 클러스터 파라미터는 고정된 모델파라미터가 아니라 잠재확률변수로 취급됨
			
			베타분포는 고정범위 안에 놓인값을 가진 확률변수를 모델링할때 자주 사용됨
			이경우 0~1사이
			
			만약 a=[0.3,0.6,0.5]일때 샘플의 30퍼센트가 클러스터 0에할당되고,남은샘플의 60퍼가 1에할당될떄,
			이프로세스는 새 샘플이 작은클러스터보다 큰 클러스터에 합류할 가능성이 높은 데이터셋에 잘 맞는 모델임
			농도가 크면 a값이 0에 가깝게되고 많은 클러스터가 생기고,농도가 낮으면  a가 1에 가깝게되고 몇개의 클러스터만 생김
			
			이렇게 클러스터가 많을지 적을지 사전믿음을 weight_concentration_prior매개변수에 넣어서 파라미터를 줄수있음
			그렇지만 데이터가 많을수록 사전믿음은 중요하지않음
			
			가우시안 혼합모델은 타원형 클러스터에 잘 작동하지만 다른모양을 가진 데이터셋은 나쁜결과가 나옴
			
		4.이상치탐지와 특이치탐지를 위한 다른 알고리즘
			PCA
				일반샘플의 재구성오차와 이상치의 재구성오차를 비교하면 후자가 훨씬 커서 큰거를 거르는식으로 쉽게만들수있음
			Fast-MCD
				보통샘플이 혼합된게 아닌 하나의 가우시안분포에서 나왔다고 가정하고,여기에 안속하는걸 다 이상치로 잡음
			아이솔레이션 포레스트
				고차원에서 효율적인 알고리즘
				무작위로 랜덤포레스트를 만들고,각노드에서 특성을 랜덤하게 선택하고 랜덤한임계값으로 데이터셋을 둘로 나눔
				이렇게 모든샘플이 다른샘플과 격리될때까지 진행함
				보통 이상치는 다른샘플보다 멀리떨어져있으므로 중앙에서 멀리있는거 가지치기하면됨
			LOF
				주어진샘플주위의 밀도와 이웃주위의 밀도를 비교해서 거름
			one-class SVM
				모든샘플을 고차원공간에 매핑하고 이 고차원공간에서 선형svm으로 두클래스를 분리함
				만약 새 샘플이 여기 보통공간에 안놓이면 이상치로 날림
				이거도 svm이라서 대규모데이터셋에는 넣기어려움
				


10.케라스 인공신경망
1.퍼셉트론
	인공뉴런은 하나이상의 이진입력과 이진출력 하나를 가지는 초창기뉴런
	여기서 발전해서 퍼셉트론이 나왔는데 퍼셉트론은 입력과 출력이 이진이 아닌 어떤 숫자이고,
	그 숫자는 가중치와 연관되어서 가중치를 곱해서 모든 입력을 더한걸 가지고 
	계단함수(역치같은거 일정이상이면 1 아니면 0리턴)에 넣어서 onoff함
	
	하나의 TLU(퍼셉트론)은 하나의 이진분류에 사용할수 있음,역치를 넘으면 양성 아니면 음성식으로
	여기서 TLU를 훈련한다는건 적절한 가중치를 찾는것
	
	각 TLU는 모든 입력에 연결되어 있음
	한층에 있는 모든 뉴런이 이전층의 모든 뉴런과 연결되어있을때 이걸 완전연결층,혹은 밀집층이라 부름
	
	퍼셉트론의 입력은 입력뉴런이라고 하는 특별한 통과뉴런에 주입되는데,입력뉴런은 어떤입력이 주입되든 그냥 출력으로 똑같이 통과시킴
	여기에 입력뉴런과 편향뉴런을 섞어서 한층을 만들어서 입력을함
	
	퍼셉트론의 훈련은 헤브학습이라고 부르는데,이건 오차가 감소되도록 연결을 강화시킴
	즉 샘플을 넣으면 샘플에 대한 예측이 만들어지는데,
	여기서 잘못된 예측을 한 모든 출력뉴런에 가중치를 변화시킴(타깃값-출력값 으로 크게틀릴수록 많이변화)
	
	각 출력뉴런의 결정경계는 선형이라서 퍼셉트론도 복잡한 패턴을 학습하진못함,
	하지만 샘플이 선형적으로 구분될수있으면 알고리즘이 정답에 수렴함
	
	사이킷런은 하나의 TLU를 구현한 Perceptron을 가지고있음 sklearn.linear_model 에 있음
	사용법은 똑같음
	
	퍼셉트론 학습 알고리즘은 확률적경사하강법과 매우 비슷함
	그리고 문제점은 단일퍼셉트론은 xor같은 문제를 풀수가 없는데,다층퍼셉트론이 되면 그런 제약이 좀 사라져서 보통 다층퍼셉트론을 씀
	다층퍼셉트론은 MLP라고함
	1.다층퍼셉트론
		다층퍼셉트론은 입력층과 은닉층이라고 부르는 하나 이상의 TLU층과 마지막 출력층으로 구성됨
		출력층을 제외하고 모든층은 편향뉴런을 포함하며 완전연결임
		
		은닉층을 여러개 쌓아올린 인공신경망을 심층신경망이라고 하고 딥러닝이라고도 부름
		
		다층퍼셉트론의 주요훈련법은 역전파인데
		역전파는 네트워크를 정방향한번 역방향한번 통과시켜서 모든 모델파라미터의 편향값과 가중치를 수정하는 방식
		예를들면
		각 에포크(반복)마다 정방향으로 평소처럼 계산하고,다음으로 넘겨주면서 자기가 계산한값은 가지고 있고
		끝까지 갔으면 출력오차를 측정한다음 각 출력연결이 오차에 기여하는 정도를 계산하고,그 전단계뉴런이 오차에 기여하는 정도를 계산하고
		이런식으로 처음까지 도달하면 모든 뉴런에대한 오차그레이디언트를 가지게 되니까 이걸가지고 네트워크에 있는 모든 연결가중치를 수정함
		
		즉 샘플에 대해 역전파알고리즘이 예측을 만들고(정방향)
		  역방향으로 각 층을 거치면서 연결이 오차에 기여한 정도를 측정(역방향)
		  마지막으로 이 오차가 감소하도록 가중치 조정(경사하강법)
		이런식으로 나감
		(은닉층의 연결가중치는 랜덤하게 초기화해야함,만약 가중치와 편향을 0으로 초기화하면 모든뉴런이 같아지게됨,즉 뉴런1개와같아짐)
		
		다층퍼셉트론에서 주로 쓰는 활성화함수는 로지스틱,하이퍼볼릭탄젠트,ReLU등이 있음
		로지스틱은 0~1사이고 하이퍼볼릭탄젠트는 -1~1이고 ReLu는 0~무한대로 발산함
		ReLU는 연속적이지만 0에서 미분되지않지만 속도가 빨라서 자주쓰임(기본값),그리고 출력에 최대값이 없다는게 장점
		
		다층퍼셉트론에서 회귀를 할때는 값 하나를 예측하는데 출력뉴런이 하나가 필요함
		만약 주택가격을 찾으려면 출력뉴런이 하나만 있으면되고
		2d중심위치를 찾으려면 출력뉴런이 두개
		3d중심위치를 찾으려면 출력뉴련이 세개
		이런식으로 차원마다 하나씩 출력하면됨
		
		보통은 회귀에선 활성화함수를 쓰지않는데,출력이 항상 양수여야하면 ReLU를 쓸수있고,또는 softplus라고 ReLU의 변종을 쓸수있음
		만약 어떤 범위안의 값을 예측하려면 로지스틱이나 하이퍼볼릭을 쓰고 스케일조정하면됨
		
		훈련에 사용하는 손실함수는 보통 평균제곱오차인데 이상치가 많으면 평균절댓값오차를 쓸수있고,두개를 섞은 후버손실을 쓸수도있음
		
		다층퍼셉트론에서 분류를할때는 한레이블당 하나의 뉴런이(이진분류의 경우)필요함
		만약 다중레이블 이진분류일경우 종류하나당 하나의 출력뉴런이 있으면됨
		
		만약 3개이상이 한클래스에 섞여있으면 소프트맥스를 써서 가장 확률높은거 고르면됨
2.케라스로 다층퍼셉트론구현
	신경망을 훈련할땐 경사하강법을 쓰니까 입력특성의 스케일을 조정해줘야함
	신경망에 레이어 더할땐
		model=keras.models.Sequential() #모델생성
		model.add(keras.layers.Flatten(input_shape=[크기,크기]))# 입력층(입력데이터를 2828로 변경)전처리
		model.add(keras.layers.Dense(뉴런수,activation='relu'사용활성화함수)은닉층1층
		model.add(keras.layers.Dense(뉴런수,activation='relu'사용활성화함수)은닉층2층
		model.add(keras.layers.Dense(10,activation='softmax'사용활성화함수)출력층
	이런식으로 더함
	
	model.summary()하면 파라미터수 볼수있음
	보통 전뉴런수x지금뉴런수+지금뉴런편향값수 임
	층의 모든 파라미터는 get_weights()set_weights()로 접근할수있음
	
	모델을 만들고나면 compile()를 해서 손식함수와 옵티마이저를 지정해야함,부가적으로 훈련과 평가시 계산할지표를 추가로 지정할수있음
		model.compile(loss="sparse_categorical_crossentropy",optimizer="sgd",metric=['accuracy'])
	loss는 클래스가 배타적이면 sparse_categorical_crossentropy을 쓰고
	샘플마다 클래스별 타깃확률이 있으면(원핫백터라든가) categorical_crossentropy를 쓰면됨
	이진분류를 수행한다면 출력층에 softmax말고 sigmoid를 쓰고 binary_crossentropy를 사용함
	
	optimizer에 sgd를 쓰면 후진모드 자동미분(연쇄규칙으로)와 확률적 경사하강법을 사용한다는뜻
	
	분류기이므로 훈련평가시에 accuracy로 정확도 측정
	
	모델훈련은
		저장변수=model.fit(데이터,레이블,epochs=반복수,validation_data=(검증데이터,검증레이블))
		
	만약 어떤클래스는 많이등장하고 다른클래스는 조금등장해서 편중되어있으면 class_weight로 등장횟수에 가중치를줄수있음
	그리고 중요도높은샘플(전문가가 직접 레이블붙인거)이 있으면 sample_weight로 샘플가중치도 줄수있음
	
	테스트세트로 테스트할땐 model.evaluate(테스트데이터,테스트레이블)하면됨
	
	예측할땐 predict쓰면되고
	
	2.순차적이지않은 신경망
		어떤 모델들은 입력층에서 은닉층을 거치는루트와 그냥 바로 출력으로가는 루트 나누고 이런식으로 두루트 다쓰는경우도있음
		이러면 간단한패턴이 은닉층을 거쳐서 왜곡되는걸 막을수있음
		이렇게하려면 
			input=keras.layers.input(shape=데이터,shape[:]선택특성)
			hidden1=keras.layers.Dense(뉴런수,activation="relu")(input)전단계층
			hidden2=keras.layers.Dense(뉴런수,activation="relu")(hidden1)
			concat=keras.layers.Concatenate()([input,hidden2])여기서 두개를 묶어서 받음
			output=keras.layers.Dense(1)(concat) 출력층concat를 받음
			model=keras.model(inputs=[input],outputs=[output])모델생성
		이런식으로 만듬
		만약 특성을 나누고싶으면 위에 인풋을 shape로 두개로 쪼갠다음 concat로 묶으면됨
		
		만약 출력을 나누고싶으면 그 은닉층에 아웃풋을 하나 더만들고 모델의 아웃풋에 추가해주면됨
		
		각 출력은 자신만의 손실함수(loss)가 필요한데,하나의손실을 주면 그거 전부똑같이 적용하니까 아웃풋수만큼 넣어주면됨
		손실함수의 가중치(loss_weights)도 줄수있음


	3.서브클래싱
		만약 동적인 구조를 필요로하면 서브클래싱api를 쓰면됨		
		keras.model을 상속받아서 __init__와 call을 채워주면됨		
		근데 이러면 케라스가 이거 쉽게 분석못하니까 꼭필요할때만 사용하고 일반적으론 시퀀설쓰는게좋음
		
	4.모델저장	
		모델저장은 model.save(파일명)하면되고
		모델로드는 keras.models.loadmodel(파일명)하면됨
	5.콜백
		만약 체크포인트를 만들어야되면(훈련이 엄청길어진다든가해서)
			check=keras.callbacks.ModelCheckpoint(파일명)
			history=model.fit(...callbacks=[check])
		해서 만들면 일정주기마다 저기다가 저장함
	
		만약 검증세트를 사용하면 save_best_only=True로 최상의 검증세트에서만 모델을 저장할수있음
		조기종료를하는 또다른 방법은 EarlyStopping콜백을 쓰는것
		
		
3.텐서보드
	텐서보드는 시각화도구임
	텐서보드를 쓰려면 로그파일을 계속 적고 그걸 텐서보드에서 읽어야됨
	
	사용법은 board=keras.callbacks.TensorBoard(파일위치이름출력함수)
	넣고
	history=model.fit(...callbacks=[board])하면됨
	이러면 케라스가 로그를만드는데

	%load_exttensorboard
	%tensorboard--logdir=./my_logs--port=6006
	
	해서 포트열고 실행하면됨

4.하이퍼파라미터 튜닝
	신경망은 유연한게 장점이지만,유연해서 하이퍼파라미터가 엄청많은게 단점임
	그래서 튜닝하는 한가지방법은 RandomizedSearchCV를써서 탐색하는것
	이러려면 케라스를 사이킷런추정기처럼 보이도록 랩핑해야함
	랩핑하려면
	kerasreg=keras.wrappers.scikit_learn.KerasRegressor(만든모델)
	하면 랩핑되는데
	그러면 그냥 사이킷런쓰던거 똑같이쓰면됨
	fit score predict 똑같이쓰면됨
	
	신경망은 하이퍼파라미터가 많아서 그리드보단 랜덤이나음
	
	그리고 RandomizedSearchCV말고도 더 나은 라이브러리들이 있으니까 찾아서쓰면됨
	
	1.은닉층갯수
		은닉층은 많으면 일반화능력도 올라가고 좋은솔루션으로 빨리 수렴하게 도와줌,즉 과대적합이 생기기 직전까지 늘리면늘릴수록좋음
	2.은닉층의 뉴런갯수
		예전에는 300 200 100 이렇게 깔때기식으로 했는데 요즘은 300 300 300이렇게한다고함,
		단 첫은닉층은 좀 크게하면 도움된다고함
		
		보통 필요한거보다 많은층과 뉴런을 선택한다음에 조기종료나 규제로 쓰는게 간단하고 효과적임
		
	3.다른파라미터들
		학습률:가장 중요한 파라미터,일반적으로 최대학습률(발산직전학습률)의 절반이 최적임,
		좋은학습률을 찾는방법은 매우낮은학습률부터 매우큰학습률까지 다 돌려보고 찾는것
		
		옵티마이저:미니배치경사하강법보다 더 좋은 옵티마이저를 선택(그리고 이걸튜닝)하는것도 중요함
		
		배치크기:배치크기는 크면 속도가 올라가는데 안정성이 떨어짐
		
		활성화함수:보통 ReLU가 제일많이쓰이고 상황따라선택
		
		반복횟수:보통은 매우크게잡고 조기종료함
		
		

11.심층신경망 훈련
1.그레이디언트 소실과 폭주
	심층신경망에서는 막 층이 깊어지면서 그레이디언트가 점점 작아지면서 0이되면 더이상 변경이 일어나지않게됨,
	이걸 그레이디언트 소실이라고함
	또 반대로 점점점 가중치가 커지면서 알고리즘이 발산할수도있는데,
	그러면 이걸 그레이디언트 폭주라고함
	
	이렇게 불안정한 기울기가 있으면  심층신경망 훈련이 어려워지는데 층마다 학습속도가 달라지기때문
	
	이런게 생기는 이유는 로지스틱함수와,평균이0이고 표준편차가 1인 가중치초기화의 합때문인데
	로지스틱함수는 0과 1에서 수렴하기때문에 기울기가 0이되면서 역전파가 점점약해져서 입력층에선 0이되면서 소실됨
	
	1.he초기화
		그래서 이걸 크게 완화하는방법으로 he초기화가 나옴
		예측을 할땐 정방향으로,그레이디언트를 역전파할땐 역방향으로 양방향 신호가 적절히 소실도 폭주도 안하면서 잘 흘러야함
		이러기위해선 각층의 출력의 분산이 입력의 분산과 같아야함,그리고 역방향에서 층을 통과하기전과 후의 기울기분산이 같아야함
		하지만 층의 입력과 출력연결갯수가 같지않으면 이 두개를 보장할수없음
		
		그래서 보장하진못하지만 실전에서 잘 적용하는 대안으로 무작위로 초기화하는것을 사용함
		이걸 세이비어초기화,혹은 글로럿초기화라고 부름
		대충 평균이0이고 입력갯수(fanin)와 출력갯수(fanout)를 더해서 2로나눈거(fanavg)의 정규분포를 사용함
		
		르쿤초기화는 1/fanin을 사용
		그리고 relu활성화함수의 초기화전략을 he초기화라고 부름 he초기화는 2/fanin을 사용
		
		초기화전략                       활성화함수                           정규분포
		글로럿(케라스기본값)               없음,하이퍼볼릭탄젠트,로지스틱,소프트맥스       1/fanavg
		He                           relu와 변종들 					   2/fanin
		르쿤							SELU							  1/fanin

		케라스는 기본적으로 글로럿을 쓰는데,he를 쓰고싶으면 층을만들떄 
			kernel_initializer='he_uniform'
			kernel_initializer='he_normal'
		을 매개변수로 주면됨
		fanin대신 fanout을 쓰고싶으면 VarianceScaling을 쓰면됨 필요할떄검색
		
	2.수렴하지않는 활성화함수
		활성화 함수를 잘못 선택하면 그레이디언트 폭주나 소실로 이어질수있음
		예전에는 생물학적뉴런과 비슷하게생겨서 시그모이드를 많이 썼는데 요즘은 안씀 
		대신 ReLU의 변종을 씀
		
		그냥 생 relu는 죽은 relu로 알려진 문제가 있음
		뭐냐면 훈련하는동안 일부뉴런이 0이외의 값을 출력하지 않음
		이게생기는 이유는 뉴런의 가중치가 바뀌어 모든샘플의 입력의 가중치의 합이 음수가되면,
		기울기가 0이되어서 경사하강법이 작동하지않음
		
		이걸 해결하려고 Leakyrelu가 나옴 
		이건 하이퍼파라미터 a가 있는데,이게 이 함수가 새는 정도를 결정함(0.01 보통줌)
		이게 가중치가 음수가 되어서 기울기가 0이되면,0.01로 약간 희망을 줘서
		혼수상태에 좀 오래있더라도 깨어날수 있는 가능성을 주게됨
		
		그래서 relu보다 Leakyrelu가 항상 성능이 좋다는 논문도 있음
		a를 0.01로 주는거보다 0.2로 크게주는게 좀 더 평균적으로 나은성능을 내는것으로 보인다고함
		
		Leakyrelu의 변종으로 a를 범위내에서 무작위로 선택하고 테스트시에는 평균을 사용하는 rrelu도 잘 작동하고,
		규제의 역할을 하는거처럼 보이고
		
		a가 훈련하는동안 학습하는(즉,역전파로 변경되는)prelu는 대규모데이터셋에는 relu보다 크게앞서지만,
		소규모에는 과대적합확률이 높음
		
		
		
		또 elu라는 활성화함수는 모든 relu의 변종보다 성능이 좋은데(훈련시간도작고 성능도높음)
		얘는 -1에 수렴하는 애라서 값이 0보다작아도 기울기가 0이아니라서 죽은뉴런을 안만들고
		값이 0보다 작을때 음숫값이 들어와서 평균출력이 0에 가까워짐,즉 그레이디언트소실을 완화해줌 
		(a는 값이 큰음수값일때 수렴할값을 정의함 보통1주지만 바꿀수있음)
		a=1일때 값이 0에서 급격히 변동하지않으므로 값=0을 포함에 모든구간에서 매끄러워 경사하강법의 속도가 올라감
		
		얘는 지수함수를 써서 relu계열보다 계산이 느리긴한데,
		훈련시엔수렴속도가(필요에포크수가)빨라서 상쇄되지만,테스트시에는 좀 느리긴함
		
		elu의 변종으로 SELU가 있는데
		이건 완전연결층만 쌓아서 신경망을 만들고,모든은닉층이 SELU를 사용한다면,
		네트워크가 자기정규화(각층의 출력이 평균0과 표편1을 유지)된다는걸 보였음,
		이건 그레이디언트소실과 폭주를 막아줌
		
		그래서 selu는 아주깊은 네트워크에서 다른활성화함수보다 뛰어난성능을 자주 냄
		
		단 얘는 조건이 좀 있음
			입력특성이 반드시 표준화(평균0표편1)되어야하고
			모든은닉층의 가중치는 르쿤정규분포초기화 되어야하고(kernel_initializer='lecun_normal')
			네트워크는 일렬로 쌓아야됨(스킵연결,즉 와이드딥에서 건너뛴층,순환신경망등 사용불가)이런애들쓰면 자기정규화되는걸 보장하지못함
			
		근데 실제로 써보면 합성곱신경망같은건 그냥써도 성능좋다고함
		
		보통 선택은
		selu>elu>leakyrelu(원본과변종들)>relu>로지스틱
		만약 네트워크가 자기정규화되지못한다면(조건만족못하면)elu가 성능 더나을수있고,실행속도가 중요하면 leakyrelu쓸수도있음
		만약 신경망이 과대적합이면 rrelu,훈련세트가 아주크면 prelu 속도가 중요하면 relu쓸수있음
		근데 기본은 elu selu임
		
	3.배치정규화
		elu와 he초기화를 같이쓰면 훈련초기단계에서 그레이디언트소실폭주를 크게 감소시킬수있지만,다시발생하지 않는다는보장은 없음
		
		그래서 그걸해결하려고 배치정규화기법이 나옴
		이건 활성화함수를 통과하기 전이나 후에 모델에 연산을 추가하는데,
		이건 단순하게 입력을 원점에맞추고 정규화한다음,각층에서 두개의 새로운 파라미터로(스케일조정과 이동)
		결괏값의 스케일을 조정하고 이동시킴
		
		보통 신경망의 첫번째층으로 배치정규화를 추가하면 훈련세트를 표준화할 필요가 없음,배치정규화층이 대신함(얜 배치단위라서 근사적임)
		얘는 미니배치단위로 처리하는데,문제는 테스트시엔 샘플이 하나씩 들어올거기때문에 배치를 만들수가 없어서
		전체훈련세트의 배치입력평균과 표편을 가지고 대신 사용할수있음,근데 대부분은 층의 입력평균과 이동평균을 사용해서 훈련하는동안
		최종 통계를 추정함,케라스의 BatchNormallization은 이걸 자동으로 하기때문에 신경안써도됨
		
		여기에 4개의 파라미터백터가 있는데
			출력스케일백터(r)와 출력이동벡터(b)는 일반적인 역전파로 학습하고
			최종입력평균백터(u)와 최종입력 표준편차 백터(q)는 지수이동평균을 사용해서 추정함
			u와q는 훈련하는동안 추정하지만,훈련이끝나고 테스트에서 쓰려고 훈련이 끝난후에 사용함
			
			보통 거의 모든 심층신경망에서 배치정규화가 성능을 크게 향상시키니까 그냥 한층마다 다끼워넣으면됨
			속도저하가 있긴한데 훈련이 끝난후엔 이전층과 합쳐서 속도느려지는걸 막을수있고,훈련중엔 필요에포크수가 줄어서 상쇄됨
			
			그리고 규제와 같은역활을 해서 다른 규제의 필요성을 줄여줌
			그리고 그레이디언트소실문제가 크게감소해서 하이퍼볼릭탄젠트나 로지스틱활성화같은 수렴하는활성화함수를 사용할수 있고,
			가중치 초기화에 훨씬 덜 민감해짐
			만능임
			
			케라스에서 쓰는법도 쉬움
			그냥
				keras.layers.Flatten(...)
				keras.layers.BatchNormallization()
				keras.layers.Dense(...)
				keras.layers.BatchNormallization()
				...
			이렇게 층마다끼우면됨
			
			
			dense같은데서 use_bias=False로 두면 이전층에서 편향을 뺄수있고 
			활성화함수전에넣을지 후에넣을지는 상황마다 다름(데이터셋마다 성능이 다름 )
				keras.layers.Flatten(...)
				keras.layers.BatchNormallization()
				keras.layers.Dense(300,kernel_initializer="he_normal",use_bias=False)
				keras.layers.BatchNormallization()
				keras.layers.Activation('elu')
			이렇게 dense안에서 밖으로 떼어내는식으로 떼어낼수있음
			
			
			BatchNormallization은 신경쓸파라미터가 딱 두개있는데,momentum,axis임
			얘는 보통 1에 가깝고 0.9,0.99,0.999이런식으로 9늘려가는데 데이터셋이 크고 미니배치가 작으면 1에 좀더 가깝게함
			
			axis는 정규화할 축을 결정함 기본값은 -1임(즉 평균과 표편을써서 마지막축을 정규화함)
			([샘플수,높이,너비] 면 너비로정규화 )
			만약 높이너비로 정규화하고싶으면(픽셀들로 정규화하고싶으면)axis=[1,2]하면 높이너비합쳐서 정규화가능
			
			배치정규화는 앞에서 말한거처럼 훈련과 테스트의 통계가 다른데(훈련은 배치통계,테스트는 최종통계)
			이걸 어떻게 처리하냐면
			BatchNormallization속에 call함수에 트레이닝인지 아닌지 체크하는 매개변수로 체크함
			
		
		4.그레이디언트 클리핑
			폭주를 막는 다른방법은,역전파될때 일정 임계값을 넘어서지못하게 그레이디언트를 잘라내는것,이걸 그레이디언트 클리핑이라고 함
			보통 순환신경망은 배치정규화를 적용하기 어려워서 이렇게 많이 씀
			다른애들은 배치정규화쓰면됨
			
			사용법은 옵티마이저에서 clipvalue와 clipnorm매개변수를 지정하면됨
				optimizer=keras.optimizers.SGD(clipvalue=1.0)
				model.compile(loss='mse',optimizer=optimizer)
			이러면 그레이디언트 벡터의 모든원소를 -1~1사이로 잘라냄
			이기능은 그레이디언트 벡터의 방향을 바꿀수있음
			즉 [0.9,100.0]이면 두번쨰축으로 가겠지만,클리핑되면[0.9,1.0]으로 중앙쯤으로 가게됨
			보통 실전에서는 잘 동작하는데 못하게하려면 clipnorm으로 퍼센트로 하게하면 벡터의 방향이 안바뀜(둘다쓸수도있음)
			
			
2.사전훈련된층 재사용
	보통 큰큐모의 dnn은 처음부터 새로훈련하는건 좋은생각이 아님
	해결하려는 비슷한유형의 문제를 처리한 다른신경망이 있는지 찾아본다음에 그 신경망의 하위층(입력층과 가까운층)을 재사용하는게 좋음
	이걸 전이학습이라고 하고,이방법은 훈련속도가 크게오르고 필요훈련데이터도 크게 줄어듬
	
	보통 출력층은 거의무조건 다르기때문에(같으면 그냥그모델쓰면됨)바꾸고,
	그밑에 층은 작업이 서로 비슷할수록 많은층을 재사용하면됨
	(상위층으로 갈수록 그데이터에 맞는 특성을 뽑기때문,비슷하면 상위층도 비슷할확률이 높음)
	
	하는법은 재사용하려는 층을 모두 동결(가중치가 바뀌지않게 훈련으로 바뀌지않게묶어둠)하고
	은닉층 한두개추가하고(데이터가 많으면 추가할수있음 적으면 그냥 출력층만) 출력층 넣은후에 모델을 훈련하고 성능평가한후에 
	맨위에있는 동결층 한두개 동결풀고 돌려봄(이때 학습률은 낮게해야함)
	학습률이 높으면 가중치가 크게틀어질수있음
	만약 이때 성능이 나쁘고 훈련데이터가 적으면 상위은닉층 몇개를 제거하고 남은애들 동결시킨후에 돌리는식으로 적절한개수 찾을때까지 반복
	만약 훈련데이터가 엄청많으면 은닉층을 제거하는대신 다른거로 바꾸거나,더많은 은닉층을 추가할수도있음
	
	1.케라스의 전이학습
		여기선 원본모델을 클론해서 사본을 만들고 그모델을 불러오고 층하나추가(출력층)해서 만들면됨
		만약 클론을 안하면 같은걸 참조하기때문에(주솟값)원본도 바뀔수있음
			modelaclone=keras.models.clone_model(원본)
			modelaclone.set_weights(원본.get_weights())클론은 가중치는 안들고와서 가중치세팅도 해줘야함
			
			modelb=keras.models.Sequential(modelaclone.layer[:-1])클론된거 -1층까지 복사
			modelb.add(keras.layer.Dense(1,activation='sigmoid')) 출력층추가
			
			for layer in modelb.layers[:-1]: 레이어 동결
				layer.trainable=False
			modelb.compile(loss='binary_crossentropy',optimizer='sgd',metrics=['accuracy'])
			레이어 동결후와 동결해제후엔 컴파일해야됨 반드시 그래야적용됨
		
		근데 전이학습은 작은 완전연결네트워크에선 잘 동작하지않음,그래서 심층합성곱신경망에서 잘 동작함
	
	2.비지도 사전훈련

		만약 레이블된 훈련데이터가 적으면 몇가지 방법이 있는데
		
		레이블되지않은 훈련샘플을 많이 모을수있으면 오토인코더나 생성적 적대 신경망으로 훈련한뒤에 하위층을 재사용하고 출력층을 추가한뒤
		지도학습으로 세밀하게 튜닝하는 방법이 있음

		요즘은 보통 전체 비지도학습 모델을 사용한뒤에 출력층 추가하고 오토인코더나 gan을 사용함
	3.보조작업에서 사전훈련
		또 다른 방법은 레이블된 데이터를 쉽게 얻거나 생성할수 있는 보조작업에서 첫번쨰 신경망을 만든뒤에,
		그거로 뽑은 하위층을 재사용하거나,거기서 레이블을 뽑아서 사용하는식임
		(자기지도학습)
		예로 자연어처리에서 what are you saying?에서 what __ you saying? 으로 만든뒤 are를 레이블로 주는식
		
		
3.고속 옵티마이저
	큰 심층신경망은 엄청느릴수 있음
	지금까지 본 속도올리는방법은
		좋은 초기화
		좋은 활성화함수
		배치 정규화
		사전훈련된 네트워크 일부 재사용
	이 있음
	여기서 훈련속도를 크게 올리는방법으로는,표준 경사하강법 대신 더 빠른 옵티마이저를 선택하는것
	1.모멘텀 최적화
		일반 경사하강법이 그레이디언트를 속도로 썼다면 얘는 그레이디언트를 가속도로 쓴다음에,규제로 마찰저항(보통 0.9)을 넣어서 사용함
		
		모멘텀최적화는 그레이디언트가 일정하면 종단속도(마찰력과 가속도의 합이 0이될떄)까지 빠르게 올라가서 
		0.9일때 10배 빠르게 진행됨
		
		얘는 마찰때문에 수렴도 어느정도하고 속도도빨라서 평평한곳도 잘넘고 지역최적점도 꽤 잘 넘음
		
		사용법은
			optimizer=keras.optimizers.SGD(lr=0.001 학습률,momentum=0.9 마찰저항)
		얘의 단점은 하이퍼파라미터 하나 늘어난다는거밖에 없음
		
	2.네스테로프 가속 경사
		얘는 모멘텀 최적화의 변종인데 얘는 모멘텀최적화보다 거의 항상 더 빠름
		
		네스테로프는 현재위치가 아니라 모멘텀의 방향으로 조금 더 나간 지점에서 비용함수의 그레이디언트를 계산하는것
		보통 모멘텀벡터가 올바른방향을 가리키기때문에 이런 변경이 가능함
		
		그리고 모멘텀이 속도를 올릴때 시작점의 비용함수의 기울기는 속도를 올리고,시작점+b의 기울기는 경사아래쪽으로 잡아당기기때문에
		진동을 감소시키고 수렴을 빠르게 만들어줌
		
		사용법은
			optimizer=keras.optimizers.SGD(lr=0.001 학습률,momentum=0.9 마찰저항,nesterov=True)
		하면됨 그냥 nesterov true해주면됨
		
	3.AdaGrad
		얘는 얘를 직접쓰진않는데 다른알고리즘의 원본이 됨
		
		경사하강법은 전역 최적점 방향으로 직진하는게 아니라 가장 가파른경사를 따라서 빠르게 내려가서 실질적으로는 좀 느림
		이걸 AdaGrad는 가장 가파른차원에다가 패널티를 좀 줘서 스케일을 감소시켜 이문제를 해결함
		
		얘의 작동원리는 학습률을 전체적으로 감소시키는데,경사가 가파를수록 깍이는량을 높게해서 더빠르게 감소되게 만듬
		이걸 적응적 학습률이라고 부르고,전역 최적점으로 곧장가도록 갱신하는데 도움을 주고,학습률의 중요도를 조금 깍아주는게 또다른장점임
		
		근데 얘는 학습률이 너무 줄어서 전역최적점에 도달하기 전에 멈추는경우가 자주있어서 심층신경망에는 쓰면안되고 다른 변종들을 써야됨
		(선형회귀같은덴 써도됨)
	4.RMSProp
		AdaGrad가 너무 빨리 느려지는게 문제였다면 RmsProp는 가장 최근 반복에서 비롯된 기울기만 누적해서 이문제를 해결함
		그래서 하이퍼 파라미터가 하나 더생기긴하는데 기본값(0.9)에서 잘 작동해서 건드릴필요없음
		사용법은 
			optimizer=keras.optimizers.RMSProp(lr=0.001 학습률,rho=0.9 지수감소)
		하면됨
	5.Adam과 Nadam
		Adam은 적응적 모멘트 추정 인데,이건 모멘텀최적화와 RmsProp을 합친것
		모멘텀최적화처럼 지난 기울기의 지수감소 평균을 따르고,RmsProp처럼 지난 그레이디언트제곱의 지수감소평균을 따름
		즉 기울기의 평균과 평균이 0이아닌 분산에 대한 예측,평균을 첫번째모멘트 분산을 두번째 모멘트라고 부름
		
		즉 마찰저항과 최근 지수감소평균을 둘다 넣은것
		얘도 적응적학습률이기때문에 학습률의 중요도가 적어서 적당히던져도됨(보통 0.001씀)
		
		사용법은
			optimizer=keras.optimizers.Adam(lr=0.001 학습률,beta_1=0.9 마찰저항,beta_2=0.999 지수감소율)
		

		Adamax는 Adam에서 기울기업데이트의 스케일을 벡터에 비례해서 낮추는데 그래서 더 안정적이긴한데 보통은 Adam이 더 나음
		nadam은 Adam에 네스테로프를 더한것
		그래서 adam보다 빠르게 수렴함
		
		그래서 보통 Nadam이 Adam보다 성능이 좋지만 가끔 RmsProp이 더나을때도 있음
		
		그래서 보통
		네스테로프가 속도는 보통인데 품질은 가장 좋고
		RmsProp,Adam,Nadam,AdaMax들이 속도는 빠른데 품질은 보통~좋음이라서 상황따라선택
		
		그냥 NAdam쓰면될거같음
		
	6.학습률 스케쥴링	
		좋은 학습률을 찾는 방법엔 작은거부터 큰거까지 다돌려볼수있지만,이거보다 더 빨리 좋은학습률을 찾을수있는 방법들이 있음
		이걸 학습스케쥴이라고 함
		
		대충 이런것들이 있는데
		거듭제곱기반 스케쥴링
			학습률을 반복횟수에 따라 감소시키는데,처음엔 크게자르고  갈수록 작게 자름
			학습률은 각 스텝마다 감소함
			파라미터는 초기학습률n,거듭제곱수c(보통1줌),스텝횟수s
			s번 스텝뒤에 n/2 가 되고 2s번이 되면 n/3 이런식으로 s번마다 1씩늘어남
			사용법은
				opt=keras.optimizers.SGD(lr=0.01학습률,decay=1e-4)
			
			
		지수기반 스케쥴링
			학습률을 n=초기학습률*0.1*횟수/스텝 으로 설정
			학습률이 s스텝수마다 10배씩 점점 줄어듬
			얘는 그냥 s번 지날때마다 0.1을 곱하는거임
			사용법은
				def expodecay(epoch):
					return 0.01*0.1**(epoch/20)
				or def expodecay(epoch,lr):
					return lr*0.1**(epoch/20) 두번쨰파라미터가있으면 학습률을 받아볼수도 있음,
					                        이러면 옵티마이저의 초기학습률에 의존함,그리고 0에포크부터 감쇠시작    
				lrscheduler=keras.callbacks.LearningRateScheduler(expodecay)
				history=model.fit(데이터,레이블,[...],callbacks=[lrscheduler])
				
			모델을 저장할떈 옵티마이저와 학습률이 함께 저장됨
			새 스케줄함수를 쓸때도 똑같이 모델을 로드해 중지된시점부터 돌릴수있는데,스케줄함수가 epoch매개변수가 있으면
			에포크는 저장되지않고 0부터 다시시작하기때문에,fit의 initial_epoch매개변수를 수동으로 세팅해줘야됨
				
		구간별 고정 스케쥴링
			일정횟수 에포크동안 일정한 학습률을 쓰고,다음 일정한횟수 에포크동안 좀더 작은일정한 학습률을 쓰는식
			잘동작할순있지만 파라미터튜닝에 시간좀오래걸림
			파라미터는 에포크수에따른 학습률 두개
			사용법은
				def piecewise(epoch):
					if epoch<5:
						return 0.01
					elif epoch<15:
						return 0.005
					else:
						return 0.001
					
			
		성능 기반 스케쥴링
			매 n스탭마다 검증오차를 측정하고 오차가 줄어들지않으면 i만큼 학습률을 감소시킴(조기종료같은느낌)
			사용법은
				lrscheduler=keras.callbacks.ReduceLROnPlateau(factor=0.5 조건달성시 곱할거,patience=5 몇번동안 향상안될지선택)
		1사이클 스케쥴링
			얘는 다른애들이랑 좀 다른데
			1사이클은 훈련절반동안 선형적으로 초기학습률에서 파라미터학습률까지 늘리고,
			그다음에 나머지절반동안 선형적으로 학습률을 초기값까지 줄임
			마지막 몇번에서는 선형적으로 학습률을 소수점 몇째자리까지 엄청나게 줄임
			모멘텀에 쓸수도있는데 이떄는 처음에 크게잡고나서 처음절반동안 낮추고 다음 절반동안 되돌리고 마지막몇번은 최댓값으로 진행
			
				
		
		여기서 선택은
		성능기반과 지수기반이 사용하기 쉬운데 성능은 1사이클이 좀 더 높아보인다고 함
		성능기반과 지수기반중엔 지수기반이 조금더 빨리수렴하고 튜닝이 쉬워서 지수기반이 더 잘선택됨
		
4.규제를써서 과대적합 피하기
	특성수는 일정범위까진 엄청나게 성능이 오르는데,그거보다 높아지면 별쓸데없어짐(과대적합일어남)
	조기종료도 엄청 좋은 규제방법이고 배치정규화도 규제로도 꽤 괜찮게 사용됨
	
	1.l1,l2규제(라쏘,릿지)
		예전에 했던거처럼 신경망의 연결가중치를 제한하기위해 l2규제를 쓸수있고,희소모델을 만들기위해 l1규제를 쓸수있음
		l2규제를 쓰는법은
			model.add(keras.layers.Dense(뉴런수,activation='elu',
			kernel_regularizer=keras.regularizer.l2(0.01)))
		얘는 훈련동안 규제손실을 계산하기위해 각 스텝에서 호출되는 규제 객체를 반환함
		이 손실은 최종 손실에 합산됨
		만약 l1을 쓰고싶으면 keras.regularizer.l1() 
		둘다쓰고싶으면 keras.regularizer.l1_l2(l1=0.01,l2=0.01)쓰면됨
		
		보통 모든 은닉층에 동일한 활성화함수,동일한 초기화전략,동일한 규제를 쓰기때문에 같은매개변수 반복이 많은데
		functools.partial을 써서 리팩토링해서 쓰면 수정할때도 편함
	2.드롭아웃
		얘는 엄청 인기있는 규제방법임
		얘는 각 스텝에서 각 뉴런들은 임시적으로 드롭아웃(무시)당할 확률을 가짐
		즉 스텝마다 뉴런들이 각각 잠잘 확률이 생겨서,모든 뉴런들은 모든걸 잘 해야함(완전체뉴런이 되어야함)
		그리고 훈련이 끝나면 예측단계에서는 드롭아웃을적용하지 않음(입력뉴런엔 드롭아웃이 적용되고 출력뉴런엔 적용되지않음)
		
		보통 드롭아웃비율p를 10~50퍼센트 사이로 지정하는데
		보통 합성곱에선 40~50을 주고 순환신경망에선 20~30쯤 줌
		
		그리고 만약에 p를 50줬으면 테스트할때는 드롭아웃이 안켜지기떄문에,훈련때보다 2배이상이 연결되어서 이걸 보상하기위해
		연결가중치에 0.5를 곱해야됨,안그러면 훈련때보다 2배이상많은 입력값이 오기때문에 잘 동작하지 않을수있음
		즉 훈련이 끝난뒤 각 입력의 연결가중치에 보존확률(1-p)을 곱해야함
		
		케라스에서는 keras.layers.Dropout을 써서 BatchNormallization이랑 똑같이 쓰면됨
		사용법은
			keras.layers.Dense(...)
			keras.layers.Dropout(rate=0.2)
			keras.layers.Dense(...)
			keras.layers.Dropout(rate=0.2)
			keras.layers.Dense(...)
		
		
		그리고 드롭아웃은 훈련동안에만 활성화되어서,훈련손실과 검증손실을 비교하면 안됨
		비슷한 훈련손실검증손실이 나왔어도 과대적합일수 있음
		그래서 훈련이 끝난후에 드롭아웃을빼고 검증세트로 훈련손실을 평가해야함
		
		그리고 모델이 과대적합되면 드롭아웃 비율을 늘리고,과소적합이면 드롭아웃 비율을 낮출수있음
		층이클땐 비율을 늘리고 작은층은 낮추는게 도움이됨
		그리고 최신의 신경망은 마지막은닉층뒤에만 드롭아웃을 씀
		전체가 너무 규제가 강하면 이렇게해보면됨
		
		드롭아웃은 수렴이 느려지지만 적절하게튜닝하면 정확도가 많이 올라서 쓸만함
		
		그리고 자기정규화하는 네트워크를(SELU를쓰는) 규제하고싶으면 알파드롭아웃을 써야함
		이건 입력의 평균과 표편을 유지하는 드롭아웃의 한 변종
		일반 드롭아웃은 자기정규화기능을 망가뜨릴수있음
		
	3.몬테카를로 드롭아웃
		만약 이미 훈련된 드롭아웃 모델이 있을때,그모델을 재훈련하거나 전혀 수정하지 않고 성능을 크게 향상시킬수 있는 방법이
		몬테카를로 드롭아웃(mc드롭아웃)임
		
		사용법은
			yprobas=np.stack([model(xtestscaled,training=True)
				for sample in range(100)
			])
			yproba=yprobas.mean(axis=0)
		이거만하면됨
		
		이게뭐냐면 드롭아웃을켜서 테스트세트(샘플100개 클래스10개)에서 예측100개를 만들면 전부 다른 예측을 주는데
		그러면 새로생긴샘플은 100개의 샘플과 10개의 클래스가 100개있는 [100,100,10]이 됨
		여기서 열단위로 평균하면(샘플을 전부 평균하면) [100,10]이 되는데 이러면 훨씬 안정적인 결과값이 나옴
		
		근데 만약 엄청 위험에 민감한 시스템이면 이런건 주의깊게써야함 99%확신을 하는 예측처럼 쓰면안됨
		
		만약 훈련하는동안 다르게 작동하는 (BatchNormallization같은)그런게 있으면 훈련모드 강제로 키면안되고
			class MCDropout(keras.layers.Dropout):
				def call(self,inputs):
					return super().call(inputs,training=True)
		이걸 Dropout층대신 쓰면됨
		그리고 처음부터 모델을 만든다면 그냥 드롭아웃대신 mc드롭아웃쓰면됨
		보통 드롭아웃쓸거면 이거쓰면됨
		

	4.맥스노름규제
		이건 각각 뉴런에 대해 입력가중치가  입력가중치w * L2노름<=맥스노름 하이퍼파라미터r 가 되도록 규제함
		얘는 전체손실함수에 규제손실항을 추가하지 않고,매 훈련스텝이 끝나고 w*l2노름을계산하고 필요하면 w스케일을 조장함
		r을 줄이면 규제양이 증가해서 과대적합감소에 도움이 됨
		얘는 배치정규화를 쓰지않았을때 불안정한 그레이디언트 문제완화에 도움을 줌
		
		사용법은 kernel_constraint매개변수를 넣으면됨
			keras.layers.Dense(100,activation='elu',kernel_initializer='he_normal',
							   kernel_constraint=keras.constraints.max_norm(1.))
		이러면 매 훈련반복이 끝나고 계산한다음에 넘치면 스케일조정해서 리턴해줌
		


5.요약,가이드라인
	기본적으론
		하이퍼파라미터        기본값
		커널초기화           he초기화
		활성화함수           ELU
		정규화             얕은거면필요없고 깊으면 BatchNormallization
		규제              조기종료,필요하면 L2규제
		옵티마이저          모멘텀최적화(RMSPROP나 Nadam써도됨)
		학습률스케쥴         1사이클
	쓰고
	완전연결층을 쌓은 단순한모델이면 자기정규화를 할수있음
	이떄는
		하이퍼파라미터        기본값
		커널초기화           르쿤초기화
		활성화함수           SELU
		정규화             없음(자기정규화됨)
		규제              필요하면 알파드롭아웃
		옵티마이저          모멘텀최적화(RMSPROP나 Nadam써도됨)
		학습률스케쥴         1사이클
		
	입력특성을 정규화해야함 자기정규화면 까먹으면안됨
	
	그리고 비슷한문제를 해결한 모델을 찾을수있으면,재사용도 해봐야하고 
	레이블없는 데이터가 많으면 비지도 사전훈련
	비슷한작업을 위한 레이블된 데이터가 많으면 보조작업에서 사전훈련
	
	
	예외적으로
		희소모델이 필요하면 L1규제사용가능
		빠른응답(예측이 매우빠른)이 필요하면 층개수를 줄이고 배치정규화층을 이전층에 합치고 Leakyrelu나 Relu사용
		위험에 민감하고 예측속도가 매우 중요하지않으면 성능을올리고 불확실성추정과 신뢰할수있는 확률추정을 얻기위해 MC드롭아웃을 쓸수있음
	



12.사용자정의모델과 훈련

	텐서플로는 기본적으로 저수준api를 제공해서 그거가지고 사용자정의로 모든걸 만들수있음(손실함수,층,모델,초기화,규제등등 모든것)
	근데 보통 95퍼센트이상은 원래제공하는거 써서 필요할때 찾아보고 지금은 스킵해도될거같긴함
	
	텐서플로는 넘파이와 매우비슷하고,넘파이가 지원하는거 거의다 지원함,그리고 gpu를 지원
	
	텐서플로는 텐서로 구성되어있는데,텐서가 명령거치면서 가공된텐서(a(1,2)+10=a(11,12))가 되면서 바뀌는느낌
	텐서를 만들려면 a=tf.constant([1,2,3]) 이렇게만들수있음,배열이랑 스칼라값이랑 다 들어감
	
	텐서는 모든종류의 텐서연산이 가능함
	a+10   a(11,12)
	tf.square(a)  a(1,4)
	a@tf.transpose(a) a랑 a를 가로세로바꾼거랑 행렬곱

	넘파이에서 지원하는거 다지원하고 tf.add tf.multiply등등 기본수학연산도 다 지원함

    근데 막 다른거(넘파이나)그냥 막 가져다쓰면안되고,
	텐서플로거 따로있으면 그거써야하는데,텐서플로는 gpu구현떄문에 정밀도를 조금 포기하고 속도많이올린걸 써서 그거쓰는게좋음
	
	텐서와 넘파이는 넘파이배열로 텐서를 만들수있고 그반대도 되고,넘파이배열에 텐서플로연산할수있고,텐서에 넘파이연산할수도 있음
	
	근데 텐서플로는 32비트쓰고 넘파이는 64비트쓰기때문에,넘파이배열로 텐서를 만들때는 dtype=tf.float32로해야함
	
	그리고 텐서플로에서 타입변환하면 코스트가 많이 크기때문에,절대 자동변환을 하지않음(1.+2 하면 에러뜸)
	꼭 캐스트해야하면 tf.cast(1.,dtype=tf.int64)하면 수동으로 할수있음
	
	1.다른데이터구조
		텐서플로는 다른 데이터구조몇개도 지원하는데
		희소텐서
			대부분이 0으로 채워진 텐서를 효율적으로 나타냄 tf.SpareseTensor
		텐서배열
			텐서의 리스트,기본값은 고정된값인데 동적으로 바꿀수있음,모든 리스트에포함된 텐서는 크기와 데이터타입이 같아야함
			tf.TensorArray
		래그드텐서
			리스트의 리스트
			텐서에 포함된값은 동일한데이터타입이어야하지만,리스트의 길이는 달라도됨
			tf.RaggedTensor
		문자열텐서
			tf.string
			유니코드가 아니라 바이트문자열
			tf.strings를 쓰면 바이트문자열,유니코드문자열,텐서사이변환을 위한 연산을 제공함
			tf.string은 기본데이터타입이라서 문자열의 길이가 텐서크기에 나타나지않음
		집합
			집합은 일반적인 텐서로 나타남 
			예로 tf.constant([[1,2],[3,4]])는 [1,2]와 [3,4] 두개의집합 
			보통 집합은 텐서의 마지막축에 있는 벡터에의해 표현됨
			tf.sets에 연산들이있음
		큐
			큐는 단계별로 텐서를 저장함
			텐서플로는 여러종류의 큐를 제공하는데
			fifo 우선순위큐 랜덤셔플큐 패딩큐등 tf.queue에 들어있음
1.사용자정의모델과 훈련알고리즘
	1.사용자정의손실함수
		그냥 
			def 손실함수(y레이블값,y예측값):
				계산
				...(계산할때도 전부 tf.abs처럼 이런거 tf함수만 써서 계산해야함)
				return tf.where(...)
			model.compile(loss=손실함수 ,...)
		이렇게 하면 알아서 함
	
	2.사용자정의요소를 가진 모델 저장하고 로드하기
		만약 사용자 정의 요소를 가진 모델을 저장하고 로드할때는
		저장은 아무문제없이 되는데 로드할땐 사용자정의요소는 저장되지않기때문에
		그 이름과 객체를 매핑해야함
			keras.models.load_model('mymodel.h5',custom_objects={'손실함수':손실함수})
		이런식으로 안에들어간 커스텀오브젝트 매핑해줘야함
		만약 안에들어간 함수가 상위함수에서 매개변수받으면
			def 손실상위함수(임계값):
				def 손실함수(y레이블값,y예측값):
			
			
			keras.models.load_model('mymodel.h5',custom_objects={'손실함수':손실상위함수(2.0)})
		이렇게넣어주면됨
		
		근데 저기서 안에들어간 매개변수는 저장이 안되는데
		클래스만든다음에 keras.losses.Loss를 상속받아서 get_config()를 구현해서 해결할수있음
		
		그러면
		custom_objects={'클래스명':클래스명}
		넣어서 매핑하면됨

	3.활성화함수,초기화,규제,제한 커스터마이징
		이거도 똑같이하면됨
			def 커스터마이징:(매개변수들):
				return tf.머시기머시기
		
		보통 매개변수는 뭔지에따라 다르고,이름은 맞춰줘야하는데
			def 활성화함수(z):
			def 초기화(shape,dtype=tf.float32):
			def 규제(weights):
			def 제한(weights):
		이렇게씀
		쓰는거도 똑같이 Dense같은데 kernel_initializer=초기화
		이렇게쓰면됨
		이거도 똑같이 함께 저장할 하이퍼파라미터가 있으면 클래스만들어서 상속받은다음에 
			get_config()매서드만들면됨
	4.사용자정의지표
		손실과 지표는 개념적으로는 같은데,손실은 우리가 이해쉽게못해도 상관없는데 지표는 이해하기쉬워야되고,미분불가능한곳이 있거나,
		모든곳에서 기울기가 0이어도 상관없음
		사용법도 손실함수 그대로쓸거면
			model.compile(loss='...',optimizer='...',metrics=[손실함수클래스(2.0)])
		이렇게 그대로쓰면됨
		
		근데 막 배치갯수가 다른데 그거그냥평균내버리면 안되는상황도 있는데 그러면 스트리밍지표를 씀
		(5개 3개일경우 4개진짜양성 1개진짜양성일때 평균내면 다합쳐서한거랑 평균값끼리 평균낸거랑 값달라짐)
		
	5.사용자정의층
		레이어를 쉽게만드는 가장쉬운방법은
			a=keras.layers.Lambda(lambda x:tf.연산메서드(x))
		이렇게 전처리층을 쉽게만들수있음
		
		만약 필요한게 상태가 있는(가중치가 있는)층이면
		keras.layers.Layer을 상속한 클래스를 만들어야함
		
		class 내층(keras.layers.Layer):
			def__init__(self,units 하이퍼파라미터,activation=None 하이퍼파라미터,**kwargs 부모생성자호출): 
				생성자함수 
				부모생성자 호출해서 kwargs를 줘서 input_shape,name같은 기본매개변수를 처리할수있음
				그리고 하이퍼파라미터를 속성으로 저장하고
				
			def build(self,batch_input_shape):
				얘는 가중치마다 add_weight()를 호출해서 층의 변수(가중치)를 생성함
				층이 처음사용될떄 호출해서 층의 입력크기를 매개변수로 가중치를 만듬
				빌드끝에서 부모의 빌드메서드를 호출해야 층이만들어졌다는걸 케라스가 인식함
			def call(self,X):
				이층에 필요한 연산을 수행함
				그다음 결과에 활성화함수를 적용,이값이 이층의 출력
			def compute_output_shape(self,batch_input_shape):
				이층의 출력크기를 반환함
			def get_config(self):
				설정값저장
		쓰는건 다른층이랑 똑같이쓰면됨,하지만 함수형api랑 서브클래싱api에만 사용가능하고,시퀀설에는 사용불가
		훈련과 테스트에서 다르게 동작하는층이 필요하면 call에 training매개변수를 추가해서 훈련인지 테스트인지 결정해야함
		
		
	6.사용자정의모델
		얘도 똑같이 keras.Model을 상속해서 생성자에서 층과 변수를 만들고 모델이 할일을 call()에 구현하면됨
		
		모델을 층처럼 정의할수는있는데(모델은 레이어의 서브클래스임)그렇게 안하는게 정상임
		
		
	7.모델구성요소에 기반한 손실과 지표
	
	만약 은닉층의 가중치나 활성화함수처럼 모델의 구성요소에 기반한 손실을 정의해야하면,
	맨위의 은닉층에 보조출력을 넣어서 거기로 뽑아볼수있음
	
	8.자동미분을 사용한 그레이디언트계산
		직접 도함수계산하는건 너무코스트크니까 파라미터가 바뀔때마다 함수의 출력이 얼마나 바뀌는지 측정해서,
		도함수의 근삿값을 계산할수있음 
		
		tf.GradientTape()를 쓰면됨
		필요할떄 이거로 검색하자
	
	9.사용자정의훈련반복
		fit()가 맘에안들때 수정해서쓸수잇는데,이런거 필요할때 가서 보자
		당장필요없을거같음 이런거할 짬이아님


4.텐서플로 함수와 그래프
	그냥 일반적인 계산을 텐서로 바꾸는 쉬운방법이있는데
	@tf.function 을 붙이면 그다음에 만나는 함수에서 수행되는 계산을 분석해서 동일한 작업을 하는 계산그래프로 바꿔줌
	
	예를들어
		@tf.function
		def 제곱(x):
			return x**2
	이러면 텐서플로가 자기가 연산할때 빠르게동작하게 알아서바꿔줌
	
	1.오토그래프와 트레이싱
		텐서플로는 소스코드를 분석해서 제어문을 전부찾은후에 모든 제어문을 텐서플로 연산으로 바꿔서 심볼릭텐서를 매개변수 대신 전달해서
		텐서로 변경해서 돌려줌 이건 그래프모드(빠른모드)로 작동하고,
		그뒤에 트레이싱모드는 그래프모드에 외부라이브러리같은거 넣어서 돌리는데,그래프모드에 최대한 많이넣는게 좋음
	2.주의점
		1.넘파이나 표준라이브러리를 포함해서 다른라이브러리를 호출하면,이건 그래프에 포함되지않아서 연산이 느려짐
		  그래서 tf.메서드를 쓰는게 좋음
		
		2.만약 다른 파이썬함수나 텐서플로함수를 호출하면,이 함수들의 연산을 감지해서 그거도 전부 그래프로 자동으로 바꾸니까
		  @tf.function을 해줄필요가없음
		
		3.함수에서 텐서플로변수나 객체를 만들땐,처음호출될때만 수행되어야함,아니면 예외발생함
		그래서 텐서플로함수밖에서 변수생성하는게 좋음
		
		4.파이썬함수의 소스코드는 텐서플로에서 사용가능해야함
		
		5.텐서플로는 텐서나 데이터셋을 순회하는 for문만 감지함
		그래서 for i in range(x)말고 for i in tf.range(x)를 써야함
		안그러면 그래프에 표현안되고 트레이싱단계에서 실행됨
		
		6.성능면에선 반복문보다 벡터화된 구현이 나음 
	
		


13.텐서플로 데이터적재와 전처리
	텐서플로에서 데이터 로드와 전처리는 텐서플로데이터를 사용하면 됨
	데이터api는 텍스트파일(csv)고정길이 이진파일,TFRecord포맷등을 읽을수있음
	
1.데이터api
	데이터api의 중심엔 데이터셋 개념이있는데,데이터셋은 연속된 데이터샘플
	1.연쇄변환
		데이터셋은 변환메서드를 쓰면 리턴이 다시 변환된 데이터셋이기때문에 메서드를 이어붙여서 변환메서드를 연결할수있음
			dataset=dataset.repeat(3).batch(7)
			
			repeat는 n번반복(123이면 123123123으로만들고)
			batch는 n만큼 자름(3이면 [1,2,3],[1,2,3],[1,2,3])
		
		map을 써서 람다식으로 내부 전체를 변환할수도있음
			dataset=dataset.map(lambda x:x*2)
		map은 각 아이템을 수정함
		
		만약 데이터셋에 변환을 해야한다면(배치를 다시 푼다던가)apply쓰면됨
			dataset=dataset.apply(tf.data.experimental.unbatch())
			
		filter로 데이터셋을 필터링할수도있음
		
			dataset=dataset.filter(lambda x:x<10)
		
		데이터셋에서 몇개아이템만(위에서부터)보고싶으면 take(n)하면됨
			dataset=dataset.take(3)
	2.데이터 셔플링
		경사하강법은 훈련세트에 있는 샘플이 독립적이고 동일한분포일때 최고의 성능을 발휘함
		그래서 데이터를 섞어서 독립적으로 만들어줘야함
		가장쉬운방법은 shuffle()로 섞는것
		
		이걸쓰면 buffer_size만큼 추출해서 버퍼에 채우고,새로운 아이템이 요청되면 이 버퍼에서 랜덤하게 하나를 꺼내서 반환후,
		원본데이터셋에서 새 아이템을 추출해서 비워진버퍼를 채우고,원본이 0이될때까지 반복
		
		이걸할땐 버퍼크기를 크게잡아주는게좋고,단 메모리크기를 넘으면안되고 원본데이터셋보다 크게할필요는없음
		
			dataset=dataset.shuffle(buffer_size=5).batch(7)
		
		만약 메모리용량보다 큰 데이터셋은 이렇게 간단히 섞으면 충분한 효과가 나오지않아서,원본데이터를 섞는거임
		그러기위한 가장 쉬운방법은 파일을 여러개로 나눈다음에,훈련동안 무작위로 읽는것
		파일을 여러개로 나누고 그중몇개를 선택한뒤 그중몇개에서 한줄씩 랜덤으로 읽으면됨
			
			파일이 나눠져있으면
			filepathdataset=tf.data.Dataset.list_files(파일주소)
			
			dataset=filepathdataset.interleave(
				lambda filepath:tf.data.TextLineDataset(filepath).skip(1), 첫줄은 데이터필드니까 스킵
				cycle_length=한번에읽을갯수
			)
		
	3.데이터전처리
		csv파일을 파싱할땐 
			filed=tf.io.decode_csv(파싱할라인,record_defaults=각열에대한기본값)
		저기서 없는값이나오면 예외발생
		열마다 하나씩 스칼라텐서의 리스트를 반환함
		마지막에 레이블이 들어가있으니까 레이블을 제외한 필드 묶어야하는데 
			x=tf.stack(field[:-1])
			y=tf.stack(field[-1:])
			return x전처리값,y
		이렇게 보내면됨

	4.데이터적재와 전처리합치기
		로드와 전처리를 한번에 한함수에 넣고 돌리면 편한데 여기서도 볼게있음
			def 데이터처리(파일주소...):
				로드
				전처리
				return dataset.batch(batch_size).prefetch(1)
		prefetch는 미리 프리로드 1개해둬서,gpu가동율을 100퍼센트로 만드는거
		
	5.tf.keras와 데이터셋사용
		데이터처리함수로 훈련세트로 사용할 데이터셋을 만들수있음
			train=데이터처리(트레인파일위치)
			valid=데이터처리(검증파일위치)
			test=데이터처리(테스트파일위치)
		사용할떄도 그냥 fit에 훈련데이터셋,검증데이터셋 넣으면됨
			model.fit(train,epochs=10,validation_data=valid)
		evaluate와 predict에도 똑같이 쓰는데
		이경우엔 레이블이 필요하지않고,있더라도 무시함

2.TFRecord포맷
	TFRecord는 텐서플로가 대용량데이터를 저장하고 효율적으로 읽기위해 선호하는 포맷
	TFRecord는 크기가 다른 연속된 이진 레코드를 저장하는 단순이진포맷(각레코드는 레코드길이,길이체크섬,실제데이터,데이터체크섬으로 구성)
	
	tf.io.TFRecordWriter로 만들수있음
		with tf.io.TFRecordWriter(데이터.tfrecord)as f:
			f.write(b'1번적을말') b는 바이트로 적는다는소리(바이트캐스트)
			f.write(b'2번적을말')
	읽을때는
		dataset=tf.data.TFRecordDataset(['데이터.tfrecord'])
	하면 됨
	
	1.압축
		네트워크를 통해 읽어야할떄나 이럴땐 파일을 압축할필요가 있음
		
			option=tf.io.TFRecordOptions(compression_type='GZIP'압축종류)
			with tf.io.TFRecordWriter(데이터.tfrecord,option)as f:
			...
		이렇게 압축파일을 만들수있고
		읽을때는
			dataset=tf.data.TFRecordDataset(['데이터.tfrecord'],compression_type='GZIP')
		이렇게읽을수있음
	
	2.프로토콜 버퍼
		일반적으로 TFRecord는 프로토콜버퍼를 사용함
		
		텐서플로에서 쓰는건
			from tensorflow.train import BytesList,FloatList,Int64List
			from tensorflow.train import Feature,Features,Example
			
			예제=Example(
				특성들=Features(
					특성={
						'name':Feature(bytelist=BytesList(value=[b'aaa'])),
						'id':Feature(Int64List(value=[123])),
						'emails':Feature(bytelist=BytesList(value=[b'a@a.com'],[b'b@b.com']))
					}
				)
			)
			with tf.io.TFRecordWriter('데이터.tfrecord')as f:
				f.write(예제.SerializeToString())
				
	3.프로토콜 버퍼일고 파싱
		tf.io.parse_single_example()로 파싱할수있음
		이건 텐서플로연산이라서 TF함수에 포함할수있음
		
		파싱할때는 설명딕셔너리(필드설명)를 만든다음에 그거주고 파싱하면됨
			feature_des={
				'name':tf.io.FixedLenFeature([]특성크기,tf.string데이터타입,default_value=''기본값),고정길이
				'id':tf.io.FixedLenFeature([],tf.int64,default_value=0),고정길이
				'emails':tf.io.VarLenFeature([tf.string) 가변길이
			}
			for x in tf.data.TFRecordDataset(['데이터.tfrecord']):
				파싱예제=tf.io.parse_single_example(x,feature_des)
		고정길이는 보통텐서로 파싱되지만,가변길이는 희소텐서로 파싱됨
		참조할떈
			
			파싱예제['emails'].values
		하면나옴
		
		BytesList는 직렬화된 객체를 포함해 어떤 이진데이터도 포함할수 있음
		tf.io.encode_jpeg()로 jpg를 인코딩한다음 BytesList에 넣을수있음
		이걸 읽을때는 tf.io.decode_jpeg()를 호출하면됨
		
		tf.io.parse_example()로 배치단위로 파싱할수있음
			for x in tf.data.TFRecordDataset(['데이터.tfrecord']):
				파싱예제=tf.io.parse_example(x,feature_des)		
		
		
	4.리스트의리스트
		리스트의리스트를 다룰떄는 SequenceExample가 있음
		필요해지면 찾아보자
		사용법은 비슷함


3.입력특성전처리
	신경망에서 데이터를 준비하려면,모든특성이 수치특성이어야하고,정규화해야함
	특히 범주형이나 텍스트특성이 있으면 숫자로 바꿔야됨
	
	가장 간단한방법은 lambda로 건드리는것
		model=keras.models.Sequential([
			keras.layers.Lambda(lambda input:(input-mean))
		])
		or
		model.add(keras.layers.Lambda(lambda input:(input-mean)))
	
	아예 층을 하나 만들고싶으면 그럴수도있음
		class 새층(keras.laters.Layer):
			def adapt(self,data_sample):
				self.means_=np.mean(...)
			def call(self,inputs):
				retrun(inputs-self.means_)
	이런식
	이걸 모델에 추가하기전에 adapt를 호출해서 미리 값을 넣어주고 써야함
		std=새층()
		std.adapt(데이터샘플)
	샘플은 전체데이터셋을 대표할만큼 커야하지만,전체훈련세트일 필요는없고,적당히 수백개정도면됨
	그다음엔 다른층이랑똑같이 model.add해서쓰면됨
	
	keras에서 노말라이제이션하려면 그냥 keras.laters.Normalization쓰면됨
	얘도 층을만들고 adapt에 샘플데이터던져주고 보통층처럼 쓰면됨
	
	
	1.원핫벡터로 범주형인코딩
		
		원핫인코딩을 할때,
		먼저 사전을 만들고 그 범주크기만큼 인덱스텐서를 만들고,
		범주리스트와 인덱스로 초기화객체를 만든다음 
		oov갯수(사전에없는거 몇개까지 처리할건지)주고 룩업테이블 만들면됨
		
			vocab=[사전 '사막','섬','해안']
			indices=tf.range(len(vocab),dtype=tf.int64)
			tableinit=tf.lookup.KeyValueTensorInitializer(vocab,indices)
			numoov=2
			table=tf.lookup.StaticVocabularyTable(tableinit,numoov)
			
		만약 oov갯수를 넘는 알려지지않은 범주가 나오면 충돌이 발생해서,범주들끼리 겹칠수있으니까 좀 크게잡아주는게좋을듯
		
		테이블만들고 쓸떄는
			catindices=table.lookup(데이터)
			catonehot=tf.one_hot(catindices,depth=len(vocab)+numoov)
		하면됨
		
		근데 keras.layers.TextVectorization쓰면 됨
		이거도 adapt가 어휘사전을 추출하고 call이 각 범주를 어휘사전의 인덱스로 바꿈
		인덱스를 원핫벡터로 바꾸고싶으면 이층을 모델의 시작부분에 추가하고,
		뒤이어 tf.one_hot()함수가 적용된 람다층을 두면됨
		
		(범주갯수가 10개이하면 원핫인코딩,10~50이면 상황따라, 50이상이면 임베딩사용)
	2.임베딩으로 범주형인코딩
		임베딩은 범주를 표현하는 훈련가능한 밀집벡터
		
		처음엔 인베딩이 랜덤하게 초기화되어있는데,이건 훈련이 되니까 점점 향상됨
		(대충 king-man+woman 하면 queen과 비슷한위치에 있다 이런식임)
		
		임베딩을 케라스에서 하려면    keras.layers.Embedding을 쓰면됨
			model.add(keras.layers.Embedding(input_dim=len(vocab)+numoov 입력차원,
											 output_dim=2 출력차원))
											 
		
		
		(원핫인코딩다음에 뒤따르는 dense가 임베딩과 같은역할을 하는데,임베딩이 좀 더 적은연산을 사용함
		길이가 20인 원핫벡터와 10개의 유닛을가진 dense를 쓰는건,input_dim이20이고 output_dim이 10인 임베딩쓰는거랑같음)
		
	3.케라스전처리층
		keras.layers.Normalization은 특성표준화를 하고
		keras.layers.TextVectorization은 각 단어를 어휘사전에 있는 인덱서를 인코딩함
		
		둘다 층을만들고 샘플데이터로 adapt를 호출한다음 일반적인층처럼 모델에 사용할수있음 
		다른 전처리층도 동일한 패턴을 따름
		
		예를들어 keras.layers.Discretization은 연속적인 데이터를 몇개의 구간으로 나누고,원핫벡터로 인코딩함
		즉 연속데이터를 범주형으로(낮음중간높음 [0,0,0])바꿈
		또한 preprocessingStage로 여러 전처리층을 연결할수 있음 
			pipeline=keras.layers.preprocessingStage([전처리1,전처리2])
			pipeline.adapt(샘플데이터)
			
		그리고 TextVectorization은 단어인덱스 대신 단어 카운트벡터를 출력하는 옵션이 있음
		and가 3번나오면 3출력하고 그런식
		그래서 tf-idf를 쓸수있음
		


4.TF변환
	전처리는 계산비용이 커서 훈련과 동시에 하는거보다,사전에 처리하면 속도를 크게 올릴수있음
	즉 데이터가 훈련하는동안 에포크마다 전처리하는게 아니라,훈련하기전에 샘플마다 한번씩만 전처리
	만약 데이터셋이 작으면 cashe로 메모리에 넣어서 할수있고,크면 아파치빔이나 스파크같은 외부도구써야함
	
	근데 모델전처리랑 외부도구랑 크게보면 2묶음인데,같이묶으면 유지보수 어려워지니까 전처리랑 외부도구를 2개로 나눠야되는데,이걸합치려면
	TF변환을 해야함
	TF변환을 하려면 TFX를 설치해야됨
	
	TFX로 전처리함수를 한번만 정의하고,그다음 아파치빔으로 그 함수를 전체훈련세트에 적용할수있음
	이과정에서 전체훈련세트에 대한 모든 통계를 계산함
	
	tf변환은 배포할모델에 추가할수있도록,동일한 역할을 수행하는 텐서플로함수를 생성한다는게 중요함
	이 tf함수는 아파치빔에서 계산한 모든 통계에 해당하는 상수를 가지고있음
	
5.TFDS프로젝트
	https://tensorflow.org/datasets 에 가면 데이터셋이 많음
	tensorflow-datasets라이브러리를 설치하고 tfds임포트하고 load하면 데이터셋이 많으니까 필요한거있으면 찾아보자









14.합성곱신경망(cnn)
	합성곱신경망은 기본적으로 이미지등 입력특성을 쪼개서 일정부분의 패턴을 인식하고,
	그걸조합해서 상위의패턴을 조합해서 완성품을 만드는형식
	
	제일 중요요소로 합성곱층과 풀링층이 있음
1.합성곱층
	첫 합성곱층의 뉴런은,입력페이지 전체픽셀에 연결되는게 아니라,합성곱층안에 수용장(일정범위)안에있는픽셀에만 연결됨
	두번째 합성곱층의 뉴런은,첫번쨰층의 일정범위 안에 있는거만 연결됨
	이렇게 첫번째 은닉층에서 작은 저수준특성에 집중한다음,그걸 다음은닉층에서 고수준특성으로 조합해나가는게 합성곱층임
	보통 이런구조가 이미지에서 많아서 이미지인식에 잘 작동함
	
	(보통 올라가면서 크기가 작아지는데,이걸 이전층과 같게 하기위해 입력주위에 0으로 패딩치는걸 제로패딩이라고함)
	
	그리고 수용장 사이에 간격을 둬서 큰입력을 작게 줄이는거도 가능한데,수용장사이의 간격을 스트라이드라고 함
	즉,스트라이드를 잡으면 7x7을 4x4층으로 만들거나 할수있음
	1.필터
		뉴런의 가중치는 수용장 크기의 작은이미지로 표현될수있음(즉,입력에서 거르고 남은걸 뱉은거로 표현될수있음)
		즉,수직선가중치를 사용하면 수평선을 제외한 모든걸 무시하는식
		
		그러므로 층의 전체 뉴런에 적용된 하나의 필터는,하나의 특성맵을 만듬(필터가 적용된 이미지)
		특성맵은 필터를 가장 크게 활성화시키는 이미지의 영역을 강조함
	2.여러특성맵
		실제 합성곱층은 여러가지 필터를 가지고 필터마다 하나의 특성맵을 출력하니까,2D가 아니라 3D임
		각 특성맵의 픽셀은 하나의 뉴런이고,하나의 특성맵안에서는 모든 뉴런이 같은파라미터(같은가중치와 편향)를 공유하지만,
		다른특성맵에 있는 뉴런은 다른 파라미터를 사용함
		그리고 한 뉴런의 수용장은,이전층에있는 모든 특성맵에 걸쳐서 확장됨,
		즉 하나의 합성곱층이 입력값에 여러필터를 동시에 적용해서,
		입력에있는 여러특성을 감지할수있음
		그러니까 한 층에있는 1,1에 있는 층마다 모든뉴런은,
		입력값으로받은 1,1에 대응되는 수용장에 있는 모든 특성맵의 값을 각뉴런마다 전부 먹고 자기필터로 거쳐서 뱉음
		즉 각뉴런이 대응되는 모든수용장을 먹음(a->1,2,3 b->1,2,3 c->1,2,3)
		계산식은 그냥 입력에대한 가중치합을 계산하고 편향을 더함
		
		입력이미지는 컬러채널마다(rgb) 여러서브층으로 구성되기도 함
		
	3.텐서플로
		사용법은
			conv=keras.layers.Conv2D(filters=필터수,kernel_size=커널크기,strides=스트라이드,
									padding="same"same는제로패딩,activation='relu'활성화함수(출력위해))
		즉 원본/커널크기x커널크기 필터수만큼 있음										

	4.메모리요구량
		cnn은 훈련할때 많은량의 램이 필요하다는 문제가 있음
		훈련때 역전파알고리즘이 역방향계산을할때 정방향에서 계산했던 모든 중간값이 필요하기떄문
		그래도 추론할떈 역전파안해도되니까 상관없는데 훈련할때가 문제가됨
2.풀링층
	풀링층은 계산량과 메모리사용량 파라미터수를 줄이기위해,이미지를 축소하는 층임
	얘는 어떻게 동작하냐면,똑같이 크기 스트라이드 패딩유형을 지정하고 크기만큼에서 평균이면 평균,최대면 최대 이런식으로
	값을 뽑아서 압축해냄(파괴적방식)그리고 다른값들은 버려짐
	일반적으로 최대풀링이 성능이 좋은듯
	계산량외에 다른 특징은,최대풀링은 일정수준의 불변성을 만들어냄
	막 옆으로 좀 움직여도,그게 최대값이 아니면 무시하니까 약간의 불변성이 생김
	
	최대풀링의 단점은,이층은 매우 파괴적이고,어떤애들은 불변성이 필요하지않음,
	특히 시맨틱분할에서는 입력이미지가 오른쪽으로 한픽셀 이동했으면 출력이미지도 한픽셀 이동해야함
	1.텐서플로구현
		텐서플로에서는
			maxpool=keras.layers.MaxPool2D(pool_size=2)
		쓰면됨
		
		그리고 특이한 풀링층에는 깊이풀링도 있는데 이건 필요할떄보고
		
		그외엔 전역평균 풀링층이 있음
		얘는 각 특성맵에서 하나의 숫자를 뽑음
		그래서 최종출력할때 유용함
		사용법은
			global=keras.layers.GlobalAvgPool2D()
		임
	
3.cnn구조
	기본적인 cnn은 합성곱층을 몇개 넣고(활성화함수로 relu를 그뒤에두고)풀링층을 쌓고,합성곱활성화풀링 이런식으로 가다가 
	마지막에 완전연결층으로 좀하고 마지막층에 소프트맥스넣은 dense로 예측 출력
	(합성곱층은 처음엔 큰크기의커널과 2이상의 스트라이드를 넣고(정보손실덜하게),그뒤부턴 작은걸 여러개넣는게 계산량도적고 결과도좋음)
	
	기본적인 구조는 저거고,성능향상을 위해 추가로 뭐 들어가는게 있는데
	
	
	LRN이라는건 경쟁적인 정규화인데,이건 가장 강하게 활성회된 뉴런이 다른특성맵에있는 같은위치의 뉴런을 억제해서
	좀더 독립적인 결과가 나오게해서 일반화성능을 올려줌
	
	케라스에선 tf.nn.local_response_normalization()을 lambda로 감싸서 쓸수있음
	
	또 다른건
	인셉션모듈이라는 서브네트워크가 있는데
		이건 처음에 입력신호를 복사해서 4개의 층에 넣음 3개는 1x1+1s로 1x1커널에 1스트라이드이고 하나는 3x3+1최대풀링층
		4개의층은 모두 relu를 사용
		두번째 합성곱층은 각기 다른 커널크기를 사용해서 다른크기의 패턴을 잡음 처음은 1x1 최대풀링층도 1x1 나머지는 알아서
		모든층은(최대풀링층까지도)스트라이드1과 same를 사용해서 출력의 높이너비가 입력과 같음
		이렇게 모든출력을 깊이연결층에서 깊이방향으로 연결함
		
	1x1커널을 넣으면 한수용장에 단 하나의 픽셀만 있기때문에 공간상의 패턴을 잡을수는없음,하지만 깊이차원패턴을 잡을수있음
	(입력값과 크기는같음 1x1에 1스트라이드면)
	그리고 입력보다 더 적은 특성맵을 출력해서 차원을 줄임,연산비용과 파라미터수를줄여 훈련속도를올리고 일반화성능향상
	[1x1,3x3]같은 합성곱쌍은 더 복잡한패턴을 감지할수있는 한개의 강력한 합성곱층처럼 작동함
	즉 그냥 여러크기의 복잡한패턴이 담긴 특성맵을출력하는 강력한 합성곱이라고 생각하면됨
	그렇지만 인셉션모듈의 각합성곱층의 합성곱커넣수는 하이퍼파라미터라서,인셉션모듈을 추가할때 하이퍼파라미터6개가 늘어남
	
	또 다른건
	잔차네트워크라는게 있음
	이거의 핵심요소는 스킵연결임
	얘는 입력과 출력바로앞까지를 스킵연결로 연결해두고,출력 바로앞에 함수를넣어서 원본입력과 층을거친입력을 합쳐서 출력함
	이러면 원본데이터가 다음에 영향을 줄수도있고,원본은 바로넘어가니까 다음층까지 데이터가 안가도 미리 일을 할수있음
	
	만약 출력과 입력의 크기가 달라서,
	입력이 잔차유닛의 출력에 바로 더해질수없으면 스트라이드를 조절해 입력을맞춰서 출력특성맵의 수가 같은 1x1합성곱층으로 입력을 통과시킴
	(층을거친값을 바꿀순없으니까 입력값을 풀링처럼 스트라이드로 크기줄여서 맞춤)
	
	또 다른건
	깊이별 분리합성곱층이라는게 있는데
	이건 원래 합성곱층은 공간상의패턴(타원형)과 채널사이의패턴(눈코입)을 동시에 잡는데,이건 공간패턴과 채널패턴을 분리해서 모델링함
	얘는 입력채널마다 하나의 공간필터만 가지기때문에 입력층처럼 채널이 너무적은층다음에 사용하면안됨
	
	또다른건 se블록이있는데
	이건 만약 눈,코,입이 동시에 발현되는게 많았다면 입이랑 코만 나와도 눈이 있을거라 기대하고,눈이 적게활성화돼도,
	눈특성의 출력을 올림
	얘는 어떻게 구성되냐면
		전역평균풀링층(입력)256특성맵입력256숫자출력
		relu밀집층    256숫자입력 16숫자출력
		시그모이드밀집층(출력)16입력 256숫자출력
	처음에 전역풀링이 각특성맵의 평균활성화를 계산하고,relu로 압축한뒤에 특성 분포를 학습해서(0과1사이),
	특성맵마다 숫자하나를 뱉어서 그걸 특성맵과 곱해 관련없는(작은)값을 낮추고 관련높은건 그대로 유지
	
4.케라스 resnet34 구현
	케라스에서 쓸땐
		model=keras.applications.resnet50.ResNet50(weights='imagenet'데이터셋웨이트)
	그냥 이거가져다쓰면됨
	만약 자기데이터셋있으면 가중치없이해야겠지만(아니면 전에했던거처럼 일부만잘라서쓰기)
	
		그리고 resnet50모델은 224x224크기를 기대하니까 
		리사이즈이미지=tf.image.resize(이미지,[224,224])로 이미지잘라서써야함
		그리고 픽셀값이 0~255사이라고 기대하니까 
		a=keras.applications.resnet50.preprocess_input(리사이즈이미지*255)로
		전처리한다음 
		b=model.predict(a)
		하면됨
5.사전훈련모델을 사용한 전이학습
	앞에말했던거처럼 훈련데이터가 적으면 사전훈련된모델의 하위층을 쓰는게좋음
	만약 resnet50쓰면
		basemodel=keras.applications.resnet50.ResNet50(weights='imagenet'데이터셋웨이트)
		avg=keras.layers.GlobalAvgPool2D()(basemodel.output)
		output=keras.layers.Dense(클래스수,activation='softmax')(avg)
		model=keras.Model(inputs=basemodel,outputs=output)
	이렇게 베이스모델-avg-output순으로 나가는 모델만들어쓸수있음
	있는모델에 층추가시키려면 처음에 가중치잠가둬야하니까
		for layer in basemodel.layers:
			layer.trainable=False
	이렇게 잠가두고
	컴파일한뒤에 몇번돌리고 잠군거 풀면됨(잠그거나 풀때 다시컴파일해야함)
	이떈 사전훈련된가중치 고장날수도있으니 학습률좀 많이 작게해야함
	
6.분류와 위치추정
	사진에서 물체의 위치를 추정하는건 회귀로 나타낼수있음
	근데 보통 데이터셋에는 물체주변에 바운딩박스가 없어서,레이블이 없으니 직접 추가하거나 크라우드소싱맡겨야함
	
	바운딩박스가 있는 데이터셋이 있다고 하면
	바운딩박스라는건 물체 중심에서 수평,수직좌표와(xy값),높이,너비를 예측하면됨
	즉 숫자4개가 필요함(레이블이 있으니 뭐따로말안해줘도 알아서 레이블이랑 비슷하게 예측하니까)
	
	여기서 손실함수로 mse는 별로 여기랑 안어울리고 여기는 iou를 씀
	iou는 예측한 바운딩박스와 타깃바운딩박스사이의 중첩되는 영역을 전체영역으로 나눈것
	tf.keras.metrics.MeanIoU에 있음
	
7.객체탐지
	근데 만약 하나의이미지에서 여러객체가 들어있으면
	예전엔 격자로 나눠서 전부 훑는식으로 했는데 이러면 코스트가 너무비싸서(조금씩다른위치에서 동일한물체 여러번감지)
	요즘은 완전합성곱신경망을 씀
	1.완전합성곱신경망
		얘는 cnn맨위의 밀집층대신 그자리에 들어가는애임
	
		얘는 특성맵의 크기와 같은 수용장크기를 써서,한특성맵을 하나의 픽셀(하나의숫자)로 바꾸는식으로 작동함
		즉 특성맵크기 7x7인걸 100개출력하는 층위에 수용장크기가 7x7인 200개의 뉴런이있는층이 있으면
		1x1크기의 200개의 출력이 나옴(뉴런은 전단계 같은위치 뉴런 전부보는데,딱 크기같아서 한번보면끝이라,거기에 x200)
		
		이거의 장점은,밀집층은 특성마다 하나의 가중치가있어서,특정입력크기를 기대하지만,
		얘는 어떤이미지크기라도 처리할수있음(단 입력채널마다 가중치가 달라서 특정개수의 채널을 기대함)
		즉 합성곱층과 풀링층만 전체네트워크에 존재하니까,어떤크기이미지라도 훈련할수있음
		
	2.yolo
		얘는 
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	

