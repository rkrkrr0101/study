1.기초

머신러닝은 작업의 성능이 경험으로 인해 변하면 머신러닝 프로그램임

시스템이 학습할때 사용하는 샘플은 훈련세트
각 훈련데이터는 훈련샘플(샘플)

스팸메일분류기에서는
작업=스팸메일구분
경험=훈련데이터
성능=정확도(이건 자기가 원하는거로 직접 정해야하는데 분류에선 정확도 보통씀)

머신러닝을 통해 우리가 몰랐던 연관관계나 추세를 발견하는것은 데이터 마이닝

레이블의 종류에 따른 분류

	지도학습:훈련데이터에 레이블(정답인지 아닌지 표시)가 있는데이터로 학습하는방법

		대표적으로 분류가 전형적인 지도학습임(스팸메일분류같은)

		또 다른 예는 회귀가 있음
		회귀는 예측변수를 통해 타깃수치를 예측하는것
		예를들어 차 브랜드,주행거리등을 파라미터로 받아서 중고차값을 뱉는식
		
	비지도학습:비지도학습은 훈련데이터에 레이블이 없는상태에서 학습하는것
			대표적으로 군집,시각화등이 있음
			시각화는 레이블이 없는 데이터를 넣으면 눈으로 볼수있는 표현을 만들어줌
			예로 강아지 고양이 트럭등을 군집지어져있는걸 시각화시킨다던지 할수있음
			
	준지도학습:준지도학습은 일부만 레이블이 있는 데이터고 나머지는 레이블이 안된 데이터인상태에서 학습하는것
			예를들어서 사진여러개에서 사진들에 사람a,사람b가 사진 1,2에 있는지는 비지도학습으로 할수있지만,
			그사람이 누군지는 지도학습으로 해야하니까 
			사진에 사람abc태그하는건 비지도학습으로 하고 그 사람 이름같은거 적는건 지도학습으로 하는식
			
	강화학습:강화학습은 환경을 관찰해서 행동을 실행하고,거기따른 보상또는 벌점을 받아서 큰 보상을 따르게 행동방식을 수정하면서 반복하는것
		  게임ai나 보행로봇등에 주로 쓰임

실시간인지 아닌지에 따른 분류

	배치학습:시스템을 오프라인에서 학습 다 시킨다음에 그걸 적용하는식,온라인상에서 입력이들어와도 학습하지않고 출력만 함
		  배치학습이 새로운데이터를 학습하려면 전체데이터를 써서 처음부터 다시훈련해야함
		
	온라인학습:시스템을 하나씩,또는 일정 묶음단위로(미니배치) 주입해서 시스템을 계속 훈련시킴
		   이건 빠른 변화에 적응해야하는 시스템에 적합함
		   
		   온라인학습은 데이터를 학습하고나면 그 데이터는 필요없으니까(전으로 돌릴필요가없으면)삭제해도 됨
		   
		   그리고 메인메모리에 들어가지 않는 크기의 데이터셋을 학습할때도 이걸 사용할수있음
		   미니배치를 계속 넣는식으로 돌리면됨(외부메모리학습,배치학습인데 데이터클때 온라인학습방식으로 돌리는거)
		   
		   온라인학습에서 중요한 파라미터는 변화하는 데이터에 얼마나 빨리 적응할것인지를 나타내는 학습률
		   학습률을 높게하면 새로운 데이터에 빨리 적응하지만,이전 데이터를 금방 잊어버림
		   학습률을 낮게하면 새로운 데이터에 적응하는데는 오래걸리지만,새로운 데이터의 잡음같은거에 덜민감해짐
		   
		   온라인학습의 가장 큰 단점은 악의적데이터가 주입될때 시스템성능이 나빠질수 있다는것
		   그래서 시스템을 모니터링하거나 입력데이터를 모니터링해서 이런걸 걸러내야함

어떻게 일반화 되는가에 따른 분류
	사례 기반 학습:훈련샘플을 기억해서 유사도등을 측정해서 비교하는식으로 일반화 하는 방식
			  특성1과 특성2가 있는 그래프가 있을때,주변에 있는 값 중 가장 가깝거나 많은거로 분류하는식
	
	모델 기반 학습:샘플들의 모델을 만들어서 예측에 사용하는 방식
			  식을 만들어서  거기에 특성을 넣고 가공해서(절편을주거나,민감도를 조절하거나 해서) 대충 근처값이 나오게 하는식임
			  
			  모델이 얼마나 좋은지는 측정지표를 정해야 하는데
			  모델이 얼마나 좋은지 측정하는 효용함수나,모델이 얼마나 나쁜지 측정하는 비용함수가 있음
			  
			  선형회귀에서는 선형모델의 예측과 훈련데이터 사이의 거리를 재는 비용함수를 사용해서 
			  파라미터를 조절해 이 거리를 최소화하는게 목표임 이걸 모델을 훈련시킨다고 함
			  
즉, 머신러닝은
	데이터를 분석해서
	모델을 선택하고
	훈련데이터로 모델을 훈련시킴(비용함수가 제일 작아지는값을 찾음)
	마지막으로 새로운 데이터를 넣어서 예측을하고 잘되기를 기대함
	
머신러닝에서 문제가 되는 가장 큰 두가지는
	나쁜데이터:
		충분하지 않은량의 데이터
		
		대표성이 없는 훈련 데이터
			우리가 일반화 하기를 원하는 새로운 사례를 잘 대표하는 데이터를 넣어야함
			근데 샘플이 작으면 샘플링 잡음(우연에의한 대표성없는 데이터)
			샘플이 커도 추출방법이 잘못되면 샘플링 편향(무슨 이유등으로 한쪽에 몰린 데이터들만 추출된다거나)
			등으로 문제가 생길수있음
		
		낮은 품질의 데이터
			데이터가 에러,이상치,잡음등으로 가득하면 이상한패턴을 찾거나 패턴을 찾기 어려워하기때문에 
			데이터 정제에 시간을 투자해야함(일부샘플이 이상치인게 확실하면 지우거나,특성이 빠져있으면 샘플을 무시하거나 중간값채우거나)
			
		관련 없는 특성
			특성이 관련없는특성만 가득하거나 그러면 막 이상한값이 나올수도있음
			그래서 훈련에 사용할 좋은 특성들을 찾고,특성들을 합쳐서 더 유용한 특성을 만들어야함(특성추출)
			
	나쁜 알고리즘:
		데이터 과대적합
			훈련 데이터에 너무 잘 맞지만, 일반성이 떨어진다는 것
			세트에 잡음이 많거나 데이터셋이 너무 작을떄(샘플링잡음)잡음이 섞인 패턴을 감지하게되면(잡음의 양에 비해 모델이 너무복잡하면),
			당연히 새로운 샘플에 일반화가 안됨
			그래서 특성을 잘 골라야하고 훈련데이터의 잡음을 줄이고,훈련데이터 양을 늘려야함
			
			모델을 단순하게하고,과대적합의 위험을 감소시키기위해 모델에 제약을 가하는걸 규제 라고 함
			만약 a+bxn=c 라는 식에서 n이 특성이면,건드릴수있는건 a와 b인데 이 두개를 바꿀수 있는 자유도를 모델에 주면,(자유도2)
			모델은 직선의 절편과 기울기를 조절할수 있는데,우리가 여기서 a=0으로 고정시켜버리면 할수있는 자유도가 줄어드니까(자유도1)
			모델이 간단해지고 막 데이터에 끼워맞춘 식을 만들기 어려워지게됨
			딱 0 이렇게 안해도 수정은 할수있지만 값의 최소,최대값을 정해두면 자유도 1과 2사이 어딘가에 위치한 모델이 됨
			
			여기서 저렇게 딱 0이렇게 모델에서 변하지않고 상수로 주는걸 하이퍼파라미터라고 함
			이건 학습알고리즘에 영향을 받지않고,훈련전에 정해져있고,훈련하는동안 상수로 남아있음
			머신러닝에서 하이퍼파라미터 튜닝은 매우 중요한 과정임
			
		데이터 과소적합
			과대적합의 반대,모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할때 일어남
			이걸 해결하려면 모델파라미터를 늘리거나,더 좋은 특성을 제공하거나(특성추출등을 해서),모델의 제약을 줄여야함
		
	테스트와 검증
		
		모델이 얼마나 잘 일반화 될지 아는 방법은 가장 확실한건 실제서비스에 넣고 모니터링하는거지만,리스크가 크니까
		훈련데이터를 훈련세트와 테스트 세트로 나눠서
		훈련세트만 가지고 훈련을 한 다음에 테스트 세트를 일반화샘플처럼 사용해서 모델을 테스트함
		새로운 샘플에 대한 오류 비율을 일반화 오차라고 하는데,테스트세트로 평가해서 이 오차에 대한 추정값을 얻을수 있음
		훈련 오차가 낮지만(훈련세트에서 모델의 오차가 적지만)일반화 오차가 크다면 이건 과대적합됐다는것
		
		보통 데이터의 80퍼센트를 훈련에 쓰고,20퍼센트를 테스트용으로 떼어두는데,데이터크기에 따라 테스트데이터를 줄여도됨
		
		하지만 일반화오차를 테스트세트에서 여러번 측정하면,모델과 하이퍼파라미터가 테스트세트에 최적화된 모델을(과대적합된)만들기떄문에
		모델이 새로운 데이터에 잘 작동하지 않을수있음
		그래서 보통 홀드아웃 검증이라는 훈련세트의 일부를 떼어내서 여러 후보모델을 평가하고 가장 좋은 하나를 선택함
		이 홀드아웃세트를 검증세트라고 함
		
		구체적으로는 검증세트가 빠진 훈련세트로 다양한 하이퍼파라미터값을 가진 여러 모델을 훈련해서 프로토타입1을 만들고,
		검증세트에서 가장 높은 성능을 내는 모델을 선택해서 전체훈련세트에서 다시 훈련해 최종모델(프로토타입2)를 만들고,
		이걸 테스트세트에서 평가해서 일반화오차를 추정함
		
		이건 보통 잘 작동하는데,검증세트가 너무작으면 모델이 정확하게 평가가 안되고,검증세트가 너무 크면 훈련세트가 너무 작아지기떄문에
		최종모델은 전체훈련세트에서할건데 너무 작은데서 하면 적절하지 않음
		그래서 이걸 해결하는 방법은, 작은 검증 세트를 여러개 만들어서 사용해 반복적인 교차검증을 수행하는것
		모든 검증세트를 모든 모델에 돌린다음 값을 평균내서 고르면 훨씬 정확한 성능을 측정할수있지만,단점으로 훈련시간이 많이늘어남
		
		데이터 불일치
			만약 사진찍어서 뭔지 맞추는걸 하고싶은데 웹에서 긁어오면 엄청나게 정확한 데이터들만 있기때문에
			실제 데이터를 완벽하게 대표하지 못할수 있음
			이럴때 진짜 찍은 사진을 반반나눠서 검증세트와 테스트세트에 넣고(중복되거나 비슷한사진이 들어가면안됨)돌려야하는데
			보통 이러면 성능이 매우 나쁘게 나옴
			
			근데 이게 데이터불일치때문인지,과대적합인지 알기 어려운데 이걸 구분하는 방법은
			웹에서 긁은 데이터를 떼어내서(훈련데이터를 떼서)훈련개발세트를 만들고(훈련데이터에서 분리함)
			훈련세트에서 돌린다음 훈련개발세트에서 평가했는데 잘 작동하면 과대적합이 아니고 데이터불일치니까 데이터 전처리를 해야하고
			만약 성능이 나쁘면 과대적합이니까 규제하거나 데이터를 늘리거나 데이터정제를 해야함
			
			그래서 머신러닝은 학습용 데이터셋에서 종속변수와 독립변수의 관계를 분석해서 이거로 모델을 만드는거기떄문에
			철저하게 학습용 데이터셋에 종속됨
			
2.머신러닝 처음부터끝까지(회귀)
		
머신러닝의 순서는
	1.큰그림보기
	2.데이터 구하기
	3.데이터에서 뭘쓸지 알기위해 탐색하고 시각화하기
	4.데이터 전처리
	5.모델 선택,훈련
	6.모델 파라미터조정
	7.솔루션 제시
	8.런칭,유지보수
순서
1.큰그림보기
	
	무슨 데이터를 써서 무슨 값을 뽑을건지 알고,
	이걸 만드는 이유(이걸 최종값으로 쓸건지 다음모델에 인풋값으로 쓸건지 등) 
	이유를 알고 얼마나 정확하게 넣어야하는지 시간투자 얼마나해야하는지 등을 판단,
	현재 솔루션이 있는지,있다면 해결방법에 관한 정보랑 참고성능으로 사용할수있음
	데이터셋이 어떻게 구성된건지 
	등을 토대로 사용할 모델과 방식을 찾아야함
	
	다음으로 성능 측정 지표를 선택해야함
	회귀에서 주로 사용하는건 평균 제곱근 오차(RMSE)를 사용,만약 이상치로 보이는 구역이 많으면 평균 절대 오차(MAE)를 사용할수있음
	
	
	

	
			
			
	
			  
	  
	   











