. 머신러닝을 어떻게 정의할 수 있나요?
	학습경험으로 인해 성능이 바뀌는 프로그램
. 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지를 말해보세요.
	이미지분류 텍스트분류 자연어인식 스팸분류
. 레이블된 훈련 세트란 무엇인가요?
	정답인지 아닌지 값이 적힌 데이터
. 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요?
	회귀 분류 
. 보편적인 비지도 학습 작업 네 가지는 무엇인가요?
	군집 시각화 머시기머시기
. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?
	강화학습
. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?
	군집
. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?
	지도학습
. 온라인 학습 시스템이 무엇인가요?
	들어오는데이터를 처리하면서 학습하는것
. 외부 메모리 학습이 무엇인가요?
	배치학습인데 데이터가 너무 클때 온라인에서 미니배치처럼 데이터잘라서 학습하는것
. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?
	사례 기반 학습 시스템
. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나요?
	모델파라미터는 모델이 바꿀수있고 하이퍼파라미터는 바꿀수없음
. 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?-
	
	방정식을 만들어서 예측함수를 가장 적게하거나(비용)가장 크게하는(효용)값을 찾음
	예측은 모든 값과의 오차를 평균내서구함(x) 예측을 만들려면 학습 알고리즘이 찾은 파라미터를 사용하는 모델의 예측함수에 새로운 샘플의 특성을 주입
	
. 머신러닝의 주요 도전 과제는 무엇인가요? -
	부족한 데이터 낮은 데이터품질 대표성없는 데이터 무의미한 특성 등등 나쁜거 적으라는거였나봄
	
. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 가능한 해결책 세 가지는 무엇인가요?
	과대적합,훈련데이터에 너무 딱맞는 식을만듬,규제를하거나 데이터잡음을 줄이거나 특성갯수를 줄임
. 테스트 세트가 무엇이고 왜 사용해야 하나요?
	실제로 넣긴 너무 위험하니까 훈련세트를 잘라서 테스트용으로 만들어둔거
. 검증 세트의 목적은 무엇인가요? -
	검증세트는 무슨 모델을 쓸지 정하기위해서 사용
. 훈련-개발 세트가 무엇인가요? 언제 필요하고 어떻게 사용해야 하나요?
	데이터 불일치인지 과대적합인지 알아낼때 훈련세트를 조금잘라서 그거로 테스트하는거
. 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기나요?
	테스트세트까지 합쳐져서 과대적합된모델이 나올수있고,오차를 낙관적으로 측정할수있음 
	
	
	
4.모델훈련

1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?
	경사하강법
2. 훈련 세트에 있는 특성들이 각기 아주 다른 스케일을 가지고 있습니다. 이런 데이터에 잘 작동하지 않는 알고리즘은 무엇일까요? 그 이유는 무엇일까요? 이 문제를 어떻게 해결할 수 있을까요?
	경사하강법,스케일이 다르면 느려짐,simplescaler같은거써서 표준화
3. 경사 하강법으로 로지스틱 회귀 모델을 훈련시킬 때 지역 최솟값에 갇힐 가능성이 있을까요?
	선형회귀는 볼록함수라서 지역최소값이없음
4. 충분히 오랫동안 실행하면 모든 경사 하강법 알고리즘이 같은 모델을 만들어낼까요?
	미니배치나 랜덤은 수렴하지 않기떄문에 매우비슷하지만 약간다른모델이 나옴
5. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?
	X 이미 최소값을 지나서 상승하는중,조기종료를 한다 
	학습률이 너무 높아서 발산,훈련오차가 올라가지않으면 과대적합이니까 멈춰야함
6. 검증 오차가 상승하면 미니배치 경사 하강법을 즉시 중단하는 것이 좋은 방법인가요?
	X조기종료
	바로멈추면 지역최소값을 탈출하는중이었을수도 있음,그냥 한바퀴돌리고 제일작은거 픽하는게 제일좋음
7. (우리가 언급한 것 중에서) 어떤 경사 하강법 알고리즘이 가장 빠르게 최적 솔루션의 주변에 도달할까요? 실제로 수렴하는 것은 어떤 것인가요? 다른 방법들도 수렴하게 만들 수 있나요?
	확률적 경사하강법,배치경사하강법 학습률을 점차 줄여서 사실상 수렴하는식으로 할수있음
8. 다항 회귀를 사용했을 때 학습 곡선을 보니 훈련 오차와 검증 오차 사이에 간격이 큽니다. 무슨 일이 생긴 걸까요? 이 문제를 해결하는 세 가지 방법은 무엇인가요?
	과대적합,모델의 규제를 올리거나,데이터를 더 넣거나 모델을 좀 간단한거로바꿈
9. 릿지 회귀를 사용했을 때 훈련 오차와 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 α를 증가시켜야 할까요, 아니면 줄여야 할까요?
	높은 편향(과소적합),규제파라미터를 감소시켜야함
10. 다음과 같이 사용해야 하는 이유는?
	●평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀
		조금이라도 규제가 있는게 성능좋게나옴
	●릿지 회귀 대신 라쏘 회귀
		쓸데없는 특성이 많을때
	●라쏘 회귀 대신 엘라스틱넷
		특성 몇개가 강하게 연관되어있을때나,특성수가 훈련샘플보다 많을때
11. 사진을 낮과 밤, 실내와 실외로 분류하려 합니다. 두 개의 로지스틱 회귀 분류기를 만들어야 할까요, 아니면 하나의 소프트맥스 회귀 분류기를 만들어야 할까요?
	두개의 로지스틱회귀,소프트맥스는 다중클래스지 다중출력이 아님
12. 조기 종료를 사용한 배치 경사 하강법으로 소프트맥스 회귀를 구현해보세요(사이킷런은 사용하지 마세요).

5.서포트벡터머신

1. 서포트 벡터 머신의 근본 아이디어는 무엇인가요?
	선을 그어두고 그선기준으로 분류를 하겠다,가장 넓은 선을 찾겠다(가장넓은도로),커널트릭으로 사기를치겠다
2. 서포트 벡터가 무엇인가요?
	구분하는 선,선의 위치는 하드일때 기준으로 군집에서 가장 멀리있는 샘플의 위치,클래스가 2개일경우 그 두샘플의 사이가 서포트벡터임
3. SVM을 사용할 때 입력값의 스케일이 왜 중요한가요?
	스케일이 다르면 서포트벡터의 크기가 작아짐(스케일이 작은걸 적게반영(무시)하는 경향이커짐)
4. SVM 분류기가 샘플을 분류할 때 신뢰도 점수와 확률을 출력할 수 있나요?
	x없음,선넘으면 저쪽이고 아니면 이쪽이고 0과 100임
	할수는있음 도로와의 거리로 신뢰도점수를 줄순있음
5. 수백만 개의 샘플과 수백 개의 특성을 가진 훈련 세트에 SVM 모델을 훈련시키려면 원 문제와 쌍대 문제 중 어떤 것을 사용해야 하나요?
		원문제, 훈련샘플수가 특성보다 작을땐 쌍대문제가 더 빠르고,커널트릭을 적용할수잇음 
6. RBF 커널을 사용해 SVM 분류기를 훈련시켰더니 훈련 세트에 과소적합된 것 같습니다. γ(gamma)를 증가시켜야 할까요, 감소시켜야 할까요? C의 경우는 어떤가요?
	감마는 증가시키면 종모양 그래프가 좁아져서 샘플의 영향범위가 좁아짐
	과소적합이면 증가시키고,과대적합이면 감소시켜야함
7. 이미 만들어진 QP 알고리즘 라이브러리를 사용해 소프트 마진 선형 SVM 분류기를 학습시키려면 QP 매개변수(H, f, A, b)를 어떻게 지정해야 하나요?
	모름
	몰라도될거같음
8. 선형적으로 분리되는 데이터셋에 LinearSVC를 훈련시켜보세요. 그런 다음 같은 데이터셋에 SVC와 SGDClassifier를 적용해보세요. 거의 비슷한 모델이 만들어지는지 확인해보세요.
9. MNIST 데이터셋에 SVM 분류기를 훈련시켜보세요. SVM 분류기는 이진 분류기라서 OvR전략을 사용해 10개의 숫자를 분류해야 합니다. 처리 속도를 높이기 위해 작은 검증 세트로 하이퍼파라미터를 조정하는 것이 좋습니다. 어느 정도까지 정확도를 높일 수 있나요?
10. 캘리포니아 주택 가격 데이터셋에 SVM 회귀를 훈련시켜보세요

6.결정트리
1. 백만 개의 샘플을 가진 훈련 세트에서 (규제 없이) 훈련시킨 결정 트리의 깊이는 대략 얼마일까요?
	20
2. 한 노드의 지니 불순도가 보통 그 부모 노드보다 작을까요, 아니면 클까요? 일반적으로 작거나 클까요, 아니면 항상 작거나 클까요?
	일반적으로는 작음,근데 다른노드가 막 순수노드되고 이렇게 감소치가 크면 오를수도 있긴함
3. 결정 트리가 훈련 세트에 과대적합되었다면 max_depth를 줄이는 것이 좋을까요?
	깊이를 줄이면 규제
4. 결정 트리가 훈련 세트에 과소적합되었다면 입력 특성의 스케일을 조정하는 것이 좋을까요?
	결정트리는 스케일에 영향을받지않음
5. 백만 개의 샘플을 가진 훈련 세트에 결정 트리를 훈련시키는 데 한 시간이 걸렸다면, 천만 개의 샘플을 가진 훈련 세트에 결정 트리를 훈련시키는 데는 대략 얼마나 걸릴까요?
	10시간 (O(n mlog m))
	11.7시간이래
6. 십만 개의 샘플을 가진 훈련 세트가 있다면 presort=True로 지정하는 것이 훈련 속도를 높일까요?
	 x미리 소트를해두면 속도가올라감
	 수천개미만일때 속도부스팅하려고 하는것,막 만개넘어가면 느려짐
	 
7.랜덤포레스트와 앙상블
1. 정확히 같은 훈련 데이터로 다섯 개의 다른 모델을 훈련시켜서 모두 95% 정확도를 얻었다면 이 모델들을 연결하여 더 좋은 결과를 얻을 수 있을까요? 가능하다면 어떻게 해야 할까요? 그렇지 않다면 왜일까요?
	같은데이터로 다른모델이면 앙상블로 정확도가 올라갈수있음
	직접투표하거나 간접투표
2. 직접 투표와 간접 투표 분류기 사이의 차이점은 무엇일까요?
	직접투표는 분류기하나가 1,0밖에 못주고 그거합산해서 제일많은거 픽하고 간접투표는 그 확률을줘서 확률을더함,간접투표가 더성능은좋음

3. 배깅 앙상블의 훈련을 여러 대의 서버에 분산시켜 속도를 높일 수 있을까요? 페이스팅 앙상블, 부스팅 앙상블, 랜덤 포레스트, 스태킹 앙상블의 경우는 어떨까요?
	기본적으로 앙상블은 병렬처리에 효과적임,단 부스팅은 전데이터에 종속적이기때문에 할수없음
4. oob 평가의 장점은 무엇인가요?
	교차검증한다고 따로 뗄필요도없고 그냥 가져다쓰면됨 편함
5. 무엇이 엑스트라 트리를 일반 랜덤 포레스트보다 더 무작위하게 만드나요? 추가적인 무작위성이 어떻게 도움이 될까요? 엑스트라 트리는 일반 랜덤 포레스트보다 느릴까요, 빠를까요?
	엑스트라트리는 편향을올리고 분산을깍음,즉 과대적합을 깎고 과소적합을 올림,임계값을 찾을필요가없으니까 훨씬빠름,예측시는 똑같음
6. 에이다부스트 앙상블이 훈련 데이터에 과소적합되었다면 어떤 매개변수를 어떻게 바꾸어야 할까요?
	학습률을 좀 올림,예측기수를 올리거나 예측기의 규제를 좀 줄여볼수도있음
7. 그레이디언트 부스팅 앙상블이 훈련 데이터에 과대적합되었다면 학습률을 높여야 할까요, 낮춰야 할까요?
	과대적합시에는 학습률을 낮춰야함