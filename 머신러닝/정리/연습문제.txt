. 머신러닝을 어떻게 정의할 수 있나요?
	학습경험으로 인해 성능이 바뀌는 프로그램
. 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지를 말해보세요.
	이미지분류 텍스트분류 자연어인식 스팸분류
. 레이블된 훈련 세트란 무엇인가요?
	정답인지 아닌지 값이 적힌 데이터
. 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요?
	회귀 분류 
. 보편적인 비지도 학습 작업 네 가지는 무엇인가요?
	군집 시각화 머시기머시기
. 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요?
	강화학습
. 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요?
	군집
. 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요?
	지도학습
. 온라인 학습 시스템이 무엇인가요?
	들어오는데이터를 처리하면서 학습하는것
. 외부 메모리 학습이 무엇인가요?
	배치학습인데 데이터가 너무 클때 온라인에서 미니배치처럼 데이터잘라서 학습하는것
. 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요?
	사례 기반 학습 시스템
. 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나요?
	모델파라미터는 모델이 바꿀수있고 하이퍼파라미터는 바꿀수없음
. 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요?-
	
	방정식을 만들어서 예측함수를 가장 적게하거나(비용)가장 크게하는(효용)값을 찾음
	예측은 모든 값과의 오차를 평균내서구함(x) 예측을 만들려면 학습 알고리즘이 찾은 파라미터를 사용하는 모델의 예측함수에 새로운 샘플의 특성을 주입
	
. 머신러닝의 주요 도전 과제는 무엇인가요? -
	부족한 데이터 낮은 데이터품질 대표성없는 데이터 무의미한 특성 등등 나쁜거 적으라는거였나봄
	
. 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 가능한 해결책 세 가지는 무엇인가요?
	과대적합,훈련데이터에 너무 딱맞는 식을만듬,규제를하거나 데이터잡음을 줄이거나 특성갯수를 줄임
. 테스트 세트가 무엇이고 왜 사용해야 하나요?
	실제로 넣긴 너무 위험하니까 훈련세트를 잘라서 테스트용으로 만들어둔거
. 검증 세트의 목적은 무엇인가요? -
	검증세트는 무슨 모델을 쓸지 정하기위해서 사용
. 훈련-개발 세트가 무엇인가요? 언제 필요하고 어떻게 사용해야 하나요?
	데이터 불일치인지 과대적합인지 알아낼때 훈련세트를 조금잘라서 그거로 테스트하는거
. 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기나요?
	테스트세트까지 합쳐져서 과대적합된모델이 나올수있고,오차를 낙관적으로 측정할수있음 
	
	
	
4.모델훈련

1. 수백만 개의 특성을 가진 훈련 세트에서는 어떤 선형 회귀 알고리즘을 사용할 수 있을까요?
	경사하강법
2. 훈련 세트에 있는 특성들이 각기 아주 다른 스케일을 가지고 있습니다. 이런 데이터에 잘 작동하지 않는 알고리즘은 무엇일까요? 그 이유는 무엇일까요? 이 문제를 어떻게 해결할 수 있을까요?
	경사하강법,스케일이 다르면 느려짐,simplescaler같은거써서 표준화
3. 경사 하강법으로 로지스틱 회귀 모델을 훈련시킬 때 지역 최솟값에 갇힐 가능성이 있을까요?
	선형회귀는 볼록함수라서 지역최소값이없음
4. 충분히 오랫동안 실행하면 모든 경사 하강법 알고리즘이 같은 모델을 만들어낼까요?
	미니배치나 랜덤은 수렴하지 않기떄문에 매우비슷하지만 약간다른모델이 나옴
5. 배치 경사 하강법을 사용하고 에포크마다 검증 오차를 그래프로 나타내봤습니다. 검증 오차가 일정하게 상승되고 있다면 어떤 일이 일어나고 있는 걸까요? 이 문제를 어떻게 해결할 수 있나요?
	X 이미 최소값을 지나서 상승하는중,조기종료를 한다 
	학습률이 너무 높아서 발산,훈련오차가 올라가지않으면 과대적합이니까 멈춰야함
6. 검증 오차가 상승하면 미니배치 경사 하강법을 즉시 중단하는 것이 좋은 방법인가요?
	X조기종료
	바로멈추면 지역최소값을 탈출하는중이었을수도 있음,그냥 한바퀴돌리고 제일작은거 픽하는게 제일좋음
7. (우리가 언급한 것 중에서) 어떤 경사 하강법 알고리즘이 가장 빠르게 최적 솔루션의 주변에 도달할까요? 실제로 수렴하는 것은 어떤 것인가요? 다른 방법들도 수렴하게 만들 수 있나요?
	확률적 경사하강법,배치경사하강법 학습률을 점차 줄여서 사실상 수렴하는식으로 할수있음
8. 다항 회귀를 사용했을 때 학습 곡선을 보니 훈련 오차와 검증 오차 사이에 간격이 큽니다. 무슨 일이 생긴 걸까요? 이 문제를 해결하는 세 가지 방법은 무엇인가요?
	과대적합,모델의 규제를 올리거나,데이터를 더 넣거나 모델을 좀 간단한거로바꿈
9. 릿지 회귀를 사용했을 때 훈련 오차와 검증 오차가 거의 비슷하고 둘 다 높았습니다. 이 모델에는 높은 편향이 문제인가요, 아니면 높은 분산이 문제인가요? 규제 하이퍼파라미터 α를 증가시켜야 할까요, 아니면 줄여야 할까요?
	높은 편향(과소적합),규제파라미터를 감소시켜야함
10. 다음과 같이 사용해야 하는 이유는?
	●평범한 선형 회귀(즉, 아무런 규제가 없는 모델) 대신 릿지 회귀
		조금이라도 규제가 있는게 성능좋게나옴
	●릿지 회귀 대신 라쏘 회귀
		쓸데없는 특성이 많을때
	●라쏘 회귀 대신 엘라스틱넷
		특성 몇개가 강하게 연관되어있을때나,특성수가 훈련샘플보다 많을때
11. 사진을 낮과 밤, 실내와 실외로 분류하려 합니다. 두 개의 로지스틱 회귀 분류기를 만들어야 할까요, 아니면 하나의 소프트맥스 회귀 분류기를 만들어야 할까요?
	두개의 로지스틱회귀,소프트맥스는 다중클래스지 다중출력이 아님
12. 조기 종료를 사용한 배치 경사 하강법으로 소프트맥스 회귀를 구현해보세요(사이킷런은 사용하지 마세요).