1.AI로 개발 생산성 높이기
  1.코파일럿 열일하게 만들기
    스킵
  2.챗GPT를 활용한 Git Flow 관리 자동화
    스킵

2.AI로 더 편리한 서비스 만들기
  1.리뷰를 재료로 GPT가 만든 메뉴 추천, 메뉴뚝딱AI
    리뷰같은걸 사용해서 gpt한테 가공시킬떈 개인정보와 지적재산권문제를 신경써야함
	즉 전처리를 거쳐야함

  2.프롬프트 엔지니어링으로 메뉴 이미지 품질 검수하기
    이미지검수에 gpt를 사용하면,머신러닝구축에서의 어려움이나 정책대응의 어려움에 유연하게 대처할수있음
	이때 프롬프트는 단순한 단어나 명령어가 아닌,사람과 llm이 만나는 핵심 매개체임
	
	이때 신경써야할건
	  1.구체성과 일반성의 균형
	    구체적인 프롬프트 작성:해당 요청을 상황과 형식을 명확히 제시해야 고품질 응답을 제공함
	    프롬프트 일반화:기본적으로는 구체적인 프롬프트를 적되,너무 구체적일경우 예외케이스를 놓칠수있음
	      즉 다른 목표에 대한 성능이 저하되는 트레이드오프가 발생할수있음
	    프롬프트 성능 평가:스프레드시트같은거로 프롬프트의 변경마다 각 정책별로 오검수항목의 비중을 확인할수있게 만들어야함
	  2.응답 최적화
	    구조화된 응답 유도:응답을 JSON같은 형식으로 포맷팅하게 예시를 주고 프롬프트를 작성하게 해야함,이래야 파싱이 쉬움
		GKP(Generated Knowledge Prompting):예시대로 주지않는걸 개선할땐 gpt가 이미지를 설명하게하고,
		  그설명을 바탕으로 최종응답을 도출하게하면 좀 더 일관성이 높아짐
		latency 최적화:프롬프트의 내용을 줄이고 응답사유를 한문장으로만 반환하게해서 응답지연을 줄임
	  3.프롬프트 구조와 형식 개선
	    이미지와 텍스트의 순서 조정:이미지와 텍스트를 함께 사용할땐 이미지를 텍스트보다 먼저 배치하는게 좋음
		마크다운과 코드스타일 활용:마크다운을 쓰며 강조를 위해 #를 사용하고,여러개는 리스트형태로 나열하면 더 알아듣기쉬워함
	이런것들이 있음
	
	gpt의 한계는,과도한 확대같은 영역에서는 기준치이상으로 못올라올수도 있고 이런건 사람이 체크해야함
	또한 llm의 특성상 정보컷이 존재해서,저작권/상표권/초상권등의 로고 저작권문제가 없는지 검수하는건 사람이 해야함
	이런건 사람이 검수하게 특정 응답코드를 줘서 이런것들만 사람이 검수하게하면 인력소모를 줄일수있음
	또한 상세한 반려사유를 받을수있으니,이걸 제공하기도 좋음
	
	gpt는 강력한 범용성을 가졌지만,업무상황별로 요구하는 조건은 제각각임
	이걸 잘 하이브리드로 접근해야 좋은 결과물을 만들수있음

  3.배민선물하기 AI 메시지 제작기
    gpt에 뭘 시킬땐 일단 제일 먼저 역할부여를 정확하게 해야하고,그다음으로 어떤식으로 만들건지 예시 컨텍스트를 주는 원샷러닝이나 퓨샷러닝을 해야함
	이떄 데이터의 품질이 중요
	또한 헛소리를 하거나 하면안될말을 할수있기때문에 가드레일지침도 프롬프트에 넣어야함

  4.실시간 반응형 추천 개발 일지 1부
    기본적으로 추천은 투타워모델을 사용할수있음
	투타워모델은 사용자와 아이템의 임베딩을 각각 구하고,두 임베딩간의 유사도로 조회하는식의 모델임
	즉
	  사용자의 주문이력을 학습데이터로 사용자임베딩을 학습
	  사용자정보와 추천후보가게목록을 모델에 입력하면,사용자와 각 가계간 유사도스코어를 응답,이 스코어바탕 정렬
	  하루한번 오프라인배치로 사용자별 추천가게목록 추출후 저장
	  저장된 데이터를 조회
	이런식임
	
	이방식은 전반적으로 취향을 맞출순있지만,현재 사용자의 입력을 기반으로 추천을 할순없음
	그래서 실시간 행동이력을 기반으로 이걸 스트리밍해서 추천에 적용하는 방식을 사용할수있음
	즉
	  행동이력을 스트리밍해서 업로드
	  임베딩모델은 원래대로 학습(유사한 가게와 검색어가 근처 벡터공간에 위치하게)
	  행동이력과 저장된 추천가게목록의 벡터유사도를 구해서 유사도대로 정렬
	이런식으로 구성할수있음
	이때 HNSW나 ANN(근사 최근접이웃)같은걸 쓰지않고 Exact search를 사용하는 이유는,사용자 주변의 n개의 가게에 대해서만 벡터유사도검색을 해야하기때문
	
	또한 각 부분을 컴포넌트로 확실히 분리해두면,이걸 다른곳에서도 사용하기 쉬워짐
	즉 입력출력스펙을 명확히 정의하고 진행하는게 좋음

  5.실시간 반응형 추천 개발 일지 2부:벡터 검색, 그리고 숨겨진 요구사항과 기술 도입 의사 결정을 다루는 방법
    프로젝트의 요구사항에 드러나지 않은,즉 암시적으로 표현된것에 대해서도 명확히 잡고 넘어가야함
	또한 당연히 이럴것이라고 생각하는것들도 명시적으로 요구사항으로 잡아야함
	이렇게 컴포넌트를 정의하고 개발을 시작하면됨
	
	컴포넌트를 개발할땐 병렬식으로 진행할테니,입출력을 명확히잡고 진행하면됨
	그러면 현재 관심사에만 집중할수있음
	
	벡터유사도검색의 필터링 방식은 post filter과 pre filter이 있음
	post는 검색 이후에 필터링을 하는 방식으로,장점은 검색은 그대로 써도되지만 단점은 검색결과가 하나도 안나올수있다는것(검색후에 필터링하니)
	pre는 검색이전에 필터링을 하고,그안에서 검색을 하는식임,장점은 검색결과 갯수가 보장되지만,단점은 인덱스를 쓸수없다는것
	검색전에 인덱스를 만들어놔야하는데 풀이 바뀌니 인덱스를 사용할수없음(특히 ANN,HNSW등의 알고리즘은 이런식으로 최적화를 함)
	보통 확률기반 스킵리스트를 사용하는애들이 이럼
	
	기술후보군을 골랐으면,이제 검증을 위해 간단히 실험을 진행해보고,그담에 성능평가를 진행해야함
	검증실험은 실제로 어떻게 동작시키는가와 플랫폼구축을 어떻게 할수있는가에 집중해야함
	즉
	  설치
	  데이터인덱싱
	  검색(순수벡터검색,하이브리드 조건 검색)
	  결과예제
	  기타사항
	이런식으로 실험/정리하면됨
	이떈 운영가능성과 검색방식과 구현가능성만 보기때문에 간단히 테스트하는게 좋음
	
	이렇게 2차실험을 할 후보군을 좁히고,2차실험은 실제 워크로드에서 부하를 주고 성능을 검증하는데 목적이 있음
	이땐 실제 사용환경에 최대한 가깝게한다음에 부하테스트를 해야함
	또한 실제 동작이 가설과 맞는지도 실험으로 확인해야함
	
	부하테스트는 부하를 넣으면서 초당처리량,응답시간,대상시스템의 부하정도가 어떻게 바뀌는지를 확인해야함
	
	간단한 성능최적화팁으로는
	각각의 임베딩을 쿼리벡터로 후보군과의 벡터검색을 n번할때,
	벡터검색에서 rds에 쿼리를 여러번 보내는거보단 한번만 보내는게 더 이득이니까,
	유니온으로 여러쿼리를 묶어서 한번에 실행하고 결과를 파싱해 그룹바이하는식으로 최적화할수있음
	
	즉
	  프로젝트의 요구사항이 무엇인가
	  숨겨진요구사항에서 기술적인 문제로 환원할 사항은?
	  어떻게 도입컴포넌트 후보를 선정하고 평가하고 결정할까?
	가 이 글의 핵심임

  6.AI 데이터 분석가 ‘물어보새’ 등장 1부 : RAG와 Text-To-SQL 활용
    텍스트를 쿼리로 바꿔주는 모델에선 사내정보를 저장하고 활용하는 rag가 꼭 필요함
	gpt4만 가지고도 쿼리문을 생성할순있지만 품질이 떨어짐
	도메인지식과 데이터정책에 대한 이해가 부족하고,기본적인 retriever의 성능이 떨어지고 환각이 있기때문
	그래서 도메인지식을 박아넣고 그걸 바탕으로 답변을 생성해야함
	이때
	  데이터 보강
	  검색알고리즘 개발
	  프롬프트 엔지니어링
	  실험 및 평가 시스템 구축
	이렇게 4개가 가장 중요함
	
	데이터 보강을 할땐,질문을 llm으로 구체화한다음에(1차질문),여기서 현재 테이블에서 필요한 정보(ddl)를 추출하고 퓨샷러닝용 예제를 뽑아낸다음,
	이 데이터들을 활용해서 실제 답변을 생성하는식(react)으로 가는 방식이 좋음,즉 이부분이 rag를 사용할 자리임
	또한 사내에서만 이해할수있는 비즈니스용어 표준화 사전을 만드는것도 필수적임

  7.AI 데이터 분석가 ‘물어보새’ 등장 2부 : 데이터 디스커버리
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	