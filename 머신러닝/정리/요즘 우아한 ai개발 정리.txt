1.AI로 개발 생산성 높이기
  1.코파일럿 열일하게 만들기
    스킵
  2.챗GPT를 활용한 Git Flow 관리 자동화
    스킵

2.AI로 더 편리한 서비스 만들기
  1.리뷰를 재료로 GPT가 만든 메뉴 추천, 메뉴뚝딱AI
    리뷰같은걸 사용해서 gpt한테 가공시킬떈 개인정보와 지적재산권문제를 신경써야함
	즉 전처리를 거쳐야함

  2.프롬프트 엔지니어링으로 메뉴 이미지 품질 검수하기
    이미지검수에 gpt를 사용하면,머신러닝구축에서의 어려움이나 정책대응의 어려움에 유연하게 대처할수있음
	이때 프롬프트는 단순한 단어나 명령어가 아닌,사람과 llm이 만나는 핵심 매개체임
	
	이때 신경써야할건
	  1.구체성과 일반성의 균형
	    구체적인 프롬프트 작성:해당 요청을 상황과 형식을 명확히 제시해야 고품질 응답을 제공함
	    프롬프트 일반화:기본적으로는 구체적인 프롬프트를 적되,너무 구체적일경우 예외케이스를 놓칠수있음
	      즉 다른 목표에 대한 성능이 저하되는 트레이드오프가 발생할수있음
	    프롬프트 성능 평가:스프레드시트같은거로 프롬프트의 변경마다 각 정책별로 오검수항목의 비중을 확인할수있게 만들어야함
	  2.응답 최적화
	    구조화된 응답 유도:응답을 JSON같은 형식으로 포맷팅하게 예시를 주고 프롬프트를 작성하게 해야함,이래야 파싱이 쉬움
		GKP(Generated Knowledge Prompting):예시대로 주지않는걸 개선할땐 gpt가 이미지를 설명하게하고,
		  그설명을 바탕으로 최종응답을 도출하게하면 좀 더 일관성이 높아짐
		latency 최적화:프롬프트의 내용을 줄이고 응답사유를 한문장으로만 반환하게해서 응답지연을 줄임
	  3.프롬프트 구조와 형식 개선
	    이미지와 텍스트의 순서 조정:이미지와 텍스트를 함께 사용할땐 이미지를 텍스트보다 먼저 배치하는게 좋음
		마크다운과 코드스타일 활용:마크다운을 쓰며 강조를 위해 #를 사용하고,여러개는 리스트형태로 나열하면 더 알아듣기쉬워함
	이런것들이 있음
	
	gpt의 한계는,과도한 확대같은 영역에서는 기준치이상으로 못올라올수도 있고 이런건 사람이 체크해야함
	또한 llm의 특성상 정보컷이 존재해서,저작권/상표권/초상권등의 로고 저작권문제가 없는지 검수하는건 사람이 해야함
	이런건 사람이 검수하게 특정 응답코드를 줘서 이런것들만 사람이 검수하게하면 인력소모를 줄일수있음
	또한 상세한 반려사유를 받을수있으니,이걸 제공하기도 좋음
	
	gpt는 강력한 범용성을 가졌지만,업무상황별로 요구하는 조건은 제각각임
	이걸 잘 하이브리드로 접근해야 좋은 결과물을 만들수있음

  3.배민선물하기 AI 메시지 제작기
    gpt에 뭘 시킬땐 일단 제일 먼저 역할부여를 정확하게 해야하고,그다음으로 어떤식으로 만들건지 예시 컨텍스트를 주는 원샷러닝이나 퓨샷러닝을 해야함
	이떄 데이터의 품질이 중요
	또한 헛소리를 하거나 하면안될말을 할수있기때문에 가드레일지침도 프롬프트에 넣어야함

  4.실시간 반응형 추천 개발 일지 1부
    기본적으로 추천은 투타워모델을 사용할수있음
	투타워모델은 사용자와 아이템의 임베딩을 각각 구하고,두 임베딩간의 유사도로 조회하는식의 모델임
	즉
	  사용자의 주문이력을 학습데이터로 사용자임베딩을 학습
	  사용자정보와 추천후보가게목록을 모델에 입력하면,사용자와 각 가계간 유사도스코어를 응답,이 스코어바탕 정렬
	  하루한번 오프라인배치로 사용자별 추천가게목록 추출후 저장
	  저장된 데이터를 조회
	이런식임
	
	이방식은 전반적으로 취향을 맞출순있지만,현재 사용자의 입력을 기반으로 추천을 할순없음
	그래서 실시간 행동이력을 기반으로 이걸 스트리밍해서 추천에 적용하는 방식을 사용할수있음
	즉
	  행동이력을 스트리밍해서 업로드
	  임베딩모델은 원래대로 학습(유사한 가게와 검색어가 근처 벡터공간에 위치하게)
	  행동이력과 저장된 추천가게목록의 벡터유사도를 구해서 유사도대로 정렬
	이런식으로 구성할수있음
	이때 HNSW나 ANN(근사 최근접이웃)같은걸 쓰지않고 Exact search를 사용하는 이유는,사용자 주변의 n개의 가게에 대해서만 벡터유사도검색을 해야하기때문
	
	또한 각 부분을 컴포넌트로 확실히 분리해두면,이걸 다른곳에서도 사용하기 쉬워짐
	즉 입력출력스펙을 명확히 정의하고 진행하는게 좋음

  5.실시간 반응형 추천 개발 일지 2부:벡터 검색, 그리고 숨겨진 요구사항과 기술 도입 의사 결정을 다루는 방법
    프로젝트의 요구사항에 드러나지 않은,즉 암시적으로 표현된것에 대해서도 명확히 잡고 넘어가야함
	또한 당연히 이럴것이라고 생각하는것들도 명시적으로 요구사항으로 잡아야함
	이렇게 컴포넌트를 정의하고 개발을 시작하면됨
	
	컴포넌트를 개발할땐 병렬식으로 진행할테니,입출력을 명확히잡고 진행하면됨
	그러면 현재 관심사에만 집중할수있음
	
	벡터유사도검색의 필터링 방식은 post filter과 pre filter이 있음
	post는 검색 이후에 필터링을 하는 방식으로,장점은 검색은 그대로 써도되지만 단점은 검색결과가 하나도 안나올수있다는것(검색후에 필터링하니)
	pre는 검색이전에 필터링을 하고,그안에서 검색을 하는식임,장점은 검색결과 갯수가 보장되지만,단점은 인덱스를 쓸수없다는것
	검색전에 인덱스를 만들어놔야하는데 풀이 바뀌니 인덱스를 사용할수없음(특히 ANN,HNSW등의 알고리즘은 이런식으로 최적화를 함)
	보통 확률기반 스킵리스트를 사용하는애들이 이럼
	
	기술후보군을 골랐으면,이제 검증을 위해 간단히 실험을 진행해보고,그담에 성능평가를 진행해야함
	검증실험은 실제로 어떻게 동작시키는가와 플랫폼구축을 어떻게 할수있는가에 집중해야함
	즉
	  설치
	  데이터인덱싱
	  검색(순수벡터검색,하이브리드 조건 검색)
	  결과예제
	  기타사항
	이런식으로 실험/정리하면됨
	이떈 운영가능성과 검색방식과 구현가능성만 보기때문에 간단히 테스트하는게 좋음
	
	이렇게 2차실험을 할 후보군을 좁히고,2차실험은 실제 워크로드에서 부하를 주고 성능을 검증하는데 목적이 있음
	이땐 실제 사용환경에 최대한 가깝게한다음에 부하테스트를 해야함
	또한 실제 동작이 가설과 맞는지도 실험으로 확인해야함
	
	부하테스트는 부하를 넣으면서 초당처리량,응답시간,대상시스템의 부하정도가 어떻게 바뀌는지를 확인해야함
	
	간단한 성능최적화팁으로는
	각각의 임베딩을 쿼리벡터로 후보군과의 벡터검색을 n번할때,
	벡터검색에서 rds에 쿼리를 여러번 보내는거보단 한번만 보내는게 더 이득이니까,
	유니온으로 여러쿼리를 묶어서 한번에 실행하고 결과를 파싱해 그룹바이하는식으로 최적화할수있음
	
	즉
	  프로젝트의 요구사항이 무엇인가
	  숨겨진요구사항에서 기술적인 문제로 환원할 사항은?
	  어떻게 도입컴포넌트 후보를 선정하고 평가하고 결정할까?
	가 이 글의 핵심임

  6.AI 데이터 분석가 ‘물어보새’ 등장 1부 : RAG와 Text-To-SQL 활용
    텍스트를 쿼리로 바꿔주는 모델에선 사내정보를 저장하고 활용하는 rag가 꼭 필요함
	gpt4만 가지고도 쿼리문을 생성할순있지만 품질이 떨어짐
	도메인지식과 데이터정책에 대한 이해가 부족하고,기본적인 retriever의 성능이 떨어지고 환각이 있기때문
	그래서 도메인지식을 박아넣고 그걸 바탕으로 답변을 생성해야함
	이때
	  데이터 보강
	  검색알고리즘 개발
	  프롬프트 엔지니어링
	  실험 및 평가 시스템 구축
	이렇게 4개가 가장 중요함
	
	데이터 보강을 할땐,질문을 llm으로 구체화한다음에(1차질문),여기서 현재 테이블에서 필요한 정보(ddl)를 추출하고 퓨샷러닝용 예제를 뽑아낸다음,
	이 데이터들을 활용해서 실제 답변을 생성하는식(react)으로 가는 방식이 좋음,즉 이부분이 rag를 사용할 자리임
	또한 사내에서만 이해할수있는 비즈니스용어 표준화 사전을 만드는것도 필수적임

  7.AI 데이터 분석가 ‘물어보새’ 등장 2부 : 데이터 디스커버리
    데이터 디스커버리는 쿼리문생성답변뿐 아니라 쿼리문과 테이블 해설,로그데이터활용안내 답변등 다양한 정보획득기능으로 구성됨
	즉 질문이 어떤 유형인지 분류하고,그걸기반으로 프롬프트를 박아서 좀 더 정확한 답변을 내는것(즉 최소 2번 요청을 날림)
	또한 사용자의 질문역량에 상관없이 질문의 완성도를 높여서 답변품질을 높여야함
	이런방식을 Router Supervisor(Agent Supervisor)라고 부름
	
	이건 전달받은 질문이 데이터와 얼마나 연관되어있는지,문제해결을 위한 구체적 단서를 얼마나 포함하고있는지를 평가하는 단계가 필요함
	그래서 여기서 평가항목당 일정점수이하면 추가적인 정보를 요청할수있음
	이때 질문이해같은 영역은 single-Turn,즉 대화문맥을 유지하지않고 속도를 올리는 방식으로 사용하고,실제 질답으로 들어가면 Multi-Turn을 사용함
	
	쿼리문 해설답변구현은,먼저 사용자의 질문에 포함된 테이블명을 추출하고,ddl벡터스토어에서 해당테이블 정보를 가져온후 ddl을 축소하고(칼럼수가 매우많은 테이블때문)
	이 ddl을 프롬프트에 넣어서 답변을 만드는식으로 구현함
	이거말고도 다양한 기능이 있음,필요해지면보자

  8.폴라스로 데이터 처리를 더 빠르고 가볍게 with 실무 적용기
    폴라스는 Pandas랑 비슷한데 이것보다 메모리효율적인 라이브러리임
	즉 성능이 뛰어난 DataFrame라이브러리라고 볼수있음
	
	얜 기본적으로 성능도 뛰어나고,LazyFrame라는 지연연산도 있어서 최적화도 잘함,또한 스트리밍기능도 있음
	또한 구조도 sql과 비슷하고,칼럼선택도 편함

  9.빠르고 안정적인 AI 서빙 시스템 구성하기
    서빙이란 학습된 모델을 실제 운영환경에 배포하여 사용자가 실시간 요청할수있게 api형태로 제공하는 과정임
	모델은 다양한 프레임워크/라이브러리로 나오게됨
	이러면 모델을 불러오고 추론하는방식이 달라 코드일관성유지와 유지보수에 악영향을 줌
	이부분을 추상화해주는 BentoML(걍 서버라이브러리라고 봐도됨)같은걸 사용해서 모델서빙환경을 구성하면 좋음
	이건 컨테이너화를 쉽게 지원하고,전후처리같은걸 간편하게 추가할수있음
	
	이걸 git 레포지토리에 넣어서 cicd하는건데,이때 ci할때 모델을 이미지안에 넣으면,빌드시간이 오래걸리고 데이터를 많이차지하지만
	모델레지스트리와의 연결이 끊겨 발생하는 spof를 회피하게해줌
	또한 서빙로직과 모델버전을 일치시키지않아도돼서 복잡도가 낮아짐
	
	cd는 아르고cd같은걸로 처리해도되고,모니터링은 plg나 elk나 이런거쓰면됨
	
	추가적으로는,keep alive(http연결을 지속해 하나의연결로 여러 요청을 보내는 설정)옵션을 쓸땐 alb와 라이브러리의 타임아웃시간을 맞춰야함
	또한 k8s에서 pod가 삭제시 지연시간을 부여해야 pod가 교체될때 트래픽손실로 인한 유실이 안뜸

  10.생성형 AI 서비스 : 게이트웨이로 쉽게 시작하기
    생성형 ai를 사용할때 가장 먼저 만들만한게 api 게이트웨이임
	이걸 만들면 생성형 ai 서비스의 프롬프트와 호출로직을 중앙집중시킬수있고,자격증명과 프롬프트를 한곳에 모아서 관리할수있게됨
	또한 민감정보,로깅,리밋등을 고려하지않아도 되고 api키같은걸 관리하지않아도 되고 변경시에도 중앙서버에서만 바꾸면됨(프록시)
	
	또한 이렇게 중앙서버를 만들면 비용관리도 편해짐

  11.로봇 ML 모델의 경량화 1부:훈련 후 양자화
    로봇은 사무실내처럼 안전한 환경을 다니는게 아니라서,칩은 좀 더 내구성에 투자할수밖에 없고 트레이드오프로 성능이 떨어짐
	이런 로봇들은 이런 요구사항을 충족하는 엣지 디바이스를 사용하게됨 
	그래서  ml모델을 처리하려면 좀 더 가볍게 만들어야함,이때 TensorRT를 사용해서 최적화를 시킬수있음
	
	또한 양자화를 사용해서 모델을 가볍게 만들수있는데,이때 학습이 완료된 모델을 가지고 정밀도를 낮추는걸 훈련 후 양자화라고 함
	이때 캘리브레이션(타깃데이터와 모델의 특성에 맞는 최적의 양자화계수 구하기)을 거치면 정확도감소가 큰폭으로 줄어드는데,
	이걸 쓰면 정확도가 크게 하락할 가능성이 적고,학습데이터가 덜필요함
	이걸로도 성능만족이 안되면,양자화인식훈련을 할수있음
	
	파이토치모델을 TensorRT로 변환하는건 글 참조,글케 어렵진않음 딸깍임
	
	캘리브레이션을 사용한 양자화를 하면 추론시간이 3배정도 줄어들고,정확도가 거의 깎이지않는걸(0.2%) 볼수있음
	랜덤데이터 양자화의 경우엔 추론시간이 3배정도 줄어들고,3%정도 정확도가 깎임

  12.로봇 ML 모델의 경량화 2부 : 양자화 인식 훈련
    훈련 후 양자화는 오차전파에 대한 대응이 부족하고,모델구조 및 연산특성 반영이 부족할수있음
	이때문에 3d객체 인식같은경우 성능감소가 눈에띄는 경우가 생김(즉 케이스따라 못쓰는경우도 있음)
	
	그래서 사용되는게 양자화 인식 훈련임
	이건 처음부터 양자화 연산을 고려해서 학습시키는 방법임
	이건 레이어 사이에 축소-확장기를 둬서 가상의 int8연산을 경험하게 하는거임(fp32를 가지고 int8의 범위로 잘라내서 int8처럼 만드는거)
	즉 의도적으로 오차를 발생시켜,순전파시에는 int8처럼 낮은 정밀도환경을 경험하고,역전파시에는 fp32의 정확한 미분값을 사용하여 가중치를 갱신하는것
	
	이런식으로 학습시킬경우에는,
	모델이 지역최저점중 narrow minima(주변이 급격하게 변하는,기울기가 큰 지역최저점,Wide Minima보다 변화에 민감하지만 정확도는 더 높을확률이 있음)이 아닌
	Wide Minima(주변이 완만한,기울기가 낮은 지역최저점,노이즈에 대한 견고성이 높음)에 갈 확률이 높아져서,
	외부요인에 의해 파라미터값이 조금 변해도 모델성능이 크게바뀌지않음
	
	즉 Wide Minima에 쉽게 수렴하도록 하는 학습기법임
	이거의 장점은,int8변환을 미리 경험해서 양자화를 해도 피해가 덜하게 만들었다는거고,단점은 학습을 새로해야한다는것
	또한 모델이나 데이터가 작을땐 큰 효과를 발휘하지 못하기도함
	
	실제 하는법은 글 참조

  13.로봇을 위한 MLOps 1부 : 에지 디바이스와 K3s, 에어플로
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	