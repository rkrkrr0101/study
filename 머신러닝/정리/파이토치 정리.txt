텐서=배치사이즈(하나마다 데이터하나),차원(파라미터)
t=(64,256)
이미지3d텐서=(배치사이즈,width,height)
파이토치의 경우에,배치사이즈,가로,깊이값순으로 넣으면됨
nlp3d텐서=(배치사이즈,길이(타임스탭),차원(문장))


numpy
	t.array([1,2,3,4]) 배열생성
	t.ndim ->차원수보기
	t.shape ->형상보기
touch
	t=torch.FloatTensor([0.,1.,2.,3.]) 텐서생성 
	t.dim() 차원수보기
	t.shape 형상보기
	t.size() 형상보기
	t.[2:5] 넘파이랑똑같음(슬라이스)
	t.mean() 전체값평균(단일값출력)
	t.mean(dim=0) 0차원의 평균(배열출력)  1x2에서 앞의 1만 남긴다고보면됨
	t.mean(dim=1) 1차원평균(배열출력)     1x2에서 뒤의 2만 남긴다고보면됨
	t.mean(dim=-1)마지막차원평균(배열출력)
	t.sum(dim) 차원으로 더하기
	t.max(dim) 차원에서 가장큰값  dim이 0이면 세로단에서 max치는거고 1이면 가로단에서 max
	t.argmax(dim) 차원에서 가장큰값의 인덱스,원핫인코딩에서 자주나옴,만약 두개이상일경우 먼저발견되는것
	t.view([-1,3])  reshape임,-1은 알아서하라는거고,3으로 고정하면,총갯수가 12면 4x3이 되고 15면 5x3이 되는식
					즉 와일드카드인데 특성상 전체중에 하나만 들어갈수있음(-1,1,3)이건가능(-1,-1,-1) 이건안됨,단 원래있던크기랑 같아야함
	t.squeeze() 전체배열의 차원에서 갯수가 1인걸 없애줌([[0],[1],[2]])->([0,1,2])
	t.squeeze(dim=1) 1차원에서 dim이 1이면 없앰(그차원만 없앰)
	t.unsqueeze(dim=1) 해당차원에 차원을 추가함
	t.float() float로 타입변경
	t.long()롱으로 변경
	touch.cat([x,y],dim=0) 0차원기준으로 두 텐서를 붙임(concat)
	touch.stack([x,y,z]) 0차원기준으로 텐서들을 쌓음(0차원기준으로 1차원배열처럼 추가됨)[1,2][3,4][5,6]->[[1,2],[3,4],[5,6]]
	touch.stack([x,y,z],dim=1)1차원기준으로 텐서들을쌓음(1차원기준으로 각 층에 추가됨)[1,2][3,4][5,6]->[1,3,5][2,4,6]
	touch.ones_like(x) x를 1로채운 텐서 리턴
	touch.zeros_like(x) x를 0로채운 텐서 리턴
	t.mul(2) 전체x2를 함(새로운 메모리선언하고,원본값은 바뀌지않음)
	t.mul_(2)전체x2를 함(원래 메모리에 덮어씀,깊은복사,즉 원본값이 바뀜) 사실쓸일없을듯
	torch.matmul(w) 텐서간(행렬) 곱
	x_train.matmul(w) xtrain과 w를 곱함
	torch.transpose(a1,0,1) 축을 지정해서 둘을 스왑(a1의 0,1차원을 스왑,즉 (10,5)->(5,10))
같은 크기의 텐서를 더하거나 빼면 같은위치에서 변동일어나고
텐서에 벡터(단일크기같은)를 더하면 그방향으로 같은값이 복사되어서 텐서로 변경된다음에 더해짐
크기가 다른벡터는 양쪽으로 값을 복사해서(1x2+2x1 ->2x2+2x2) 연산이 진행됨

bt=lt==3 이런 논리문을 텐서에 걸면,각 위치마다 t,f를 넣은 byteTensor이 출력됨

행렬곱은 2x2   * 2x1일떄 앞의 뒷자리와 뒤의 앞자리가 같을때 수행할수있고 그걸 양쪽다없애고 2x1로 출력이나옴
(앞의뒤와 뒤의앞을 합치고 앞의앞과 뒤의뒤만 남음)


cpu디바이스텐서와 gpu디바이스텐서를 연산하면 에러남
gpu+gpu경우에도 다른디바이스면 에러남

선형모델은 가장 모델과 맞는 직선을 찾음
w는 가중치 b는 편향
w=torch.zeros(1,requires_grad=True)
b=torch.zeros(1,requires_grad=True) requires_grad=True는 학습할거라고 명시하는것
hypothesis=x_train*w +b


선형모델에서 로스펑션은 mse사용
cost=torch.mean((hypothesis=y_train)**2) //mse

optimizer=optim.SGD([w,b],lr=0.01) //w,b는 학습할텐서들

optimizer.zero_grad() //기울기초기화
cost.backward() //기울기계산
optimizer.step() //스텝으로 개선(진행)

즉 
xtrain=adada
ytrain=adadad
w=torch.zeros(1,requires_grad=True)
b=torch.zeros(1,requires_grad=True) requires_grad=True는 학습할거라고 명시하는것


optimizer=optim.SGD([w,b],lr=0.01) //w,b는 학습할텐서들
//여기까진 한번만


for epoch in range(1,30):
    hypothesis=x_train*w +b    //계산
	cost=torch.mean((hypothesis=y_train)**2) //mse
	
	optimizer.zero_grad() //기울기초기화
	cost.backward() //기울기계산
	optimizer.step() //스텝으로 개선(진행)
이런식으로 진행됨

비용함수는 0일때 가장 좋음
그래서 그레이디언트는 0에 수렴하게 만들어야함->학습을 해당방향의 기울기x학습률만큼 이동(빼는)하는식으로 함

기본적으로 파이토치에선,옵티마이저를 선언하고(설정하고)
옵티마이저를 초기화하고 코스트펑션으로 기울기를 계산한후에 optimizer.step로 경사하강법을 진행하는식으로 간략화되어있음
	optimizer.zero_grad() //기울기초기화
	cost.backward() //기울기계산
	optimizer.step() //스텝으로 개선(진행)
이거임
즉,옵티마이저에 설정된 파라미터만 저장해서,그걸 계산하고 연산해서 경사하강법을 진행하는거임


만약 입력 파라미터갯수가 여러개일경우
	w=torch.zeros((3,1),requires_grad=True)
	hypothesis=x_train[0]*w[0] +x_train[1]*w[1]+x_train[2]*w[2] +b 
이런식으로 됨
근데 이게 파라미터가 많아지면 다적기힘드니까
	hypothesis=x_train.matmal(w)+b
로 사용함(x_train과 w의 같은항을 묶어서 계산)
이경우에도 비용함수의 계산식은 동일하고
	cost=torch.mean((hypothesis=y_train)**2)
옵티마이저도 동일함
	optimizer=optim.SGD([w,b],lr=0.01) //w,b는 학습할텐서들

	optimizer.zero_grad() //기울기초기화
	cost.backward() //기울기계산
	optimizer.step() //스텝으로 개선(진행)

근데 이 
		hypothesis=x_train.matmal(w)+b
이거도 귀찮으니까,보통은 
	class aamodel(nn.module):
		def __init__(self):
			super().__init__()
			self.linear=nn.Linear(3,1)  //레이어쌓기
			
		def forward(self,x):
			return self.linear(x)
			
	model=aamodel()		
	hypothesis=model(x_train)
	optimizer=optim.SGD(model.parameters(),lr=0.01) //w,b는 학습할텐서들
	for epoch in range(20+1):
		optimizer.zero_grad() //기울기초기화
		cost.backward() //기울기계산
		optimizer.step() //스텝으로 개선(진행)
		
		
이런식으로 forward를 정의하면 hypothesis를 계산해주고,gradient계산은 backward()를 정의하면 파이토치가 알아서해줌

그리고 파이토치 자체에서 비용함수를 제공함
	import torch.nn.functional as F
	
	cost=F.mse_loss(prediction,y_train)
이렇게


데이터가 많아서 메모리에 들어가지않을경우엔,미니배치를 사용해서 데이터를 떼서 조금씩 역전파하는식으로 하고,
데이터를 전부사용하면 한 에포크가 지나는식으로 할수있음(이게 미니배치임)
장점은
	학습이 빠름
	메모리에 다 넣을수있고,저장공간이 덜필요
단점은
	잘못된 학습이 될수있음(좀 학습값이 튐)

미니배치를 파이토치에서 구현할땐
	from torch.utils.data import Dataset
	class cuDataset(Dataset):
		def __init__(self):
			self.x_data= 데이터값
			self.y_data= 데이터레이블값
			
		def __len__(self):
			return len(self.x_data)
			
		def __getitem__(self,idx):
			x=torch.FloatTensor(self.x_data[idx])
			y=torch.FloatTensor(self.y_data[idx])
			return x,y
	
	dataset=cuDataset()
이렇게 init에 데이터넣고 len과 getitem을 구현하고
	from torch.utils.data import DataLoader
	
	dataloader=DataLoader(dataset,batch_size=2,shuffle=True)//데이터셋넣고,배치사이즈 지정하고(보통 2의제곱수),
															//셔플은 에포크마다 데이터 섞는거

그리고 이렇게 한뒤에 학습하는건
	for epoch in range(21):
		for batch_idx,samples in enumerate(dataloader):
			x_train,y_train=samples
			
			prediction=model(x_train)
			
			cost=F.mse_loss(prediction,y_train)
			
			optimizer.zero_grad() //기울기초기화
			cost.backward() //기울기계산
			optimizer.step() //스텝으로 개선(진행)			
			
			print('epoch {:4d} batch{}/{} Cost:{:.6f}'.format(
				epoch,21,batch_idx+1,len(dataloader),cost.item()))
이렇게 순전파를하고 코스트를 구하고 기울기를 계산하고 스탭을 밟음


로지스틱회귀는 0~1의 값을 뽑아내는 회귀문제임,이걸 0.5으로 잘라서 클래시피케이션하면 분류문제가 되는것
그래서 이진분류할때 시그모이드를 사용함(보통 이진분류의 마지막층에서 사용)

이경우
	w=w-lr*미분값(그레이디언트)*cost(w) 
이렇게 학습이 일어남

h(가설함수,y=wx+b 같은,w와 b의 값을 찾을때의 뼈대,레이어에서의 함수랑 같은거임)는
 h=1/(1+torch.exp(-(x_train.matmul(w)+b))->h=torch.sigmoid(x_train.matmal(w)+b)
비용함수는 이진크로스엔트로피
	losses=-(y_train*torch.log(h)+(1-y_train)*torch.log(1-h))
	cost=losses.mean()
이런식
내부함수쓰면
	F.binary_cross_entropy(h,y_train)
	
실제구현은
	w=torch.zeros((2,1),requires_grad=True)
	b=torch.zeros(1,requires_grad=True)
	optimizer=optim.SGD([w,b],lr=1)
	for epoch in range(21):


			h=torch.sigmoid(x_train.matmal(w)+b)
			cost=F.binary_cross_entropy(h,x_train)
			
			optimizer.zero_grad() //기울기초기화
			cost.backward() //기울기계산
			optimizer.step() //스텝으로 개선(진행)			
			
			print('epoch {:4d} batch{}/{} Cost:{:.6f}'.format(
				epoch,21,batch_idx+1,len(dataloader),cost.item()))

이렇게만 하면 회귀고,
prediction=hypothesis>=torch.FloatTensor([0.5])
하면 1아니면 0으로 나옴
그리고
corrent_pre=prediction.float()==y_train
으로 정답확인을 하고,저걸 평균내면 acc(정확도)가 나옴
즉 다더하고 len으로 나누고 100곱하면됨

실제로 구현할땐
	class binaryClassifier(nn.module):
		def __init__(self):
			super().__init__()
			self.liner=nn.Linear(2,1)
			self.sigmoid=nn.Sigmoid()
		def forward(self,x):
			return self.sigmoid(self.linear(x))
이런식으로 레이어를 구현함

다중분류에선 softmax를 사용함
이산확률분포는 1,2,3,4,5,6처럼 .5가 나오지않는것
연속확률분포는 연속적으로 1.1,1.2이렇게 연속적으로 분포하는것
소프트맥스는 이산확률분포를 연속확률분포처럼 근사할수있음(1,2,3일때 0.09,0.25,0.67 이런식으로 잘라서 이산적으로 처리)
	F.softmax(z,dim=0)//나올것의 갯수가들어있는 텐서(1,2,3),그텐서에서 차원 선택
크로스엔트로피는 현재가설분포에서  역전파분포값만큼을 빼는식으로 이상적인가설에 다가가는식

원핫을 만들땐
	yonehot=torch.zeros_like(h)
	yonehot.scatter_(1,y.unsqueeze(1),1)//dim1차원

그리고 크로스엔트로피 비용함수는
	cost=(yonehot * -torch.log(h)).sum(dim=1).mean()
	        3,5           3,5         3,1        1,1
이렇게 나옴
이건 행렬에대해 연산을하고,그걸 더해서 (x,1)로 줄인다음,그걸 평균내서 스칼라값으로 뽑아내는것
파이토치에서 소프트맥스는
	F.softmax(z,dim=0)
	F.log_softmax(z,dim=1)
로 제공함
크로스엔트로피는
	F.nll_loss(F.log_softmax(z,dim=1),y)//z==h y==y_train
	F.cross_entropy(z,y) //z==h  y==y_train
이렇게 사용할수있음
실제구현은
	w=torch.zeros((4,3),requires_grad=True)//입력4 출력3
	b=torch.zeros(1,requires_grad=True)
	optimizer=optim.SGD([w,b],lr=1)
	for epoch in range(21):


			z=x_train.matmal(w)+b
			cost=F.cross_entropy(z,y_train)
			
			optimizer.zero_grad() //기울기초기화
			cost.backward() //기울기계산
			optimizer.step() //스텝으로 개선(진행)			
			
			print('epoch {:4d} batch{}/{} Cost:{:.6f}'.format(
				epoch,21,batch_idx+1,len(dataloader),cost.item()))

레이어(모델)로 만들땐
	class softmaxClassifierModel(nn.module):
		def __init__(self):
			super().__init__()
			self.liner=nn.Linear(4,3)//입력값이4 출력값이3
			
		def forward(self,x):
			return self.linear(x)

model=softmaxClassifierModel()
하면됨
모델을사용할떄 구현은
	model=softmaxClassifierModel()
	optimizer=optim.SGD(model.parameters,lr=0.1)
	for epoch in range(21):


			prediction=model(x_train)  //xtrain=(m,4) prediction=(m,3)
			
			cost=F.cross_entropy(prediction,y_train)  //y_train=(m,1)
			
			optimizer.zero_grad() //기울기초기화
			cost.backward() //기울기계산
			optimizer.step() //스텝으로 개선(진행)			
			
			print('epoch {:4d} batch{}/{} Cost:{:.6f}'.format(
				epoch,21,batch_idx+1,len(dataloader),cost.item()))


보통 다중분류에선 소프트맥스(마지막층함수),크로스 엔트로피(손실함수) 이진분류에선 바이너리 크로스 엔트로피(손실),시그모이드(마지막층함수)를 사용함



딥러닝할때
	기본아키텍쳐를 만들고
	트레인 하고 체크하고 하는걸 오버핏될때까지 반복
		오버핏이 안되면 모델사이즈를 늘리고
		오버핏되면 드롭아웃과 배치정규화를 추가
	이걸 계속반복함


파이토치에서 train,valid,test 나눴을때
test는
	def test(model,optimizer,x_test,y_test):
		prediction=model(x_test)
		predicted_classes=prediction.max(1)[1]
		correct_count=(predicted_classes==y_test).sum().item()
		cost=F.cross_entropy(prediction,y_test)
		print('Accuracy:{}% Cost:{:.6f}'.format(correct_count/len(y_test)*100,cost.item()))
로 테스트할수있음

파이토치에서 데이터 전처리는
	x_train.mean(dim=0)
	sigma=x_train.std(dim=0)
	norm_x_train=(x_train-mu)/sigma
로 정규분포화를 할수있음(-1~1)

mnist는 1x28x28이미지임,즉 784픽셀,y값은 0~9고
파이토치에서 mnist같은 유명한 데이터셋들은 torchvision에 들어있음
이건 데이터셋,모델,트랜스폼(전처리),유틸로 구성되어있음
사용시엔
	import torchvision.datasets as dsets
	//다운로드
	mnist_train=dsets.MNIST(root="저장경로/",train=True,transform=transforms.ToTensor(),download=True)
	mnist_test=dsets.MNIST(root="저장경로/",train=False,transform=transforms.ToTensor(),download=True)
	//데이터읽기
	data_loader=torch.utils.DataLoader(DataLoader=mnist_train,batch_size=batch_size변수,shuffle=True,
									   drop_last=True)//맨뒤에 배치사이즈보다 모자랄때 버릴건지말건지
	//
	for epoch in range(training_epochs):
		for x,y in data_loader: //데이터로더에서 x와 레이블을 분리
			x=x.view(-1,28*28).to(device)//1*28*28을 784로 만듬(cnn이 아니니까 배열로 만들어야함)
			
여기서 transform=transforms.ToTensor()는,일반적으로 이미지는 높이,너비,채널순으로 됐는데,이걸 파이토치에서 쓰는 채널,높이,너비순으로 바꿔줌

학습은
	linear=torch.nn.Linear(784,10,bias=True).to(device)
	training_epoch=15
	batch_size=100
	
	criterion=torch.nn.CrossEntropyLoss().to(device)//자동으로 소프트맥스로 들어감 파이토치에선
	optimizer=torch.optim.SGD(linear.parameters(),lr=0.1)//w,b
	
	for epoch in range(training_epoch):
	avg_cost=0
	total_batch=len(data_loader)
	for X,Y in data_loader:
		X=X.view(-1,28*28).to(device)
		optimizer.zero_grad()
		hypothesis=linear(X)
		cost=criterion(h,y)
		cost.backward()
		optimizer.step()
		avg_cost+=cost/total_batch
	
	print("epoch: ","%04d"%(epoch+1),"cost=","{:.9f}".format(avg_cost))

테스트는
	With torch.no_grad(): //grad계산방지,즉 학습방지
		X_test=mnist_test.test_data.view(-1,28*28).float().to(device)
		Y_test=mnist_test.test_labels.to(device)
		
		prediction(linear(X_test))
		correct_prediction=torch.argmax(prediction,1)==Y_test
		accuracy=corrent_prediction.float().mean()
		print("acc:",accuracy.item())
		
		


퍼셉트론은 그거임,가중치의 합+b가 임계치 이상이면 1을 출력,아니면 0을출력하는거,여기서 활성화함수를 거쳐서 최종출력이 나옴
퍼셉트론은 xor같은게 해결불가능해서 멀티레이어퍼셉트론이 나왔고,그걸 학습시키기위해 역전파가 나옴

파이토치에서 역전파는,원래 역전파 하는거처럼 첫로스를 구하고,그걸가지고 뒤로 밀어가면서 계산하면됨
즉,각 레이어에 해당하는 역전파 값을 구한뒤
	w1=w1-lr*d_w1
	b1=b1-lr*torch.mean(d_b1,0)
을 수행하면됨(lowlevel)
하이레벨에선




파이토치에서 다중레이어모델은
	sigmoid=torch.nn.Sigmoid()
	model=torch.nn.Sequential(l1,sigmoid,l2,sigmoid).to(device) //l1 l2생략
이렇게 하면됨

relu는 평상시 사용하는 활성화함수임,보통 시그모이드나 소프트맥스는 모델종류에 따라 최종활성화함수로만 사용하고,보통은 relu변종들을 사용함
시그모이드를 보통 안쓰는이유는,미분했을때 0이되는 부분(양끝)이 존재하기때문,이러면 기울기소실이 일어나게됨
relu는 f(x)=max(0,x)임
파이토치에서 쓸땐
	torch.nn.ReLU(x)
	torch.nn.leaky_relu(x,0.01)//기울기 0인부분을 매우작은수로 변경
이렇게 사용
	relu=torch.nn.ReLU()
	model=torch.nn.Sequential(l1,relu,l2,relu,l3).to(device)//마지막엔 마지막층활성화함수를 넣어야함,시그모이드나 소프트맥스같은

파이토치에서 옵치마이저는
	torch.optim.Adam
	torch.optim.SGD
등이 있음
보통 adam잘쓰는듯

멀티레이어에선 가중치를 0으로 초기화하면 다 하나의 퍼셉트론처럼 동작해서,각각 다 랜덤하게 초기화를 해야함
보통 xevier나 he초기화를 사용함
파이토치에서 사용할땐
	torch.nn.init.xavier_uniform(l1.weight)
이런식으로 초기화하면됨,레이어생성하고 초기화하고 에포크들어가면됨

드롭아웃은 연습할때 일부 뉴런을 꺼버림으로써,다른 모든 뉴런들이 좀 일반적으로 학습할수있게 도와줌(오버핏을 좀 막음)
물론 실제 prediction상황에선 모든 뉴런을 사용함
즉 model.train()에선 드롭아웃을 키고,
model.eval()에선 드롭아웃을 끔
그래서 학습할때는 에포크직전에
	model.train()
	for epoch in range(21):
	...
선언을 해야함
예측시엔
	with torch.no_grad():
		model.eval()
		...
을 선언해야함
파이토치에서 쓸땐
	dropout=torch.nn.DropOut(p=drop_prob)//몇퍼센트를 끌건지
	relu=torch.nn.ReLU()
	model=torch.nn.Sequential(l1,relu,dropout,l2,relu,dropout,l3,relu,dropout,l4).to(device)//
이런식으로 그냥 레이어처럼 사용하면됨

batch normalization은 기울기소실과 폭주를 어느정도 막기위해 생긴,정규화임
즉,각 층의 값들을 일정한 범위안으로 넣어버림으로써 항상 미분했을때 값이 일정크기내에서 나오게 만듬
보통 각 층에다가 기본적으로 박아넣음,안넣는게 특이한거
이건 각 미니배치에서의 최대값과 최소값을 1~0으로 잡고 그사이에 넣는거

배치노말라이제이션도 트레인에선 동작하고,예측에선 동작하지않음
이유는,각 배치를 기준으로 잡는거라서,미니배치크기가 작아지면 오차가 커질수있어서 예측에서빼버림(같은샘플이라도 다른값이 나올수있음)

파이토치에서 쓸땐
	dropout=torch.nn.DropOut(p=drop_prob)//몇퍼센트를 끌건지
	bn1=torch.nn.BatchNorm1d(32)//32는 입력값갯수
	bn1=torch.nn.BatchNorm1d(32)//32는 입력값갯수
	relu=torch.nn.ReLU()
	model=torch.nn.Sequential(l1,bn1,relu,dropout,l2,bn1,relu,dropout,l3,bn2,relu,dropout,l4).to(device)//
이런식으로 그냥 레이어처럼 사용하면됨
보통 레이어,배치정규화,활성화함수,드롭아웃 순으로 두면됨


conv에서 stride는 필터를 이동시키는 픽셀수(1이면 한칸씩,2면 두칸씩)
패딩은,이미지의 겉에 모든값이 0인 픽셀을 추가하는데,1이면 한칸씩,2면 두칸씩 추가됨

파이토치에선
	torch.nn.Conv2d(입력채널수(rgb같은),출력채널수(rgb같은),커널사이즈,스트라이드,패딩,bias)//커널사이즈는 필터의 크기 bias는 TF값
로 사용할수있음
그리고 conv의 인풋타입은 torch.Tensor이고,
차원은 배치사이즈x채널(rgb같은)x높이x넓이
로 구성되어야함
그리고 아웃풋사이즈 구하는건
	(인풋사이즈-필터사이즈+(2*패딩)/스트라이드) + 1 //인풋사이즈가 가로세로동일할떄는 한번만하면 되고,다르면 양쪽으로 해줘야함,소수점은 버림
									   //값이 30이면 30x30,(17,7)이면 17x7,값이 27.5면 27x27
임
conv는,필터를 학습시켜서 가장 나은 값을 뽑아내는거임,학습대상은 필터와 bias임
필터는 각 채널마다 하나씩 존재함
풀링은 필터내에 평균이나 맥스나 정해진 조건으로 필터크기만큼을 압축시키는거임
	torch.nn.MaxPool2d(커널사이즈,스트라이드,패딩)//스트라이드와 패딩은 기본값이있어서 maxpool2d(2)만 해도됨 기본값쓰려면
으로 사용할수있음


학습할때 optimizer.zero_grad()를 안해주면 학습안됨

visdom은
	pip install visdom
으로 설치할수있음
서버킬땐
	python -m visdom.server
로 킬수있음
텍스트띄울땐
	vis.text("텍스트",env="main")//env는 그 환경변수를 가지고있는걸한번에끌때 사용함
이미지는
	a=torch.randn(3,200,200)
	vis.image(a)
이미지여러개는
	vis.images(torch.Tensor(3,3,28,28))
이렇게 한번에 넣을수있음(입력값 텐서,텐서들의 배열이면됨)
그래프는
	y_data=torch.randn(5)
	plt=vis.line(Y-y_data)
이렇게 그릴수있음
주의점은 x축을 안넣으면,x축은 0~1이 됨
x축을 넣으려면
	x_data=torch.Tensor([1,2,3,4,5])
	plt=vis.line(Y=y_data,X=x_data)//vis.line(y축,x축)
이렇게하면됨

그래프 업데이트할땐
	vis.line(Y값,x값,vin=업데이트할그래프이름,update="append")

창을 닫을떈
	vis.close(env="main")//main인걸 다끔

그래프하나에 선두개그릴땐
	num=torch.Tensor(list(range(0,10)))
	num=num.view(-1,1)
	num=torch.cat((num,num),dim=1)
	
	plt=vis.line(Y=torch.randn(10,2),X=num)
이렇게 차원수 맞추면됨
선 설명넣을땐
	vis.line(Y=y_data,X=x_data,opts=dict(title="test",legend=['1번','2번'],showlegend=True))
이렇게하면됨,딕셔너리 형태로 넣으면됨
보통 num과 loss_value를 받는 함수형태로 만들어서 학습할때 마지막에 뱉으면됨

토치에서 이미지데이터 불러올땐,imagefolder로 하면됨
데이터는,각 클래스별로 폴더로 구분해서 넣고
	origin
		gray
		red
		blue
이런식으로
그리고 cnn돌릴때 이미지크면 너무오래걸리고,램도 많이드니까 전처리로 이미지를 줄여서 처리하는게 좋음
imagefolder는
	torchvision.datasets.imageFolder(root='경로',transform=None)
사진이미지 줄일땐
	trans=tranfforms.Compose([
		transforms.Resize((64,128))
	])
	torchvision.datasets.imageFolder(root='경로',transform=trans)
이렇게 적용하면됨
그리고 전처리한거 저장하려면
	for num,value in enumerate(train_data):
		data,label=value
		if (label==0):
			data.save('저장경로/클래스별0/%d_%d.jpg'%(num,label))
		else if (label==1)
			data.save('저장경로/클래스별1/%d_%d.jpg'%(num,label))
이렇게 저장하면됨


모델저장할땐
	torch.save(모델.state_dict(),"저장경로")
로 저장하면됨
로드할땐
	새모델.load_state_dict(torch.load(저장경로))
당연히 레이어는 같아야함












