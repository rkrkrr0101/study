1.서문
	카프카는 데이터 서빙의 중앙에서 모든 데이터처리를 중앙집중해서 파편화를 없애는 툴임
	즉 모든곳에서의 데이터스트림을 카프카로 통합하고,소비자들도 여기서 소비할수있게 만드는툴
	이렇게되면 데이터를 생성하는애도 그냥 카프카에 밀어넣는책임까지만 가지게되고,소비자를 신경쓰지않아도됨
	
	카프카에서 데이터를 보내는쪽을 프로듀서라고 부르고,
	소비하는쪽을 컨슈머라고 부름(생산자-소비자 패턴)
	카프카로 전달할수있는 데이터포맷의 제한은 사실상없고(직렬화 역직렬화를 사용하기때문에),
	기본적으로는 ByteArray, ByteBuffer, Double, Long, String 타입에 대응한 직렬화클래스를 기본제공함
	커스텀도 Serialzer<T>,Deserialzer<T>를 상속받아서 만들면 됨
	
	상용환경에서 카프카는 최소 3대이상의 서버에서 분산운영해야함
	이래야 한서버가 장애가 발생해도 지속적으로 데이터를 복제하기때문에 안전하게 운영할수있음
	그리고 데이터를 묶음단위로 배치전송하기때문에,낮은지연과 높은데이터처리량도 가지게됨
	
	
	카프카는 데이터레이크로 사용됨,일단 모든데이터를 다 때려박고(정제되지않은),여기서 나중에 필요한걸 알아서 찾으면됨
	이떄 e2e방식으로는 넣으면 한두군데서넣긴 할만한데,많아지면 파편화되고 복잡도가 올라감,그래서 하나로 통일된 솔루션이 필요한데,그게 카프카임
	카프카의 장점은
		배치전송해서 처리량이 높음
		확장이 쉬움(스케일아웃이 쉬움)
		영속성을 가지면서 느리지않음(캐시를 사용해서)
		고가용성(3대이상으로 구성해야하는이유)
	이 있음
	
	카프카는 모든 데이터를 스트림데이터로 취급해서 처리함
	데이터는 배치데이터와 스트림데이터로 나뉘는데,
		배치데이터는 한정된기간단위(140130일 데이터 이런식)의 데이터고,즉 끝이 정해져있고 일괄처리가 쉬움
		스트림은 한정되지않은 데이터고,끝이 정해지지않은(주식정보,클릭로그등)데이터임
	배치데이터를 스트림으로 처리하는건,모든데이터에 타임스탬프를 붙여서 배치데이터로 구성된 스트림으로 취급하는거임(스트림<배치> 이런느낌)
	이렇게 처리하려면 변환기록이 일정기간 삭제되면 안되고,지속적으로 추가되어야함
	그리고 해당레이어는 spof가 될수있으므로 반드시 내결함성과 장애허용특징을 지녀야함
	즉 이런식으로 카프카는 데이터를 처리함
	
2.카프카 빠르게 시작해보기
	aws설치부분은 넘어감 필요하면보자
	
	카프카 커맨드라인툴은 카프카를 사용할때 가장 많이 사용하는 툴임
	이거로 토픽을 생성하고,토픽리스트를 확인하고,프로듀서 컨슈머를 할수있음
	
	
	
	kafka-topics.sh는 이걸 사용해 토픽과 관련된 명령을 실행할수있음
	토픽은 카프카에서 데이터를 구분하는 가장 기본적인 개념임(rdb의 테이블이라고 생각하면됨)
	즉 토픽은 한 카프카 클러스터내에서 여러개 존재할수있고,토픽을 파티셔닝해서 각 클러스터마다 분산배치할수있음
	파티션은 토픽에서 매우 중요한데,이걸사용해서 한번에 처리할수있는 데이터양을 늘릴수있고,토픽내부에서도 파티션을 통해 데이터의 종류를 나눠처리할수있음
	
	토픽을 생성하는방법은 2가지가있는데
		컨슈머나 프로듀서가 생성되지않는 토픽에 대해 데이터를 요청할때(묵시적)
		커맨드라인툴로 명시적으로 토픽을 생성할때
	가급적이면 명시적으로 토픽생성하는게 좋음,토픽마다 처리되어야하는 데이터특성이 다르기때문
	토픽을 생성할때는 데이터특성에 따라 옵션을 다르게 설정할수있음
	만약 동시데이터처리량이 많아야하면 파티션을 100개로 설정하던가,단기데이터처리만 필요하면 데이터보관기간을 짦게 잡던가 할수있음
	
	토픽생성은
		bin/kafka-topics.sh --create --bootstrap-server 카프카1ip:포트 카프카2ip:포트 --topics 토픽명
	으로 생성할수있고,bootstrap-server뒤에 적힌 카프카 클러스터들에 동시에 세팅할수있음
	토픽명은 내부데이터가 뭐들어있는지 유추가 가능할정도로 자세하게적는게 나중에 알아보기좋음
	그리고 추가적으로 설정추가하려면(엔터넣으려면 \ 추가)
		bin/kafka-topics.sh --create 
			--bootstrap-server 카프카1ip:포트 카프카2ip:포트 
			--partitions 3 //파티션수,기본값1
			--replication-factor 1 //파티션복제갯수,기본값은 브로커설정따라감,복제1마다 저장하는 브로커갯수가 늘어남
			--config retention.ms=172800000 //토픽데이터 유지기간,ms단위
			--topics 토픽명
	이렇게 할수있음
	
	토픽리스트조회는
		bin/kafka-topics.sh --bootstrap-server 카프카1ip:포트 --list
	로 목록조회할수있고,자세히는
		bin/kafka-topics.sh --bootstrap-server 카프카1ip:포트 --describe --topic 토픽명
	으로 상세조회할수있음
	상세조회시에는 해당토픽설정,파티션과,리더,레플리카등이 나타남
	이때 토픽들의 리더가 일부 브로커에 몰려있는경우,부하가 특정브로커들로 몰릴수있어서,네트워크 대역이슈시 이런식으로 확인후 분산배치해야할수있음
	
	토픽의 옵션을 수정할땐,kafka-topics.sh나 kafka-configs.sh 두개를 사용해서 수정할수있음
	파티션갯수수정을 할때는 kafka-topics.sh를 사용하고,토픽삭제정책인 리탠션기간을 수정할땐 kafka-configs.sh를 사용해야함
	파티션갯수수정은
		bin/kafka-topics.sh 
			--bootstrap-server 카프카1ip:포트
			--topic 토픽명
			--alter
			--partitions 바꿀파티션갯수(증가만 가능)
	리탠션수정은
		bin/kafka-configs.sh
			--bootstrap-server 카프카1ip:포트
			--entity-type topics
			--entity-name 토픽명
			--alter
			-- all-config retention.ms=바꿀삭제시간
	이렇게 하면됨
	이떄 파티션은,늘릴수는있지만 줄일수는 없으니 잘생각해야함
	
	
	
	토픽에 데이터를 넣을땐,kafka-console-producer.sh를 사용할수있음
	토픽에 넣는 데이터는 레코드라고 부르며,메세지키와 메세지값으로 이루어져있음
	메시지 키 없이 보낼수도있는데 이땐
		bin/kafka-console-producer.sh 
			--bootstrap-server 카프카1ip:포트
			--topic 토픽명
	하면 텍스트를 입력할수있게됨
	그뒤로 입력하고 엔터치면 데이터 들어가는거
	이떄 주의할점은,이거로 던지면 무조건 스트링타입으로 던져지니까 주의해야함
	메시지키를 가진걸 보낼땐
		bin/kafka-console-producer.sh 
			--bootstrap-server 카프카1ip:포트
			--topic 토픽명	
			--property "parse.key=true"
			--property "key.separator=:" //기본값 \t(탭문자)
	이렇게 키사용 true로 놓고,키 구분자를 넣어주면됨
	그리고 텍스트를
		abc1:ppp123
	이런식으로 넣으면 abc1이 키고 ppp123이 값이됨
	만약 이렇게했는데 키를 넣지않으면 익셉션터지면서 종료됨
	
	메세지키가 없이 전송한 레코드는 라운드로빈으로 하나씩 던지고(키가 null),
	메세지키가 있는 레코드는,키의 해시값으로 던져서 키가 같은 모든 데이터는 한 파티션에 존재하게됨
	만약 파티션갯수를 바꿀경우엔 이게 보장되지않으니,이땐 커스텀파티셔너를 만들어야함
	카프카는 레코드를 오프셋,키,값으로 저장함
	오프셋은 컨슈머가 어디까지 데이터를 처리했는지같은걸 처리할때 사용하는 타임스탬프임
	
	
	
	이렇게 전송한 데이터를 받아볼땐 kafka-console-consumer.sh로 받아볼수있음
	이때 --from-beginning옵션을 주면 토픽에 저장된 가장 처음데이터부터 출력하고,없으면 지금부터받는걸 출력함
	기본적으론 키를 출력하지않고 값만 출력함
		bin/kafka-console-consumer.sh
			--bootstrap-server 카프카1ip:포트
			--topic 토픽명
			--from-beginning
	키도 보고싶으면
		bin/kafka-console-consumer.sh
			--bootstrap-server 카프카1ip:포트
			--topic 토픽명
			--property print.key=true
			--property key.separator="-"
			--group 그룹명
			--from-beginning	
	이렇게 할수있음
	이때 그룹은 컨슈머그룹으로,만약 해당이름의 그룹이 없었다면 새 그룹을 생성함
	그룹은 1개이상의 컨슈머로 이루어져있고,이 그룹을 통해 가져간 컨슈머는 토픽의 메시지에 대해 커밋(해당오프셋까지 처리완료했다고 브로커에 저장하는것)함
	이때 카프카프로듀서로 전송할때와 순서가 다를수있는데,이건 파티션때문에그럼
	컨슈머는 모든 파티션으로부터 동일한 중요도로 데이터를 가져가기때문에 순서를 보장하지않음
	만약 순서를 보장해야한다면,파티션을 1개로만 구성하면 순서를 보장함
	
	
	컨슈머그룹의 목록을 확인할땐 kafka-consumer-groups.sh를 사용할수있음
	생성은 그냥 따로 할필요없고,컨슈머를 킬때 그룸명을 지정하면 새로 생성됨
	목록확인은
		bin/kafka-console-consumer-groups.sh
			--bootstrap-server 카프카1ip:포트
			--list
	로 확인할수있음
	이거도 describe로 자세히보기할수있음
		bin/kafka-console-consumer-groups.sh
			--bootstrap-server 카프카1ip:포트
			--group 그룹명
			--describe
	이러면 
		그룹이 마지막으로 커밋한 토픽과 파티션
		그룹의 최신오프셋
		처리한 마지막 오프셋
		둘간의 차이(지연)
		내부id(컨슈머id+uuid)
		컨슈머 호스트명 or ip
		컨슈머id
	를 확인할수있음
	이걸로 그룹중복확인과 랙이 얼마인지를 확인하여서 컨슈머상태최적화를 할수있음
	
	
	그냥 간단히 네트워크통신테스트할땐
		kafka-verifiable-producer.sh
		kafka-verifiable-consumer.sh
	둘을 사용해서 할수있음
	핑테스트같은느낌
	이건
		bin/kafka-verifiable-producer.sh 
			--bootstrap-server 카프카1ip:포트
			--max-messages 10 //보낼메시지수,-1이면 종료될때까지 계속보냄
			--topic 토픽명
	로 보내고
	이때 
		최초실행시점
		메시지별 보낸시간,키,값,토픽,저장된파티션,저장된오프셋번호
		max도달후 통계값
	이 표시됨
	
	받을땐
		bin/kafka-verifiable-consumer.sh
			--bootstrap-server 카프카1ip:포트
			--topic 토픽명
			--group-id 그룹명
	으로 받아볼수있음
	이때
		최초실행시점
		할당된파티션
		받아온레코드들(파티션명,갯수,최소오프셋,최대오프셋)
		커밋메시지
	가 나타남
	컨슈머는 레코드를 한꺼번에 리스트로 받기때문에,한번에 n개씩 받음
	
	
	카프카에서 레코드를 삭제할땐 kafka-delete-records.sh를 사용할수있음
	이건 이미 적재된 데이터중 가장 오래된데이터(가장 낮은숫자의 오프셋)부터 특정시점까지의 오프셋까지를 삭제할수있음
	즉,0번부터 100번까지 있을때 0번부터 30번까지 지우는건 되지만 30번만 지우는건 불가능하다는거에 유의해야함
	
	이건 삭제할 토픽을 json으로 만들고 sh를 실행해야함
	json은
		{"partitions":[{"topic":"토픽명","partition":파티션명,"offset":삭제할오프셋}],"version":1}
	그리고나서
		bin/kafka-delete-records.sh
			--bootstrap-server 카프카1ip:포트
			--offset-json-file 삭제json.json
	하면 저 json에 있는 오프셋까지를 삭제함
	
	
3.카프카 기본개념	
	카프카 브로커는 카프카 클라와 데이터를 주고받기위해 사용하는 주체이자,
	데이터를 분산저장하여 장애가 발생해도 안전하게사용할수있게 도와주는 어플리케이션임(워커노드라고 생각하면될듯)
	하나의 서버에는 한개의 카프카브로커 프로세스가 실행되고,보통 3개이상을 묶어서 클러스터로 만들어서 사용함
	클러스터로 묶인 브로커들은 프로듀서가 보낸 데이터를 안전하게 분산저장,복제함
	
	프로듀서로부터 데이터를 전달받으면 브로커는 프로듀서가 요청한 토픽의 파티션에 데이터를 저장하고,
	컨슈머가 데이터를 요청하면 브로커는 파티션에 저장된 데이터를 전달함
	프로듀서로부터 받은 데이터는 파일시스템으로 저장됨
	파일시스템을 쓰긴하는데 캐시를 잘써서 그렇게 느리지도않음(페이지캐시)
	
	그리고 데이터복제를 사용해서,카프카는 장애허용시스템임
	즉 브로커의 일부가 장애가 발생해도 데이터를 유실하지않고 안전하게 사용할수있음
	카프카의 데이터복제는 파티션단위로 이뤄짐
	복제는 리더와 팔로워로 이뤄지고,리더를 통해 입력이 일어나고,
	팔로워들은 리더와 주기적으로 통신하면서 차이나는 오프셋만큼을 가져와서 계속 갱신함
	이걸 복제라고 부름
	이렇게 복제를 사용하면 데이터가 안전해지는 강력한 장점때문에,기업용의 경우 2이상의 복제개수를 정하는게 중요함	
	만약 클러스터의 리더에 장애가 발생할경우,다른 팔로워중 하나가 리더가 됨
	운영시에는 데이터 종류마다 다른 복제대수를 설정하고,상황에따라서는 토픽마다 복제개수를 다르게 설정하기도 함
	보통 데이터 일부유실이 중요하지않고,데이터처리속도가 중요하면 1 혹은 2
	금융권의경우 3으로 설정하는게 보통임
	
	클러스터의 브로커중 한대는 컨트롤러의 역할을 함
	얘는 브로커들의 상태를 주기적으로 체크하고,브로커가 클러스터에서 빠지는경우 해당브로커에 존재하는 리더파티션을 재분배함 
	카프카는 지속적데이터 처리가 중요하기때문에,브로커상태가 비정상이면 빠르게 제거하는게 중요함
	만약 컨트롤러가 비정상이면 다른브로커가 컨트롤러역할을 함
	
	카프카는 다른메시지플랫폼과 다르게 컨슈머가 데이터를 가져가도 데이터를 삭제하지않고,컨슈머나 프로듀서가 데이터삭제요청을 할수도 없음
	오직 브로커만이 삭제할수있음
	데이터삭제는 파일단위로 이루어지는데,이 단위를 로그세그먼트라고 부름
	이 세그먼트에는 다수의 데이터가 들어있기때문에,일반 db처럼 특정데이터를 선별삭제가 불가능함
	세그먼트는 데이터가 쌓이는동안 열려있고,설정값만큼의 크기가 되면 닫히고 다음세그먼트가 열림(기본값1기가)
	또한 오래된 데이터는 삭제되는데,데이터를 삭제하지않고 압축하는 정책을 가져갈수도있음
	
	컨슈머그룹은 토픽이 특정 파티션으로부터 데이터를 어디까지 가져갔는지 확인하기위해 오프셋을 커밋함,이건 시스템토픽에 저장됨
	
	클러스터의 다수브로커중 한대는 코디네이터의 역할을 수행함,코디네이터는 컨슈머그룹의 상태를 체크하고,파티션을 컨슈머와 매칭되도록 분배함
	컨슈머가 컨슈머그룹에서 빠지면 매칭되지않은 파티션을 정상동작하는 컨슈머로 할당하여 끊임없이 데이터가 처리되게 도와줌
	이걸 리밸런스라고 부름
	
	여기까지가 브로커의 역할임
	대체적으로 k8s에서 워커노드와 비슷한듯
	카프카서버에서 직접 주키퍼에 붙을수도있는데,localhost:2181로 
		bin/zookeeper-shell.sh localhost:2181
	이렇게 접근하면됨(같은서버에 있으니까 로컬호스트)
	이러면 어떤애가 컨트롤러인지,카프카에 저장된 토픽등등을 알수있음
	그리고 클러스터로 묶인 브로커는 동일한경로의 주키퍼경로로 선언해야 같은 카프카브로커묶음(클러스터)가 됨
	그리고 클러스터가 여러개면 이것들을 묶어서 사용할수도있음
	
	
	토픽은 카프카에서 데이터를 구분하기위해 사용하는 단위로,토픽은 1개이상의 파티션을 소유하고있음
	파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데,이걸 레코드라고 부름
	그냥 테이블이라고 생각하면됨
	
	파티션은 카프카 병렬처리의 핵심으로,그룸으로 묶인 컨슈머들이 레코드를 병렬로 처리할수있도록 매칭됨
	컨슈머의 처리량이 한정된상황에서 레코드병렬처리하는 가장 좋은방법은 컨슈머의 갯수를 스케일아웃하는거고,
	이와동시에 파티션갯수도 늘리면 처리량이 증가함
	파티션은 큐와 비슷한 자료구조인데,여기서 삭제를 뺀거임
	보통 컨슈머수와 파티션수를 맞추면 그게 제일 빠름
	
	토픽의 이름의 제약조건중 중요한건
		영어대소문자와 숫자,마침표,언더바,하이픈조합으로 구성되어야함
		마침표와 언더바가 동시에 들어가면안됨(정확히는 만들어는지는데 문제생길수있음)
	토픽의 이름은 명시적으로 잘지어야함
	토픽이름을 통해 어떤개발환경에서 사용되는지 판단이 가능해야하고,어떤어플리케이션에서 어떤데이터타입으로 사용되는지 유추가능해야함
	전사공용카프카라면 토픽의 오너십팀명을 추가하는거도 고려할만함
	히스토리를 명확히 파악하고싶으면 지라티켓번호를 토픽이름에 넣는거도 괜찮음
	보통 카멜케이스보단 하이픈이나 언더바로 구분하는식을 잘 사용함
		환경(dev,prod)-팀명-애플리케이션명-메시지타입(json등)
		프로젝트명-서비스명-환경-이벤트명
		환경-서비스명-지라번호-메시지타입
		클러스터명-환경-서비스명-메시지타입
	이런식으로 구성됨
	중요한건,카프카는 토픽이름변경을 지원하지않아서 이름변경하려면 삭제후 재생성밖에 없으니,반드시 규칙을 만들고 규칙을 따라야함
	
	
	레코드는 타임스탬프,메시지키,메시지값,오프셋,헤더로 구성되어있음
	프로듀서가 생성한 레코드가 브로커로 전송되면,오프셋과 타임스탬프가 지정되어 저장됨
	한번 브로커에 적재된 레코드는 수정할수없고,기간이 지나거나 용량부족에 의해서만 삭제됨
	
	타임스탬프는 프로듀서에서 생성된시점이 기준인데,프로듀서가 임의의값을 넣을수있고,토픽설정에 따라 브로커적재시간으로 바꿀수있는거에 대해 유의해야함
	메시지키는 메시지값을 순서대로 처리하거나,메시지값의 종류를 나타낼때 사용함
	메시지키를 사용하면 프로듀서가 토픽에 레코드를 전송할때,키의 해시값을 토대로 파티션을 지정하게됨
	즉 같은키면 같은 파티션에 들어감
	단 이거도 어느파티션에 갈지 알수없고,파티션갯수변경시 해시값이 달라져서 다른데갈수있으니 주의해야함
	만약 키가 널이면 라운드로빈으로 분배됨
	메시지값은 실제데이터가 들어있고,직렬화되어 저장되기때문에 컨슈머가 받아갈땐 역직렬화를 거쳐야함
	오프셋은 0이상의 숫자로 이뤄지고,이건 컨슈머가 데이터를 가져갈때 어디까지가져갔는지 확인을위해 사용됨
	헤더는 레코드의 추가정보를 담는 메타데이터저장소임,여기에 키값형태로 데이터를 추가하여 레코드속성을 저장해서 컨슈머에서 받아볼수있음
		
		
  1.카프카 클라이언트		
	카프카클러스터에 명령을 내리거나 데이터송수신을 할때는 카프카 클라이언트를 사용해서 앱을 개발하면됨
	카프카클라이언트는 라이브러리고,프로듀서api,컨슈머api,어드민api로 구성됨
	
	
	프로듀서api는 카프카에다 필요한데이터를 선언하고,브로커의 특정토픽의 파티션에 전송함
	이때 리더파티션을 가진 브로커와 직접통신해서 전달함
	프로듀서는 데이터를 직렬화해서 던지기때문에,모든형태를 브로커로 전송할수있고,그래서 동영상,이미지등도 던질수있음
	
	대충 자바에서 그래들로 라이브러리 받고,
	설정만들고 프로듀서만들고 메시지만들어서 던지면되는듯(82p)
	프로듀서는 브로커로 데이터를 전송할때,내부적으로 파티셔너와 배치생성단계를 거침
	데이터는 파티셔너로 가고,파티셔너는 토픽의 어떤파티션으로 갈지 정하고(기본값은 defaultPartitioner),버퍼에 쌓아둠
	버퍼에서 일정갯수가 되거나,일정시간이 지나면 일괄전송해서 프로듀서처리량을 늘림
	
	추가적으로 카프카프로듀서는 압축옵션을 제공하는데,그래서 브로커로 전송시 압축방식을 정할수있음
	만약 정하지않으면 압축되지않은상태로 전달함
	
	프로듀서를 사용할때는,필수옵션과 선택옵션이 있음
	필수옵션은
		bootstrap.servers:프로듀서가 데이터전송할 대상브로커의 호스트:포트를 1개이상 작성,2개이상이면 한개뻗어도 버틸수있음
		key.serializer:레코드의 메시지키를 직렬화하는 클래스를 지정
		value.serializer:레코드의 메시지값을 직렬화하는 클래스를 지정
	선택옵션은
		acks:프로듀서가 전송한 데이터가 정상저장되었는지 확인할지말지를 정함,
			0은 안받아봄(무조건성공),1은 받아봄,-1은 리더+팔로워 다저장해야 성공,기본값1
		buffer.memory:브로커로 전송할때 버퍼에 모을 양,기본값 32메가
		retries:acks에러떴을때 재시도횟수,기본값 21억
		batch.size:배치로 전송할 레코드 최대용량,기본값 16384
		linger.ms:배치전송하기전까지 기다리는 최소시간,기본값 0
		partitioner.class:레코드를 파티션에 전송할때 적용하는 파티셔너클래스를 지정
		enable.idempotence:멱등성프로듀서로 동작할지여부를 설정
		transactional.id:프로듀서가 레코드전송할때 레코드를 트랜잭션단위로 묶을지 설정,기본값은 사용안함(null)
	등이 있음
	그리고 메시지에서 파티션을 직접 지정해서 던질수도있음
	그리고 특정데이터의 레코드를 특정파티션으로 꼭 보내야한다면,Partitioner인터페이스를 상속받은 커스텀파티셔너를 만들수있음(91p)
	
	카프카프로듀서의 send메시지는 future객체를 반환함,이건 비동기결과를 표현하는것으로,여기다 get을 치면 데이터결과를 동기적으로 가져올수있음
	근데 동기로 전송결과를 확인하는건 여기가 병목이 될수있음,
	그래서 callback인터페이스를 제공하는데,이걸사용해서 커스텀을 만들어 레코드전송결과에 대응하는 로직을 만들수있음(93p)
	그리고 send메서드에서 뒤에 콜백을 넣으면됨
		producer.send(record,new CustomCallback())
	이렇게,그러면 성공실패 결과나올때 뒤에있는콜백이 실행됨
	단 비동기기때문에 순서가 중요할땐 동기로 받아봐야함(실패후 재전송시 순서꼬일수있기때문)
	
	
	프로듀서가 전송한 데이터는 브로커에 적재되고,이 데이터는 컨슈머로 가져올수있음
	예를들면,프로듀서가 마케팅문자를 던지면,브로커가 그걸 토픽에 저장하고,컨슈머는 토픽에서 그걸 가져와서 문자발송처리를 하는거임
	이거도 앱으로 만들수있음
	설정만들고 컨슈머만들고 구독신청하고 무한루프로 받아보면됨
	
	토픽의 파티션으로부터 데이터를 가져가기위해 컨슈머를 운영하는방법은 2가지가 있음
		1.1개이상의 컨슈머로 이루어진 컨슈머그룹을 운영
		2.토픽의 특정파티션만 구독하는 컨슈머를 운영
	가 있음
	
	1번의 컨슈머그룹은 컨슈머를 각 컨슈머그룹으로부터 격리된환경에서 운영할수있게 도와줌
	이건 각 컨슈머들이 토픽의 1개이상 파티션에 할당되어 데이터를 가져감
	이때 파티션은 한 컨슈머그룹에서 최대 1개의 컨슈머에만 할당될수있고,1개컨슈머는 여러 파티션을 할당될수있음
	그래서 컨슈머갯수는 토픽의 파티션갯수보다 같거나 작아야함
	즉 3개의 파티션을 가진 토픽의경우,컨슈머는 3개 이상이 될수없음(정확히는 생성은되는데 놀수밖에없음)
	
	또한 컨슈머그룹은 다른 컨슈머그룹과 독립적으로 동작해서,서로간에 영향을 받지않음(오프셋도 그룹단위로 관리하니)
	즉 컨슈머그룹이 2개고 각각 컨슈머가 3개일때,파티션 3개밖에 없어도 각각 붙을수있다는거(한파티션당 각각1개,2개씩)
	
	이때 컨슈머에 장애가 발생하면,컨슈머에 할당된 파티션은 장애가 발생하지않은 컨슈머에 소유권이 넘어가고,이걸 리밸런싱이라고 부름
	이건 컨슈머가 추가되거나,컨슈머가 제외될때 발생함
	이게 카프카의 가용성을 높이면서 안정적으로 만들어주지만,당연히 자주발생하면안됨(발생할때 잠시동안 컨슈머가 토픽데이터를 읽을수없어짐)
	그리고 브로커중 한대는 이걸 관리하는 그룹조정자의 역할을 맡음
	
	컨슈머는 카프카브로커로부터 데이터를 어디까지 가져갔는지 커밋을통해 기록함
	특정토픽의 파티션을 어떤 컨슈머그룹이 몇번째 가져갔는지를 기록하는데,
	컨슈머동작이슈가 발생하면 처리중복이 발생할수있으니,이걸막기위해 오프셋커밋이 정상처리됐는지를 검증해야함
	오프셋커밋은 명시적으로도,묵시적으로도 처리할수있음
	기본값은 poll()메서드가 실행될때 일정간격(시간)마다 커밋하도록 설정되어있음,이게 묵시적 오프셋커밋임
	만약 데이터중복이나 유실을 허용하면안되면 이 자동커밋말고 명시적으로 처리해줘야하는데,이걸 쓰려면
	poll()이후에 commitSync()를 실행하면 동기적으로 커밋완료를 받아볼수있음(가장마지막오프셋)
	이건 동기처리기때문에 컨슈머처리량에 영향을 미침,그래서 비동기도 있음
	비동기는 commitAsync()를 사용하면됨
	단 비동기는 커밋이 실패했을경우,현재처리중인 데이터의 순서를 보장하지않고,데이터중복처리가 발생할수있음
	
	컨슈머의 옵션도 필수옵션과 선택옵션이 있음
	필수옵션은
		bootstrap.servers:컨슈머가 연결할 브로커정보,2개이상연결하면 하나뻗으면 대신딴거씀
		key.deserializer:레코드의 메시지키 역직렬화클래스지정
		value.deserializer:레코드의 메시지값 역직렬화클래스지정
	선택옵션은
		group-id:컨슈머그룹아이디,subscribe()로 토픽지정구독을 할땐 필수값임
		auto.offset.reset:컨슈머그룹이 특정파티션을 읽을때 저장된 컨슈머오프셋이 없을때 어디부터시작할지 지정
			즉 데이터처음부터,아니면 지금부터,아니면 저장된컨슈머오프셋이 없으면 예외발생시킬수있음
		enable.auto.commit:자동커밋을 쓸지 선택,기본값 true
		auto.commit.interval.ms:자동커밋시 대기시간지정,기본값 5초
		max.poll.records:poll()을 통해 반환되는 레코드갯수를 지정,기본값 500
		session.timeout.ms:컨슈머가 브로커와 연결이 끊기는 최대시간,이시간안에 하트비트를 안날리면 연결끊김,보통 하트비트x3설정,기본값 10초
		hearbeat.interval.ms:하트비트전송시간,기본값 3초
		max.poll.interval.ms:poll()메서드 호출하는 간격 최대시간,이시간안에 다음poll()을 실행하지않으면 문제생겼다고 판단하고 리밸런싱함
			기본값 5분
		isolation.level:트랜잭션프로듀서가 레코드를 프랜잭션단위로 보낼때,커밋된거만 읽을지 안된거도 읽을지 선택,기본값 read_ubcommitted
	이 있음
	
	동기오프셋커밋시 commitSync()에 파라미터가 들어가지않으면,poll로 반환된 가장 마지막레코드의 오프셋을 기준으로 커밋됨
	즉 데이터 받아서 처리하고 for돌릴필요없이 걍 마지막에 커밋날리면끝임
	만약 하나하나커밋하고싶으면 매개변수로 Map<TopicPartition,OffsetAndMetadata>를 넣어주면됨
	그리고 오프셋수동커밋시엔 enable.auto.commit를 false로 바꿔주는걸 잊으면안됨
	
	비동기오프셋커밋을 하면 더 많은 데이터를 처리하면서 수동커밋도 할수있음
	이거도 동기와 마찬가지로 poll의 가장 마지막레코드오프셋을 커밋하는데,
	commitAsync()의 리턴값으로 콜백함수를 받을수있고,이 콜백함수안에 로직을 짜서 처리를 해주면됨(108p)
	콜백함수안에 onComplete를 구현하면됨
	성공했을때랑 실패했을때로 나눠서
	정상적으로 커밋되면 Exception이 null이고,커밋완료된 오프셋정보가 맵에 들어있음
	실패했으면 Exception이 null이 아니고,이걸확인해서 커밋실패이유를 확인해서 로깅하고 뭐하고하면됨
	
	컨슈머그룹에서 컨슈머가 추가 또는 제거되면 리밸런스가 일어나는데,
	poll()메서드를 통해 반환받은 데이터를 모두 처리하기전에 리밸런스가 발생하면 데이터중복처리가 일어날수있음
	데이터일부를 처리했지만 커밋되지않았기때문
	그래서 이럴때 중복처리를 막으려면,리밸런스발생시 처리데이터를 기준으로 커밋을 시도해야함
	이 리밸런스감지를 위해 카프카라이브러리는 ConsumerRebalanceListener인터페이스를 지원함
	얘는 리밸런스가 끝난뒤에 파티션이 할당완료되면 호출되는 메서드와,리밸런스직전에 호출되는 메서드 2개가 있음
	그래서 리밸런스직전에 마지막에 처리한 오프셋+1까지 커밋을 날리는 로직을 구현하고,구독걸때 매개변수로 넣어주면됨(109P)
	
	
	컨슈머를 운영할때 구독을 사용해서 쓰는거말고,파티션을 컨슈머에 명시적으로 할당할수도 있음
	이땐 assign()메서드를 사용하면됨
	이경우엔 컨슈머가 직접 처리하니,리밸런싱같은게 없음
	
	컨슈머에 할당된 파티션을 확인할때는 assignment()메서드를 사용하면됨
	
	컨슈머를 종료할땐 안전하게 종료되어야함,그때는 wakeup()메서드를 사용해서 나올수있음
	저걸 사용하고나서 poll()을 땡기면 예외가 발생하는데,
	그걸받아서 자원을 해제하고 close()메서드로 컨슈머안전종료완료를 알려주면됨
	이러면 컨슈머가 공식적으로 빠지고,컨슈머그룹은 리밸런싱을 진행함
	자바의 경우는 셧다운훅(프로그램종료시 실행되는스레드)에 구현하면됨(113p)
	
	
	어드민api는 브로커에 직접 접속하지않고도 값들을 설정하거나 조회할수있게해줌
	예를들면
		구독하는 토픽의 파티션수만큼 스레드를 생성하거나 할때,토픽의 파티션수를 가져올수있음
		웹 대시보드를 통해 리소스접근권한규칙 추가를 할수있음
		토픽데이터양 증감을 감지하고 해당토픽의 파티션을 자동으로 늘릴수있음
	이건 AdminClient.create(config)로 생성하면됨
	설정은 그냥 configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "my-kafka:9092") 주면됨
	이걸 사용해서 브로커정보,토픽리스트,컨슈머그룹,신규토픽생성,파티션개수변경,접근제어규칙생성 등을 할수있음
	
	
	
	카프카 스트림즈는 토픽에 적재된 데이터를 실시간변환하여 다른토픽에 적재하는 라이브러리임
	카프카의 배치라고 생각하면됨
	이거랑 비슷한일을 하는애들로는 스파크,플링크,스톰,플루언트디 등이 있음
	
	스트림즈는 내부적으로 스레드를 1개이상 생성할수있고,스레드는 1개이상의 태스크를 가짐
	태스크는 스트림즈의 데이터최소처리단위임
	그래서 3개의 파티션으로 이뤄진 토픽을 처리하려면 3개의 태스크가 생김(컨슈머그룹이랑 똑같이된다고 생각하면됨)
	이거도 한 서버에 다때려박을수있지만,보통 분할해서 처리하는편(장애허용),이러면 한군데 문제생겨도 속도가 느려지긴해도 처리는 다 하니까
	
	스트림즈는 트리형으로 구성됨
	배치에서 리더,프로세서,라이터처럼,여기서는 소스(데이터가져오기),스트림(데이터가공),싱크(데이터 쓰기) 3가지임
	이때 스트림이 2군데이상의 싱크에 전달해서,여러토픽에 한번에 적거나,소스에서 스트림2군데로 보내는등 여러응용이 가능함
	예를들면
	스트림즈dsl은
		메시지값 기반 토픽분기처리
		10분간 데이터갯수집계
		토픽과 다른토픽결합
	프로세서api는
		메시지값 종류에따라 토픽 가변전송
		일정시간간격 데이터처리
	이런식으로 처리가 가능함
	
	
	스트림즈dsl은,레코드의 흐름을 추상화한 개념인 KStream,KTable,GlobalKTable가 있음
	이건 스트림즈dsl에서만 사용되는 개념임
	
	KStream은 레코드의 흐름을 표현한것으로,키와 값으로 구성되어있고,이거로 데이터를 조회하면 토픽의 모든 레코드가 출력됨
	즉 컨슈머로 토픽을 구독하는것과 같음
	
	KTable은 메시지키를 기준으로 가장 최신의 값만 출력함,즉 같은키값으로 다른값이 들어올경우 덮어쓰이는느낌
	회원정보같은거를 사용하기좋음
	
	GlobalKTable은 KTable처럼 키를 기준으로 묶는데,
	KTable은 1개파티션기준으로 유니크처리가 되고,GlobalKTable은 모든 파티션,즉 토픽전체기준으로 유니크처리가 됨
	이건 조인같은걸 할때 자주사용되는데,KStream이나 KTable은 서로간의 파티션개수가 동일하고 파티셔닝전략이 동일해야 조인할수있음(코파티셔닝)
	그래야 같은메시지키를 가진 데이터가 같은태스크에 들어가는게 보장되기때문
	만약 파티션갯수가 다르다면 해당토픽으로 새로운토픽을 만들어서(리파티셔닝) 갯수를 맞추는작업을 해야함
	이러면 중복이 발생하고 프로세싱도 해야하는데,
	근데 GlobalKTable를 사용하면 이걸 하지않고 조인할수있음
	KTable을 GlobalKTable로 선언하여 사용하면,이건 코파티셔닝되지않은 KTable과 조인을 할수있음(모든테스크에서 값이 전부같기때문)
	단,이건 모든데이터를 저장하고 사용하기때문에,디스크용량을 많이차지하고 네트워크,브로커에 부하가 걸리므로 작은용량의 데이터에만 사용하는게 좋음
	만약 데이터가 많은걸 조인해야한다면 그냥 KTable을 리파티셔닝을 해서 KTable을 사용하는게좋음
	
  2.카프카 스트림즈	
	스트림즈DSL의 옵션도 필수옵션과 선택옵션이 있음
	필수옵션은
		bootstrap.servers:서버나열,2개이상가능
		application.id:스트림즈 앱을 구별하기위한 아이디,다른로직을 가진 어플리케이션은 서로 id가 달라야함(같은 디플로이먼트면 같게,다르면 다르게)
	선택옵션은
		default.key.serde:레코드의 메시지키 직렬,역직렬화 클래스지정,기본값 바이트직렬화
		default.value.serde:레코드의 메시지값 직렬,역직렬화 클래스지정,기본값 바이트직렬화
		num.stream.threads:스레드갯수설정,기본값1
		state.dir:데이터 저장위치,기본값 /tmp/kafka-streams,상용일경우 바꾸는게좋음
	가 있음	
	
	스트림즈dsl에서는 stream()으로 받아와서 filter()로 처리하고 to()로 적을수있음
	해당토픽을 구독한뒤 자기 처리방식에 맞춰서 테이블을 짜는느낌
	이때 stream()은 KStream을 만드는거고,table()과 globalTable()도 있음
	StreamsBuilder로 이렇게 로직을 짠다음, KafkaStreams로 해당스트림을 빌드해서 start()날리면됨(128p)
	
	filter로 해당값중 필터링을 할수있음
		StreamsBuilder builder = new StreamsBuilder();
		KStream<String, String> streamLog = builder.stream(STREAM_LOG);
		KStream<String, String> filteredStream = streamLog.filter((key,value)->value.length()>5)
		filteredStream.to(STREAM_LOG_FILTER);
	이런식임(필터와 to는 한줄로묶어도됨)
	그리고나서 카프카스트림으로 start()날리는건 똑같음
	
	조인을 칠때는 소스로 2개를 가져온뒤에,join()으로 조인하고 데이터를 가공한뒤 to()로 적으면됨
	이때 가장 중요한건 코파티셔닝이 되어있는지 확인하는것
	조인도
		StreamsBuilder builder = new StreamsBuilder();
		KTable<String, String> addressTable = builder.table(ADDRESS_TABLE);
		KStream<String, String> orderStream = builder.stream(ORDER_STREAM);
		orderStream.join(addressTable,(order, address) -> order + " send to " + address);	
		orderStream.to(ORDER_JOIN_STREAM);
	이런식으로 두개를 조인한뒤에,두테이블의 값을 람다로 처리할수있음
	이경우 orderStream를 풀테이블서치한다음,해당하는 키값을 address로 검색해서 그걸 붙이는느낌일듯
	테이블의 경우 가장 최신값만을 가지고있으니까,해당 키값에 대해 반드시 1개이하가 존재한다는게 보장되니까
	
	만약 코파티셔닝이 되지않아서,GlobalKTable로 만들어서 처리하려면
		StreamsBuilder builder = new StreamsBuilder();
		KTable<String, String> addressGlobalTable = builder.globalTable(ADDRESS_GLOBAL_TABLE);
		KStream<String, String> orderStream = builder.stream(ORDER_STREAM);
		orderStream.join(addressGlobalTable,(order, address) -> order + " send to " + address);	
		orderStream.to(ORDER_JOIN_STREAM);	
	이런식으로 똑같이 처리하면됨
	
	
	커스텀 프로세서api는 스트림즈dsl보다 투박하지만,토폴로지기준으로 처리한다는거에서 같은역할을 함
	만약 스트림즈dsl보다 더 추가적인 상세로직이 필요하면,커스텀 프로세서api를 활용할수있음
	단 이때 커스텀 프로세서api에는 KStream같은게 없다는거에 대해 주의
	
	이건 그냥 Processor<키타입,밸류타입>을 상속받아서,init와 process,close를 구현하면되는데
	이때 ProcessorContext를 init에서 di받고,process에서 이걸사용해서 로직을 짠다음 커밋(ok),포워드(ng)를 선택하면됨
	그리고나서 이걸 사용하는 Topology를 만들어서 소스,프로세서,싱크를 더하고 실행하면됨(151p)
  3.카프카 커넥트	
	카프카 커넥트는 다른사람들이 만들어두거나,내가 미리 만들어둔 프로듀서 컨슈머 앱을 가져다가 쓸수있는거임(템플릿)
	여기서 파라미터로 속성만 받게해서 처리하는식
	어짜피 프로듀서는 데이터저장,컨슈머는 데이터받기를 하는게 메인이니까
	
	커넥터는 프로듀서역할을 하는 소스커넥터와 컨슈머역할을 하는 싱크커넥터로 나눠짐
	만약 파일데이터를 가지고 주고받고하는 커넥터라면,
	파일 소스 커넥터는 파일데이터를 토픽으로 전송하고,파일 싱크 커넥터는 토픽을 파일로 저장하는 역할을 함
	대표적으로 mysql,s3,mongoDB등과 같은 저장소에 대한것들이 있음
	카프카 커넥트는 기본적으로 클러스터간 토픽 미러링을 지원하는 미러메이커2커넥터와,파일싱크,소스커넥터를 기본플러그인으로 제공함
	이외에 추가커넥터를 사용하고싶으면 커넥터jar파일을 추가해서 사용할수있음
	이런식으로 커넥터를 만들거나,커넥터를 받아다쓸수있음(어지간한건 이미 다있음)
		https://www.confluent.io/hub/
	여기가보면 많음
	
	사용자가 커넥터에 커넥터생성명령을 내리면,커넥트는 내부적으로 커넥터와 태스크를 생성하고,커넥터는 태스크들을 관리함
	태스크는 커넥터에 종속되는개념으로 실질적으로 데이터처리를 하는데,그래서 데이터를 정상처리하는지를 확인하려면 태스크상태를 확인해야함
	
	사용자가 커넥터를 사용하여 파이프라인을 생성할때,컨버터와 트랜스폼을 옵션으로 추가할수있음
	컨버터는 데이터처리전에 스키마를 변경할수있게해줌
	트랜스폼은 데이터처리시 각메시지단위로 데이터를 간단히 변환할수있게해줌(json에서 특정키를 삭제하거나 추가하는식)
	
	커넥트를 실행할때는 단일모드와 분산모드가 있음
	이거도 마찬가지로 분산모드가 더 안전함(고가용성때문에 장애에안전함)
	단일모드는 중요하지않거나 개발환경에서 사용
	
	restAPI로 현재실행중인 커넥트의 커넥터플러그인종류,태스크상태,커넥터상태등을 조회할수있음
	8083번포트로 접근하면됨(157p참조)
	단일모드설정과 분산모드설정도 책참조
	이때 단일모드는 커넥트설정과 커넥터설정을 둘다해야하는거에 주의하고,분산의경우 group.id로 같은거 체크된다는거도 주의
	분산모드는 커넥트설정만 하면,restAPI로 커넥트를 실행,중단,변경할수있음
	ip:8083/connectors로 바디에 json을 담아서 post로 보내는식(get날리면 현재실행중인 커넥터목록 표시됨)
	
	소스커넥터는 소스로부터 데이터를 가져와 토픽에 넣는역할을 함
	있는거 가져다쓰면 상관없지만,만들어야하면 SourceConnector와 SoruceTask클래스를 사용해서 소스커넥터를 구현하면됨
	그뒤에 jar파일로 빌드하면끝
	이때는 connect-api라이브러리를 추가하면됨
	
	SourceConnector는 태스크실행전 커넥터설정파일을 초기화하고,어떤태스크클래스를 사용할지 정의하는데만 사용함,그래서 실질데이터처리는 없음
	SoruceTask가 실제 데이터를 처리함,얘는 소스로부터 데이터를 가져와서 토픽으로 데이터를 보내는역할을 수행함 
	여기서 특이한점은,토픽에서 사용하는 오프셋이 아닌,얘 자체적으로 오프셋을 사용한다는것
	그래서 내부적으로 오프셋을 가지고있고,이걸사용해서 데이터중복처리를 막음(파일의경우 마지막으로 보낸 줄번호)
	상세구현은 책참조
	
	싱크커넥터는 토픽데이터를 타깃앱이나 타깃파일로 저장하는 역할을 함
	이거도 SinkConnector과 SinkTask로 구현할수있음
  4.카프카 미러메이커2	
	미러메이커는 서로 다른 두개의 클러스터간에 토픽을 복제해주는 어플리케이션임
	물론 직접 프로듀서컨슈머로 만들어도되지만,이걸사용하면 토픽의 모든것(메시지키,메시지값,같은 파티션진입보장)을 복제해줌
	설정은 189p참고하고,그냥 클러스터 2개 접근방법이랑,어떤토픽을 양방향으로 할지,단방향으로 할지 설정해주는거임
	
	이걸 사용해서 여러가지 확장성있는 클러스터운영을 할수있는데,
		재해복구를 위한 액티브-스탠바이 클러스터 운영(계속 복제치다가 액티브뻗으면 바로 스탠바이로 연결)
		글로벌서비스의 액티브-액티브 클러스터 운영(모든값이 아닌 실제로 사용하는값만 전송해서 지연줄이기)
		모든 카프카데이터를 모아 레이크로 만들기위한 허브앤스포크 클러스터 운영(모든팀들의 클러스터를 복제해서 레이크로 생성)
	등이 있음
	
	
4.카프카 상세 개념 설명
  1.토픽과 파티션
	토픽은 카프카의 시작과 끝이고,토픽에 대해 잘 이해하는게 중요함
	
	토픽의 파티션개수는 카프카의 성능과 관련이있고,적절한 파티션갯수를 설정하고 운영하는게 매우 중요함
	토픽 최초생성시 파티션개수를 정할때 고려해야할건
		데이터 처리량
		메시지키 사용여부
		브로커,컨슈머 영향도
	임
	
	
	데이터 처리량은,파티션은 병렬처리의 핵심이고,
	파티션갯수가 늘어나면 1대1매핑되는 컨슈머개수가 늘어나서 해당 토픽에 필요한 데이터 처리량을 측정해서 정하는게 중요함
	이떄 데이터처리속도를 늘리는방법은,컨슈머의 처리량을 늘리던가(스케일업),컨슈머를 추가하는것(스케일아웃)
	스케일업은 어려우니,스케일아웃을 하는게 젤 간편함,그냥 갯수늘리면되니까
	이떄
		프로듀서 전송량<컨슈머처리량*파티션갯수
	를 해서 계속 쌓이지않는 선에서 처리만 되게하면됨(좀 여유주는거도 괜찮음)
	이 데이터처리량과 전송량은,운영중인 카프카에서 더미데이터로 테스트를 해보는게 젤 확실한데,
	컨슈머는 외부연동이 있을확률이 높기때문에 상용환경에서 테스트를 해야함
	
	컨슈머 데이터 처리량을 구한뒤엔 프로듀서가 보내는데이터양을 하루,시간,분단위로 쪼개서 예측하고,
	만약 데이터지연이 절대 발생하면 안되면 저기중에서 가장 최대치를 잡고,좀 발생해도 일정시간안에만 처리하면되면 그시간값으로 처리하면됨
	
	파티션갯수를 무조건 늘리면 좋은게 아닌게,이러면 컨슈머와 브로커에 부담이 생겨서,지연발생에 대한 서비스영향도를 같이 고려해서 갯수를 구해야함
	
	
	메시지키 사용여부는,정확히는 메시지키를 사용함과 동시에 데이터처리순서를 지켜야할경우에 고려해야함
	처리순서를 지켜야하면 파티션갯수를 변경하면 일이 매우 복잡해지고(해시값이 달라지니),가능하면 넉넉하게 잡고 만드는게 좋음
	물론 처리순서를 안지켜도되면 갯수 막늘려도되니까 타이트하게잡아도됨
	
	
	브로커와 컨슈머 영향도는,파티션은 브로커의 파일시스템을 사용하기때문에 파티션이 늘어나면 브로커의 파일갯수가 늘어남
	근데 os단에서 프로세스당 열수있는 파일최대갯수 제한이 있기때문에 브로커당 파티션개수를 모니터링해야함
	데이터량이 늘어나서 파티션갯수를 늘려야한다면,브로커당 파티션개수를 확인해야하고,만약 너무많다면 브로커갯수를 늘리는것도 고려해야함 
	
	
	토픽의 데이터는 시간이나 용량에 따라 삭제될수있고,삭제를 하지않을수도 있음
	근데 삭제를 하지않으면 비용이 계속 쌓이니까 보통 삭제를 하는데,이때 삭제가 아닌 압축을 사용할수도 있음
	압축은 그 진짜압축이 아니라,KTable처럼 최신키만 남기고 나머지기록들을 다 삭제하는방식임(특별한일없으면 이거보다 삭제를 사용하는편)
	이 압축을 사용하면 오프셋이 중간에 건너뛰고 그럴수있으니 주의하긴해야함(보통 오프셋직접볼일이 없긴하겠지만)
	이때 무조건 같은값나오면 다 압축하게 설정할수있긴하지만,보통 압축되는부분(테일)과 압축되지않는부분(헤드)가 있는데,이 비율에 따라 압축을 할수있음
	즉 n개는 무조건 압축하지않고 들고가다가,n개가 지나서 과거데이터가 되면 압축을 하는식
	이 압축을 너무 자주하면 브로커에 부담을 줄수있으니,토픽별 데이터특성에 맞는 값을 설정하는게 중요함
	
	
	isr(in-sync-replicas)은 복제에서 리더와 팔로워파티션이 모두 싱크가 된 상태를 뜻함(둘의 최신오프셋이 같을때)
	즉 isr인 상태의경우 동기화가 완료된상태이고,이때 리더가 죽어도 팔로워가 바로 대체해도 아무 문제가 없고 데이터는 다 살아있음
	근데 복제에는 시간이 걸리고,이것때문에 데이터가 들어오고 일정시간안에 데이터를 복제하지 못한다면,
	리더는 해당파티션에 문제가 생겼다고 판단하고 해당파티션을 isr그룹에서 제거함
	isr로 묶인 파티션은 리더로 갈 자격이 있지만,아닌파티션들은 자격이 없음
	물론 데이터유실이 별로 중요하지않다면 isr이 아니라도 리더로 선출되도록 설정할수있음
	만약 isr이 없다면 리더의 장애가 발생한 브로커가 재시작될때까지 서비스가 중단됨(대신 데이터유실은 없음)
	이 설정은 토픽단위로 설정할수있음
	
  2.카프카 프로듀서
	프로듀서는 카프카에 데이터를 저장하는 첫단계임
	카프카 클러스터는 3대이상의 브로커로 이루어져서 일부브로커가 뻗어도 데이터유실을 막을수있는데,이때 프로듀서의 설정값을 잘 설정해야함
	
	프로듀서의 acks옵션은 0,1,all(-1)이 있음,이 옵션은 정상처리됐는지를 응답받을건지,또 어디까지 받을건지임
		0이면 그냥 던지고 정상처리되든말든 신경안씀(udp스타일),그래서 속도가빠름
		1이면 리더에 정상처리됐는지까지만 받아봄(기본tcp)
		-1이면 리더와 팔로워까지 정상처리후 복제까지 완료됐는지까지 체크함,느린대신 안전함
	이떄 -1일경우 팔로워 몇대까지 성공했으면 성공했다고 칠지를 선택할수있음(min.insync.replicas)
	이떄 세는갯수는 isr인 팔로워만 세고,이 값이 1일경우엔 acks가 1일떄랑 똑같이동작함(젤먼저 처리되는건 리더일테니)
	그래서 2이상으로 설정했을때부터 의미가있음(보통 2로만둬도 2개 동시에뻗는일이 잘없기떄문에 ㄱㅊ)
	여기서 주의해야할건,총 복제댓수와 이 옵션을 똑같이두면,팔로워나 리더중 하나만 뻗어도 복구전까지 영구히 처리할수없어지기때문에 예외가 발생하니 주의해야함
	그래서 이 옵션은 무조건 최대브로커갯수 미만으로 설정해야함(1이상이어야하고 최대브로커갯수 미만)
	
	
	프로듀서를 멱등성 프로듀서로 설정할수도있음
	기본 프로듀서의 동작방식은 적어도 한번 전달임,무조건 한번은 전달하는거까지만 보장하겠다는뜻,대신 중복이 일어날수있음
	이걸 막기위해 enable.idempotence옵션을 사용해서 정확히 한번 전달을 켤수있음(기본값 false)
	이걸켜면 데이터를 브로커로 전달할때 프로듀서pid와 시퀀스넘버를 같이 전달해서,둘을확인하고 같은메시지의 적재요청이 오면 무시하는식으로 동작함
	단,이건 같은세션에서만 정확히 한번을 보장하기때문에(pid기준),재부팅등으로 pid가 달라질경우엔 같은메시지가 들어갈수있다는거에 대해 주의해야함
	그리고 구조상 시퀀스넘버가 일정하지 않을수있는데,이경우엔 OutOfOrderSequenceException이 발생할수있음
	순서가 중요한경우엔 이 익셉션을 잡아서 어떻게 처리할지를 고려해야함
	
	
	트랜잭션 프로듀서는 다수의 파티션에 데이터를 저장할때,원자성을 부여하기위해 사용됨
	이렇데 트랜잭션으로 묶인 데이터를 컨슈머가 브로커에서 가져갈땐,기본적으로는 트랜잭션 안된식으로 가져가기때문에 컨슈머도 설정을 해줘야함
	일단 프로듀서에서
		enable.idempotence를 true로 설정하고
		transactional.id를 임의의 string값으로 정의
	컨슈머에서
		isolation.level을 read_committed로 설정
	이러면 프로듀서와 컨슈머 모두 트랜잭션으로 처리완료된 데이터만 읽고씀
	
	트랜잭션은 파티션의 레코드로 구분되고,프로듀서는 레코드를 보낼때 트랜잭션의 시작과 끝을 표현하기위해 트랜잭션레코드를 하나 더 보냄
	컨슈머는 이걸 보고 트랜잭션이 끝났는지 아닌지를 확인하고 데이터를 가져감(즉 트랜잭션시작부터 끝까지 한번에가져감)
	이 트랜잭션레코드는 데이터를 포함하지않고,트랜잭션이 끝났다는거만 표현함
	대신 얘도 레코드기때문에 오프셋을 하나 차지함
	즉,파티션에서 transactional.id가 있는값은,해당하는 id의 commit가 나올때까지 기다렸다가 한번에 긁어오는느낌
  3.카프카 컨슈머
	컨슈머는 카프카에 적재된 데이터를 처리함
	
	카프카는 처리량을 늘리기위해 파티션과 컨슈머갯수를 늘려서 운영할수있음
	파티션을 여러개로 운영할때,데이터병렬처리를 위해 파티션갯수와 컨슈머갯수를 동일하게 맞추는게 가장 좋고
	파티션은 1개컨슈머가 할당되어 데이터를 처리할수있음
	그래서 파티션갯수가 n개면 동일컨슈머그룹으로 묶인 컨슈머스레드를 n개 운영할수있고,
	즉 n개의 스레드를 가진 프로세스 1개나,1개의 스레드를 가진 프로세스n개를 운영할수있음(단일스레드vs멀티스레드)
	전자의경우 단일스레드를 스케일아웃해서 쓰면되고,후자의경우를 지원하기위해 멀티스레드 컨슈머를 카프카는 지원함
	
	이 멀티스레드 컨슈머의 경우 고려할부분이 많음
		한 워커스레드의 예외발생으로 프로세스가 종료되고,다른스레드들의 데이터유실
		컨슈머스레드간 영향이 미치지않도록 스레드세이프로직,변수적용
	등이 있음,단 효율이 좋긴함
	이 멀티스레드에서도 2가지방식이 있는데
		컨슈머는 1개만 실행하고,워커스레드를 여러개 실행(데이터 처리가 느릴경우),멀티워커스레드라고 부름
		컨슈머스레드 자체를 n개 실행(데이터처리가 할만할경우),컨슈머멀티스레드라고 부름
	가 있음
	
	멀티워커스레드의 경우 레코드의 처리속도자체가 빨라짐,이건 ExecutorService라이브러리를 사용하면 편함(220p)
	스레드풀을 생성하고 관리하는식
	이경우에 주의해야할건
		스레드를 쓰는것때문에,데이터처리가 일어나지않았는데 커밋을 치기때문에,리밸런싱,컨슈머장애시 데이터유실가능성이 있음
		레코드처리의 순서가 보장되지않음,스레드에서 순서지켜서 처리하지않으니
	가 있음,그래서 이건 서버리소스 모니터링이나 데이터수집같은 순서가 중요하지않은거에 유용함
	
	컨슈머멀티스레드는 진짜 컨슈머를 여러개만드는거임,이때 컨슈머는 토픽의 파티션개수만큼만 운영해야함,더있어봐야 쓸데없음(223p)
	
	
	컨슈머랙은 토픽의 최신오프셋과 컨슈머오프셋간의 차이임,프로듀서는 계속 새로운데이터를 파티션에 저장하고,컨슈머는 자기가 처리할수있는 만큼만 가져감
	이때 나는 차이가 컨슈머렉임
	컨슈머랙은 컨슈머가 정상동작하는지를 확인할수있기떄문에,컨슈머를 운영할떄 필수적으로 모니터링해야함
	
	컨슈머랙은 컨슈머그룹과 토픽,파티션별로 생성됨(즉 각 컨슈머그룹마다,파티션마다 각각 생성함)
	만약 컨슈머랙이 점점 커지면,프로듀서의 데이터전송량이 컨슈머데이터처리량보다 크다는것
	만약 컨슈머랙이 점점작아지던지 0에 수렴하면 지연이 없다는것
	
	이때 컨슈머랙이 점점 커질때가 장애분기점인데,이때도 여러종류가있음
		프로듀서의 전송량이 커져서(추석,설날등)컨슈머랙이 올라감->스케일아웃으로 대처
		프로듀서의 전송량은 그대로인데 컨슈머랙이 올라감->해당 컨슈머랙이 올라가는 파티션에 붙은 컨슈머장애
	이 컨슈머랙을 확인할때,카프카 명령어로 조회할순있지만 이건 로컬이나 개발에서의 단기테스트용이고,모니터링을 할려고하면 외부 모니터링툴쓰는게 젤나음
	카프카버로우나 데이터독등을 사용해서 수집하고,그라파나같은거로 보는식으로 할수있음
	카프카 버로우를 사용하면,단순히 랙이 커진거만 아니라 슬라이딩윈도우를 사용해서 실제 장애발생인지 아닌지를 체크해서 알림을 던져줌
	설정은 237p참고
	
	컨슈머를 배포할때는 무중단과 중단배포가 있음,무중단은 블루그린이나 롤링을 사용하면되고,중단은 인스턴스못늘릴떄 사용하면됨
	롤링업데이트시 주의할건,파티션갯수가 많을수록 n번 끄고킬때마다 계속 리밸런스를 해야하니 파티션갯수가 적을떄만하는게 좋음
  4.스프링 카프카
	
  
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	