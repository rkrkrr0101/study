캐글 번역할떄 iframe긁어와서 style="overflow:scroll; height:950px;"로 스크롤바추가

캐글에서나 할때 미리 테스트데이터 갯수만 적어둔다음에 합쳐서 전처리끝내고 다시 나누는게 편한듯
그리고 카테고리는 그냥 다 원핫인코딩하는게 편하고 
pd객체는 그냥 사이킷런 standardscaler로 스케일조정하는게 편함
그리고 모델인풋크기는 그냥 pd객체[1]주면 그크기만큼 알아서 하니까 중간에 바뀌어도 자동으로 조정되고 편함



범주형에서 범주를 숫자로 바꿀때
	xtrain['Sex']=xtrain['Sex'].astype('category').cat.codes 
cut에서도 똑같이쓸수있음
	xtrain['agecut']=pd.cut(xtrain['Age'],6).cat.codes	

숫자를 범주로 바꿀떈
	ytain=keras.utils.to_categorical(ytain,갯수) 
쓰면됨
	
	
	data.isnull().sum() 
널값있는거 개수보기 각 컬럼별로

이미지의 y값(정답)은 당연히 카테고리화 해놓아야함


만약 각 로우별 인덱스값 필요하면 (csv컬럼에)
	res=pd.concat([pd.Series(range(1,28001), name="ImageId"),res],axis=1)


tfrecord 안에 이진데이터읽기나 tpu연결코드는 그냥 있는거쓰자



자연어처리에서 pad_sequences는 가변길이 시퀸스를 예측할때 사용함



GLOVE_EMB = '/kaggle/input/glove6b/glove.6B.300d.txt' 임베딩시 미리 임베딩완료된거집어넣고 그거가지고 연산하면 더높게잡힘
->한 2%정도나는듯

임베딩후 Tokenizer()은 초기화도 하면안되고 fit_on_texts도 하면안되고 그냥 pad_sequences만 테스트에 해서 토큰화시켜야함,
리셋하면 트레인훈련데이터사라짐

합성곱 전치층(Conv2DTranspose)에서
(패딩이 same일경우) 전치층의 입력값* 스트라이드의 배수만큼 (2이면 2배 3이면 3배) 출력값의너비높이가 커짐(채널은 정한크기대로나오고)
(패딩이 valid일경우) (입력값-1)*스트라이드의배수+필터수만큼 나옴(채널은 정한크기대로나오고)


