1.경진대회란
	1장은 뭐없으니 스킵

2.평가지표
1.문제종류
	보통 문제는 회귀,분류,추천이 있는데 
	회귀는 mse를 쓰고
	분류는 
		이진분류는 바이너리 크로스엔트로피
		다중클래스분류는 멀티 클래스 크로스엔트로피,mse,카테고리컬 크로스엔트로피를 사용
	
	추천은 분류의 하위라고 보면됨(이진분류로 품,각 사용자가 a,b,c상품을 구매할지 말지를 분류하는식으로)
	
2.데이터셋
	1.정형데이터
		정형데이터는 csv같은 행과 열이 있는 형식의 데이터
	2.외부데이터
		외부데이터는 캐글에서 주는데이터가 아닌 외부에서 가져온데이터,대회마다 사용가능,불가능한게 있고 사용할땐 공개해야함
	3.시계열데이터
		시간의 흐름에 따라 관측된 데이터,즉 데이터의 순서에 인과관계가 있을수있음(음식점의 일별 손님수,주식그래프등)
	4.기타데이터
		이미지,동영상,음성등의 데이터,얘들은 딥러닝을 많이 사용함(합성곱)
		
		
		
		
		
		
3.평가지표
	평가지표는 모델의 성능이나 예측결과의 좋고 나쁨을 평가하는 지표임
	그래서 목적함수랑 겹치는 부분이 많음
	1.회귀의 평가지표
		1.rmse
			mse에 루트씌운거 
			각 데이터에 예측값과 실제값의 차이를 제곱하고 평균을 내 루트씌움
			특성상 회귀문제에 사용편함 목적함수로
		2.mae
			mse에 절대값씌운거,이상치영향을 좀 덜받는대신,좀 쓰기힘듬(2차미분0,미분 불연속)
		3.결정계수
			회귀분석의 적합성을 나타내는데,이지표의 최대화는 rmse의 최소화와 같음
		
	2.이진분류의 평가지표
		이진분류의 평가지표는 크게 두개로 나눔
		결과값만 중시하는것(혼동행렬기반)
		확률값대로 계산하는것(크로스엔트로피기반)
		1.혼동행렬
			tp,tn,fp,fn으로 나누는 그거
			이쪽이 기반이되는 평가지표는 임계값을 올렸다내렸다 한다는걸 미리 바닥에 깔아두고있음
			
			1.정확도
				정확하게 예측한 비율,(tp+tn)/전체행수
				이건 이거자체로는 쓰기힘들어서(불균형한 데이터일때 전부 p나 n으로 밀면 정확도높게나옴)잘안씀
			2.정밀도와 재현률 
				양성으로 예측한값중 실제값도 양성일 확률은 정밀도
				실제값이 양성인거중 예측값이 양성일 확률은 재현율
				
				즉 정밀도는 진짜 확실한거말고는 다 네거티브에 던져서 사기칠수있고
				재현율은 다 포지티브에 던지면 사기칠수있어서
				둘을 섞은 f1스코어를 주로 사용함
			3.f1스코어
				정밀도와 재현율을 섞은것
				
		2.로그손실
			1.바이너리 크로스 엔트로피
				기본적인 바이너리 크로스엔트로피
				확률이 크게 틀리면 값을 많이더하고(머리를 세게치고)확률이 거의 맞으면(양성인데 0.95라던가)값을 조금만 더하고(살살 톡건드리고)
			
			
			2.auc
				roc곡선의 아래면적을 auc라고 부르나봄
				roc곡선은 임계값을 움직일떄의 거짓양성비율(진짜거짓인걸 양성으로 잘못예측한비율(fp/(fp+tn))과 
				참 양성비율(tp/(tp+fn))을 그래프의 xy축으로 나타낸것
				
				
				

	3.다중클래스 분류의 평가지표
		1.멀티 클래스 액츄얼리
			이진분류의 정확도를 다중클래스로 확장한것
			예측이 정답인 행 데이터 수를 모든 행 데이터 수로 나눈 결과
			
		2.멀티 클래스 로그손실(크로스엔트로피)
			이진분류의 바이너리 크로스엔트로피를 멀티클래스로 확장한것
			각 클래스의 예측확률을 내고 행 데이터의 예측확률에 로그를써서 부호를 반전시킨값이 점수임
			
		3.meanf1,macrof1,microf1
			말그대로 다중레이블에서의 f1평균값들
			mean은 전체평균낸거
			macro는 각 클래스별f1평균값,얘는 각 클래스에서 이진분류를 하고 그거의 f1스코어를 평균하는것과 같아서,
			다중레이블에서는 각 클래스별로 독립적으로 임계값을 최적화 가능(즉 a,b,c 세레이블이 있으면 각기 f1스코어를 하나씩 가지는거)
			micro는 행데이터x클래스의 각 쌍에대해 어디인지(tp,tn,fp,fn)카운트해서 그 혼동행렬에 근거해서 f1을 계산함
			
		4.qwk
			이건 다중클래스 분류에서 클래스간의 순서관계가 있을때 사용(영화점수 1~5라던가)
			각 행 데이터의 예측값이 어느클래스에 속하는지 제출함
			즉 이건 순서가 멀리 떨어질수록 패널티를 세게줌(5점이 레이블인데 2점예측했다던가)
			얘는 완전한예측이면 1,랜덤일땐 0 랜덤보다 나쁘면 -값을 줌
			
	4.추천의 평가지표
		1.MAP@k
			얘는 각 행 데이터가 하나 또는 여러 클래스에 속할떄,포함될 가능성이 높을것으로 예측한 순서대로 k개를 예측값으로 삼음
			단 k번째 예측값이 정답일경우에만 값을 취하고,그 외에는 0이됨
			계산방식은 1번부터 k번까지 가면서 분모는 계속+1을 하고 분자가 정답일때만 +1을 해서 k번까지 가는 식
				1번 정답 1/1
				2번 오답 --1/2 총합에는빠짐
				3번 정답 2/3
				...
			이런식
			저기에 답의 갯수로 총합을 나누면 map@k
				(5/3)/정답수
			
			
4.평가지표와 목적함수
	1.평가지표와 목적함수의 차이점
		기본적으로 평가지표는 목적함수로 사용할수있음(같은함수를 사용하는경우가 많음)
		그렇지만 평가지표가 좀 더 제약이 덜함(목적함수보다)
		목적함수는 미분을 할수 있어야함(그레이디언트 최소화)
		그리고 보통 회귀는 mse,분류는 크로스엔트로피를 자주 사용함
		
		만약 목적함수와 평가지표를 통일시킬수있다면 통일시키는게 좋음
		
	2.사용자 정의 평가지표와 목적함수
		실제로 뭐 이상한 목적함수를 요구하면 만들어쓸수도 있음(머신러닝책참고)
		
		
5.평가지표의 최적화
	평가지표랑 목적함수를 통일시킬수있으면 통일시키는게 좋음
	학습데이터를 전처리해서 평가지표를 통일시킬수있음(레이블에 로그를써서 변환하고 학습시킨뒤 로그를 푼다던가)
	다른 평가지표를 사용하고 후처리
	사용자 정의 목적함수의 사용
	다른 평가지표를 사용하고 조기종료
	
	1.임계값 최적화
		임계값을 0.5가 아닌 최적의 임계값을 찾기
		단 트레인데이터에 하면 오버핏날수있으니까 분할해서 검증(oof)
		
		하는건 0.01부터 0.99까지 다 돌려보거나,scipy.optimize사용
		
	2.예측확률과 조정
		평가지표를 최적화하려면 타당한 예측확률이 필요함
		보통 신경망등은 크로스엔트로피를 목적함수로 사용하니까 대충 타당한 예측확률이라고 할수있는데,
		이게 특정원인에 따라 왜곡될수있는데 이때 확률을 조정하면 점수가 올라갈수있음
		
		1.예측확률의 왜곡
			1.데이터가 충분하지 않을때
				데이터가 적으면 0이나 1에 가까운 확률을 뱉기힘듬
			2.모델 학습 알고리즘상 타당한 확률을 예측하도록 최적화 되지 않은경우
				랜덤포레스트같은데 크로스엔트로피를 쓴다던가 그러면 확률이 꼬임(이진트리랑 안맞으니까)
			
		
		2.예측확률의 조정
			1.예측값을 n제곱
				마지막에 예측값을 0.9~1.1을 곱해서 보정할수있음
			2.0이나 1에 가까운확률 제외
				너무 큰 패널티를 피하는것(0.1~99.9까지만 받는다던지)
			3.스태킹
				확률예측모델을 사용(신경망쓰면 됨)
			4.calibratedcalssifierCV사용
				예측값을 보정하는 방법인데,시그모이드나 등위회귀등을 선택할수있음
				얘는 0이나 1에 한없이 가까운 확률을 보정함
				
				
6.데이터 정보 누출
	1.예측에 유용한 정보 누출
		막 테스트데이터같은게 유출되는것
		중반이후에 갑자기 말도안되는점수 올라오면 이거찾아다녀야함
	2.검증방법이 잘못된 누출 
		oof에서 막 id값같은걸 사용해서 학습했는데,테스트데이터는 그런게 없을수있음
		이건 5장에서 다시보자




3.특징생성
1.모델과특징
	1.모델과 특징의 관계
		모델에 따라 특징을 먹는 방식이 있음
		gbdt같은경우
			수치의 크기(범위)는 의미가 없고 크고작은관계만 영향이 있음(트리니까)
			결측값이 있어도 그대로 처리가능
			결정트리 내부 반복작업에따라(안에서 분기갈리는거에 따라) 변수간 상호작용을 반영함
			
		즉 수치의 대소관계가 영향을 안주니 정규화를 안해도되고,결측값을 꼭 채워야하는것도아니고(에러가안뜸)
		범주형을 원핫인코딩이 아닌 레이블인코딩(0,1,2,3으로 인코딩하는거)해도 됨
		그래서 gbdt를 간단하게쓸떄 자주씀
		
		신경망은
			값의 범위에 영향을 받음
			결측값을 채워야함
			앞층의 출력을 결합하여 하는 계산으로 변수간 상호작용을 반영함
		
		즉 수치의 대소관계에 영향을 받아서 정규화해야하고,결측값은 꼭 채워야하고(안채우면에러)
		레이블인코딩한 값이 그대로 쓰이니까(숫자크기에 영향을 받으니까(1과4보단 1과2가 가깝다고 생각하는것))레이블인코딩보단 원핫인코딩이 더 좋음
		
	2.베이스라인이 되는 특징
		gbdt는 그냥 id만 지우고 범주형을 레이블인코딩하면 바로 베이스라인으로 쓸수있음(결측치도 안매워도되니까)
		신경망은 범주형을 원핫인코딩하고 결측값을 채우고 표준화를 한걸 기본베이스라인으로 쓸수있음
		
	3.결정트리의 사고방식으로 생각하기
		특징이 유효할지 생각할때 결정트리처럼 생각하면됨
		기본적으로 데이터를 입력하면 변수간 상호작용이나 비선형관계성도 정확히 반응하여 예측하지만(분기를 조합하여 상호작용이나 비선형의 관계성이 표현가능하니까),
		그러나 기본적으로 존재하지않는 정보를 입력정보로 반영할수는 없음,그리고 상호작용을 직접 표현한(두특징을 합쳐서 컬럼에넣었다던가,명확한특성)특징이 있으면
		그걸 반영하는게 더 쉬움
		
		그러니까 우리가 해야할건 입력으로 읽어낼수 없거나(아예 다른데이터셋에 있거나),읽기 어려운(찾아내기 좀 빡세보이는 특징)을 뽑아내서 생성해줘야함
		즉 평균단가같은게 레이블결정에 크게 영향을 주는데,이걸 그냥 판매금액과 판매갯수로 들어가있어도 어느정도 반영이 되긴하지만,
		둘을 나눈 컬럼을 추가하면 더 정확하게 100%반영이됨
		
		
		
2.결측값 처리
	결측값은 몇가지 이유로 만들어지는데
		값이 존재하지 않거나(개인과 법인데이터가 섞여있을때 법인의 나이)
		특정의도가 있는경우(측정을 하지않음(데이터가없음))
		값을 얻는데 실패한경우(오류로 입력이안됨)
	gbdt는 결측치무시하고 쓰면되는데 신경망은 채워줘야함
	
	여기서 몇가지 선택사항이 있음
	1.결측값인채 사용
		gbdt에서는 사용가능한 방식
		만약 결측값이 에러뜨는데 결정트리식모델이면 결측값을 -9999처럼 안쓰는수로 바꿔주면됨
	2.대푯값으로 채우기
		제일 많은수나,평균값으로 채우기
		근데 결측값이 랜덤하게 발생하는게 아니면 추천할만한 방법은 아님(결측이 발생하는 이유가있을때)
		또 다른방법은 다른 컬럼의 범주형값으로 그룹을 만들어서 그 그룹의 평균을 넣던가할수도 있음
	3.다른변수로 결측값 예측하기
		결측값을 예상하는 모델을 만들어서 그거로 넣을수도있음,당연하지만 여기서도 레이블은 뺴야함 테스트데이터엔 레이블이 없으니까
		
		na인걸 전부 테스트데이터로 사용하고 값있는거만 남기고 그거가지고 모델돌리고 na값에 예측해서 넣고 그걸 사용하는식
		
	4.결측값으로 새로운 특징 만들기
		결측값 자체가 특징이라고 할수도 있으니까,새 필드를 만들어서 거기다 이게 특정컬럼이 결측이었냐 아니냐를 0,1로 나타내게 할수있음
		그리고 결측값이 여러개 나타날때 그 조합을 패턴으로 분류할수있으면,그 패턴을 원핫인코딩할수있음
	
	5.데이터의 결측값 인식
		결측값이 공백이나 na가 아니라 -1이나 9999같이 입력되어있을수도 있으니까 히스토그램등으로 확인해야함
		그리고 어떤 컬럼에선 -1이 결측값인데 어떤건 -1이 유효한값이면 해당컬럼을 읽어서 치환시키면됨(b['ggg'].replace(-1,np.nan))
		
		
3.수치형 변수 변환
	수치도 변환을 하긴해야함(정규화같은거나 그룹핑하는거)
	그리고 여기서 중요한게 캐글에서는 학습데이터랑 테스트데이터를 결합해서 평균분산을 계산하고 다시 떼는게 좋음(일이편함)
	그냥 만들때는 예측대상 데이터가 없을테니까 학습데이터기준으로 해야겠지만
	1.표준화
		말그대로 정규화하는거
		모델밖에서 할떈 사이킷런의 standardscaler쓰면되고 모델안에선 어짜피 배치노말라이제이션쓰겟지
	2.최소최대스케일링
		이건 최소값을 전체에 뺀후에 max-min으로 나눈거
		최대는 1이되고 최소는 0이됨
		
		이건 보통 숫자형에는 잘 안쓰고 이미지나 소리같은데서 사용함(픽셀은 0~255가 정해져잇으니까)
		숫자는 표준화사용함
	3.비선형변환
		앞에거는 그냥 숫자만 줄지 그래프의 형태는 바뀌지않음(분포는 안바뀜)
		이건 데이터가 불균형상태일때 데이터의 형태를 바꾸는거(값이 커지면 많이깎는다던가)
		
		1.로그변환
			이건 log(x+1)을 씌우는거
			+1은 log 0들어갈까봐 해둔거
			만약 -값이 있으면 절대값씌우고 로그하고 다시 부호붙이면됨
			
		2.박스칵스변환,여존슨변환
			이건 로그변환을 일반화한거(박스칵스)와 그걸 음수에도 사용할수있게한거(여존슨변환)
			사이킷런에 있으니까 필요하면검색
		
		
		이런거들을 사용하고나면 그래프가 보통 표준분포에 가까워짐(중앙이 높은 산모양)
		
	4.클리핑
		이건 상한 하한을 잘라내서(상한 하한값으로 치환) 이상치를 없애는거
		간단하게는 1%와 99%를 잘라낼수있음
		이러면 그래프가 압축되어서 표시잘될수있음
		
	5.구간분할
		구간별로 범주형변수로 만들어서 사용하는거
		데이터에 대한 사전지식이 있고 나눠야하는 이유가 있을때 효과적임
		이걸 범주형의 중간값으로 치환할수도있고,원핫인코딩할수도있고 그럼
		
	6.순위로 변환
		수치형 변수를 대소관계에 따른 순위(1~9이런식으로)바꿀수도있음
		수치의 크기나 간격을 버리고 대소관계만을 얻는 방법
		
	7.rankgauss
		이건 순위로 변환한후 순위를 유지한채로 반강제적으로 정규분포로 바꾸는것
		신경망에서 일반적인 표준화보다 성능이 좋다고함
		
		
4.범주형 변수 변환
	범주형 변수 변환에선 원핫인코딩,레이블인코딩,임베딩등 여러방법이 있음
	그리고 수치형변수라고 해도 값의 크기나 순서에 의미가 없으면 범주형변수로 인코딩해야함(1~9로 종류나눠둔거)
	
	그리고 학습데이터엔 없고 테스트데이터에만 존재하는 범주가 있을땐
		대응하지 않아도 될경우
			특별히 영향안주는 하꼬데이터면 무시함
		최빈값이나 예측으로 보완
			결측값으로 간주해서 모델만들어서 예측하거나 자주나오는값으로 매꾸기
		해당 변환의 평균으로 입력
			학습데이터 전체의 최빈값으로 채움
			
			
	1.원핫인코딩
		가장 대표적인 처리방법
		범주의 각 레벨(카테고리)에 대해 맞는지 아닌지를 0,1로 표현함
		이건 문제가 범주형변수의 레벨이 많은경우 특징갯수가 엄청나게 늘어남
		이런경우
			다른인코딩방법을 찾던가
			규칙을 찾아서 그륩화해서 레벨을 줄이던가
			빈도낮은걸 모아서 기타로 넣던가
		
	2.레이블 인코딩
		각 레벨을 단순하게 정수로 변환(aaa,bbb,aaa->1,2,1)
		이러면 결정트리는 상관없는데,신경망같은건(사실상 결정트리뺴고 전부) 숫자크기에 영향을 받음(1과2가 1과4보다 가깝다고생각하는등)
		타깃정도만 레이블인코딩 할수있음(0,1 이진이라던지 이럴떄)
		
	3.특징 해싱
		원핫인코딩에서 특징수가 정해져있는경우(a3815,b2232)계수정렬처럼 하나하나 떼서 원핫인코딩하는거(a,3,8,1,5 b,2,2,3,2 이런식)
		캐글에선 잘 안쓰긴하는듯
		
	4.프리퀀시 인코딩
		각 범주의 출현 횟수나 빈도로 변수를 대체함
		출현빈도와 목적변수와의 관련성이 있을때 사용
		근데 이렇게쓰면 동률이 나올수도 있으니 주의해야함
		
	5.타깃인코딩
		목적변수(레이블)을 사용하여 범주형을 수치형으로 변환하는것
		이건 잘못쓰면 데이터누출확률 올라감
		
		특정 범주형을 전부 카운트한다음에 그거의 목적변수의 평균을 내서 그걸 대입해버림
		그러니까 잘못하면 데이터누출나서 오버핏남
		
		그래서 이거 사용할때는 데이터를 나눈후 자신을 제외한 나머지폴드들의 평균을 넣는식으로 좀 막을수있음
		테스트데이터에선 트레인데이터 전체를 사용해서 넣고
		
		1.누출
			만약 어떤 레벨에 속하는 데이터가 1개일때 해당레벨의 타깃인코딩값은 목적변수 그 자체가 되어버림
			극단적으로 프라이머리키로 돌리면 당연히 목적변수가 쓰이니까 정답을 먹여주는꼴이됨
			
		2.폴드시 문제
			폴드수가 너무 많아져도 문젠데 그럼 나누기의 값을 보고(0.5,0.25) 값을 추측해서 목적변수 누출이 일어날수있음
			그래서 4~10개만 폴드만드는게 좋음
			
		3.기타 누출막는법
			노이즈 추가하거나 데이터 수가적은레벨은 데이터전체 평균값과 가중치 부여하는식으로 막을수있음
			
			
	6.임베딩
		범주나 자연어등을 실수벡터로 변환하는거
		임베딩 자체도 하나의 모델로 볼수있음
		
		임베딩쓸땐 이미 처리 끝난 모델들 있으니까 그거가져다쓰면됨

	7.순서변수의 취급
		순위처럼 순서관계에만 의미가 있고 간격은 의미없는애들(등수)
		보통 수치형으로 치환할수도있고(a,b,c->1,2,3)범주형으로 치환할수도있음
		
	8.범주형 변수값의 의미 추출
		만약 레벨이 무의미한게 아닌 의미가 있다면(abc-00123에서 abc가 로뜨넘버라든가)abc랑 숫자를 분리해서 사용할수도 있음
		그냥 임베딩돌리면 의미가 사라져버림
		
		
		
5.날짜및 시간변수 변환
	날짜와 시간은 시계열데이터니까 주의할점이 있음
	만약 같은 날짜를 테스트와 트레인으로 짤랐다면 날짜시간특징을 트레인으로 훈련하면 테스트에도 같은 영향을 주지만,
	미래정보를 테스트로 주고 그 전 데이터가 트레인이면 같은 영향을 준다는 보장이 없음(일단 연도부터가 다름)
	
	이럴땐 연도정보를 빼버리거나 ,최신데이터만 사용하거나(테스트와 가까운) 하는게 오히려 더 좋은 모델이 나올 가능성이 있음
	
	그리고 주기성이 있는 데이터가 있을때,만약 주기가 2번이상 돌아가지 않을경우(2년이하일경우) 예측이 떨어질수있음(이게 주기적으로 이러는건지 확신을 하지못함)
	
	이럴땐 월을 빼버리고 일수(30 60 90)로 바꿔버리고 이걸 특징으로 사용할수도 있음
	
	1.주기성 변수다루기
		월같은 주기성변수를 단순원핫인코딩해버리면 서로간의 관계가 날아가버려서 정보가 손실되고,수치로 다뤄도 12~1의경우 반영이 제대로안됨
		그래서 두개의 변수로(xy좌표로) 원형으로 나타내는방법도 있는데 이경우도 3월9월을 같은레벨에 있다고 취급할 위험성이 생김
		
	2.날짜변수와 시간변수로 만드는 특징
		1.연도
			연도데이터가 예측에 유효하게 작용할지 아닐지는 데이터 분할방식에 따라 다름(주가는 연도에 영향을 받는데 그건 테스트트레인이 같이잘려야함)
			이때 추가하는 방법은
				단순추가
				연도정보를 특징에 추가하되 테스트데이터에만 존재하는 연도를 학습데이터의 최신연도로 치환
				연도를 사용하지않음
				연도와 월을 사용해서 학습데이터의 사용기간을 제한
				
		2.월
			월 정보를 넣으면 1년간의 계절성을 파악할수 있음
			단 2년미만일땐 빼는게나음
			
		3.일
			일을 수치로 넣으면 월에 주기적인 경향이 있을때 일정보를 토대로 파악할수있음(월급날,월초,월말)
			이걸 전부 원핫인코딩하면 변수가 너무 많아지니까 특징있는날에만(월말 월급날 월중간 월초)해당일인지 아닌지 바이너리로 변수만드는게 좋음
			
		4.요일,공휴일,휴일
			요일은 원핫인코딩도 쉽고(값이 7개뿐임)혹은 공휴일을 포함해 휴일인가 아닌가로 원핫인코딩할수도있음
			
			또 설날이나 크리스마스같은걸로 사용할수도있음
			
		5.시분초
			시간을 사용하면 하루중 주기적인 움직임을 반영할수 있음(24개변수)
			보통 분초는 안쓰고 시간도 3시간단위 이렇게쓸수도있음(8개변수)
			
		6.시간차
			건물지은지 얼마됐는지 이런걸로 값 2개빼서 시간의 차이를 사용할수도 있음
			즉 데이터 별로 다른 시간을 기준으로 삼아 시간차를 뽑아냄
			

















