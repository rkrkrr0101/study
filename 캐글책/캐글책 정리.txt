1.경진대회란
	1장은 뭐없으니 스킵

2.평가지표
1.문제종류
	보통 문제는 회귀,분류,추천이 있는데 
	회귀는 mse를 쓰고
	분류는 
		이진분류는 바이너리 크로스엔트로피
		다중클래스분류는 멀티 클래스 크로스엔트로피,mse,카테고리컬 크로스엔트로피를 사용
	
	추천은 분류의 하위라고 보면됨(이진분류로 품,각 사용자가 a,b,c상품을 구매할지 말지를 분류하는식으로)
	
2.데이터셋
	1.정형데이터
		정형데이터는 csv같은 행과 열이 있는 형식의 데이터
	2.외부데이터
		외부데이터는 캐글에서 주는데이터가 아닌 외부에서 가져온데이터,대회마다 사용가능,불가능한게 있고 사용할땐 공개해야함
	3.시계열데이터
		시간의 흐름에 따라 관측된 데이터,즉 데이터의 순서에 인과관계가 있을수있음(음식점의 일별 손님수,주식그래프등)
	4.기타데이터
		이미지,동영상,음성등의 데이터,얘들은 딥러닝을 많이 사용함(합성곱)
		
		
		
		
		
		
3.평가지표
	평가지표는 모델의 성능이나 예측결과의 좋고 나쁨을 평가하는 지표임
	그래서 목적함수랑 겹치는 부분이 많음
	1.회귀의 평가지표
		1.rmse
			mse에 루트씌운거 
			각 데이터에 예측값과 실제값의 차이를 제곱하고 평균을 내 루트씌움
			특성상 회귀문제에 사용편함 목적함수로
		2.mae
			mse에 절대값씌운거,이상치영향을 좀 덜받는대신,좀 쓰기힘듬(2차미분0,미분 불연속)
		3.결정계수
			회귀분석의 적합성을 나타내는데,이지표의 최대화는 rmse의 최소화와 같음
		
	2.이진분류의 평가지표
		이진분류의 평가지표는 크게 두개로 나눔
		결과값만 중시하는것(혼동행렬기반)
		확률값대로 계산하는것(크로스엔트로피기반)
		1.혼동행렬
			tp,tn,fp,fn으로 나누는 그거
			이쪽이 기반이되는 평가지표는 임계값을 올렸다내렸다 한다는걸 미리 바닥에 깔아두고있음
			
			1.정확도
				정확하게 예측한 비율,(tp+tn)/전체행수
				이건 이거자체로는 쓰기힘들어서(불균형한 데이터일때 전부 p나 n으로 밀면 정확도높게나옴)잘안씀
			2.정밀도와 재현률 
				양성으로 예측한값중 실제값도 양성일 확률은 정밀도
				실제값이 양성인거중 예측값이 양성일 확률은 재현율
				
				즉 정밀도는 진짜 확실한거말고는 다 네거티브에 던져서 사기칠수있고
				재현율은 다 포지티브에 던지면 사기칠수있어서
				둘을 섞은 f1스코어를 주로 사용함
			3.f1스코어
				정밀도와 재현율을 섞은것
				
		2.로그손실
			1.바이너리 크로스 엔트로피
				기본적인 바이너리 크로스엔트로피
				확률이 크게 틀리면 값을 많이더하고(머리를 세게치고)확률이 거의 맞으면(양성인데 0.95라던가)값을 조금만 더하고(살살 톡건드리고)
			
			
			2.auc
				roc곡선의 아래면적을 auc라고 부르나봄
				roc곡선은 임계값을 움직일떄의 거짓양성비율(진짜거짓인걸 양성으로 잘못예측한비율(fp/(fp+tn))과 
				참 양성비율(tp/(tp+fn))을 그래프의 xy축으로 나타낸것
				
				
				

	3.다중클래스 분류의 평가지표
		1.멀티 클래스 액츄얼리
			이진분류의 정확도를 다중클래스로 확장한것
			예측이 정답인 행 데이터 수를 모든 행 데이터 수로 나눈 결과
			
		2.멀티 클래스 로그손실(크로스엔트로피)
			이진분류의 바이너리 크로스엔트로피를 멀티클래스로 확장한것
			각 클래스의 예측확률을 내고 행 데이터의 예측확률에 로그를써서 부호를 반전시킨값이 점수임
			
		3.meanf1,macrof1,microf1
			말그대로 다중레이블에서의 f1평균값들
			mean은 전체평균낸거
			macro는 각 클래스별f1평균값,얘는 각 클래스에서 이진분류를 하고 그거의 f1스코어를 평균하는것과 같아서,
			다중레이블에서는 각 클래스별로 독립적으로 임계값을 최적화 가능(즉 a,b,c 세레이블이 있으면 각기 f1스코어를 하나씩 가지는거)
			micro는 행데이터x클래스의 각 쌍에대해 어디인지(tp,tn,fp,fn)카운트해서 그 혼동행렬에 근거해서 f1을 계산함
			
		4.qwk
			이건 다중클래스 분류에서 클래스간의 순서관계가 있을때 사용(영화점수 1~5라던가)
			각 행 데이터의 예측값이 어느클래스에 속하는지 제출함
			즉 이건 순서가 멀리 떨어질수록 패널티를 세게줌(5점이 레이블인데 2점예측했다던가)
			얘는 완전한예측이면 1,랜덤일땐 0 랜덤보다 나쁘면 -값을 줌
			
	4.추천의 평가지표
		1.MAP@k
			얘는 각 행 데이터가 하나 또는 여러 클래스에 속할떄,포함될 가능성이 높을것으로 예측한 순서대로 k개를 예측값으로 삼음
			단 k번째 예측값이 정답일경우에만 값을 취하고,그 외에는 0이됨
			계산방식은 1번부터 k번까지 가면서 분모는 계속+1을 하고 분자가 정답일때만 +1을 해서 k번까지 가는 식
				1번 정답 1/1
				2번 오답 --1/2 총합에는빠짐
				3번 정답 2/3
				...
			이런식
			저기에 답의 갯수로 총합을 나누면 map@k
				(5/3)/정답수
			
			
4.평가지표와 목적함수
	1.평가지표와 목적함수의 차이점
		기본적으로 평가지표는 목적함수로 사용할수있음(같은함수를 사용하는경우가 많음)
		그렇지만 평가지표가 좀 더 제약이 덜함(목적함수보다)
		목적함수는 미분을 할수 있어야함(그레이디언트 최소화)
		그리고 보통 회귀는 mse,분류는 크로스엔트로피를 자주 사용함
		
		만약 목적함수와 평가지표를 통일시킬수있다면 통일시키는게 좋음
		
	2.사용자 정의 평가지표와 목적함수
		실제로 뭐 이상한 목적함수를 요구하면 만들어쓸수도 있음(머신러닝책참고)
		
		
5.평가지표의 최적화
	평가지표랑 목적함수를 통일시킬수있으면 통일시키는게 좋음
	학습데이터를 전처리해서 평가지표를 통일시킬수있음(레이블에 로그를써서 변환하고 학습시킨뒤 로그를 푼다던가)
	다른 평가지표를 사용하고 후처리
	사용자 정의 목적함수의 사용
	다른 평가지표를 사용하고 조기종료
	
	1.임계값 최적화
		임계값을 0.5가 아닌 최적의 임계값을 찾기
		단 트레인데이터에 하면 오버핏날수있으니까 분할해서 검증(oof)
		
		하는건 0.01부터 0.99까지 다 돌려보거나,scipy.optimize사용
		
	2.예측확률과 조정
		평가지표를 최적화하려면 타당한 예측확률이 필요함
		보통 신경망등은 크로스엔트로피를 목적함수로 사용하니까 대충 타당한 예측확률이라고 할수있는데,
		이게 특정원인에 따라 왜곡될수있는데 이때 확률을 조정하면 점수가 올라갈수있음
		
		1.예측확률의 왜곡
			1.데이터가 충분하지 않을때
				데이터가 적으면 0이나 1에 가까운 확률을 뱉기힘듬
			2.모델 학습 알고리즘상 타당한 확률을 예측하도록 최적화 되지 않은경우
				랜덤포레스트같은데 크로스엔트로피를 쓴다던가 그러면 확률이 꼬임(이진트리랑 안맞으니까)
			
		
		2.예측확률의 조정
			1.예측값을 n제곱
				마지막에 예측값을 0.9~1.1을 곱해서 보정할수있음
			2.0이나 1에 가까운확률 제외
				너무 큰 패널티를 피하는것(0.1~99.9까지만 받는다던지)
			3.스태킹
				확률예측모델을 사용(신경망쓰면 됨)
			4.calibratedcalssifierCV사용
				예측값을 보정하는 방법인데,시그모이드나 등위회귀등을 선택할수있음
				얘는 0이나 1에 한없이 가까운 확률을 보정함
				
				
6.데이터 정보 누출
	1.예측에 유용한 정보 누출
		막 테스트데이터같은게 유출되는것
		중반이후에 갑자기 말도안되는점수 올라오면 이거찾아다녀야함
	2.검증방법이 잘못된 누출 
		oof에서 막 id값같은걸 사용해서 학습했는데,테스트데이터는 그런게 없을수있음
		이건 5장에서 다시보자

























