kubectl get pods
kubectl get pods --namespace=네임스페이스명
kubectl get pods --all-namespace
kubectl get all
kubectl get pods --selector 키=벨류
kubectl get pods --show-labels 레이블표시
kubectl get pods --no-headers | wc -l  갯수만 표시
kubectl describe pod123
kubectl get event
kubectl top node  리소스사용량보기
kubectl logs -f 파드명 컨테이너명(컨테이너가 2개이상일떄,이거안붙이면 무조건 첫번째컨테이너 출력)
kubectl -n 네임스페이스명  logs -f 파드명 컨테이너명(로그는 파드내 /log/컨테이너명.log에 저장되고,그걸불러옴)

kubectl explain pods --recursive //파드 아래에 속한 모든 필드 설명 보기

kubectl exec -it 파드명 -c 컨테이너명(컨테이너2개이상일때) -- bash (여기에 리눅스명령어 넣으면됨 cat /log/app.log넣으면 저파일 읽기)


kubectl run 파드명 --image=nginx   (파드는 런임 크리에이트안됨)
kubectl run 파드명 --image=nginx --labels=tiers=db 이런식으로 레이블은 넣으면됨
kubectl expose deployment 디플로이먼트명 --name=서비스 이름   기타등등(서비스 특정디플로이먼트에 생성할때)
,포드도 가능,이러면 셀렉터에 포드나 디플로이먼트가 가지고있던 레이블 전부가 들어감
kubectl run 파드명 --image=nginx --port=80 --expose 이런식으로 바로 서비스생성도 가능

당연하지만 yaml에서 위에메타데이터레이블은 디플로이먼트레이블이고 밑에 템플릿밑에 레이블은 파드레이블임

kubectl describe 머시기 | grep -i image나 뭐 찾을거

리눅스 파일실행 ./파일명
쉘스크립트 sh 파일명 으로 실행하면 한번실행되고 맘



kubectl run nginx --image=nginx
kubectl run nginx --image=nginx --restart=never --dry-run=client -o yaml  리스타트네버 넣어야함
kubectl create namespace dev
kubectl create ResourceQuota
kubectl create deployment --image=nginx nginx
kubectl create deployment --image=nginx nginx --dry-run=client -o yaml
kubectl create deployment --image=nginx nginx --dry-run=client -o yaml > nginx-deployment.yaml
kubectl create deployment --image=nginx nginx --replicas=4 --dry-run=client -o yaml > nginx-deployment.yaml
kubectl run 파드명 --image=이미지 --dry-run -o yaml > bee.yaml

kubectl run  --image=busybox sbox --dry-run -o yaml --command -- sleep 1000 > /etc/kubernetes/manifests/static-busybox.yaml    스태틱파드생성

kubectl create configmap 컨피그맵이름 --from-literal=설정이름=설정값 --from-literal=설정이름2=설정값2
kubectl create secret generic 시크릿이름 --from-literal=설정이름=설정값 or --from-file=파일경로  둘중 선택해서,혹은 둘다 넣을수있음

kubectl apply -f .   현재폴더내 전부 크리에이트


데몬셋은 크리에이트안됨,디플로이먼트로 야믈뽑고 수정해야함

kubectl scale deployment --replicas=5 디플로이먼트명

servicename.namespace.svc.cluster.local

kubectl config set-context $(kubectl config current context) --namespace=dev

노드접근시 curl ip or dns(노드 ssh접근):포트(그노드의 포트접근)

서비스도 셀렉터넣어서 선택

kubectl taint nodes 노드명 key=value:tainteffect(noSchedule(노스케쥴),preferNoSchedule(가능하면),NoExecute(톨러없이실행x))
spec:
	tolerations:
	- key:테인트키값
	  operator: equal(연산자넣는거)
	  value:테인트밸류값
	  effect:테인트이펙트값

테인트 삭제시엔,테인트넣는거 똑같이넣고 마지막에 -붙여서 한번더 날리면됨
그리고 특정노드 배치하는거할땐,톨러레이션은 일반노드에도 배정될수있기때문에 노드어피니티와 같이써야함(노드어피니티만 쓰면 다른애들이 여기들어올수있음)

kubectl label nodes 노드명 키=밸류    노드에 레이블추가

노드어피니티에서 키만 일치시키려면 오퍼레이터에 Exists줘야함

파드 변경시엔,이미지와 액티브데드라인세컨드,톨러레이션말곤 수정할수없어서,yaml로 뽑아서 원본을 삭제시키고 다시넣어야됨
디플로이먼트야 바꾸면 바로 자기가 다삭제하고 다시만듬

메모리 리소스 초과시엔 describe로 보면 last state-reason에 나옴,이벤트에 표시안됨

스태틱파드는 워커노드의 /etc/kubernetes/mainifests 에 yaml을 두면 알아서 읽고 만듬,이건 삭제되도 yaml이 폴더에 남아있으면,계속 유지시킴
이건 기본값이고,kubelet.service에서 pod-manifest-path를 바꾸면 경로바꿀수있음
이거파일 찾을때는 ps -aux | grep kubelet로 config.yaml 경로찾고,거기접속해서(vi)경로보면됨(staticpodpath)
만약 다른노드면 ssh ip 로 거기 접속해서하면됨
그리고 스태틱파드볼땐,api서버가 없으면 docker ps로 볼수있음
api서버가 있으면 get할수는있지만 수정할순없음(파일이 노드에있기때문)
그리고 파드뒤에 노드이름붙어있으면 스태틱파드

커스텀스케줄러할때 스케줄러파드 배포할떈,원본(디폴트)복사해다가 이름만바꾸면됨,그리고 leader-elect=true한애가 리더임(얘가 우선)
즉,스케줄러 추가할때
커맨드밑에
	- --leader-elect=false
	- --scheduler-name=스케줄러이름
	이거넣고 파드 이름 바꿔주면됨
그리고 스태틱파드폴더에 넣으면됨
그리고 파드 스펙밑에(컨테이너랑 같은라인에) schedulerName:스케줄러파드이름 으로 자기가 스케줄링당할 스케줄러를 고를수있음
그리고 k get events 로 어떤스케줄러가 어떤파드를 어떻게했는지 볼수있음
그리고 이전기록은 k logs 스케줄러이름 --name-space=네임스페이스이름  으로 볼수있음  
커스텀스케줄러 디렉토리는 /etc/kubernetes/manifests/(스케줄러는 스태틱파드로 실행됨 )커스텀스케줄러는 자신없으니까 한번더보자

메트릭서버 모니터링은,시험범위 내에선 저장을 못함(프로메테우스같은거있어야함),그래서 k top node,pod같은거로 현재값검색밖에 못함
메트릭서버 설치할땐   git clone 깃주소     하면됨


kubectl rollout status deployment/디플이름  으로 롤아웃상태 볼수있음(롤링업데이트할때 현재상태)
kubectl rollout history deployment/디플이름  으로 디플로이먼트 전단계 볼수있음(롤백할떄쓸거)
kubectl rollout undo deployment/디플이름 히스토리숫자   로 롤백할수있음,히스토리숫자없으면 전거로 롤백함

kubectl set image deployment/디플이름 이미지명=새이미지:태그  으로 명령형이미지변경가능

kubectl drain --ignore-daemonsets 노드명 파드 밖으로 다뿌리고 스케줄러차단
kubectl cordon 노드명 스케줄러만 차단 
kubectl uncordon 노드명 차단해제





describe로 디플로이먼트 배포전략을 볼수있는데(strategyType),
리크리에이트는 전버전을 0으로 줄이고 새걸 그숫자만큼올림
롤링업데이트는 1씩 줄이고 올림(이건 설정할수있음)


cmd는 항상 전체를 바꾸는데(매개변수에 뭘넣어도 전부 바뀜)
entrypoint는 엔트리 포인트에 더해서 뒤에 매개변수가 적힘

기본값을 두고 값만 받아오게하려면
	엔트리포인트 명령어
	cmd 값
을 하면 매개변수없으면 cmd값,있으면 cmd를 대체함

엔트리포인트를 오버라이드하고싶으면,
	docker run --entrypoint 대체명령어 이미지 매개변수
이렇게 하면됨


쿠버네티스에서 매개변수를 줄땐
	spec:
		containers:
		-  name: 이름
		   image: 이미지
		   args:['매개변수값']
을 하면됨
엔트리포인트를 오버라이드할땐
	spec:
		containers:
		-  name: 이름
		   image: 이미지
		   command: ['명령어']
		   args:['매개변수값']
하면됨
만약 도커파일에 엔트리포인트가 있는데,커맨드쓰면 다 덮어씌워지니까 주의

컨테이너속 앱에 매개변수줄땐
	spec:
		containers:
		-  name: 이름
		   image: 이미지
		   env:
		   -  name: 변수이름
		      value: 변수값
넣으면됨
그러면 앱에서 이걸 가져다가 쓸수있음,그리고 직접 값을 하드코딩하는대신 valueFrom으로 값을 어디서 가져올수도 있음(컨피그맵이나 시크릿)
컨피그맵을 파드에 넣고,그걸 컨테이너에 삽입하고,이름찾으면 거기서 찾는식
	spec:
		containers:
		-  name: 이름
		   image: 이미지
		   envFrom:  (여기에 -가 컨피그맵은 있고 시크릿은 없었음)
		   -   configMapRef:   //시크릿은 secretRef 넣으면됨 똑같이씀
				 name:컨피그맵이름(미리만들어둔거)
or
		   env:
		   -  name: 변수이름
		      valueFrom:
				configMapRef:
					name:컨피그맵이름
					키:컨피그맵에있는키
or
		volumes:
		-  name:볼륨명(지금붙인거)
		   configMap:
			  namle: 컨피그맵이름



시크릿에서 사용할땐 base64로 저장되니까,이걸 해독해줘야함
리눅스상에선
	echo -n 'gdfgd==' | base64 --decode

그리고 시크릿 desc로 봤을때 데이터밑에 있는게 각각 하나의 default-token임
왠진모르겠는데 시크릿은 이미지랑 이름 밑에 생성해야지,컨테이너 맨위에 생성하면 에러뜸(아 이미지에 속해있어야되나봄 이미지부터 행렬시작이니까)

initContainers는 그밑에 여러 컨테이너를 가질수있고(-배열로 이름,이미지를 하나씩 포함한),그러면 위부터 순서대로 실행하고,실패하면 파드를 다시시작함
그리고 실행된후에 종료되니까,컨테이너갯수에 포함안됨(get으로보는거)

노드아웃됐을때 타임아웃 세팅은 kube-controller-manager --pod-eviction-timeout=3m0s 로 설정가능 (기본값5분)
저 타임아웃시간내에 다시 가동가능하면, 그안에 업그레이드나 재부팅을 해도됨,근데 확신못하면 미리 다 뿌려두고 여기배치못하게 막고 업뎃하는게 안정적
kubectl drain 노드명 --ignore-daemonsets 으로 현재그노드 파드 전부 다 밖으로 뿌리고 스케줄러차단
드레인은 레플리카셋이 아닌 개별로 생성된 파드는 지우지못함(지우려면 뒤에 --force 붙이면되는데,이러면 파드소실됨)

노드 업그레이드는 kubeadm upgrade apply v1.13.4 이렇게 하면됨(클러스터는 이렇게 안하고 자체적으로 지원함)
현재 최신버전보려면 kubeadm upgrade plan
업그레이드는 한번에 한버전씩 하는게 좋음(10에서 13으로 건너뛰지말고 11,12,13이렇게)
다운타임 있어도되면 한번에업ㄱ글,없어야하면 하나씩업글,클러스터면 그냥 새로 노드추가하고(새버전으로)구버전노드 삭제
kubelet 업그레이드는 apt-get upgrade  kubelet=1.12.9.00 하면 됨(마스터노드)
그리고 systemctl restart kubelet 하면 재시작되고 업글됨

워커노드는 마스터에서 그노드 드레인하고,그노드 접속해서 똑같이 업글하면됨(ssh),업글끝나면 드레인 해제(uncordon)

kubeadm 마스터노드 업데이브방법
	apt update
	apt install kubeadm=1.20.0-00
	kubeadm upgrade apply v1.20.0
	apt install kubelet=1.20.0-00
	systemctl restart kubelet

워커노드 업데이트
	드레인하고
	ssh접속
	apt update
	apt install kubeadm=1.20.0-00
	kubeadm upgrade node
	apt install kubelet=1.20.0-00
	systemctl restart kubelet
	exit

즉 adm을 업데이트하고 그거로 노드를 업데이트하고 쿠버렛을 업데이트하면됨



kubectl get all --all-namespace -o yaml >백업.yaml 로 현재실행중인것들을 백업할수있음
물론 상용에선 백업도구를 사용함(velero같은)
etcd는 etcd.service에 있는 data-dir=/var/lib/etcd 에 저장됨
etcdctl snapshot save 파일명.db 로 etcd 백업할수있음
etcdctl snapshot status 파일명.db 로 상태볼수있고
//친건 시험에선 안해도됨  클러스터메인터넌스는 한번더해보자 잘못하겠음
//////////////service kube-apiserver stop 로 api서버 멈추고
etcdctl snapshot restore 파일명.db --data-dir etcd경로     로 리스토어할수있음(/var/lib/etcd-from-backup)
겹치는거 방지위해서,새로 경로를 지정해야함,겹쳐도되긴함 원래자리랑 혹시 겹쳐서 파일날아갈까봐 이렇게해둔거
그리고 경로바뀌었으면, 
/etc/kubernetes/manifests 이런 스태틱파드자리가서 볼륨(volumes,맨밑에있을거임)의 etcd위치(etcd-data)를 바꾼거로 바꿔줘야함

////////////systemctl daemon-reload   로 서비스데몬 재시작하고
//////////////service etcd restart    로 etcd 리스타트하고
//////////////service kube-apiserver start 로 api서버 재시작하면됨

그리고 인증서파일을 쓰면,
snapshot save 할때
	--endpoints=https://ip:포트(127.0.0.1:2379),etcd는 마스터노드에서 실행되고(로컬호스트) 포트기본값은 2379임 listen-client-urls
	--cacert=ca.crt파일경로,tls보안인증서  ,trusted-ca-file
	--cert=etcd-server.crt 경로,tls보안클라이언트식별  cert-file
	--key=etcd-server.key 경로,보안클라이언트 식별 키  key-file
지정해주면됨

etcd파드에서 cert-file는 서버인증서,peer은 클라이언트인증서
etcd ca 인증서는 trusted-ca-file

이렇게 백업방식은 두가지가있음 
etcdctl을 쓰기 전에
export ETCDCTL_API=3 을 날려서 etcd버전을 3으로 설정해줘야함(백업및 복원은 3에있음)

시험칠땐 하고나서 describe로 다시 확인하래


static password방식은 kube-apiserver.service의 --basic-auth-file=파일경로 로 파일이 저장되어있고,
거기에 패스워드 이름 아이디 그룹(옵션)이 저장됨(추가할땐 execstart밑에 더하면됨,그리고 서버재시작)
그리고 파드 커맨드에 kube-apiserver 밑에 -- --basic-auth-file=파일경로 를 넣으면 거기들어간애만 파드가 받아들임

그리고 암호대신 토큰을 가지면,static token방식
이떈 --token-auth-file=경로  를 대신넣으면됨
그러면 토큰을 받아서 확인하고 맞으면 들여보냄

보통 이건 잘 안쓰긴하는데,기본이래(요즘쿠버네티스에선 아예 사용불가래)

쿠버네티스엔 
	api서버용 인증서(공개키),비밀키쌍(서버)
	api서버->etcd용 인증서(공개키),비밀키쌍(클라이언트)
	etcd용 인증서(공개키),비밀키쌍
	워커노드의 kubelet용 인증서(공개키),비밀키쌍
	api서버->kubelet용 인증서(공개키),비밀키쌍
	스케줄러의 인증서(공개키),비밀키쌍
	컨트롤러매니저의 인증서(공개키),비밀키쌍
	쿠베프록시의 인증서(공개키),비밀키쌍
	ca기관의 인증서(공개키)(비밀키는 안가지고있음 우리가)
이 있음
여기서 스케줄러는,성질상 사용자와 같은취급임

나누면,
etcd용 인증서,api서버용 인증서,워커노드의 kubelet용 인증서가 서버역할이고,
나머지는 클라이언트역할임

그리고 etcd서버와 통신하는 etcd용 인증서,api서버->etcd용 인증서는 자체서명된 인증서를 사용함

여기서 워커노드,스케줄러,컨트롤러매니저,쿠베프록시,각 롤(접속한사람)은 전부 api서버와 통신하고,etcd는 유일하게 api서버와만 통신함
이떄 etcd가 서버역할이라서,클라이언트인 api서버는 인증이 필요함

그리고 각 롤마다 인증서(공개키),비밀키쌍 이 있음

ssl로 키를 만들려면
	openssl genrsa -out ca.key 2048
이렇게 만들수있음
그리고 그 키를 사용해서 csr(서명없는 인증서)를 만들수있음
	openssl req -new -key ca.key -subj '/CN=KUBERNETES-CA' -out ca.scr
그리고 그 파일과 키를 사용해서 (crt)서명된 인증서를 만들수있음
	openssl x509 -req -in ca.csr -signkey ca.key -out ca.crt
	
클라이언트에서 인증서를 만들때도 비슷하게 하면됨
	openssl genrsa -out admin.key 2048
	openssl req -new -key admin.key -subj '/CN=kube-admin/O=system:masters' -out admin.scr
	//cn은이름에대한메모,막적어도됨,로그에서 이게표시됨 O는 무슨그룹에 속했는지
	openssl x509 -req -in admin.csr -Ca ca.crt -CAkey ca.key -out admin.crt
여기서 ca.crt와 ca.key를 사용해서 어드민crt를 생성하는거만 다름(tls랑 같이 어드민에서 공개키비밀키를 두고 그걸 암호화해서 보내는거)

인증서는 id,비밀키는 패스워드라고 생각하면 됨
그리고 인증서 서명에,그룹 세부정보를 입력할수있고 이걸기반으로 사용자를 그룹별로 나눌수있음

이걸 모든 오브젝트에 다 해줘야함(스케줄러,컨트롤러매니저,쿠브프록시)

인증서를 사용하는방법은
	curl https:ip:포트  --key admin.key --cert admin.crt --cacert ca.crt
하면됨
이게 귀찮으니까
kubeconfig에 이걸 기록해두고,모든 명령에 자동으로 적히게 할수도있음
얘는 kind가 Config이고
api서버 엔드포인트,세부정보,인증서들을 지정할수있음

그리고 모든 오브젝트엔 ca.crt가 복사되어서 들어가 있음

서버도(etcd서버) 똑같이 만들면됨,이때 고가용성을위해 복사노드들이 있으면,서로 통신하기위한 인증서가 또 필요함
이건 메인을 서버로,나머지를 클라이언트로 하는 인증서임
이건 etcd.yaml에 있음(peer-cert-file,peer-key-file)
그리고 거기엔 key-file,cert-file도 있고,trusted-ca-file도 있음

api서버용 인증서도 비슷하게 만드는데
	openssl genrsa -out apiserver.key 2048
	openssl req -new -key apiserver.key -subj '/CN=kube-apiserver' -out apiserver.scr-config openssl.cnf
	
	openssl x509 -req -in apiserver.csr -Ca ca.crt -CAkey ca.key -out apiserver.crt

openssl.cnf는 api서버의 dns이름과 모든 ip를 적어둔 파일,인증서만들땐 모든 dns를 포함해야하니까 넣어준거

이 파일의 위치는 kubeapiserver파일의(/etc/systemd/system/kube-apiserver.service,kubeadm은 스태틱포드의 apiserver.yaml) 
	client-ca-file에 ca파일이 있고
	tls-cert-file에 apiserver crt파일
	tls-private-key-file에 apiserver.key파일

	etcd-cafile에 ca파일
	etcd-certfile에 api클라이언트-etcd crt
	etcd-keyfile에 api클라이언트-etcd key

	kubelet-certificate-authority에 ca파일
	kubelet-client-certificate=에 api클라이언트-kubelet crt파일
	kubelet-client-key=에 api클라이언트-kubelet key파일
이 있음

kubelet(kubectl)은 모든 노드에(워커마스터포함) 각각 자신의 kubelet마다 자신의 인증서를 가지고있음(자기노드이름을 붙인,system:node:노드명)
kubelet-config.yaml파일의
	clientCAFile을 보면 ca파일위치
	tlsCertFile을 보면 crt위치
	tlsPrivateKeyFile을 보면 key위치
를 알수있고,바꿀수있음(파일위치를)
kubelet의 인증서엔,그룹을 O=SYSTEM:NODES 해야함

kubeadm이 만든거의 인증서 확인 위치
	apiserver /etc/kubernetes/manifests/kube-apiserver.yaml 에서 
	ca,etcd,api-etcdclient,api-kubeletclient,apiserver 확인가능

인증서를 확인할땐
	openssl x509 -in crt파일 -text -noout
하면 됨
	subject는 인증서이름
	x509v3 subject alternative name은 dns명이나 자신의 다른ip
	validity의 after은 인증서만료날짜
	issuer은 인증서 발급자

가장 중요한건,올바른 발급자가 발급하고,인증서가 만료되지 않았는지를 확인하면됨(특히 인증서만료로 문제생기는게 젤많음)

직접 구성하면
	journalctl -u etcd.service -i
에서 crt파일을 찾아야함

그리고
	kubectl logs etcd-master
로 cert,key 위치와 뭐땜에 문제생겼는지를 볼수있음(모든 파드에서 다 됨)

api서버나 etcd가 다운되면
도커에서
	docker ps -a 로 프로세스id확인하고
	docker logs 프로세스id
로 로그확인할수있음

그리고 알수없는 서명이라고 뜨고 클러스터다운되면,보통 etcd가 api서버와 다른 ca를 사용하는데,이게 api서버쪽에서 ca가 잘못설정된거니까
etcd.yaml에 있는 ca 가져와서 api서버의 etcdca에 붙여넣으면됨


기본적으로 로컬일경우,마스터노드가 ca서버역할을 같이함
그리고 상용일경우,인증서가 만료되기전에 자동으로 인증서를 교체하는 자동화가 되어야함
이때 사용하는게 certificates api

인증서 갱신 요청을 날리면 마스터노드는 CertificateSigningRequest 오브젝트를 생성하고
이거 관리자가 보고 승인할수있음(kubectl로)

이때 순서는
	openssl genrsa -out user.key 2048
	openssl req -new -key  user.key -subj '/CN=user' -out  user.scr
	CertificateSigningRequest yaml 생성
		apiVersion: certificates.k8s.io/v1
		kind: CertificateSigningRequest
		metadata:
			name: 이름1
		spec:
			signerName: kubernetes.io/kube-apiserver-client
			groups:
			-  system:authenticated  //무슨그룹들어갈건지
			usages:
			- client auth  //요청문자열,뭘원하는지 무슨그룹들어갈건지
			request:
				베이스64포멧한 자신의 csr파일(base64 파일명.csr하면 됨)
				
	kubectl get csr로 확인하고
	kubectl certificate approve 이름1 로 승인 or  kubectl certificate deny 이름1 로 거절
	kubectl get csr 이름1 -o yaml 로 추출해서 certificate항목을 주면됨(이때 base64로 암호화됐으니까 base64 --decode로 해독해야함)
	echo '내용' |base64 --decode
이 모든 인증서작업은 컨트롤러매니저가 함
그래서 컨트롤러매니저의 yaml을 보면 ca인증서와 키가 있음(인증서 제대로못주면 얘보면됨)


기본적으로 클라이언트는 모든요청에 전부 키,자기crt,ca.crt를 보내야함
	kubectl get pods --server ip:포트 /
	--client-key 클라.key --client-certificate 클라.crt --certificate-authority ca.crt

근데 머리아프니까 이걸 kubeConfig에 넣어둠(#HOME(환경변수 HOME)/.kube/config(얘가파일임))
export로 리눅스에서 환경변수 확인가능
	--kubeconfig config
	
kubeconfig파일은 클러스터,컨텍스트,유저 섹션으로 나눠져있음
클러스터는 말그대로 클러스터임,개발클러스터 프로덕션클러스터 이런식으로 아예 분리를 해두는거
유저는 그 유저의 권한이라고 보면됨
컨텍스트는 어떤 클러스터에 그 유저가 권한이 있는지를 나타냄

저 위의 서버ip:포트는 클러스터섹션,crt랑 키는 user섹션에 적어짐
그리고 컨텍스트에서 그거 두개를 바인딩한걸 들고있음(키밸류로)
얘도 yaml형식으로 apiVersion은 v1이고 kind는 Config임

	apiVersion: v1
	kind: Config
	
	current-context:컨텍스트명1
	
	clusters:
	-  name: 클러스터명1
	   cluster:
	     certificate-authority:ca.crt  //ca는 여기
		 server: https://경로:포트
	contexts:
	- name: 컨텍스트명1
	  context:
		cluster: 클러스터명1
		user: 유저명1
		namespace: 네임스페이스명1  //옵션,클러스터1의 네임스페이스1로 들어감
	users:
	-  name: 유저명1
	   user:
	     client-certificate: 유저.crt
		 client-key: 유저.key

당연히 클러스터 컨텍스트 유저는 여러개될수있음
그리고 커런트컨텍스트가 기본값이고,저걸 바꿔서 다른컨텍스트로 넘어갈수있음

현재 kubeconfig를 보려면
	kubectl config view 
특정파일을 열려면
	kubectl config view --kubeconfig=파일경로
현재컨텍스트 바꾸려면
	kubectl config use-context 컨텍스트명
	ex) kubectl config --kubeconfig=/root/my-kube-config use-context research
하면됨
그리고 certificate-authority-data필드를 쓰면 파일경로말고 base64된 파일데이터를 그대로넣을수도 있긴함









yaml로 생성시 api버전
	pod:v1
	service:v1
	replicaset:apps/v1
	deployment:apps/v1
	
	
apiVersion: v1
kind: Pod
metadata:
	name: pod123
	namespace: dev
	labels:
		app: myapp
spec:
	containers:          //initContainers는 그냥 멀티컨테이너처럼 쓰는데,컨테이너앞에 init붙이고 그대로쓰면됨 C대문자에 주의 
		- name: con123
		  image: nginx   //여기까지 기본
		  ports:
			- containersPort: 8080
		resources:                  //파드에서 직접쓸땐,그 네임스페이스에 LimitRange를 만들어둬야 쓸수있음
			requests:
			  memory: '1gi'
			  cpu: 0.5
			limits:                   //cpu는 초과시 쓰로틀,메모리는 초과시 재시작
			  memory: '3gi'          
			  cpu: 1.5

apiVersion: apps/v1
kind: ReplicaSet
metadata:
	name: repl123
	labels:
		app: repl
spec:
	replicas: 3
	selector:
		matchLabels:
			app: podre1
	template:
		metadata:
			name: pod123
			labels:
				apps: podre1
		spec:
			containers:
				- name: pod123
				  image: nginx

apiVersion: v1
kind: Service
metadata:
	name: pod123
	namespace: dev
	labels:
		app: myapp
spec:
	type:LoadBalancer
	ports:
		- targetPort: 80
		  port: 80
		  nodePort: 30008		  

apiVersion: v1
kind: ConfigMap          //시크릿도 카인드만바꾸면 똑같음
metadata:
	name: conapp

data:
	변수명1:변수값1
	변수명2:변수값2






		  
For Windows: Ctrl+Insert to copy and Shift+Insert to