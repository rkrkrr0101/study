1.소프트웨어세상의 세가지혁명
	스킵

2.쿠버네티스 첫걸음
1.도커
	1.이미지란?
		컨테이너 이미지는 그 앱실행에 필요한 모든걸 모아둔 압축파일이라고 보면됨
		이미지는 바이너리파일로 되어있음
		
		도커파일은 보통 베이스이미지라고 부르는 시작이미지를 가져와서,거기에 자기가 만든 앱을 넣어서 새 이미지를 만드는식으로 운용됨
		즉 밀키트사서 거기다 치즈넣어서 먹는거임
		
		도커파일은 텍스트파일로,이미지가 포함할걸 구체적으로 지정함
		즉, 이런식으로 하면 컴파일러같은건 외부의 경로로 지정할수있어서 용량이 매우 작아지게됨(기본베이스는 외부로빼고 바뀐거만 가지니까)
		
	2.포트포워딩
		컨테이너에서 실행되는 프로그램은 같은컴퓨터의 다른프로그램과 격리됨,즉 직접 포트로 접근할수없음
		그래서 내부포트랑 외부포트랑 연결시켜줘야함,즉 포트포워딩이 필요함
		
	3.컨테이너레지스트리
		기본 이미지를 외부에서 가져온다면 그 외부는 컨테이너레지스트리고,일반적으로 사용되는건 도커허브임
		물론 직접 레지스트리를 구축할수도있음
		


3.쿠버네티스 구축하기
1.클러스터아키텍쳐
	쿠버네티스는 여러서버가 하나의 클러스터로 작동함
	클러스터는 컨트롤플레인(마스터노드)과 노드(워커노드)로 구성되어있음
	
	마스터노드는 api서버 etcd 스케줄러 컨트롤러매니저로 구성되어있고
	워커노드는 쿠베렛,쿠베프록시,컨테이너런타임을 구성되어있음
	
	여기서 마스터노드는 여러개로 구성되어 고가용성을 보장함,즉 여러개로 복사해서 하나가 고장나도 정상적으로 동작하는걸 보장함(대역폭은좀깍여도)
	그리고 마스터노드는 정상작동하지만 네트워크장애때문에 일부컴포넌트가 통신하지못하는상황에서도
	컨트롤플레인의 고가용성으로 이걸처리할수있음(한마스터노드랑 통신안되면 다른마스터노드 사용해서 통신한다는소리)
	
	그리고 etcd도 여러노드에 걸쳐 복제되어서,절반이상이 사용가능하면(보통홀수로 해야함 3,5이런식)개별etcd가 고장나도 버팅수있음
	
	컨트롤플레인 장애는 앱을 다운시키진않지만 이상하게 동작하게할수있어서 마스터노드의 고가용성을 유지하는게 중요함
	단,워커노드장애는 별상관없는게 워커노드에 장애가생겼으면 그냥자동으로 지우고 다시만들어주면 알아서 정상작동하는 노드로 옮겨줌
	
2.자체호스팅비용
	자체호스팅하는건 너무 비싸고 단가안맞으니까 구글이나 아마존같은거쓰자는소리

3.관리형 쿠버네티스
	뭐 구글이랑 아마존 아주레 3개 있는거 소개하는거

4.턴키형 쿠버네티스
	얘는 관리형을 사용할수없을때 웹브라우저에서 버튼눌러서 클러스터를 받아 쓰는거
5.직접구축
	하지마라는데 하지말자

6.클러스터가없는 컨테이너 서비스
	클러스터신경쓸필요없이 이미지랑 cpu메모리같은거만 지정해주면 알아서 하고 값 돌려주는거,그 아마존람다같은 faas의 전형태같음 2019년책이니




4.쿠버네티스 오브젝트
1.디플로이먼트
	레플리카셋+업데이트시 레플리카셋을 여러개만들수있는권한이 있는,레플리카셋에 어댑터씌운오브젝트
	이때 갯수체크는 레이블기준으로 하기때문에 레이블을 똑같이 디플로이먼트 2개를 만들어서 카나리아도 할수있고 그럼
	
	그리고 컨테이너(파드)가 어떤이유든 종료되면,갯수맞추려고 다시 재생성날림(물론 갯수오버해서지울땐 제외)
	
	조회는 kubectl get deployment로 할수있고,
	한디플로이먼트 상세조회는 kubectl describe 디플로이먼트명 으로 할수있음
	
2.파드
	파드는 쿠버네티스의 제일 작은단위임
	쿠버네티스는 컨테이너의 묶음인 파드단위로 관리를 함
	그래서 파드는 컨테이너의 종류를 여러개 가지고 할수도있긴한데,일반적으로는 하나만넣고쓰는경우가 젤많은듯
	
	파드를 생성할땐 파드를 직접생성하는게 가능하긴한데,어지간하면 단 하나라도 디플로이먼트로 생성해서 관리하는게 좋음

	조회도 디플로이먼트랑 똑같이하면됨

3.레플리카셋
	레플리카셋은 파드의 갯수를 관리하는 오브젝트임
	얘는 자기가 관리하는 레이블명을 가진 파드의 갯수를 관리함
	디플로이먼트가 업데이트할땐,레플리카셋을 하나 더만들고 전레플리카셋의 갯수를 줄이는식으로 업데이트를 함
	
4.상태유지
	쿠버네티스는 사용자가 상태를 선언하고 그걸 쿠버네티스가 알아서 맞추는식으로 돌아감
	이건 쿠버네티스가 꺼질때까지 영원히 반복되고,이걸 조정루프라고 부름(계속 감시하고있음)
	
5.스케줄러
	스케줄러는 파드를 생성할 위치를 정하는 모듈임
	파드의 조건에 맞춰 파드가 생성될 가장 좋은 위치를 정해서 거기다 생성명령을 날림
	
6.yaml형식의 리소스매니지먼트
	쿠버네티스는 선언형시스템이라서 실제상태와 의도한상태를 조정해서 맞춰나감
	즉 의도한상태에서 스펙만 수정하면 쿠버네티스가 나머지일을 알아서 다하니까,디플로이먼트를 삭제하고 다시생성할이유가 없음
	
	쿠버네티스에 날린 yaml값은 내부db에 저장되어있고,그 기록을 감시하고있다가 변경사항이 생기면 거기맞춰 동작하는방식임
	
	쿠버네티스에 yaml을 적용하려면, kubectl apply -f 경로/파일이름.yaml을 하면됨
	
	그리고 여기에 접속하려면 서비스를 만들어서 연결할 앱의 레이블을 지정하고 외부포트와 파드포트를 지정하면 알아서 포워딩도 함
	

7.헬름
	헬름은 yaml템플릿을 관리하는 패키지매니저임
	얘는 다른사람들이 만들어둔걸 가져올수있고,yaml의 의존성을 명시해서 순서대로 설치하게 할수도있고 그런식으로 해야할일을 줄여줌
	즉,yaml을 둘러싼 래퍼를 만들어줌
	
	헬름에서 차트를 설치할땐,
		helm install --name 이름 ./경로
	를 하면 그위치에 지정한이름의 차트가 설치됨







5.리소스관리하기
1.리소스이해
	가장 안정적이면서 클러스터 리소스를 최대한 활용하려면,각 파드들을 적절한 위치에서 실행시켜야하고,그러려면 파드들의 리소스요구량을 알아야함
	그래서 파드들의 최소요구량과 최대요구량을yaml에 적어둬야함
	
	리퀘스트로 최저치(최소 이정도는있어야돌림)리미트로 최대치(아무리많이써도 이정도만씀)을 지정해둬야함
	만약 리미트를 초과하여 파드가 cpu를 사용하려고하면 쓰로틀링이걸리고 성능저하가 발생하고
	메모리를 초과하면 파드는 종료되고(아웃오브메모리) 다시실행됨
	
	쿠버네티스는 리소스 오버커밋을 허용함
	즉 노드는 리미트의 상한을 넘는 파드를 가질수있음,이건 항상 모든 파드가 상한을 치고있진 않을거라 계산하기때문
	여기서 만약 전체리소스의 사용량이 노드의 최대용량에 근접하면,쿠버네티스는 미리 부여한 우선순위에따라 파드를(컨테이너를)종료함
	이떄 우선순위가 없으면 리소스요청을 가장 많이 초과한파드부터 종료함
	
	그리고 이미지는 최대한 작게 유지하는게 여러점에서 좋음,
	작은건 빨리빌드되고,저장공간을 덜차지하고,풀링이 빠르고 보안취약점이 줄어듬
	
2.컨테이너 생명주기 관리
	컨테이너가 스턱상태(프로세스가 실행중이지만 요청을 처리할수없는상태)에 빠지는건 일반적임
	이상태를 감지하고 재시작해서 문제를 해결할수 있어야함
	
	여기서 사용되는게 활성프로브(livenessprove)와 준비성프로브(readinessprove)임
	활성프로브는 컨테이너가 살아있는지 헬스체크를 하고,
	준비성프로브는 컨테이너가 응답을 받을수있는지 체크를 함
	준비성프로브검사에서 실패하면,성공할때까지 파드가 속한 서비스의 엔드포인트에서 제거되고,성공하면 다시 넣음
	그리고 준비성프로브검사가 성공하고나서도,안정화를위해 몇초뒤까지 기다리게할수있음
	
	그리고 준비성프로브는 파일을 생성하고,exec로 파일이 존재하는지를 확인하는식으로 사용할수있음
	이건 테스트에서 유용한데,멈춰야할때 파일만 지워버리는걸로 서비스중단상태를 만들수있음
	
	프로브들은 컨테이너스펙에 지정할수있고,시작딜레이랑 중간딜레이와 패스,포트를 지정하고 넣으면됨
	프로브들은 http,tcp소켓,exec로 커맨드를 쓸수도 있음
	커맨드는 커맨드가 성공하면(리턴값이 0이면)성공함,이건 준비성프로브에서 잘쓰임
	
	그리고 파드가 멀쩡해도 파드를 중지해야할때에(노드업그레이드하거나 파드를 다른노드로 옮겨야할때)
	PodDisruptionBudget를 써서 파드를 제거할 양을 제한해서 순차적으로 제거할수있음
	minAvailable필드로 최소실행갯수를 지정할수있고
	maxUnAvailable로 퇴출할 총갯수나 비율을 제한할수있음
	
	그리고 이건 쿠버네티스의 자발적퇴출에만 적용되고,당연히 서버다운같은거엔 적용안됨
	

3.네임스페이스 사용
	네임스페이스로 리소스사용을 관리할수 있음
	네임스페이스마다 사용량을 제한하고(즉 네임스페이스를 가상클러스터로 사용할수있음) 내부의 격리된 상태를 만들수있음
	그리고 조심해야할건,네임스페이스를 삭제하면 안에있던 모든게 날아감(폴더랑같음)
	
	네임스페이스끼리 통신해야하면 dns에 적힌 이름으로 들어가면됨
	즉 dns에 이름을 추가하면 연결할 서비스를 정확히 지정할수있음,
	보통 기본값은 서비스.네임스페이스.svc.cluster.local임
	
	그리고 앞에서말했던거처럼,네임스페이스에 ResourceQuota를 만들어서 리소스총량을 제한할수있음
	이떄 cpu나 메모리같은거 뿐만아니라 파드의 총갯수같은거도 제한할수있음
	그리고 보통 이렇게쓰고,cpu나 메모리같은거 제한은 문제생길까봐 잘 안하는데
	파드총갯수는 실수로 엄청많이 복제될까봐(레플리카셋 레플리카 숫자 0하나 더넣던가그래서) 그런걸 막으려고 넣는거같음
	
	그리고 limitRange로 기본 리소스 요청과 상한을 정할수있는데,
	이걸 만들어두면 파드들의 리소스 요청상한 기본값을 지정하는거임
	그렇다고 이거만들어뒀다고 너무믿지말고,실수로 빼먹을까봐 넣어두는거니까 명시적으로 적어두는게 좋음
	



4.클러스터비용최적화
	레플리카(디플로이먼트)는 많으면 업데이트를 하거나 파드에 장애가 발생해도 처리하기 좋긴하지만,그 파드 하나하나가 다 리소스니까
	파드는 컨테이너의 조건에 따라(즉발적으로 반응해야하는지,좀 느려도되는지) 최대한 수를 줄이는게 좋음
	그리고 업데이트시 몇초정도 멈춰도 되면 레플리카셋도 한두개정도로 처리가 가능함
	
	그리고 파드의 요구사항도,최대한 현실과 가까워야함
	너무 제한이 높으면 비용이 높게나오고(요구치에따라 할당하니까)
	제한이 낮으면 제대로 실행이 안됨
	
	이건 직접 모니터링을 하면서 체크하는게 좋음,프로메테우스와 그라피나를 쓰던가,아마존같은데선 직접 통계도구 지원하니까 그거쓰던가
	그리고 메모리나 cpu는 실제 최대치보다 약간 높게잡는게 좋긴함 튈수있으니까(500정도쓰면 600)
	
	그리고 이떄 쓸수있는 애드온으로 Vertical pod autiscaler가 있는데,
	이건 디플로이먼트를 관찰하고 실제사용량에 따라 자동으로 파드의 리소스요청을 조정하는데,보통은 수정하진않고 제안만 하는 드라이런모드를 사용함
	1.노드최적화	
		모든 노드는 운영체제가 있어서 이거로 디스크,메모리cpu자원을 소모함
		그래서 노드크기가 작을수록 고정비가 오르는데,그렇다고 무조건 큰노드쓰면 문제생겼을때 일이 크게터짐
		
		그래서 일반적으론 노드가 파드를 5개정도 실행시킬수있게 하고,버려지는리소스를(고정비) 10%이하로 유지시키고
		파드를 10개이상 실행시킬땐 고정비를 5%미만으로 유지해야함
		
	2.스토리지 최적화
		스토리지도 다 비용임
		스토리지는 요청과 상한으로 조정이 불가능함
		그래서 실제 사용하는 처리량과 공간을 기준으로 가장 작고 낮은등급의 iops볼륨을 할당하는게 좋음
	3.더미리소스정리
		안쓰는 리소스들이 계속 쌓이면(잡같은거) 그거자체로 비용이니까 안쓰는게 있으면 정리해야함
		이떈 만든사람의 이름을 anno에 적어서 자기꺼 책임지고 관리하게하면됨
		
		그리고 트래픽이 매우낮거나 없는걸 메트릭을 써서 볼수있는데,이걸기준으로 낮은걸 삭제할수도 있음
		
	4.여유용량 파악
		그렇다고 완전히 꽉꽉채워두면 뭐 하나 문제터지면 그대로 쓰러지니까 어느정도 빈공간을 만들어둬야함
		이떄 확인하는방법은 현재 사용중인 노드중 제일큰걸 터트려보면됨
		그때 문제생기면 좀 더 여유공간을 만들어둬야함

	5.클라우드결제
		클라우드를 3년정액으로 사면 싸긴한데,나중에 증설해야하면 그대로 다 날아가니까,미래의 요구사항을 예측할수있을때 사용하면좋음
		그리고 스폿인스턴스는 필요할때 요구해서 사용하는식임
		근데 이건 비용은 싸긴한데 좀 불안정하니까 비선점형하고 섞어쓰는게 좋음,이떄 비율은 선점형을 66퍼센트 이하로 맞추는게 좋음
		
		그리고 선점형에다가 좀 덜 중요한 파드들을 어피니티로 우선스케줄링 할수있음
		
	6.클러스터 균형 유지
		보통 일반적으로 파드들을 퍼트려놓는데 쿠버네티스는,업데이트등의 이유로 한군데 몰릴수가 있음
		이러면 위험성이 커지니까,디스케줄러같은 도구를 크론잡으로 실행해서 균형을 맞춰주는게 좋음
		디스케줄러는 사용률이 낮은 노드를 찾고 다른노드에서 실행중인 파드를 종료해서 유휴노드로 스케줄되게하거나(즉 노는노드 일시키거나)
		두개이상의 레플리카가 같은노드에서 실행중일때 중복파드를 퇴출시킴
		
	
	
6.클러스터 운영하기
1.클러스터사이징과 스케일링
	클러스터의 크기는 가용성을 유지할수 있는 한 최대한 큰 노드를 쓰는게 좋음(그래야 고정비도 적고,가격도 쌈)
	보통 안정적인 마스터노드 갯수는 3개고,워커노드는 장애를 고려하면 두개로하고,모든 레플리카를 최소 2개는 실행하는게좋음
	스케줄러가 항상 균등하게 할당하진 않으므로,노드는 많으면 많을수록 좋음
	
	그리고 뭐 테스트할때까지 이렇게할필욘없고,테스트할땐 제일작은거로 쓰자
	
	그리고 뭐 클러스터 제한을 넘길수준까지 운영해야하거나 지역 두군데이상해야하면,
	클러스터 페더레이션으로 두개이상의 클러스터를 동기화시킬수있긴한데,쓸일이 있을까
	
	보통은 클러스터 두개(하나는 상용 하나는 테스트용도)면 충분한데,이것도 네임스페이스로 나누면 하나만써도됨
	
	그리고 사용할작업에 따라 노드어피니티로,gpu가 있는데서만 실행되는 컨테이너도 있을수있으니까 이렇게 우선순위주면됨
	
	수요나 요청에따라 클러스터를 확장하거나 축소할때,확장은(노드추가) 그냥 관리도구로 추가하면되고 
	축소할땐 노드를 비우고 해야하니 여유공간이없으면 작업이 취소되고 그럴수도있음,즉 정상적으로 종료되어야만 클러스터에서 사라짐
	
	보통 오토스케일링을 지원하는데 그렇다고 서비스초기에 바로 쓰지말고,처음엔 수동으로해보면서 수요예측한다음에 감잡히면 오토스케일링쓰는게 좋대
	보통 큰규모아니면 이것도 쓸일없을거고

2.검증과 감사
	쿠버네티스에서 적합성 검사에서 걸러내지못하는 문제들도 있음
		지나치게 용량이 큰 컨테이너이미지를 사용하면 클러스터리소스가 낭비됨
		단일파드레플리카만 지정하는 디플로이먼트는 고가용성보장이 안됨
		루트권한 클러스터실행은 보안위험이있음
	
	이런것들은 k8guard툴로 체크할수있음
	
	그리고 copper은 배포전에 쿠버네티스 매니페스트(yaml)를 검사하는 툴임
	일반적으로 두개 추가하는게 권장된대
	
	그리고 구글은 로그가 켜져있는게 기본값이지만 아닌애들도있다니까 확인

3.카오스 테스팅
	이건 랜덤하게 노드,파드,앱을 꺼서 테스트하는 툴임
	진짜로 문제상황을 만들어서 대처가되는지 검증하는것
	
	이쪽 툴로 카우스몽키가 있음
	
	그리고 파드를 무작위로 끄는건 카오스쿠베가 있음
	
	
	
	
	
	
	
7.유용한 쿠버네티스 도구
1.kubectl
	kubectl에서 alias로 별칭을 지정할수있음
		alias k=kubectl
	이렇게하면 k get pod하면 됨
	
	그리고 명령어도 별칭으로 압축할수있음
		alias kg=kubectl get
		alias kgd=kubectl get deployment
	이런식
	
	그리고 --로 옵션주면 전체입력이고,-로하면 단축어임
		--namespace의 단축어는 -n
		--selector의 단축어는 -l(레이블)
	그리고 리소스 단축형도 있음
		pod=po
		deployment=deploy
		sevice=svc
		persistentvolumes=pv
		
	그리고 배시를 쓰면 자동완성되니까 꼭 넣어두고,탭으로 자동완성가능
	그리고 배시쓸거면 kube-ps1쓰면 현재컨텍스트가 프롬프트에 표시되고,kube-shell쓰면 팝업으로 자동완성됨
	
	그리고 자세히 출력하고싶으면 -o wide를 하면 자세히 출력됨
		kubectl get pod -o wide
	
	그리고 get은 json으로도 출력이 가능한데
		kubectl get pod -o json
	하면 json으로 출력됨
	그리고 여기서 jq를깔고(json처리 프로그램) 파이프라인으로 json을 넘겨서 쿼리가 가능함
		kubectl get pod -o json | jq '.item[].metadata.name'
	이런식으로 파드의 이름만 출력한다거나,어떤거 웨어하고 오더바이한다거나
	
	그리고 kubectl get pods --watch 하면 자동으로 계속 갱신되고
	kubectl describe pods 파드이름 하면 파드이름에 대한 자세한 정보가 출력됨
	
2.리소스 다루기
	이건 명령형 커맨드(직접 kubectl로 만들고지우고)하는거라 안봐도될듯 알고있기도하고
	
	여기서 yaml을 적용하기전에
	kubectl diff 파일명.yaml으로 변경점을 알수있으니까
	apply하기전에 미리 저거해보고 적용하는게 좋음
	
	그리고 원래 있던 파드를 kubectl get --export로 yaml로 받아볼수있음
	이렇게해서 수정해서 적용해도됨
	

3.컨테이너 다루기
	클러스터의 작동 대부분은 컨테이너 안에서 이루어져서 문제가 생기면 찾기 쉽지않음
	
	1.컨테이너로그
		컨테이너 로그는 컨테이너가 정상작동하는지 문제가있어서 해결해야할때 유용한 정보임
		이떄 로그엔 표준출력과 표준오류가 모두 포함됨
		프로그램이 터미널에서 실행중이면 터미널에서 출력결과를 볼수있음
		
		이때 컨테이너의 로그를 보려면
			kubectl logs -n 네임스페이스명 --tail=로그볼갯수 파드이름
		으로 파드의 로그를 테일갯수만큼 볼수있음
		
		로그출력을 실시간으로 터미널로 스트림하고싶으면 --follow를 저기 붙이면됨
			kubectl logs -n 네임스페이스명 --tail=로그볼갯수 --follow 파드이름
		
		이건 api서버 로그볼때 유용한데,예를들어 rbac권한에러같은게 여기 표시돼서 바로볼수있음
		그리고 관리형서비스면 마스터노드접근이 불가능하니까 서비스업체별로 접근방법을 찾아야함
		
		그리고 파드에 컨테이너가 여러개면 -c 컨테이너명을 저 뒤에 붙이면됨
			kubectl logs -n 네임스페이스명 --tail=로그볼갯수 파드이름 -c 컨테이너이름
		
		그리고 그거로 충분하지않으면 컨테이너에 직접 연결해서 컨테이너의 출력을 볼수도 있음
			kubectl attach 컨테이너명
		
	2.kubespy로 리소스감시
		kubespy라는 툴은 앱 배포할때나 그럴때 클러스터 내 개별 리소스의 상태를 관찰하고 시간에 따른 변화를 사용자에게 보여줌
		예를들어 서비스가 생성될떄,ip주소가 할당될때 엔드포인트가 연결될때같이 모든 상황을 볼수있음
		
	3.컨테이너 포트포워딩
		kubectl port-forward로 서비스에 연결해서쓰는게 일반적이지만,파드에(컨테이너에) 직접 연결할수도 있음
			kubectl port-forward 파드이름 컴퓨터포트:컨테이너포트
		
	4.컨테이너에 명령어 실행
		컨테이너에 문제가 생기면 kubectl exec로 컨테이너에서 셸을 실행해서 명령어를 날려볼수있음 
			kubectl exec -it 파드명 명령어
		기본적으로는 첫번째컨테이너에 명령어를 실행하는데,이거도 -c 컨테이너이름으로 컨테이너 지정할수있음
		
	5.문제해결을 위한 컨테이너
		문제해결을위해 일회용 컨테이너를 만들고 실행해서 확인할수있음
			kubectl run 붙일dns이름 --image 이미지명 --expose --port 붙일포트번호
		로 생성하고
			kubectl run dns명 --image=이미지명 -rm -it --restart=Never\--command --쓸커맨드
		이런식으로 한번만들어서 커맨드 날리고 자동으로 삭제하는식으로 쓸수있음
		
		여기서 
		-rm은 실행후 컨테이너 이미지삭제하라는 플래그고
		-it는 컨테이너를 터미널을 통해 대화형으로 실행하라는거,이거넣어야 커맨드넣을수있음
		-restart=Never은 컨테이너 종료돼도 다시실행 생략하는거
		--command --는 뒤에나올 명령어를 실행하라는거
	
	6.비지박스 명령어
		busybox이미지는 문제생겼을때 자주 run하는 이미지임
		그리고 명령어실행패턴은 항상 같으니까(kubectl run~--command--까지) 전체를 alias해버리면 편함
		
		여기서 /bin/sh하면 대화형셸 실행이고
		nslookup 파드명 등 이 있음
		필요해지면보자
		
		그리고 컨테이너가 이미 셸을 포함하면
			kubectl exec -it 파드명 /bin/sh
		으로 컨테이너의 셸로 직접 접근할수 있는데
		만약 없으면 busybox를 빌드할때 복사해 넣어서 그거로 접근할수있음(도커파일에)
		
		그리고 비지박스에 없는 프로그램이 필요한데,공개 이미지에도 없으면 alpine나 우분투이미지를 실행하고 프로그램을 설치하면됨
		
	7.kubesquash디버깅
		상용 디버거를 컨테이너 내 프로세스와 연결하고싶으면 kubesquash로 디버거를 연결하면됨
		저걸 설치하고 실행중인 컨테이너의 이름을 지정해서 실행하면됨
		
		
4.컨텍스트와 네임스페이스
	만약 클러스터가 여러개면,이걸 구분하기위해 컨텍스트라는 개념이 있음
	컨텍스트는 클러스터와 사용자,네임스페이스의 조합임
	즉 네임스페이스랑 논리적으론 같은데,클러스터까지 확장된거임
	
	컨텍스트를 바꿀땐 kubectl config use-context 컨텍스트명으로 넘어갈수있고
	kubectl config get-context로 현재 알려진 컨텍스트를 볼수있음
	그리고 kubectl config current-context로 현재컨텍스트를 알수있음
	무슨 명령어를 실행하든 현재 컨텍스트에 실행되니까 컨텍스트 여러개일땐 주의해야함
	
	그리고 컨텍스트 변환을 쉽게하고싶으면 kubectx와 kubens 툴을 깔아서 쓰면됨
	그럼 이전컨텍스트를 기억하다가 왔다갔다하는식으로 쉽게쓸수있음
	kubens는 네임스페이스 전환임
	이거도 똑같이 기억하고 전환할수있음
		
		
5.셸과 도구
	click는 kubectl의 대화형버전임
	얘는 현재 작업중인 오브젝트를 기억함
	즉 get으로 목록불러오고,거기 인덱스번호로 작업을 할수있음
	
	kubed-sh는 클러스터 내에서 셸이 실행됨
	얘는 현재클러스터에서 js,루비,파이썬등 프로그램실행에 필요한 컨테이너를 자동으로 풀해서 실행함
	즉 이렇게 자동화가 됨
	
	stern은 정교한 로그 검색도구임 얘는 정규표현식으로 로그를 거를수있음,즉 쿼리가 됨
	
	





8.컨테이너 실행
1.컨테이너와 파드
	컨테이너는 운영체제관점에서 볼때 분리된 네임스페이스에 존재하는 격리된 프로세스임
	그래서 밖과 서로 직접적으로 접근할수없고,다른곳의 자원을 서로 건드릴수없음

	그리고 컨테이너 속 프로세스는 단일프로세스로 자신의 컨테이너 자원 전부를 사용할수있음
	실제로 동작하는 프로세스를 보면 직접실행시킨 프로세스밖에없음
	
	그리고 하나의 컨테이너에 여러 앱과 네트워크등 잔뜩넣어서 실행시킬수도 있지만,일반적으로 이건 별로좋은방식은 아님
	보통 프로세스가 서로 알필요가 없으면,컨테이너 하나는 하나의 작업만 수행하는게 권장됨
	
	그리고 컨테이너가 실행될때 실행하는 명령어인 엔트리포인트가 있음
	일반적으로는 명령실행을위해 단일 프로세스만 실행하고,특수컨테이너만 여러개를 실행시킴
	이떈 엔트리포인트에 스크립트로 순서대로 실행하게 넣어주면됨
	
	파드는 서로 통신하고 데이터를 공유하는 컨테이너의 그룹임
	컨테이너가 하나의 역할을 수행하면,파드는 그 컨테이너들끼리 통신하고 데이터공유가 필요하면 컨테이너를 종류별로 넣어서 하나의 기능을 완성하면됨
	이땐 디스크볼륨으로 통신하거나,http로 연결하면됨
	
	이때 파드별로 묶어야하는 기준은,같은컴퓨터에서 실행시켜야하면 파드로 묶어야하고,아니어도되면 따로 떼면됨
	즉 파드내의 컨테이너는 한가지 목적으로 작동해야함,이때도 컨테이너가 3개넘어가면 분리 고려하는게 좋음
	
2.컨테이너 매니페스트
	컨테이너를 실행할땐 디플로이먼트의 스펙-컨테이너에 컨테이너명,사용이미지,포트를 넣어주면됨
	여러컨테이너를 실행하면 이름별로 -로 묶어서 나열하면됨
	
	이때 이미지는
		레지스트리호스트네임/리포지터리네임스페이스/이미지리포지터리:태그
	로 이름이 정해짐
	
	레지스트리호스트네임은 docker.io같은 이미지 저장소의 주소
	리포지터리네임스페이스는 그 레지스트리의 구분된 네임스페이스,디폴트값은 공개네임스페이스임(공식이미지)
	이미지리포지터리는 이미지의 이름으로,레지스트리/네임스페이스에 있는 이미지이름임
	태그는 이미지의 버전을 나타냄,일반적으로 특정버전을 명시하는게 좋음(latest쓰면 안좋음)
	
	latest는 마지막버전인데,이건 계속 이미지가 바뀌면 문제가 발생할텐데 어디서 문제발생했는지 찾기힘들기때문에 쓰면 안좋음
	명시적으로 가져올버전 명시하는게 좋음
	물론 한번실행시키고 말거(alpine같은거)는 상관없는데 계속 가져와야되면 지양하는게 좋음
	
	그리고 도커파일에서 베이스이미지를 참조할때 태그를 지정하지않으면 컨테이너 배포할때처럼 latest를 가져오니까 이때도 버전명시하는게 좋음
	
	그리고 컨테이너를 실행할때 환경변수를 줘야하면 컨테이너밑에 env로 환경변수 이름과 값을 주면됨


3.컨테이너 보안
	기본적으로는 컨테이너가 root로 실행되는데,이건 최소권한의 원칙에 위배됨
	프로그램은 실제 작업에 필요한 정보와 자원에만 접글할수 있어야함
	그리고 잘못하면 해커가 컨테이너를 벗어나서 컴퓨터전체의 권한을 획득할수도 있음
	
	루트가 아닌 사용자로 컨테이너 실행하려면 이미지랑 같은라인에
		securityContext:
			runasUser:1000(1000이상의 값 아무거나)
	으로 하면 일반유저권한을 줌
	저렇게하면 컨테이너이미지의 모든 사용자권한설정을 덮어쓰니까 주의
	그리고 컨테이너마다 각기 다른 권한을 주면 각기 다른 볼륨에 접근하고,같은값을 주면 같은볼륨에 접근하니까
	서로 접근이 필요하면 같은값,아니면 다른값주면됨
	
	그리고
		securityContext:
			runAsNonRoot:True
	하면 루트로 실행을 이미지가 원하면 실행을 차단함
	그러면 파드는 크리에이트에러가됨
	
	그리고 컨테이너의 쓰기를 막고 읽기권한만 주려면
		securityContext:
			readOnlyRootFilesystem:true
	하면됨
	
	그리고 일반사용자로 실행되더라도 컨테이너가 setuid로 루트로 일시적으로 권한상승을 할수있는데,이걸막으려면
		securityContext:
			allowPrivilegeEscalation:False
	하면됨
	
	그렇다고 전부 루트를 막을순없는데,80포트로 수신해야하는 웹서버는 루트로 실행해야함
	1024이하의 포트는 권한이 필요한 시스템포트로 관리때기때문
	그리고 캐퍼빌리티(안드로이드권한같은거)를 부여하는식으로도 되는데 이거관리할땐
		securityContext:
			capabilities:
				drop:[드랍권한]
				add:[추가권한]
	이렇게하면됨
	일반적으로 drop:['all']하고 add에 필요한거만 추가하는식으로 쓰는듯
	
	그리고 지금까지 했던 보안설정들은,컨테이너단이 아니라 파드단에서 파드의 spec에 설정하면 안에 컨테이너 전부에 적용됨
	이때 컨테이너 자체의 설정이 있으면 파드설정은 덮어씌워짐
	그리고 클러스터 수준으로 기본값을 설정할수도 있는데 podSecurityPolicy를 선언하면됨 
	
4.볼륨
	컨테이너는 각 컨테이너에서만 접근가능한 비영구적 파일시스템을 보유함
	이때 파일시스템내 모든데이터는 컨테이너를 재시작하면사라지는데
	이때 저장할필요가 있고,같은파드의 디른컨테이너와 데이터를 공유할수있어야하면 볼륨을 쓰면됨
	
	볼륨은 emptydir,퍼시스턴트볼륨이 주로쓰임
	emptydir는 비영구적 스토리지로 껏다키면 사라짐
	이건 추가데이터공간이 필요한데 저장할필요는 없으면 사용하고,
	저장할필요는 없는데 파드내 컨테이너간 파일공유가 필요하면 사용함
		
	사용방법은 생성하고 컨테이너에 마운트하면됨
	이때 주의할점은 쿠버네티스는 쓰기작업에 락을 안걸어서,동시에 작업되면 데이터가 날아갈수있으니까 주의해야함
	
	퍼시스턴트 볼륨은 영구적으로 데이터를 보관해야할때 사용함
	즉 db같은거,근데 db는 클라우드서비스의 데이터베이스 서비스를 쓰는게 좋대
	일반적으로 쿠버네티스에서 스테이트풀한 서비스는 별로 추천하지않는대
	
5.재시작정책
	파드가 종료되고 재시작은 기본적으로 always지만 실패했을때만 재시작이나 never로 바꿀수도있음(restartPolicy)
	그리고 파드가 작업완료후 다시시작하지 않기를 원하면 job쓰면됨
	
6.이미지풀시크릿
	이미지 풀 시크릿은 사설레지스트리에서 접근권한을 시크릿에 담아서 여기다가 넣어두면 알아서 보고 접근할수있음
	이걸 계정단위로 추가할수도 있음,그러면 이때 생성한 모든 파드는 레지스트리 작업증명이 자동으로 추가됨
	
	
		
		
	
			

9.파드관리
1.레이블
	쿠버네티스는 레이블과 셀렉터 조합으로 모든 오브젝트를 판별함
	뭐 레이블셀렉터는 많이봤고 스킵(in notin 수치형이면 <>로 할수잇다는 그거)
	그리고 조회할때도 레이블로 조회된다는거 정도
	
	레이블은 보통 파드를 서비스에 연결할때 많이 사용하지만 레이블로 상용과 테스트용을 구별하는용도로도 쓸수있음
	레이블 2개를 셀렉터에서 체크하는식으로 쓰면됨(무슨앱인지,상용인지 테스트용인지 and연산)
	
	레이블과 어노테이션의 차이는,레이블은 직접적으로 쿠버네티스에서 식별용도로 사용하고,
	어노테이션은 사용자가 컨테이너에 정보전달이나 주석용으로 사용함 

2.노드어피니티
	노드어피니티는 특정노드나 특정노드를 제외하는걸 스케줄링에 조건을 추가하는것
	노드어피니티는 강제와 반강제가 있고
	강제는 무조건 그게 이뤄져야함,그런노드가 없으면 스케줄링 실패
	반강제는 그러면 좋겠음,우선적으로 그런노드에 스케줄링하지만 없으면 아무데나 함
	
	보통 gpu가 있는거에는 비싼거만 두려고 반강제를 걸어두고(배치 어지간하면안되게),gpu가 무조건 필요하면 강제를 붙이는듯
	
	그리고 반강제 어피니티는 각 조건마다 점수를 줄수있어서,점수가 가장 높은데에 스케줄링되고
	어피니티는 스케줄링할때만 체크하지,중간에 노드 레이블이 바뀌면 그건체크하지않음

3.파드어피니티와 안티어피니티
	파드단위로 어피니티를 붙일수도 있는데,이건 그 노드에 이 레이블을 가진 파드가 있냐없냐에 따라 스케줄링함
	파드어피니티는 그 파드가 있으면 거기 가서 달라붙고,안티어피니티는 그 파드가 있으면 다른 없는데 가서 스케줄링함
	
	즉 파드어피니티는 같은노드에 묶어두면 좋은 파드들끼리(통신속도라든가 떄문에) 묶어두는용도
	안티어피니티는 고가용성떄문에 파드들을 퍼트려야할떄 사용함
	
	이것도 강제와 비강제 두개 다 있음
	쓰는거자체는 파드에 spec:affinity:podAntiAffinity 이런식으로 똑같이 쓰면됨
	
	그리고 파드는 균등분배보다 갯수채우는게 일단 우선이니까 보통 반강제로 사용함
	그리고 문제가 생기기전엔 안쓰는게 쿠버네티스가 알아서 분배하게 하는게 좋음


4.테인트와 톨러레이션
	이거도 특정 노드가 오염됐다고 특정노드에 스케줄링을 막는게 테인트고,그 테인트를 뚫고 스케줄링하는게 톨러레이션
	이건 뭐 구형노드있으면 테인트로 막아두고,그거도 괜찮다고 하는애들만 톨러레이션 붙여서 스케줄링하게 하는거
	톨러레이션을 붙여도 테인트노드에만 스케줄링하는게 아니라,전체 노드에서 테인트를 더해서 거기서 스케줄링함
	
	그거말고는 어피니티처럼 gpu같은거를 별도로 관리할수도있음


5.파드컨트롤러
	파드 컨트롤을 하는 오브젝트의 대표격으로는 디플로이먼트가 있고,그거외에도 데몬셋,스테이트풀셋,잡,크론잡등이 있고 다알고있으니까 넘어감
	
	이거외에도 HPA라는거도 있는데,얘는 그 오토스케일러임,자동으로 파드 레플리카수 조절하는거,
	그리고 일반적으로 사용하는 스케일링 메트릭은 cpu사용율이지만,그것외에도 앱에서 정의한 사용자정의메트릭같은거도 사용가능함
	이것도 뭔지아니까넘어감
	
	파드프리셋은 파드를 정의할떄,기본값을 설정하는거임
	즉 이거로 role:frontend를 하면,따로 파드에서 정의하지 않았으면 저게 자동으로 들어가고
	파드에 같은볼륨에 자동으로 마운트를 하게 하는 그런식으로,즉 기본값을 설정할수있음
	
	표준 쿠버네티스는 기본적으로 스테이스리스로 작동하고,
	그래서 순서대로 켜야하는거때문에 스테이트풀이 생기긴했지만 그거보다 더 복잡한게 필요하면 커스텀리소스정의를 만들어서 정의할수도 있음

6.인그레스
	인그레스는 서비스들 앞에서 로드밸런싱을 하는 로드밸런서임
	얘는 외부에서 안으로 요청을 받아서 서비스로 전달하고,서비스는 전달받은 요청을 레이블셀렉터기반으로 파드에 전달함
	
	일반적으로 인그레스를 쓰는 방법은,요청 url에 따라서 다른목적지로 라우팅하는것임(/hp와 /welcome 이렇게 두 서비스로 각각 전달)
	
	그리고 인그레스로 tls를 사용한 보안연결을 할수도 있음
	하나의 도메인으로 다른 서비스와 앱을 운영할때 tls인증서를 공유해서 단일인그레스로 보안연결을 관리할수있음
	인그레스의 spec:tls:에 시크릿을 넣고,백엔드로 연결하면됨
	
	그리고 인그레스를 관리하는 인그레스 컨트롤러도 있는데 얘들은 인그레스에 특정 어노테이션을 추가해서 인식하게 해서 관리함
	보통 관리형 쿠버네티스의 경우엔 거의 다 자체로드밸런서가 있음
	
7.이스티오
	이스티오는 서비스메시를 말할때 자주 언급되는 툴로,
	서로 통신하는 앱과 서비스가 여러개일때 서비스간 네트워크 트래픽 라우팅 및 암호화를 처리하고,
	메트릭,로그,로드밸런서같은 중요한 기능을 추가함

8.엔보이
	일반적으로 로드밸런싱 알고리즘은 random으로 무작위로 백엔드에 전달하는데,다른 알고리즘이 필요하면 엔보이를 사용하면됨
	






10.컨피그과 시크릿
	설정값이랑 시크릿은 앱에 적기보다 외부로 빼내는게 맞는설계임
	이때 설정할때 ini대신 쓸수있는게 컨피그맵,비밀번호아이디를 적어두는게 시크릿
	이걸 환경변수로 던지면 앱에서 받아서쓰면됨
	
1.컨피그맵
	컨피그맵은 설정값을 저장하는 키/값쌍의 집합임
	생성은 오브젝트생성하는거처럼 하면되고
	받는건 코드내에 언어별로 env받는법 찾아서 쓰면됨(파이썬은 os.environ('키이름'))
	그리고 파드설정에서 env에 valueFrom:configMapKeyRef로 컨피그맵을 연결해주면됨
	이때 이렇게 연결하면 키 하나를 받아오는거고,전체를 다 긁어오려면 envFrom:configMapRef로 전체를 긁어오면됨
	
	그리고 컨피그맵을 명령줄인자로 받으려면
		spec:
			containers:
				image:...
				args:
					-"-키"
					-"$(env이름)"
	으로 디플로이먼트에 파드 명령줄인자에 키/값쌍을 넣을수있음
	
	그리고 컨피그맵을 디스크에 저장된 설정파일로 만들땐
		data:
			config:|
				설정키:설정값
				...
	이렇게 컨피그맵에 나열하면됨
	여기서 |는 데이터블록임
	쿠버네티스에서 데이터블록을 쓰면,파일형식과 관계없이 전체 데이터블록을 컨테이너에 파일로 생성함
	
	이걸 디플로이먼트에서 볼륨을 생성하고 볼륨을 마운트해주면 그쪽에서 불러옴
	
	그리고 디플로이먼트가 실행중일때 컨피그맵의 값을 변경하고싶으면,헬름차트로 자동으로 설정변경을 감지할수있음
	디플로이먼트의 어노테이션에
		checksum/config:{{include(print$.Template.BasePath"/configmap.yaml").|sha256sum}}
	를 추가하면됨
	그러면 컨피그맵매니페스트의 해시값을 포함하게해서,그게 바뀌면 모든파드를 재시작함
	
2.시크릿
	시크릿은 데이터보안을 위해(패스워드나 api키같은) 보안이 필요한 데이터들을 모아둠
	이거도 쓰는방식은 똑같이 env에 쓰면되고,configMapKeyRef 대신 secretkeyref:로 바꾸기만하면 됨
	둘다 똑같이 키/값쌍이니까
	이거도 똑같이 파일로 만들어서 할수도 있음,컨피그맵과 똑같이쓰면됨
	
	그리고 시크릿은 kubectl describe로 내부데이터 조회가 안되고, -o yaml로 난독화버전을 조회할순있음
	이건 base64값이니까 그냥 인코딩바꾸면 되서 암호화라고 볼순없음
	
	시크릿을 조회하고 수정하는 권한은 rbac로 줄수있고,etcd에 접근할수있으면 기본적으로는 api권한없이 시크릿데이터에 접근가능한데
	저장데이터 암호화라는 기능으로 etcd의 시크릿데이터를 암호화해서 키없이 해독불가능하게 할수있음
	이 키는 api서버만 가지고있음
	
	그리고 매우 중요한 시크릿같은건 헬름지정 어노테이션을 쓰면,특정 리소스가 삭제되지 않게할수도 있음
		kind: Secret
		metadata:  
			annotations:    
				"helm.sh/resource-policy": keep
	
	
3.시크릿 관리전략
	시크릿은 기본적으로,매니페스트파일에 평문으로 저장되어있음
	이때 소스제어에 커밋하는 파일에 이런 시크릿데이터를 노출시키면 안됨
	이때 만족해야할건
		시크릿데이터저장공간의 고가용성
		앱에 시크릿을 제공하는 방법
		시크릿 교체나 변경시 실행중인 앱의 영향
	을 알아야함
	
	가장 쉬운방법은,소스제어저장소(깃헙)의 코드에 시크릿을 직접 저장하는것
	이때 시크릿은 암호화되어있어야하고 절대 평문으로 저장하면안됨
	그리고 특정키로 복호화할수있어야함
	
	이건 앱 배포과정에서 시크릿은 매니페스트가 클러스터에 적용되기 전에 복호화됨
	앱은 다른 데이터와 같이 시크릿을 읽고 사용할수 있음
	
	소스제어에서 시크릿을 암호화하려면,앱 코드변경과 같이 시크릿의 변경도 변경사항을 검토하고 추적해야함
	소스저장소가 고가용성을 제공하면,시크릿도 고가용성을 보장함
	
	이떄 시크릿을 변경하거나 교체하려면,해당 시크릿을 소스의 로컬복사본에서 해석하고 업데이트하고 암호화하고,소스제어에 변경사항을 커밋하면됨
	
	이건 소스단에서 하는거라서,그 시크릿을 사용하는 모든 소스코드에서 시크릿의 복제본이 필요함
	
	이거 말고는 aws같은 외부저장소에 파일로 시크릿을 저장하는것
	이건 다좋은데,시크릿이 소스제어에 포함되지않기때문에 관련 로그를 관리하는루틴이 추가되어야함
	
	보통 중요한시크릿은 소규모에선 몇개안되니까 sops같은 가벼운거 써서 하자
	
4.sops로 암호화하기
	sops는 개별 시크릿값을 값만 암호화함
	즉,pass:qwer이면 qwer만 암호화함
	그래서 코드리뷰가 쉬움
	
	sops사용법은
	gpg로 키를 생성한다음에 그 키를 적어두고
	sops --encrypt --in-place --pgp 키값 시크릿.yaml
	하면 암호화된값이 적힌 시크릿으로 바꿔줌
	
	이걸 복호화할떈 sops --decrypt 시크릿.yaml
	한뒤에 키 넣으면됨
	
	그리고 앱을 배포할떈 sops를 복호화모드로 시크릿을 평문으로 만들고 쓰면됨
	
	sops는 클라우드 키 관리도구들(아마존 kms같은)것들과도 같이쓸수있음
	쓰는법은 책보자



11.보안과 백업
1.접근제어와 권한
	쿠버네티스에선 역할기반 접근제어로 권한을 관리함
	이건 역할을 만들고,역할이 할수있는 일을 정해주고,그 역할을 사람한테 맵핑시키는거임
	롤은 접근가능한api그룹,리소스,할수있는일로 이루어져있음
	선언된 리소스에 선언된 행동을 할수있는거
	
	롤은 clusterRole로 선언하고,롤바인딩은 RoleBinding로 바인딩함
	
	사용자는 아무 권한이없는상태에서 시작해서,롤과 롤바인딩으로 권한을 추가할수있지만,권한을 제거할순없음
	
	그리고 cluster-Admin은 어드민권한인데,이건 막 남용하면안됨
	
	앱은 일반적으로 rbac권한이 필요없는데,
	만약 api에 연결되어야하면(파드목록조회같은거필요하면)앱 전용 계정을 만들어서 바인딩으로 역할주고,네임스페이스로 제한하면됨
	
2.보안스캐닝
	클러스터에서 서드파티로 보안문제점을 알수있는 툴들이 있음
	
	클레어는 컨테이너가 실행되기전,이미지를 분석해서 문제있는이미지나 버전인지 확인함
	
	아쿠아는 컨테이너의 보안취약점,악성소프트웨어,이상행위들을 스캔하고 정책을 잘 적용하고 규정준수를 돕는 보안제품임
	얘는 이미지에 추가해서 패키지의 알려진 취약점을 스캔하는 도구를 제공함
	도커파일에 추가하면됨
	
	앵커엔진은 컨테이너 이미지를 스캔하는 툴로,알려진 보안취약점뿐아니라,라이브러리,구성파일등 모든것을 검사함
	
	
3.백업
	쿠버네티스에서도 백업은 해야함
	기본적으로 고가용성을 유지하니,하드가 날아가는거는 괜찮은데,사용자실수로 파일을 덮어쓰면 바로 다른데도 갱신되니까,사용자실수때문에라도 백업을 해야함
	그리고 퍼시스턴트볼륨은 고가용성을 유지하지않아서,노드에 문제가 생기면 날아감
	
	그리고 etcd백업은 보통 관리형쿠버네티스를 쓰면 자동으로되고,직접운영하면 주기적으로 스냅샷을 떠둬야함
	
	쿠버네티스의 모든건 이론적으로 yaml만 있으면 복구가 가능하긴하지만,보통 저장소엔 예전버전같은거도 다 섞여있으니까
	주기적으로 현재 클러스터의 상태를 스냅샷떠두는게좋음
	
	그리고 velero라는 도구로 클러스터의 상태와 퍼시스턴트 데이터를 백업하고 복구할수있음
	이건 아마존같은 클라우드에도 연결이 가능하고,클러스터에서 실행할수있음
	사용법은 필요하면 보자

4.클러스터상태 모니터링
	클러스터 상태를 모니터링하는건,간단하게는 kubectl get cs로 현재 스케줄러,컨트롤러매니저,etcd같은 컨트롤플레인의 상태를 볼수있음
	클러스터 상태를 확인할떈,큰거부터 내려가는게 좋음
	먼저 
		kubectl get cs
		kubectl get nodes
		kubectl top nodes(cpu사용률같은거 보는명령)
		kubectl get pods --all-namespace
	이런식으로 순서대로 확인하는게 좋음
	
	그리고 클라우드서비스의경우는 보통 콘솔을 따로 제공하고,자체클러스터면 쿠버네티스 대시보드를 쓰면됨
	대시보드는 시크릿같은걸 다 볼수있기때문에,시크릿만큼 주의해서 관리해야함,절대 패스워드없이쓸수잇으면안됨
	
	이거외에도
	위브스코프는 클러스터 모니터링도구로,현재 노드,컨테이너,프로세스의 상태를 실시간맵으로 시각화함
	kube-ops-view는 현재 노드현황과 노드의 cpu및 메모리사용률,노드별 실행중인 파드갯수,파드상태등을 시각화해서 보여줌
	node-problem-detector은 노드단위에서 어디서 문제가 생겼는지 알려줌




12.쿠버네티스 앱 배포
1.헬름으로 매니패스트 빌드
	그냥 yaml로만으로 리소스를 관리할순있지만,헬름으로 관리하는게 좋음
	그러면 다른클러스터에서 실행할때도 설정바꾸기가 쉬움
	헬름은 설정값을 yaml과 분리할수있고,의존성도 지정할수있기때문
	
	헬름차트는
		chart.yaml
			이건 차트의 이름과 버전을 지정함
			여기서 소스코드의 링크같은 선택필드등이 존재함
			
		values.yaml
			이건 사용자가 수정 가능한 설정을 포함함
			이건 자유형식의 yaml이기떄문에,어떤 변수,이름/값쌍을 지정해도됨
			헬름차트에서 필요한변수가 있으면,여기넣으면 차트어디서든 참조가능함
			이떄 참조할땐,{{.Values.containers.name}} 이런식으로 .values.상위필드값.하위필드값.최하위필드값
			이렇게 계속 나가서 필요한 이름을 적으면됨
			
			즉 이렇게 디플로이먼트 yaml을 전부 참조값으로 적어버리면,values만 수정해도 되고,
			만약 디플로이먼트 3개랑 서비스 2개가 있으면,values만 수정해도 전부 수정이됨
			
			그리고 템플릿에서 인용부호가 있는 값을 처리하려면 quote를 쓰면됨(문자열전체를 ""로 묶어줌)
				namle:{{.Values.myname|quote}}
			이건 문자열에만 붙어야함,포트번호처럼 숫자형엔 못씀
		
		requirements.yaml
			이건 의존성을 지정함
			여기에 필요한 차트의 이름과 버전을 적으면,일단 이거부터 설치하고 자기가 지정한걸 설치함
		
2.헬름차트 배포			
	헬름차트를 실제로 배포할떄,헬름의 가장 중요한 특징은 구성설정을 지정,변경,업데이트,재정의할수 있다는것
	
	values에서 헬름차트의 작성자가 기본값을 적어두고,그걸 바꿔서 재정의하려면
	helm install에 변수파일을 지정해서,values파일에서 새로운 변수파일에 적힌값이 있으면 덮어씌우고 없으면 밑에다 추가함
	즉,기본값을 덮어씌울수있음,이건 파일바꿔치기가 아니라서 지정하지 않은건 그냥 기본값그대로 남아있음
	
	이때 사용법은
		helm install --name 차트이름 --values=.경로/파일이름.yaml
	이때 yaml말고 그냥 변수를 넣어도되긴하는데,어지간하면 yaml로 해야 기록이 남아서 나중에 문제생기면 찾기쉽고,선언형시스템이라는 틀에도 맞음
			
	그리고 차트에서 설정할수 있는 값의 목록을 보려면
		helm inspect values 저장소/차트이름
	하면 values에 있는 모든 키값을 리턴함
	
	그리고 헬름으로 실행중인 앱의 일부 값만 바꾸고싶으면,helm update를 쓰면됨
		helm update  차트이름 --values=.경로/파일이름.yaml .경로
	여기서 경로는 value의 경로와 마지막경로가 같음,어짜피 위치지정인데 왜 두번적었는진모르겠는데,
	마지막에 경로설정하면 앞에 파일이름만 적어도 거기가서돌리는듯
	
	그리고 업데이트가 문제생겨서 롤백하려면
		helm rollback 차트이름 1
	이렇게하면됨,저기서 1은 바로 이전릴리스고 기본값으로 3인가까지 저장된다고함
	
	그리고 메트릭기반으로 자동으로 롤백할수도 있음
	시간당 에러횟수가 일정량을 초과하면 자동으로 롤백하는거임
	
	만약 자체헬름차트 저장소를 운영하고싶으면,helm repo index로 저장소메타데이터를 포함한 index.yaml이 생성되는데
	그러면 차트저장소를 사용할수있음 
	사용법은 찾아보자 필요하면
	
	그리고 sops로 헬름차트의 시크릿을 관리할땐,그냥 한시크릿에 모든 데이터를 몰아넣는게 편함
	
	이떄 sops로 복호화하고 변경사항적용하고 스테이징시크릿으로 스테이징버전을 배포하는 파이프라인은
		sops -d .경로/시크릿.yaml > temp시크릿.yaml && \
		helm upgrade --install 차트이름 --values 변수파일.yaml\
		--values temp시크릿.yaml ./경로 &&rm temp시크릿.yaml
	이런식으로 파이프라인짜면됨
	sops로 시크릿복호화하고 템프파일만들고,그거 클러스터 적용할때 사용하고,다시 템프파일 삭제하는식
			
			
3.헬름파일로 여러 차트 관리			
	헬름은 한번에 한개의 차트만 설치할수 있음
	그래서 한번에 여러개를 설치할때(클러스터에 설치할 모든 앱차트) 단일명령어로 설치하려면 헬름파일임
			
	헬름파일은 repositories에 저장소이름과 url을 적고
	releases에 설치할 모든 차트의 이름과 네임스페이스,차트와 values파일을 적어주고
	helmfile sync 로 적용시키면됨
	그러면 모든게깔림
			
4.고급 매니페스트 도구			
	ksonnet는 계산과 로직이 필요한 복잡한배포에서 선언적 yaml이 충분하지 않고,프로그래밍을 해야할떄 사용함
	이건 json의 확장버전인 jsonnet를 사용해서 매니페스트를 작성함
	jsonnet는 json에 변수,반복문,산술문,조건문,오류처리등이 추가로 들어있음
	그리고 중요한건,얘가 프로토타입개념이 있어서,매니페스트를 상속하는거처럼 복제해서 쓸수있음
	
	kapitan은 얘도 jsonnet기반으로 여러 앱이나 클러스터간 구성값을 공유함
	얘는 환경이나 앱에 따라 다른값을 연결해서 매니페스트 패턴을 재사용할수있는 구성값의 계층적db를 가지고있음
	즉 설정값도 따로 차트처럼쓰는거
	
	kustomize는 yaml로 오버레이를 사용해서 다른 환경이나 구성에 대한 매니페스트를 패치할수있음
	
	kompose는 도커컴포즈를 쿠버네티스로 변환할떄 사용하는도구
	
	앤서블은 인프라 자동화 도구로,템플릿생성과 관리,계층시스템으로 변수를 관리할수있음
	즉 층별로 변수를 지정해두고,템플릿에서 그걸 가져다쓰는식으로 변수통일을 할수있음
	
	kubeval은 매니페스트를 검증함
	얘는 특정 오브젝트에 지정되지않은 필수필드가 있는지 확인하고,값의 형식이 올바른지 검사함
	kubectl은 실행시점에서 오류발생되지만,이거쓰면 그전에 확인할수있어서 편함






13.개발 워크플로
1.개발도구 
	skaffold툴은 로컬에서 개발한 컨테이너를 자동으로 리빌드하고,변경사항을 로컬이나 원격클러스터에 배포함
	얘는 로컬디렉토리를 설정하고,거기서 변경점이 생기면 자동으로 컨테이너빌드하고 자동으로배포함(레지스트리에 수동으로 푸시하고 풀링하는작업을 없애줌)
	
	draft는 skaffold처럼 헬름으로 클러스터에 자동으로 업데이트함
	얘는 skaffold에서 추가로 새 앱으로 시작해서 도커파일이나 헬름차트가없으면,
	draft init&&draft create 를 하면 디렉토리에 있는 파일을 검사하고,무슨언어인지 판별해서 자동으로 해당언어의 도커파일과 헬름차트를 생성함
	
	telepresence는 로컬클러스터를 원격클러스터에 포함시킴,앱코드를 수정하면 새 컨테이너를 배포하지않아도 업데이트는 실제 클러스터에 반영됨
	얘의 파드는 실제 클러스터에서 앱을 대신하여 실행됨,이거의 파드의 트래픽은 로컬머신의 컨테이너로 라우팅됨
	
	knative는,앞의도구들이 개발속도를 올리는 용도였으면,이건 컨테이너앱만이 아니라 서버리스스타일의 함수같은 모든 워크로드를 쿠버네티스에 배포하기위한
	표준 메커니즘을 제공함
	얘는 쿠버네티스와 이스티오를 통합해서 앱/함수배포플랫폼을 제공함
	빌드프로세스설정,자동화배포,표준화메시징과 큐잉시스템을 사용한 이벤트처리등을 지원함
	
	
2.배포전략
	이건 그 무중단배포 하는방법임
	무중단배포는 실제 돌아가고있는 앱이면,생각해볼만함	
	이때 롤링업데이트를 하거나(한번에 한파드씩업그레이드),
	블루/그린배포(한번에 완전히 새로운 디플로이먼트를 생성해서,일시적으로 2개의 디플로이먼트를 만들고,디플로이먼트 헬스체크되면 서비스를 그쪽으로넘기고 원본삭제),
	카나리아배포(조그만 디플로이먼트를 새로만들어서 기존서비스에 같은레이블로 섞어두고,문제없으면 업그레이드,소극적으로 테스트용)
	이때 maxSurge(최대초과파드수,이갯수만큼 일시적으로 파드갯수를 초과해도됨)와 
	maxUnavailable(최대 사용불가능파드수,이갯수이상 파드수가 떨어지지않음)로
	안정성을 설정할수있음
	
	아니면 그냥 recreate로 전부 같이 올리면,잠시끊기긴해도 두가지버전이 동시에 실행되는상황을 피할수있음


3.헬름으로 마이그레이션 처리
	스테이트리스는 쉽게 배포하고 업그레이드하지만,db같은 스테이트풀이 섞이면 작업이 복잡해짐
	db의 스키마를 변경하면 일반적으로 롤아웃 중간과정에서 마이그레이션 작업이 필요함
	쿠버네티스에서는 잡리소스를 사용해서 마이그레이션작업을 할수있음
	이때 업그레이드과정에서 kubectl의 스크립트를 쓸수도있고,헬름으로 훅을 쓸수도 있음
	
	이때 훅은 정해진 이벤트가 발생하면,가로채서 거기에 발생하는 작업의 순서를 제어하는거임
	그리고 업그레이드중에 문제가 생겼다는 이벤트가 발생하면,훅으로 작업을 중단할수도 있음
	
	헬름훅의 사용법은,잡의 annotations에 'helm.sh/hook'같이 'helm.sh/이벤트명':처리방식
	을 적으면됨
		'helm.sh/hook':pre-upgrade
	는 업그레이드 전에 이 잡을 적용시키라는소리고,
		'helm.sh/hook-delete-policy':hook-succeeded
	는 잡이 성공하면 잡을 삭제하라는 소리
	
	그리고 잡이 0이 아닌 코드를 리턴하면,에러가 발생하거나 마이그레이션이 실패한거,그러면 헬름은 잡을 실패상태에 유지해놓고,잘못된걸 디버깅함
	이때 릴리스는 멈추고 앱은 업그레이드되지않음
	이슈가 해결되면 실패한잡을 제거하고 업그레이드를 다시하면됨
	
	훅은 pre-upgrade말고 여러개가있음
		pre-install은 템플릿이 렌더링된후 리소스생성전에 실행됨
		post-install은 모든 리소스가 설치된후 실행됨
		pre-delete는 리소스를 삭제하기전,삭제요청시점에 실행됨
		post-upgrade는 모든 리소스를 업그레이드하고 실행됨
		pre-rollback은 템플릿이 렌더링된후,롤백요청에서 리소스롤백전에 실행됨
		post-rollback은 롤백실행하고 리소스가 전부수정된후에 실행됨
		
	그리고 훅은 훅체이닝으로,특정순서대로 훅을 순차적으로 실행시킬수있음
		helm.sh/hook-weight:'숫자'
	로 가중치를 줄수있는데,저게 낮은거부터 높은거 순으로 실행됨



14.지속적배포(ci/cd)
1.지속적배포란
	지속적배포는,완성된 빌드를 자동으로 상용환경에 배포하는것
	배포는 테스트와 같이 중앙에서 관리하고 자동화해야함
	지속적배포(cd)는 지속적 통합(ci)와 관련이 있음
	지속적통합은 메인브랜치에 대한 변경사항을 자동으로 통합하고 테스트함,이걸 자동으로 배포하면 지속적 배포임
	
	즉 메인은 지속적통합으로,여기서도 제일중요한건 자동테스트임
	
	cd는 종종 파이프라인으로 언급됨
	순서는
		개발자가 변경코드 깃에 푸시
		빌드시스템은 변경코드를 빌드하고 테스트
		모든테스트 통과하면 컨테이너이미지는 중앙레지스트리에 푸시
		새롭게 빌드된컨테이너는 자동으로 스테이징환경에 배포
		스테이징은 몇가지 자동화된 인수테스트를 함
		검증된 이미지는 상용환경에 배포
	순임
	그러니까 테스트를 믿고 그냥 테스트거치면 안정성이 있다고 판단하고 자동으로 배포하는것
	그리고 이때 중요한점은 다양한테스트의 환경은 코드가 아닌 컨테이너라는것
	보통 컨테이너에선 다른 외부변수가 없으니까,같은값을 넣으면 같은값이 나옴(순수함수에 가까움)
	
2.cd도구
	cd도구에는 대표적으로 젠킨스가 있음
	말고도 드론,구글클라우드빌드(구글클라우드쓰면 이거쓰면됨)등등이 있음
	보통 깃헙저장소를 감시하다가 변경점이 생기면(트리거) 그걸 테스트하고 배포하는식으로 많이사용하는듯

3.cd컴포넌트
	이미 cd시스템이 운영중이고,컨테이너빌드하고 배포만 필요하면
	도커허브,gitkube,flux등이 있음
	

4.cd파이프라인
	먼저 테스트컨테이너를 빌드하고
	테스트를 실행하고,
	성공했으면 앱컨테이너를 빌드하고,
	성공했으면 매니패스트를 검증하고(헬름차트)
	성공했으면 이미지를 개시함(ci완료)
	이제 이미지가 새로올라온걸 확인할 트리거를 만들고
	트리거가 작동하면
	테스트를 하고
	자동으로 상용에 배포됨(cd완료)























































