1.컨테이너인프라환경
	별거없음 스킵
	뭐 마이크로서비스 아키텍쳐정도는 나중에 책 한권사든가하자  
	
	
2.설치
	버추얼박스 베이그런트 푸티 수퍼푸티 설치
	
	베이그런트 명령
		vagrant init:기본파일생성(vagrantfile 생성)
		vagrant up:vagrantfile를 읽고 프로비저닝(서버 설정하고 파일넣어서 가동시키는것) 실행
		vagrant halt:가상머신 종료
		vagrant destroy:가상머신 삭제
		vagrant ssh:가상머신에 ssh로 접속,만약 여러개일경우 이름을 뒤에 적어야함
		vagrant provision:설정변경시 그걸 적용(켜진상태에서 바꾸는거)
		
	루비작성할때 vb.customise 같은거 뒤에 뛰워야 매개변수로 인식안함(vb.customise[...]이러면안되고 vb.customise [...]이래야함)
	
	
3.쿠버네티스
1.쿠버네티스 이해
	쿠버네티스는 컨테이너 관리형 도구,주로 도커를 올려서 사용함
	보통은 관리형 쿠버네티스(구글아마존같은)를 사용함
	이책은 직접 테스트용도니 직접설치해서 베이그란트로 가상머신돌려서 설치해서 사용
	
	쿠버네티스 안에서 서치야 kubectl get 쓰면되고(여기서 뒤에 --all-namespaces붙이면 디폴트말고 나머지서치한다는거)
	
	마스터노드는 api서버,etcd,컨트롤러매니저,스케줄러로 구성되어있고,외부통신(우리가 인풋할거)로 kubectl이 있음
	워커노드는 kubelet,컨테이너런타임,파드로 구성되어있음,
	kubelet는 파드스펙을 받아서 컨테이너 런타임한테 전달하고,제대로생성됐는지를 모니터링함
	컨테이너런타임은 실제로 컨테이너를 생성(실행)시키는애
	파드는 컨테이너런타임이 생성시킨애
	
	그외에 네트워크플러그인,dns로 구성됨(이건선택사항)
	
	우리가 파드에 접속하면,kubeproxy로 일단 접근하게되는데,그럼 프록시가 서비스에 전달하고 서비스는 파드주소로 전달하는식
	
	쿠버네티스는 선언형이기때문에,우리는 이렇게 해주세요 하고 발주만내고,거기맞추는건 쿠버네티스가 알아서함
	그리고 쿠버네티스 안에서도,마스터노드는 생성감시만 하고,
	직접생성은 밑에단에서 계속 논리적객체가(디플로이먼트같은) 생성되면서 밑단으로 하청주면서 컨테이너런타임까지 내려가서 파드까지(컨테이너까지)생성되면 완성임
	
	즉,선언한 형태와 일치하도록,api서버(etcd)에 있는 값과 계속 비교하면서 거기에 맞게 맞춰나감
	
	그리고 kubectl은 실제로,마스터노드가 아닌 클러스터 외부에서도 클러스터 정보만 있으면 사용할수있음
	kubelet는,여기 문제가 생기면 파드가 정상적으로 관리되지않음,만약 삭제를 날려도 얘에 문제가 생기면 삭제명령이 전달이안됨(모든명령이 그럼 중간이 막히니)
	kubeproxy에 문제가 생기면,파드는 정상적으로 동작하는데,파드에 접속을 할수없음(서비스에 접근이안되니까)
	
2.쿠버네티스 사용법
	파드를 생성할떈 create,run,apply3개가 있는데,create와 run보단,yaml을 apply하는식으로 apply가 주로쓰임
	쿠버네티스는 선언형이라서,복구를 위해선 파일이 남아있는게 편하기때문(그리고 크리에이트는 파드는생성못하고,디플로이먼트를 생성해야됨)
	
	쿠버네티스의 오브젝트는 
		파드:쿠버네티스에서 관리하는최소단위,전체가 1개의아이피,1개이상의 컨테이너로 구성
		네임스페이스:쿠버네티스에서 오브젝트들을 관리하는 폴더같은형식,일반적으론 자기가 속한구역만 접근할수있고,필요하면 외부접근도 가능
		볼륨:컨테이너나 파드에서 사용하는 디스크용량,이거도 파드날아갈때 같이날아가는형태랑,계속 보존되는 형태 2개가있음
		서비스:파드들을 로드밸런싱하고,파드들이 어딜가도 상관없이 연결가능하게 테이블을 관리하는오브젝트,여기에 명령을보내면 얘가 적절한파드로 명령을보냄
		레플리카셋:파드들을 묶어서 지정된갯수만큼 실행시키는걸 보장하는 오브젝트
		디플로이먼트:레플리카셋에서 롤업데이트를 추가한것
	디플로이먼트도 보통 yaml로 선언하고 apply로 적용시킴,사실 거의모든걸 다 이렇게함
	
	파드는 만약에 문제가 생겨서 종료되면,자동으로 다른 노드나 같은노드에 재생성됨(디플로이먼트로 생성했을때)
	이때 삭제하려면 디플로이먼트 레플리카 수를 줄이거나,디플로이먼트를 삭제함
	
	만약 특정노드에 파드생성을 막으려면 cordon으로 막으면되고(테인트랑 똑같은데,테인트는 톨러레이션있는걸 통과시킨다는거만 다름,cordon이 일괄방어)
	특정노드의 파드를 전부 삭제하고 cordon을 씌우려면 drain을 하면됨
	드레인은 데몬셋을 지울수없으므로,뒤에 --ignore-daemonsets로 데몬셋을 무시하게해야함
	cordon을 취소하려면 uncordon하면됨
	
	파드를 업데이트할땐 apply로 하고,뒤에 --record를 붙이면 배보정보를 기록하는데,
	이걸가지고 롤백할수있음(언두)
	
	버전은 kubectl rollout history로 볼수있고,
	여기있는 숫자를 
		kubectl rollout undo 오브젝트 오브젝트명 --to-revision=버전
	으로 되돌릴수있음,그러면 현재오브젝트의 파드들이 전부삭제되고,그버전으로 다시생성됨
	
		


3.서비스
	서비스는 파드들에 통신하는 방식임
	직접 통신을 하면,파드들의 위치가 바뀔때마다 ip값이 바뀌므로,서비스를 거쳐서 서비스에있는 테이블로 파드에 접근함
	
	가장 간단한 방식은 노드포트임
	이건 모든 노드에 특정 포트번호를 매핑해서,
	이포트번호로 오는 모든 요청을 노드포트로 전달하고(서비스로전달)
	서비스가 부하가 덜걸린 파드(서비스셀렉터에 적힌 레이블을 가진 파드)로 전달하는식
	
	서비스의 타입을 정할떈,yaml에 type:NodePort 이런식으로 적으면됨
	
	그리고 간단히 서비스 만들떈,expose로 yaml안만들고 만들수도 있긴한데,보통 추천하진않는듯
	이땐 노드포트번호가 30000~32767사이에서 랜덤하게 지정됨
	
	
	인그레스는 노드포트가 여러개있을때,들어온 명령별로 뒤에 뭐붙었나를 확인하고,그거에따라 다르게 배분하는애임
	만약 naver.com이 들어오면 1번서비스,naver.com/ip가 들어오면 2번서비스 이런식임
	인그레스 접근순서:사용자요청-노드에전달-인그레스에전달-서비스에전달-파드에전달-사용자에게전달
	인그레스는 고유한 주소를 제공해 사용목적에 따른 다른응답을 제공하고,트래픽에 대한 l4/l7로드밸런싱과 보안인증서를 처리할수있음
	
	인그레스는 파드와 직접 통신할수 없어서,중간에 무조건 노드포트나 로드밸런서를 끼우고 통신해야함
	
	
	로드밸런서는,노드에 접근하지않고,자기가 직접 부하를 관리하면서 파드에 다이렉트로 명령을 보내는방식임
	사용자는 로드밸런서에만 접근하면,노드의 번호를 몰라도 원하는 파드에 접근할수있음
	로드밸런서는 보통 클라우드에선 그 서비스업체거를 쓰면되는데,온프레미스에선 metallb같은걸 깔아야함
	
	로드밸런서를 쓰면 서비스에 외부와 통신할수있는 ip가(external-ip)부여되고,그거로 외부와통신하면 자동으로 부하도 분산됨
	
	hpa는 자동으로 부하에따라서 파드수를 조절하는것(오토스케일러)
	hpa를 쓰려면 디플로이먼트들의 리소스필요량과 리미트가 설정되어있어야함(안써도 기본적으로 적어둬야하지만)
	그리고 이때 이 정보들을 수집할 메트릭서버가 있어야함(프로메테우스같은)
	
	그리고 hpa의 부하는,전체파드의 부하를 총합한후 나눈거기때문에,한두개가 넘는다고 바로 생성하진않음
	즉,부하 5를넘으면 분리한다면, 만약 29일경우 29/5 한뒤에 올림을 함
	
	


4.쿠버네티스 오브젝트
	데몬셋은 각 노드에 하나씩 배포해야할때 사용함
	보통 로그수집이나,네트워크 통신 이런걸쓸때 사용함
	데몬셋을 사용하면 모든 노드에 하나씩 배포해야한다는걸 신경안써도됨
	
	컨피그맵은 설정정보를 담아둔 오브젝트임
	보통 기본설정을 여기다가 적어두고 이걸 디플로이먼트같은 다른오브젝트에서 받아서 쓰는식으로 사용함
	유사한거로 시크릿이 있는데,이건 컨피그맵이랑 구조는똑같은데,좀더 민감한 정보를 넣어둠(비밀번호같은)
	
	pv와pvc는 퍼시스턴트볼륨과 퍼시스턴트볼륨클레임으로, 만약 파드에서 생성한 내용을 기록하고 보관하거나,모든파드가 같은값을 읽어야할때 사용함
	pv에는 정적과 동적이 있는데,정적은 미리 일정크기로 볼륨을 생성해 두는거고,동적은 pvc요청이 들어오면 그크기에맞춰 생성하는것
	이떄도,원래 있던 공간을 묶어두고,pv에 바운드시키는느낌
	
	pvc는 볼륨을 요청하는것,그리고 pvc에 적힌 스토리지는,동적볼륨이 아니라면 대충 레이블같은 그근처크기를 달라는느낌임
	동적볼륨일경우 요청하는순간에 볼륨을 생성해서 바운드함,이땐 StorageClass를 사용하면됨
	만약 같은pvc를 파드들에 동시에 사용하면,모든 파드들은 같은 볼륨을 보게됨
	이때는 디플로이먼트에서 볼륨마운트를 하고,볼륨에 pvc로 클레임이름을 연결해주면됨
	
	그리고 pv와 pvc를 안쓰고,한컴퓨터에서 처리할거면 그냥 디플로이먼트에서 볼륨을 마운트하고 그볼륨을 사용하는식으로도 쓸수있긴함
	
	스테이트풀셋은 파드를 순서대로 만들필요가 있을때(db같은)사용함
	이걸 사용하면 각 파드가 순서대로 생성되어서 고정된이름,볼륨,설정을 가질수있고,volumeClaimTemplates로 자동으로 pvc를 생성할수도있음
	이건 전번호가 러닝에 들어가야 다음거가 시작됨,삭제할때도 역순으로 마지막거부터 삭제하고 하나씩 삭제함
	
	스테이트풀셋은 효율적인 오브젝트는 아니므로,어쩔수없이 필요할때만 사용해야함(쿠버네티스는 상태없는 걍 막다뤄도되는걸 좋아함)
	
	
	
	
	
	
	
	
	
	
	
	
	
	
4.도커	
1.도커를 알아야하는이유
	사실 도커몰라도 대충 이미지에 추가만 할수있으면 쿠버네티스를 돌릴수있음,어지간한건 이미지가 다있음
	그래도 트러블슈팅하려면 알고는있어야함
	
	쿠버네티스와 도커와의 관계는,도커는 파드가 관리하는 컨테이너를 구성함
	파드는 쿠버네티스로부터 ip를 받아 컨테이너가 외부와 통신할수있게 해주고,
	컨테이너가 정상적으로 동작하는지 헬스체크하고,네트워크나 저장공간을 공유하게 만듬
	그래서 컨테이너들은 마치 하나의 호스트에 존재하는 것처럼 작동할수있음(그렇다고 기본적으로 얘들이 공용공간만 아니면 충돌하진않음,각컨테이너가 하나의 머신임)
	이런 컨테이너들을 논리적으로 관리하는게 쿠버네티스
	
	보통 이런 컨테이너들을 생성하고,관리할떈 도커를 사용함
	
	
2.도커로 컨테이너 다루기
	컨테이너와 컨테이너 이미지는,이미지는 그자체론 사용할수없고 이게 도커같은 cri로 불러들여야 사용할수있음
	즉 보조기억장치에서 주기억장치로 넘어가야 동작하는거랑비슷함
	그래서 컨테이너를 삭제할땐,컨테이너만 끄는게 아니라 이미지와 컨테이너를 둘다 삭제해야 용량이 온전히 복원됨
	
	컨테이너 이미지들은 레지스트리에 모여있음,디폴트값은 도커허브
		docker search 이미지명
	으로 검색할수있음
	
	검색한 이미지를 다운로드받으려면
		docker pull 이미지명
	으로 다운받을수있음
	
	이러면 레이어들을 받는데,이미지는 사실 그자체로 파일이 아닌,레이어들의 묶음을 나타낸 값임
	즉 이미지는 레이어들의 위치값을 묶어둔 차트라고 볼수있음
	그래서 이미지를 여러개받았을떄,레이어가 겹치면 그건 다운받지않고 있는걸 가져다가 써서 용량소모를 줄임
	
	그리고 이미지 뒤에 이미지명:latest처럼 태그를 붙일수있는데,이 태그로 자기가 무슨버전 받을건지를 정할수있고,
	기본값은 lasest인데 이건 무조건 버전을 명시해서 받아야함,아니면 yaml에 기록도 안되고 나중에 파드의 동일성도 깨짐(무조건 마지막거를 받으니까 저러면)
	
	
	컨테이너를 생성할땐
		docker run -d --restart always 이미지명
	이런식으로 하면되는데
	런은 생성하라는거고
	-d는 백그라운드로 구동하라는소리임
	--restart always는 컨테이너가 정상적으로 종료되지않았을때 재시작정책에 관한거임,always는 비정상종료시 재시작,도커시작시 시작함
	이거외에도 no는 재시작하지않음(기본값) unless-stopped는 재시작은 하는데 도커시작시엔 정지하지 않은거만 시작
	
	이러면 16진수 문자열이 나오는데 이게 컨테이너의 id값임
	
	컨테이너를 확인할땐
		docker ps
	로 전체를 확인할수있고
		docker ps -f id=id값
	으로 검색할수있음,이떄 id값은 like라서 앞자리만 적어도 검색함
	이거말고
		docker ps -f name=이미지명
	으로 이미지로 검색할수도있음
	
	이렇게 만들고나서 접근할땐 curl로 접근하면되는데
		curl 127.0.0.1
	로 접근하면 접근이 안되는데,그이유는 호스트네트워크랑 도커랑 연결이 안되어있기때문,그래서 로컬호스트의 80번포트엔 가는데 거긴아무것도없음
	그래서 컨테이너를 생성할때 80번포트를 호스트의 몇번포트에 바인딩할건지를 명시해줘야함
		docker run -d -p 8080:80 --name 이름 --restart always 이미지명
	이런식으로 -p 호스트포트:컨테이너포트 로 매핑을 해서 호스트포트로 받아야함
	
	
	컨테이너의 내부 파일을 변경할땐,간단히
		docker cp 호스트경로 컨테이너이름:컨테이너내부경로
	이런식으로 넣을수도 있긴하지만,간단히 한번넣고말거나 로그꺼내볼때쓰고
	
	여러번 사용해야 한다면
		호스트의 디렉토리와 컨테이너 내부를 연결하는 바인드 마운트
		호스트의 디렉토리를 볼륨으로 만들어서 볼륨을 컨테이너내부와 연결하는 볼륨
	을 사용함
	
	바인드 마운트는 디렉토리와 컨테이너 내부를 연결하는데,
	그러면 어느 한쪽에서 파일을 변경하면 그게 양쪽에 동시에 반영됨(사실 컨테이너내부는 전부 바로가기라고 보면됨)
	바인드마운트의 단점은,컨테이너 내부의 그위치에 있는 파일 전부가 삭제되고,디렉토리로 덮어쓰여짐
	
	볼륨은 디렉토리를 볼륨으로 만들어서 그걸 컨테이너에 연결하는데,
	이러면 다른 호스트에서도 볼륨지정을 하면 이 볼륨을 같이쓸수있음(다른컴퓨터에서도 사용가능)
	그리고 볼륨은 파일명이 중복되지않으면 사라지지않고,겹친거만 컨테이너 우선으로 덮어쓰여짐
	
	둘중에는 볼륨이 더 많이쓰이는듯
	
	바인드마운트의 사용방법은
		docker run -d -p 8080:80 -v 로컬경로:컨테이너경로 --restart always --name 이름 이미지명
	으로 바인드할수있음
	이러면 호스트에 있는거로 컨테이너경로에 있는폴더속을 포맷하고 호스트로 덮어씀
	
	
												(cp는 리눅스에서 카피명령어)
	
	볼륨을 사용할땐
		docker volume create 볼륨명
	하면 볼륨이 생성되는데,경로는 /var/lib/docker/volumes/볼륨명/_data로 자동으로 지정됨
	볼륨의 확인은 
		docker volume inspect 볼륨명
	으로 할수있음
	
	이걸 연결할땐 
		docker run -d -v 볼륨명:컨테이너경로 -p 호스트포트:컨테이너포트 --restart always --name 이름 이미지명
	으로 그냥 볼륨명만 써서 연결할수있음
	이러면 컨테이너와 볼륨의 파일들이 이름만 안겹치면 다 살아있음
	그리고 파일을 넣을땐 cp로 /var/lib/docker/volumes/볼륨명/_data에 넣어주면 자동으로 동기화됨
	
	사용중인 볼륨을 조회할땐
		docker volume ls
	볼륨을 삭제할떈
		docker volume rm
	
	
	
	사용하지 않는 컨테이너를 삭제할땐,컨테이너를 정지하고 컨테이너를 삭제하고 이미지를 삭제해야함
	
	컨테이너를 
		docker ps -f ancestor=이미지명
	으로 검색하고(ancestor는 생성할때의 이미지명)
	컨테이너를 정지할땐
		docker stop 컨테이너이름 or id값
	으로 정지할수있음
	만약 특정 이미지의 컨테이너를 전부정지하려면
		 docker stop $(docker ps -q -f ancestor=이미지명)
	으로 정지할수있음(-q는 quite로 검색된걸 id값만 출력)
	
	그리고 컨테이너를 재시작하려면
		docker start 컨테이너명 하면되고
	컨테이너를 삭제하려면 
		docker rm 컨테이너명 
	하면됨,이것도 위와같이 $를 쓸수있음
	
	그리고 이미지를 삭제할땐
		docker rmi 이미지명
	하거나
		docker rmi $(docker images -q nginx)
	로 특정이미지의 모든태그를 삭제할수도있음
	
	
	
	
3.컨테이너 이미지 만들기
	기본적으로 빌드는,컨테이너 내부에서 자동으로 빌드하고 그걸 사용하는식과,밖에서 빌드하고 넣어주는식이 있음
	기본은 밖에서 빌드하고 넣어주는건데
		일단 mvnw(메이븐)으로 빌드한다음에
		도커파일에 
		실행이미지를 임포트한다음
		빌드한걸 호스트에서 카피해가는 명령어를 넣고 
		이미지를 실행시킬때 그곳을 실행시키는식으로 명령어를 짜서 
		이미지를 만들면됨
	그리고 도커를 런해서 컨테이너를 실행시키고 포트를 부여하고 거기 접근하면됨
	
	이때 도커파일에 따라 해시값이 부여되므로,도커파일에 약간의 변화가있을떄만 해시값이 바뀜(image id)
	
	이때 실행이미지를 실행전용이미지로 사용하면 용량사용을 확 줄일수 있음
	자바의경우 openjdk가 컴파일랑 실행 둘다 들어간거고,distroless가 실행만 들어간것
	
	이때 그냥 openjdk를 사용하고,git에서 소스를 받아서 컨테이너내에서 컴파일 하는식으로도 할수있음
	이러면 따로 뭐 할필요없이 ci/cd가 되는것
	이러려면
		openjdk를 임포트하고
		run git clone로 소스코드를 받아오고
		workdir로 소스코드있는데로 이동한다음에
		run mvnw로 메이븐으로 컴파일하고
		실행할곳으로 파일을 옮기고
		이미지가 실행되면 그곳을 실행
	하면됨
	
	이건 문제가,원터치로 되긴하는데 용량이 그냥openjdk쓰는거보다 많이들어감,openjdk+컴파일중간파일들이 섞여있기떄문
	
	그래서 사용하는게 멀티 스테이지 빌드임,이건 도커 17.06부터 지원함
		이건 스테이지 2개를 만들고,
		생산전용스테이지에서 openjdk임포트를 한 다음에 컴파일하고 생산하고,
		생산파일을 실행용으로 옮기고
		실행용에서는 실행전용이미지를 임포트한다음
		실행용에서  실행할위치와 명령어를 정하고 
		명령이 들어오면 그곳을 실행
	하는식임
	이러면 댕글링이미지라는 생산전용이미지가 쌓이므로,dangling=true로 이미지명이 없는걸 주기적으로 지워주면됨
	
	
4.쿠버네티스에서 직접만든 컨테이너 사용
	쿠버네티스에서 직접만든 컨테이너를 사용할땐,모든 노드에 이미지를 넣어줄게 아니면,
	도커허브에 이미지를 올리거나,자기레지스트리에 이미지를 올려서
	그걸 받아야함
	클라우드같은경우 보통 이미지저장소가 있고 그거쓰면되고,
	개인환경일경우 로컬로 도커레지스트리같은거 쓰면됨
	
	도커레지스트리같은거의 경우,인증서를 가지고있어야하고
	컨테이너로 구동되기때문에,볼륨을 연결해서 컨테이너가 사라질때마다 내부저장소들이 사라지지않게해야함
	그렇게 설정하고나서 레지스트리에 자기 이미지를 등록할땐
	이미지의 이름을
		ip주소나 url:포트번호/이미지이름:태그
	이런식으로 한다음에
		docker push 이미지이름
	하면 ip주소의 포트번호로 이미지를 던지고 레지스트리가 그 이미지를 받아서 저장함
	
	그리고 쿠버네티스에선 이미지를 이미지이름(ip주소와 포트가 들어간이름)으로 받아서 디플로이먼트생성하면됨
	
	
	
	
	
	
5.젠킨스
1.컨테이너인프라환경에서 ci/cd
	ci는 소스코드를 올리면(깃같은데에) 그걸 문제없는지 유닛테스트같은거로 자동으로 확인해서 소스코드에 머지시키는거까지가 ci(지속적통합)
	cd는 소스코드가 머지되면 그걸 확인해서 자동으로 배포하는게 cd(지속적 배포)
	cd를 할때 각 상황에 맞는 설정을 cd에 미리 정의해서 실수를 줄이고 적용시간도 최소화할수있음
	
	실제로 할떈
		소스를 커밋하고 푸시하면 ci상태로 들어감
		그상태에서 앱이 자동빌드되고 테스트를 거쳐 신뢰할수있는지 확인하고
		테스트가 끝나면 신뢰할수있는 앱으로 간주하고 cd상태로 들어감
		그상태에선 앱을 이미지로 만들어서 디플로이먼트같은 오브젝트에 조건이 들어있는 파일을 합쳐서 배포함
		
	ci/cd툴에는 젠킨스랑 깃헙액션이 주로 쓰이는듯
	말고는 클라우드를 쓸땐 클라우드기반의 ci/cd도구(aws codebuild)같은게 쓰이는듯
	
	젠킨스로 ci/cd를 할땐,
		깃에 푸시하고
		젠킨스가 그걸 확인하고 
		코드를 빌드하고 레지스트리에 푸시해서 
		쿠버네티스에서 사용가능한 형태로 배포함
	이떄 작업내용을 아이템단위로 정의하고 조건에 따라 자동으로 수행해 실수를 줄임
	
	
2.젠킨스 설치를 위한 간편화 도구
	쿠스토마이즈를 사용하면,
	기본 야믈파일과 쿠스토마이즈야믈파일을 합쳐서,
	쿠스토마이즈파일이 기본야믈파일에 적용되게 해서 한 야믈파일로 상황에따라 다른 오브젝트를 생성할수있음
	
	헬름은 쿠스토마이즈에 차트(패키지)를 더했음
	얘는 그 파이썬pip처럼 동작해서,쉽게 다른사람이 정의해둔 오브젝트를 받을수있음
	그리고 종속성같은거대로 순서대로 설치도 가능함
	
	쿠스토마이즈는 기본 야믈파일에 있는값을 기본값으로 두고,쿠스토마이즈파일을 거기에 덮어씌운 야믈을 만드는식으로 작동함
	그리고 야믈 리소스를 여러개두면,같은파일에서 그걸 전부 합친파일로 만들어줌(헬름차트처럼)
	사용법은
		kustomize create 로 yaml을 생성하고
		거기에 원하는 설정을(이미지태그같은) 넣고
		kubectl build로 yaml을 뽑고
		kubectl apply로 적용
	하면됨
	
	쿠스토마이즈의 단점은,
	여러 변경점을 사용자가 직접 kustomization에 추가해야하고(수동적이고 선언적이지않음),
	그걸 최종적으로 필요한 매니패스트를 만들어 배포해야하기때문
	그리고 주소영역같은 건드리지 못하는 영역도 있음
	
	헬름은 이런 문제들을 해결함
	
	헬름은 쿠버네티스 전용 패키지 매니저임
	그래서 pip처럼
		패키지 검색
		패키지 관리(시스템에 설치,삭제,업그레이드,언두)
		패키지 의존성관리(의존성있는걸 같이설치하고 같이삭제할수있음)
		패키지 보안관리(해시값으로 해당패키지가 변조되었는지를 감시)
	를 할수있음
	
	헬름을쓰면 주소할당같은 값의 형태가 아닌것도 변경할수 있고
	여러 야믈을 요구조건별로 편집하고 변수를 넘기는식으로 만들수있고,
	이걸 공유할수있음(차트공유)
	헬름 기본저장소는 아티팩트허브로,다른 패키지매니저처럼 외부(다른사람의서버)에 있고,
	아티팩트허브는 설치할 패키지의 경로값만 가지고있음
	
	헬름은 생산자가 차트를 만들고(이때 설치할 yaml목록과 values에서 정의한 변수와 분기들이 있음)
	그걸 아티팩트허브에 올리고
	그걸 다운받아서 설치함
	
	실제로 하는건
		helm repo add로 로컬 레퍼지토리를 추가하고
		helm repo update로 레퍼지토리를 갱신하고
		helm install 이름 차트이름 --namespace=네임스페이스 --set 설정값
	으로 차트를 설치하고 설정값을주면됨
	
	이떄 설정값은 차트의 values.yaml에 있는 값을 바꿀수있음
	
	
3.젠킨스 설치 및 설정
	젠킨스도 클러스터 내부에서 돌아가기때문에 헬름으로 설치하면됨
	이때 젠킨스도 파드이기떄문에 pv를 마운트하지않으면 파드가 재시작될떄 데이터가 다사라져서 pv를 써야함
	
	젠킨스를 설치하면 서비스에 있는 ip로 접근하면됨
	그리고 젠킨스는 테인트와 톨러레이션으로 마스터노드에 설치됨
	
	젠킨스는 컨트롤러와 에이전트로 구성되어있음
	컨트롤러는 마스터노드에 설치된거고
	에이전트는 필요시에 생성되고 작업을 마치면 삭제됨
	그래서 에이전트 작업내용들은 삭제되기전에 컨트롤러에 저장되어야해서 항상 젠킨스 에이전트 서비스가 동작하고있음
	
	젠킨스의 컨트롤러 설정은 설정에서 시스템설정에 있음
	여기서 
		동시에 빌드실행할 실행기 갯수나
		노드 구분할 레이블지정하거나
		파드를 특정 레이블에만 설치하거나
		젠킨스로 만들어지는 작업의 이름을 설정하거나
		빌드 결과물같은 내용을 외부에 공개하는 ip를 설정하거나 할수있음
	
	젠킨스는 모든 기능을 플러그인으로 구현하게 설계되어있음
	그래서 필요한 플러그인을 받아서 cicd를 구현할수있음
	
	젠킨스 에이전트는 설정을 설정 노드관리에서 할수있음
	여기서 신규 에이전트 노드를 추가하거나 클라우드기반에서 에이전트를 설정하거나 할수있음
	
	에이전트 설정 수정은 configure clouds로 가서 pod templates로 수정을 하면됨
	에이전트도 파드로 실행되니까 파드템플릿을 건드리면되는거
	
	기본적으로 에이전트는 도커빌드를 위한 docker명령과 쿠버네티스 배포를 위한 kubectl이 존재하지않음
	그래서 호스트에 있는 도커와 kubectl을 볼륨연결해서 가져다쓰면됨
	이땐 볼륨추가를 해서 hostpath volume를 3개 만들고
		/usr/bin/kubectl
		/usr/bin/kubectl
		
		/bin/docker
		/bin/docker
		
		/var/run/docker.sock
		/var/run/docker.sock
	이렇게 3개를 넣어주면됨
	1번은 kubectl이고
	2번은 도커
	3번은 도커도 도커데몬과 통신해서 기존호스트의 소켓을 넣어준거
	
	그리고 젠킨스 에이전트 파드에서 사용할 서비스 어카운트와 사용자id 그룹id를 설정하면됨
	그리고 쿠버네티스에서 클러스터롤을 에이전트 서비스에 줘야지 에이전트가 api서버로 통신할수있음
	
	
4.젠킨스 ci/cd 
	젠킨스로 cicd를 할땐 아이템을 만들어야함
	이때 사용하는걸론 프리스타일이나 파이프라인을 쓰는데,
	일회성작업이면 프리스타일이고,주기적으로 해야하면 파이프라인을 씀
	
	프리스타일은
	프리스타일을 생성하고 소스코드관리에서 git으로 체크하고 url과 브랜치태그를 주면,거기서 그 브랜치를 긁어옴
	그리고 빌드에서 exec shell을 골라서 
		도커빌드하고 도커이미지 푸시하고(여기까지 ci) 
		디플로이먼트 배포하고 서비스노출(여기까지 cd)
	하면 끝임
	그리고 build now눌러서 빌드하면 됨
	만약 실패하면 빌드히스토리를 눌러서 콘솔 아웃풋을 누르면 원인을 알수있음
	
	파이프라인은 직접 명령어를 젠킨스에 치지않고,따로 파일로 만든다음 그걸 읽어와서 사용하는식임
	파이프라인엔 스크립트문법과 선언적문법이 있음
	일반적으론 스크립트로 변수만 받고 선언적문법으로 쓰는듯
	스크립트는 직접 프로그래밍하는느낌이고,선언적문법은 스트링으로 써서 그걸 쿠버네티스한테 그대로 주는느낌임
	
	파이프라인은
		깃허브같은데서 소스와 젠킨스파일(파이프라인파일)을 받아서
		그걸 해석해서 작업을 자동으로 수행
	
	파이프라인을 생성하고 설정에서 빌드트리거는,빌드가 일어나는 조건을 정할수있음
	특정 저장소를 10분에 한번씩 변화가 있을때만 빌드하거나, 깃헙같은데서 빌드시에 젠킨스에 알림을 주는식으로도 할수있음
	그리고 파이프라인에서 pipeline script from scm을 사용하면 특정 깃헙저장소에 특정 브런치에 특정 파일을 지정해서 그걸 읽어서 실행함
	
	파이프라인 문법은
		pipeline{
			agent any //에이전트의 종류,any,label,docker,kubernetes등이 있음
			stages{ //stage를 모아둔것
				stage('스테이지명,이름붙이면됨'){ //실제 동작하는 한덩어리를 묶어둔것,이안에 스텝여러개가 모아져있음
					steps{ //실제 동작
						sh '''  //스트링으로 이걸 순서대로 실행
							git url: 'https://git주소' branch:'브랜치태그명'
						'''
					}
				}
				stage('도커빌드'){
					steps{
						sh '''
							docker build -t ip:port/이미지명   //이미지 빌드
							docker push ip:port/이미지명       //이미지 레지스트리에 푸시
						'''
					}
				}
				stage('쿠버네티스디플로이먼트 생성'){
					steps{
						sh '''
							kubectl create deploy 디플로이먼트이름 --image=이미지명
							kubectl expose deploy 디플로이먼트이름 --type=LoadBalancer --port=8080 --target-port=80 name=서비스이름
						'''
						
					}
				}
			}
		
		}
	이렇게
	파이프라인이라고 선언하고
	
	어떤 에이전트에서(그 레이블을 가지고있는 노드에 속한 에이전트에서)돌릴건지 확인하고
	(여기엔 레이블을 확인하는 label,노드의 이미지를 도커로 지정하는 docker,에이전트노드를 파드로 지정하는 kubernetes등이 있음)
	
	스테이지들을 묶고
	스테이지를 각기 만들고
	그안에 속한 스탭들을 넣는식
	
	이렇게 sh를 쓰는게 선언적인방식이고,스크립트는 대표적으로 블루그린배포같은걸 할때 사용함
	블루그린은 알다시피 새버전 디플로이먼트를 전부 만들고 한번에 거기로 넘어가는식
	이떄 지금빌드를 블루할건지 그린할건질 알아야하는데,이때 스크립트를 사용해서 판별함
	이땐 블루냐 그린이냐에 따라서 레이블을 다르게줘야하니까,agent를 kubernetes로 줘서 쿠스토마이즈 파드를 생성하고 거기서 돌림
		pipeline{
			agent{
				kubernetes{
				yaml '''
					쿠스토마이즈 파드 yaml
					...
					serviceagent:jenkins
				'''
				
				
				}
			stages {
				stage('깃 가져오기'){
					steps{
						깃가져오는내용
					}
					
				}
				stage('태그확인'){
					steps{
						script{  //이런식으로 스크립트를쓰면,반복문과 조건문,변수들을 쓸수있고 이걸 선언적에서 가져다쓸수있음
							if(env.BUILD_NUMBER.toInteger()%2==1){
								env.tag="blue"
							} else{
								env.tag='green'
							}
						}
					}
				}
				stage('디플로이먼트생성'){
					steps{
						container('kustomize'){  //쿠스토마이즈 컨테이너 내에서
							dir('deployment'){ 디플로이먼트를
								sh '''
									kubectl apply -f 컨피그맵.yaml
									kustomize create --resources ./디플로이먼트.yaml
									
									kustomize edit add label deploy:$tag -f //스크립트로 생성한 블루그린 레이블붙이기
									kustomize edit set namesuffix -- -$tag 
									kustomize edit set image 이미지명:$tag //이미지태그에 블루인지그린인지 적기
									kustomize build . | kubectl apply -f -
								'''
								
							
							}
						}
					}
				}
				stage('로드밸런서생성후 연결'){
					steps{
						...
						여기서 무한루프를 돌리면서 새로생성된 디플로이먼트의 레플리카와 원래있던 레플리카수가 같을때까지 루프돌리다 
						같아지면 연결을 바꿔준다음 원래디플로이먼트를 지우고  루프탈출
					}
				}
			}
		
			}
		}
	
	이런식으로 스크립트로 태그를 만든다음,그걸 가져다쓰는형식임,여기서 가져오는 빌드넘버는 젠킨스빌드넘버기때문에,무조건 순서대로나옴
	직접 적는게 아니라 자동화기떄문에,쿠스토마이즈를 사용하고, 걔가 파일을 덮어씌우는식으로 동작하게 만듬
	
	
	
5.젠킨스 플러그인으로 gitops
	젠킨스에서 플러그인을 추가해서,외부에 있는 클러스터,즉 여러 클러스터에 같이 배포를 할수있음
	이건 테스트환경과 상용환경을 같게 만들어주는거
	
	외부 클러스터에 접근하려면 외부클러스터의 kubeconfig를 받아서 거기로 배포해야함
	이때 사용하는게 kubernetes continuous deploy 플러그인임
	이거로 컨피그파일을 받아와서 거기로도 같이 배포를 할수잇음
	
	플러그인을 설치하고 젠킨스설정의 manage credntials로 kubeconfig에 대한 접근권한을 줘야함
	여기서 줘야할건 2갠데,마스터노드의 접근권한과 그안에서 kubeconfig의 접근권한임
	먼저 마스터노드에 접근권한을 주고,그 자격증명을 사용하는 kubeconfig의 접근권한을 주면됨
	
	그리고 파이프라인을 생성한뒤 빌드트리거에서 poll scm을 선택하고 
	크론잡식으로 */10 * * * * 을 주면 10분마다 확인해서 변경점이 있으면 빌드함
	그리고 밑에 파이프라인에 저장소와 브런치와 젠킨스파일패스를 주면됨
	
	이러면 10분마다 확인해서,변경점이 있으면 자동으로 ci/cd를 함
	
	그리고 이걸 알림으로 받을수도 있음
	보통 슬랙을 많이 사용하는듯
	순서는
		슬랙채널생성
		슬랙채널에 jenkins ci앱을 추가해 채널연동을 위한 토큰과 워크스페이스도메인주소를 확인함
		토큰을 젠킨스 자격증명에 등록함
		젠킨스에서 슬랙알림플러그인을 설치하고,설정에서 토큰과 도메인주소를 넣어서 연동을 함
		
	플러그인을 설치하면 젠킨스 설정 제일밑에 slack영역이 생기는데,거기에 워크스페이스랑 자격증명,채널이름을 넣으면됨
	그리고나서 젠킨스파일에 
		시작할때 stage로  slackSend(message:'디플로이 ${env.JOB_NAME} ${env.BUILD_NUMBER} Started')
		끝날때 stage로 slackSend(message:'디플로이 ${env.JOB_NAME} ${env.BUILD_NUMBER} end')
	2개 넣어주면됨
	
	그리고 여기서 변경사항도 같이 보고싶으면,last Changes플러그인을 설치해서 거기에 책처럼 publusher를 설정하고 그걸 불러오면됨
	별건아닌데 기니까 책보자
	
	
	
	



6.프로메테우스와 그라파나

1.컨테이너인프라환경 모니터링
	쿠버네티스에서 모니터링을 할땐,수집-통합-시각화 구조로 각기 다른 플러그인?파드?를 붙여야함
	보통 오픈소스는 한 프로그램이 2개이상의 일을 잘 하지않음,그래서 프로메테우스로 수집-통합을 하고 그라파나로 시각화를 함
	물론 관리형으로 하면,그동네의 모니터링도구를 쓰는게 제일합리적
	
	데이터수집은 보통 풀과 푸시가 있는데,보통은 데몬셋으로 각 노드에 수집용을 하나씩 퍼트려두고,걔들이 메트릭서버로 데이터를 푸쉬하는 형태를 취함
	그걸 시계열데이터베이스로 저장하고,쿼리로 불러오는것


2.프로메테우스로 데이터수집과 통합하기
	프로메테우스 서버는 3가지 역할이 있는데
		노드익스포터등 여러대상에서 공개된 메트릭을 수집해오는 수집기
		수집한 시계열메트릭데이터를 저장하는 데이터베이스
		저장된 데이터를 질의하거나 수집대상의 상태를 확인하는 ui
	가 있음
	
	노드익스포터는 노드의 시스템메트릭정보를 http로 공개함
	설치된 노드에서 특정파일을 읽어서 메트릭데이터로 변환하고 이걸 서버에 올리는거임
	
	쿠버스테이트 메트릭은 서버의 데이터를 수집한후 이걸 프로메테우스용으로 가공해서 공개함,즉 서버용 수집기
	
	얼럿매니저는 메트릭을 계속확인하다가 설정해둔 임계값이나 이벤트가 발생하면 알람을 보내줌
	
	프로메테우스도 헬름으로 pv/pvc만들고 설치하면됨
	프로메테우스의 서비스ip로 접근하면 프로메테우스 웹ui로 감
	
	거기서 그래프는
		쿼리입력
		쿼리한데이터 그래프로 변환
		쿼리한데이터 콘솔로 표시
	로 이루어져있음,여기서는 add graph로 창을 추가해서 쿼리를여러개날리고,그래프를 여러개띄워둘수있음
	
	얼럿은 특정이벤트때 신호날리는거고
	
	스테이터스는 현재 프로메테우스서버의 상태,프로메테우스의 규칙,프로메테우스가 수집해오는 대상의 상태(Targets),수집해온 대상에대한 정보요약등을 볼수있음
	
	프로메테우스는 수집대상을 자동으로 인식하고 필요한정보를 수집함
	이건 서비스 디스커버리때문인데,
		프로메테우스서버는 컨피그맵에 기록된 내용을 바탕으로 대상을 읽어서
		그 대상에게 메트릭을 가져오기위해 api서버에 정보를 요청하고
		그경로로 메트릭데이터를 수집함
	즉 api서버에 경로를 요청하고,그경로로 직접가서 데이터를 수집함

	여기서 데이터 수집대상은,컨피그맵에 정해진 대상만을 가져오는데,이건 컨피그맵이 조건식으로 되어있기때문,
	즉 새로운 디플로이먼트같은 오브젝트가 생기면 자동으로 이 사정권안으로 들어오는거
	
	익스포터로 수집할땐,자동적으로 이뤄지긴하지만 사전작업을 2개해야함
		api서버에 등록되어 경로를 알수있어야하고
		익스포터가 데이터를 프로메테우스타입으로 노출해야함
	즉 이건 배포된 디플로이먼트yaml의 어노테이션에,
	prometheus.io/port:포트번호 와 prometheus.io/scrape:'true'가 있어야함
	이러면 저 어노테이션이 있는걸 api서버가 따로 관리를 하고,일단 경로는 알수있게됨
	
	그리고 나면,컨테이너가 그 포트로 정보를 계속 줘야하는데,
	이건 직접 그런 컨테이너이미지를 만들수도 있지만 보통은 사이드카패턴으로 정보를 뿌리는 컨테이너이미지를 받아서 그거로 메트릭을 뿌림
	
	그리고 익스포터도 종류가 많아서,db용,스토리지용등 종류별로 다양하게 있음
	보통 가장 많이쓰이는건 노드익스포터와 쿠버스테이트메트릭
	
	노드익스포터는 노드의 상태값을 메트릭으로 추출하는데 특화되어있음
	얘는 노드의 /proc와 /sys에 있는값을 노출하는데,
	이걸 데몬셋으로 뿌려진 마운트노드익스포터가 메트릭으로 변환해서 노드익스포터한테 전달하고,이걸 수집함
	
	여기서 
	/proc는 리눅스에서 구동중인 프로세스의 정보를 파일 시스템 형태로 연결한 디렉토리임
	이안에는 현재 구동중인 프로세스들의 id가 디렉토리형태로 나타나고,해당 프로세스의 상태나 환경정보가 들어있음
	여기서 구동중인 프로세스의 정보나 상태,자원사용량들을 알수있음
	
	/sys는 저장장치,네트워크,입출력등 장치들을 시스템 형태로 연결한 디렉토리임
	이거로 전체 장치의 상태를 알수있음,즉 시스템정보를 알수있음
	
	이걸 모아서 메트릭형태로 바꾸고 이걸 /metrics로 넣으면,프로메테우스서버에서 이걸 수집해감
	
	쿠버 스테이트 메트릭은,쿠버네티스의 상태를 보여주는메트릭임
	얘는 쿠버네티스의 상태를 가지고와서,프로메테우스가 받아들일수 있는 메트릭형태로 변환하고 변환한 메트릭을 http서버를 통해 /metrics로 공개함
	근데 얘는 각 노드의 특정 디렉토리를 마운트하지않고,어짜피 api서버랑 같은위치에 있으니까 바로 접근해서 긁어서 메트릭화해서 저장함
	
	얘가 수집한건 앞에 kube가 붙어있음
	
	
3.promQL로 메트릭데이터 추출
	보통은 메트릭데이터를 바로쓰지않고,한번더 가공해서 추출함
	이떄 사용하는게 promQL임
	
	promql은
		메트릭이름{레이블명=레이블값}
	으로 이루어져있음
	
	여기서 메트릭이름은 현재 값의 상태나,수집대상등이고,레이블은 그 안에서의 조건임
	
	메트릭값의 종류엔
		카운터:누적된값을 표현함,이건 계속 쌓여가서 줄어들지않음,보통은 변화율을 사용해 오류나 이벤트가 급증하는구간을 파악할떄 사용함
		게이지:특정시점의 값을 표현할때 사용함,얘는 시점마다 증감이 다표시됨,보통 cpu온도나 메모리사용량등 현재가 중요할때 사용함
		서머리:전체중 백분위에서 현재 질의한 분위(99%를달라고했으면 99%)의 값을 리턴함,
			 이거도 레이블에 quantile='0.99'이런식으로 적혀있으니 저걸로검색
		히스토그램:얘는 쿼리를 보내면 그때부터 특정범위내의 값을 가지고 서머리를 매김,현재도되고 과거시간도됨 histogram_quantile()로 사용
	가 있음,보통 메트릭이름이 어떤단어로 끝나냐에 따라 추정할수있음
	total로 끝나면 카운터,bytes나 created로 끝나면 해당시점,또는 생성된값이니까 게이지임
	정확히 볼려면 curl로 조회할수있음
		curl -s 마스터노드ip:프로메테우스포트/metrics | nl | grep 메트릭이름 
	
	모든 메트릭데이터는 하나이상의 레이블을 가짐
	프로메테우스의 레이블은,주석이 아니라 메트릭데이터의 속성을 표현하는 유일한 방법이라서,제공할 모든 속성을 키:밸류로 전부 적어넣음
	그래서 여기서 선택해서 추출하는거임
	
	여기서도 =뿐만 아니라 다양하게 조건을 줄수있음
		==은 같은걸 보여줌
		!=은 다른걸 보여주고
		=~는 조건의 정규표현식에 맞는값을 보여줌(w.+는 w로 시작하는메트릭)
		!~는 조건의 정규표현식에 맞지않은값을 보여줌
	즉 정규표현식으로 표현할수있음
	
	예로,보통 디플로이먼트에 속한 파드들은 해시값때문에 계속 값이 변하니까
		kube_pod_container_status_restarts_total{pod=~"coredns.*"}
	이런식으로 coredns로 시작하는 메트릭명을 검색하고 뒤를 와카처리할수있음
	
	그리고 !~로 ip주소(숫자3개이하.숫자3개이하.숫자3개이하.숫자3개이하)가 포함한걸 표시안하는식으로 걸러낼수도 있음
	
	여기도 똑같이 비교연산자랑 논리연산자가 존재하고,
	산술연산이랑 집계연산(avg,sum같은 함수들)이 존재함
	
	논리연산엔 and or등이있고
		and는 양쪽 레이블값이 일치하면 왼쪽표시
		or은 왼쪽값이 없으면 오른쪽표시,있으면 왼쪽표시
	특이한건
		unless는 양쪽을 비교해서 오른쪽을 왼쪽이랑 겹치는걸 빼고 출력함
		
	보통
		sum(up{job='kubernetes-nodes'})==4 and avg(up{job='kubernetes-nodes'}) == 1
	은,만약 둘다 참이면 왼쪽값인 4를 반환함
	
	산술연산은 검색된 메트릭의값을 원하는형태로 바꿔줌
	보통 수치단위를 변경할때 사용함
	
	보통 바이트의경우 메트릭리턴값이 바이트니까
		node_memory_MemAvailable_bytes /1024/1024/1024
	이렇게하면 바이트를 기가바이트까지(킬로메가기가)올려서 표시해줌(나누기3번하면되니까)
	
	집계연산은 메트릭값을 종합해서 유용한형태로 변환함
	전부 더하거나(sum),평균(avg),그룹화(by),제외(widhout)등이 있음
	이거도 sql쿼리랑 똑같이쓰면됨
		avg(노드cpu idle시간 총합) by (kubernetes_nodes)
	를 하면 노드별로 cpu가 놀고있는 시간 총합이 리턴되는식
	
	
	메트릭데이터는 전부 시계열데이터임
	근데 그냥 서치하면 그냥 값만주고,시계열로 데이터를 추출해야하면 구간값을 입력해야함
		node_cpu_seconds_total[5m]
	이런식
	
	이런 구간이 있는 데이터타입을 레인지벡터라고 하고,여기서 특정시점(일반적으로 현재)에 대한값만을 가지는 타입을 인스턴트벡터라고 함
	즉,구간데이터타입이 레인지,값만있는게 인스턴트
	레인지타입은 리턴으로 시간도 같이표시되고,그 시간까지만 표시됨(5m이면 5분까지만 표시됨)
	즉 이때까지 썼던게 인스턴트고,레인지는 거기에 시간값조건과 값도 추가한거
	만약 범위정해서 그사이만 보고싶으면 레인지쿼리를 쓰면됨
	
	이걸가지고 특정 시간까지의 그래프를 그릴수있는데,
	게이지의 경우 그냥 그리면되지만 카운터는 그냥 선형함수처럼 그려지게됨
	이렇떈 rate(게이지메트릭)을 하면 변화율로 그래프를 그려줌
	
	이렇게 프로메테우스에는 메트릭을 가공하는 함수들이 있음
		abs는 절대값
		ceil은 올림
		floor은 내림
		round는 반올림
		predict_linear은 예측값
	변환함수는
		scalar은 스칼라변환
		vector은 벡터변환
		rate는 변화율
		irate는 순간변화율
	집계함수는
		avg_over_time(평균)
		sum_over_time(합계)
		count_over_time(계수)
	등이 있음
	
	가장 많이쓰이는건 rate,irate,predict_linear
	
	rate는 앞에서처럼 특정 범위에대해 0~1사이의 범위값으로 출력해줌
	그 딥러닝할때 분포그대로두고 정규화하던 그거임
	시작값-현재값한후에 그값을 현재 계산하는 시간에 맞춰 나눔
	
	irate는 rate와 비슷한데,얘는 시작종료가 아닌,현재값과 바로 직전값을 가지고 계산함,그래서 순간변화율임
	얘는 구간이 길어지면 의미가없어지고 rate쓰는게나음
	
	predict_linear는 선형회귀로 예측하는거임
		predict_linear(메트릭(레이블)[시간범위],60*60*1)  //60초 60분 x1=1시간
	이런식임
	메트릭을 지정하고,학습할 범위를 정하고,예측할 위치(여기선 3600초뒤)를 정하면 값이 리턴됨
	
	서머리는 백분률값이고 히스토그램은 자기가 정한 범위내의 백분률값인데
	여기서 히스토그램에 연산자를 추가해서 사용할수도 있음
		histogram_quantile(0.99,sum(rate(메트릭[5m])))
	이런식
	
	
	
4.그라파나로 모니터링시각화
	그라파나도 똑같이 헬름으로 설치하면됨
	얘도 영구적으로 저장해야하니까 pv/pvc연결시켜주고
	
	설정에서 데이터소스로 프로메테우스를 불러오고
	url에 쿠버네티스 프로메테우스의 도메인이름(그 prometheus.default.svc.cluster.local같은 그 쿠버네티스기본 dns이름)
	넣어주면됨
	
	그리고 대시보트추가할땐 +눌러서 추가하고,거기다 promql로 긁어서 표시하면됨
	
	만약 cpu사용률을 보고싶으면
		1- avg(rate(node_cpu_seconds_total{mode='idle'[5m]})) by (kubernetes_node)
	하면 1에서 cpu노는만큼을 빼서 cpu사용률이 나옴
	
	여기서 위에 대시보드명 바꿀수있고,받아오는데이터 범례이름도 바꿀수있음
	
	이런식으로 식을주고,그래프그리고 이름바꾸고 이게 다임
	
	한그래프에서 식2개를 같이그릴수도 있는데
	밑에 쿼리넣는데서 add query로 쿼리를 추가한다음,만약 0밑으로 안떨어지는거면 식 하나에 -1을 곱해서 밑쪽을 차지하게할수있음
	네트워크 송수신받는거 그래프에서 이렇게씀 예제는
	
		avg(rate(node_network_transmit_bytes_total[5m])) by (kubernetes_node) //송신
		avg(rate(node_network_receive_bytes_total[5m])) by (kubernetes_node) * -1  //수신
	이렇게 식2개를 한곳에서 처리해서 한눈에볼수도있음
	
	그리고 한 대시보드를 나눠쓸수도 있는데,
	만약 모든값이 같으면 구분을 할수가없으니까,
	식을 준다음 오른쪽패널의 시각화에서 그래프를 stat로 바꾸면 전부 나눠져서 막대그래프로 나옴
	
	여기서는,그래프,스탯,게이지(0~100이렇게 상방하방이 막혀있을때 게이지로 표시,원형),바게이지(게이지랑 같은데 바형),
	테이블(데이터 그대로표현),히트맵(그 겹치는거많으면 색 진하게하는거,산점도였나 그거),텍스트(내가 뭐적을수있음),로그(특정로그를 표시할수있음)
	등이 있음
	
	시각화에서 상태값 형태도 바꿀수있음,값에따라서 1을 ok 0을 ng 이런식으로 표시하는거
	
	그리고 오른쪽 상단에 아코디언을 누르면,만들었던 대시보드들을 한군데 몰아넣을수도있음
	
	기본적으로 노드시각화는 이렇게하고,파드시각화도 이거랑 같긴한데,파드는 여러 네임스페이스가 있으니까 원하는 네임스페이스만 확인할수도 있음
	그러려면 대시보드설정에서 변수를 추가하고(네임스페이스명같은걸 추가할수있음)나면 대시보드에서 선택상자가 있는데 그거누르면 그 변수를 적용해서 검색할수있음
	
	이때 promQL에서도 쓸수있는데,$변수명을 붙이면 사용할수있음
	메트릭식에 $Namespace를 사용하면 네임스페이스라는 변수를 사용하는거
	
	그리고 대시보드가 주기적으로 데이터를 수집하게하려면 오른쪽위의 새로고침에서 리프레시주기를 설정하면됨
	
	그리고 만든 대시보드를 공유할수도있고,다른사람이 만들어둔걸 받아다 쓸수도 있음,json으로 파일공유도 가능하고
	그라파나랩스에서 대시보드게시판에서 받아올수도 있음


5.견고한 모니터링
	젠킨스처럼 프로메테우스/그라파나에서도 알림을 슬렉에 던질수있음
	보통은 프로메테우스로 하는편
	슬랙에서 웹훅 앱을 추가하고
	프로메테우스에 웹훅을 헬름으로 설치함
	
	여기다 promql 표현식으로 경보식을 설정해서 true면 알람을 보내는식
	알람내용도 적을수있음
	
	그리고 이건 좀 느린데,왜냐면 노드가 나가리되면 보통 좀 기다렸다가 터미네이팅하는데,
	그 기다리는시간+만약 프로메테우스나 얼럿매니저가 거기있었으면 다시 복구되는시간까지 더해야해서 한 10분은 걸림
	
	저기에 주기설정도 할수있어서,문제가 해결될때까지 계속 알람을 보낼수도있음
	
	
	
	
	
	
	
	
	